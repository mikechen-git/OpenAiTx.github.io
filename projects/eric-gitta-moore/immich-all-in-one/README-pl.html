<!DOCTYPE html>
<html lang="pl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>immich-all-in-one - eric-gitta-moore/immich-all-in-one</title>
    <meta name="title" content="immich-all-in-one - eric-gitta-moore/immich-all-in-one">
    <meta name="description" content="eric-gitta-moore/immich-all-in-one - GitHub repository pl documentation and informationImmich + cn-clip + RapidOCR + InsightFace ~~Planuję przenieść się na ente-io/ente, ponieważ potrzebuję s3 do przechowywania zdjęć~~ Funkcjonalności ente są nada...">
    <meta name="keywords" content="eric-gitta-moore, immich-all-in-one, GitHub, repository, pl documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/eric-gitta-moore/immich-all-in-one/README-pl.html">
    <meta property="og:title" content="immich-all-in-one - eric-gitta-moore/immich-all-in-one">
    <meta property="og:description" content="eric-gitta-moore/immich-all-in-one - GitHub repository pl documentation and information">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/eric-gitta-moore/immich-all-in-one" id="githubRepoLink" target="_blank">eric-gitta-moore/immich-all-in-one</a>
<h1 style="display: none;">Immich + cn-clip + RapidOCR + InsightFace ~~Planuję przenieść się na ente-io/ente, ponieważ potrzebuję s3 do przechowywania zdjęć~~ Funkcjonalności ente są nada...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <h1>Immich + cn-clip + RapidOCR + InsightFace</h1>
<div style="text-align: center"><p><a href="https://openaitx.github.io/view.html?user=eric-gitta-moore&project=immich-all-in-one&lang=en"><img src="https://img.shields.io/badge/EN-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=eric-gitta-moore&project=immich-all-in-one&lang=zh-CN"><img src="https://img.shields.io/badge/简中-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=eric-gitta-moore&project=immich-all-in-one&lang=zh-TW"><img src="https://img.shields.io/badge/繁中-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=eric-gitta-moore&project=immich-all-in-one&lang=ja"><img src="https://img.shields.io/badge/日本語-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=eric-gitta-moore&project=immich-all-in-one&lang=ko"><img src="https://img.shields.io/badge/한국어-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=eric-gitta-moore&project=immich-all-in-one&lang=th"><img src="https://img.shields.io/badge/ไทย-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=eric-gitta-moore&project=immich-all-in-one&lang=fr"><img src="https://img.shields.io/badge/Français-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=eric-gitta-moore&project=immich-all-in-one&lang=de"><img src="https://img.shields.io/badge/Deutsch-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=eric-gitta-moore&project=immich-all-in-one&lang=es"><img src="https://img.shields.io/badge/Español-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=eric-gitta-moore&project=immich-all-in-one&lang=it"><img src="https://img.shields.io/badge/Italiano-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=eric-gitta-moore&project=immich-all-in-one&lang=ru"><img src="https://img.shields.io/badge/Русский-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=eric-gitta-moore&project=immich-all-in-one&lang=pt"><img src="https://img.shields.io/badge/Português-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=eric-gitta-moore&project=immich-all-in-one&lang=nl"><img src="https://img.shields.io/badge/Nederlands-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=eric-gitta-moore&project=immich-all-in-one&lang=pl"><img src="https://img.shields.io/badge/Polski-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=eric-gitta-moore&project=immich-all-in-one&lang=ar"><img src="https://img.shields.io/badge/العربية-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=eric-gitta-moore&project=immich-all-in-one&lang=tr"><img src="https://img.shields.io/badge/Türkçe-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=eric-gitta-moore&project=immich-all-in-one&lang=vi"><img src="https://img.shields.io/badge/Tiếng Việt-white" alt="version"></a> </p></div>
<blockquote>
<p>~~Planuję przenieść się na ente-io/ente, ponieważ potrzebuję s3 do przechowywania zdjęć~~</p>
<p>Funkcjonalności ente są nadal zbyt ograniczone</p>
<p>Przełączono na użycie juicedata/juicefs do montowania s3</p>
</blockquote>
<h2>Opis projektu</h2>
<p>Projekt ten stanowi rozwiązanie rozszerzające możliwości AI systemu do zarządzania zdjęciami <a href="https://github.com/immich-app/immich">Immich</a>. Główne rozszerzenia natywnej funkcjonalności Immich realizowane są przez następujące komponenty:</p>
<ul>
<li><strong>inference-gateway</strong>: bramka napisana w języku Go, odpowiedzialna za inteligentne przekierowywanie zapytań ML z Immich</li>
<li><strong>mt-photos-ai</strong>: usługa AI oparta na Pythonie i FastAPI, integrująca modele RapidOCR i cn-clip</li>
<li>Rozszerzenie funkcji Immich, w tym wyszukiwanie tekstu OCR oraz ponowne przetwarzanie AI pojedynczych mediów, mieszane sortowanie OCR i CLIP na podstawie wektorów i wyników</li>
<li>Dodanie segmentera chińskiego <code>zhparser</code> do PostgreSQL</li>
</ul>
<h2>Główne funkcjonalności</h2>
<h3>1. Rozpoznawanie i wyszukiwanie tekstu OCR</h3>
<ul>
<li>Wykorzystanie RapidOCR do rozpoznawania tekstu na zdjęciach</li>
<li>Obsługa rozpoznawania tekstu mieszanego chińsko-angielskiego</li>
<li>Możliwość wyszukiwania zdjęć na podstawie rozpoznanej treści tekstowej</li>
</ul>
<h3>2. Przetwarzanie wektorów obrazu CLIP</h3>
<ul>
<li>Dokładniejsze dopasowanie obrazu i tekstu w języku chińskim w oparciu o model cn-clip</li>
<li>Obsługa wyszukiwania semantycznego, zwiększająca precyzję wyszukiwania</li>
</ul>
<h3>3. Ponowne przetwarzanie AI pojedynczego medium</h3>
<ul>
<li>Możliwość ponownego generowania danych OCR dla pojedynczego zdjęcia/wideo</li>
<li>Możliwość ponownego generowania wektorów CLIP dla pojedynczego zdjęcia/wideo</li>
<li>Ręczne odświeżanie danych w przypadku niedokładnych wyników rozpoznawania</li>
</ul>
<h2>Architektura systemu</h2>
<pre><code>┌─────────────┐      ┌──────────────────┐      ┌───────────────┐
│             │      │                  │      │               │
│   Immich    │─────▶│ inference-gateway│─────▶│  Immich ML    │
│   Server    │      │    (Go bramka)   │      │   Server      │
│             │      │                  │      │               │
└─────────────┘      └──────────────────┘      └───────────────┘
                              │
                              │ Zapytania OCR/CLIP
                              ▼
                     ┌──────────────────┐
                     │                  │
                     │   mt-photos-ai   │
                     │  (Usługa Python) │
                     │                  │
                     └──────────────────┘
</code></pre>
<h2>Szczegóły komponentów</h2>
<h3>inference-gateway</h3>
<p>Bramka napisana w Go, główne zadania:</p>
<ul>
<li>Odbieranie zapytań ML z Immich</li>
<li>Przekierowywanie zapytań OCR i CLIP do usługi mt-photos-ai na podstawie typu żądania</li>
<li>Przekierowywanie innych zapytań ML (np. rozpoznawanie twarzy) do natywnej usługi ML Immich</li>
<li>Obsługa autoryzacji i konwersji formatów danych</li>
</ul>
<h3>mt-photos-ai</h3>
<p>Usługa AI napisana w Pythonie (FastAPI), oferuje:</p>
<ul>
<li>API rozpoznawania tekstu OCR (w oparciu o RapidOCR)</li>
<li>API przetwarzania wektorów CLIP (w oparciu o cn-clip)</li>
<li>Obsługa akceleracji GPU</li>
</ul>
<h2>Instrukcja wdrożenia</h2>
<h3>Wymagania środowiskowe</h3>
<ul>
<li>Docker i Docker Compose</li>
<li>Karta NVIDIA GPU (opcjonalnie, zalecana dla przyspieszenia)</li>
<li>Wystarczająca ilość miejsca na dane</li>
</ul>
<h3>Konfiguracja</h3>
<ol>
<li><strong>Konfiguracja inference-gateway</strong></li>
</ol>
<p>Główne zmienne środowiskowe:</p>
<pre><code>IMMICH_API=http://localhost:3003  # Adres API Immich
MT_PHOTOS_API=http://localhost:8060  # Adres usługi mt-photos-ai
MT_PHOTOS_API_KEY=mt_photos_ai_extra  # Klucz API
PORT=8080  # Port nasłuchu bramki
</code></pre>
<ol start="2">
<li><strong>Konfiguracja mt-photos-ai</strong></li>
</ol>
<p>Główne zmienne środowiskowe:</p>
<pre><code>CLIP_MODEL=ViT-B-16  # Nazwa modelu CLIP
CLIP_DOWNLOAD_ROOT=./models/clip  # Ścieżka pobierania modelu
DEVICE=cuda  # Lub cpu, urządzenie do inferencji
HTTP_PORT=8060  # Port nasłuchu usługi
</code></pre>
<h3>Kroki wdrożenia</h3>
<ol>
<li>Sklonuj repozytorium:</li>
</ol>
<pre><code class="language-bash">git clone https://github.com/TwojaNazwaUzytkownika/immich-all-in-one.git
cd immich-all-in-one
</code></pre>
<ol start="2">
<li>Uruchom usługę:</li>
</ol>
<pre><code class="language-bash">docker-compose up -d
</code></pre>
<h2>Instrukcja użytkowania</h2>
<ol>
<li><strong>Konfiguracja Immich do korzystania z niestandardowej usługi ML</strong></li>
</ol>
<p>W pliku konfiguracyjnym Immich ustaw adres usługi ML na inference-gateway:</p>
<pre><code>MACHINE_LEARNING_URL=http://inference-gateway:8080
</code></pre>
<ol start="2">
<li><strong>Wyszukiwanie OCR</strong></li>
</ol>
<ul>
<li>W pasku wyszukiwania Immich użyj prefiksu <code>ocr:</code> aby wyszukiwać za pomocą OCR</li>
<li>Przykład: <code>ocr:发票</code> wyszuka zdjęcia, na których wykryto słowo &quot;发票&quot;</li>
</ul>
<ol start="3">
<li><strong>Ponowne przetwarzanie AI pojedynczego medium</strong></li>
</ol>
<ul>
<li>Na stronie szczegółów zdjęcia, kliknij menu opcji</li>
<li>Wybierz &quot;Ponownie wygeneruj dane OCR&quot; lub &quot;Ponownie wygeneruj wektor CLIP&quot;</li>
<li>System ponownie przetworzy dane AI dla tego zdjęcia</li>
</ul>
<h2>Przewodnik dla deweloperów</h2>
<h3>inference-gateway (Go)</h3>
<p>Kompilacja i uruchomienie:</p>
<pre><code class="language-bash">cd inference-gateway
go build
./inference-gateway
</code></pre>
<h3>mt-photos-ai (Python)</h3>
<p>Konfiguracja środowiska deweloperskiego:</p>
<pre><code class="language-bash">cd mt-photos-ai
pip install -r requirements.txt
python -m app.main
</code></pre>
<h2>Licencja</h2>
<p>Projekt udostępniany na licencji MIT.</p>
<h2>Podziękowania</h2>
<ul>
<li><a href="https://github.com/immich-app/immich">Immich</a> - Otwartoźródłowe rozwiązanie do backupu i hostowania zdjęć i wideo</li>
<li><a href="https://github.com/RapidAI/RapidOCR">RapidOCR</a> - Wieloplatformowa biblioteka OCR oparta na PaddleOCR</li>
<li><a href="https://github.com/OFA-Sys/Chinese-CLIP">cn-clip</a> - Chiński multimodalny model wstępnie wytrenowany do uczenia kontrastowego</li>
</ul>
<hr />
<p>Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx">Open Ai Tx</a> | Last indexed: 2025-06-09</p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Statcounter and other scripts can be added here -->
</body>
</html>