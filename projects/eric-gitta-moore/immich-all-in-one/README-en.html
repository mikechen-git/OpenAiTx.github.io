<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>immich-all-in-one - eric-gitta-moore/immich-all-in-one</title>
    <meta name="title" content="immich-all-in-one - eric-gitta-moore/immich-all-in-one">
    <meta name="description" content="eric-gitta-moore/immich-all-in-one - GitHub repository en documentation and informationImmich + cn-clip + RapidOCR + InsightFace ~~The plan is to migrate to ente-io/ente in the future, since I need s3 to store photos~~ Ente still lacks features Ch...">
    <meta name="keywords" content="eric-gitta-moore, immich-all-in-one, GitHub, repository, en documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/eric-gitta-moore/immich-all-in-one/README-en.html">
    <meta property="og:title" content="immich-all-in-one - eric-gitta-moore/immich-all-in-one">
    <meta property="og:description" content="eric-gitta-moore/immich-all-in-one - GitHub repository en documentation and information">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/eric-gitta-moore/immich-all-in-one" id="githubRepoLink" target="_blank">eric-gitta-moore/immich-all-in-one</a>
<h1 style="display: none;">Immich + cn-clip + RapidOCR + InsightFace ~~The plan is to migrate to ente-io/ente in the future, since I need s3 to store photos~~ Ente still lacks features Ch...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <h1>Immich + cn-clip + RapidOCR + InsightFace</h1>
<div style="text-align: center"><p><a href="https://openaitx.github.io/view.html?user=eric-gitta-moore&project=immich-all-in-one&lang=en"><img src="https://img.shields.io/badge/EN-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=eric-gitta-moore&project=immich-all-in-one&lang=zh-CN"><img src="https://img.shields.io/badge/简中-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=eric-gitta-moore&project=immich-all-in-one&lang=zh-TW"><img src="https://img.shields.io/badge/繁中-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=eric-gitta-moore&project=immich-all-in-one&lang=ja"><img src="https://img.shields.io/badge/日本語-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=eric-gitta-moore&project=immich-all-in-one&lang=ko"><img src="https://img.shields.io/badge/한국어-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=eric-gitta-moore&project=immich-all-in-one&lang=th"><img src="https://img.shields.io/badge/ไทย-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=eric-gitta-moore&project=immich-all-in-one&lang=fr"><img src="https://img.shields.io/badge/Français-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=eric-gitta-moore&project=immich-all-in-one&lang=de"><img src="https://img.shields.io/badge/Deutsch-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=eric-gitta-moore&project=immich-all-in-one&lang=es"><img src="https://img.shields.io/badge/Español-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=eric-gitta-moore&project=immich-all-in-one&lang=it"><img src="https://img.shields.io/badge/Italiano-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=eric-gitta-moore&project=immich-all-in-one&lang=ru"><img src="https://img.shields.io/badge/Русский-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=eric-gitta-moore&project=immich-all-in-one&lang=pt"><img src="https://img.shields.io/badge/Português-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=eric-gitta-moore&project=immich-all-in-one&lang=nl"><img src="https://img.shields.io/badge/Nederlands-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=eric-gitta-moore&project=immich-all-in-one&lang=pl"><img src="https://img.shields.io/badge/Polski-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=eric-gitta-moore&project=immich-all-in-one&lang=ar"><img src="https://img.shields.io/badge/العربية-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=eric-gitta-moore&project=immich-all-in-one&lang=tr"><img src="https://img.shields.io/badge/Türkçe-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=eric-gitta-moore&project=immich-all-in-one&lang=vi"><img src="https://img.shields.io/badge/Tiếng Việt-white" alt="version"></a> </p></div>
<blockquote>
<p>~~The plan is to migrate to ente-io/ente in the future, since I need s3 to store photos~~</p>
<p>Ente still lacks features</p>
<p>Changed to use juicedata/juicefs to mount s3</p>
</blockquote>
<h2>Project Overview</h2>
<p>This project is an AI capability enhancement solution for the <a href="https://github.com/immich-app/immich">Immich</a> photo management system. It mainly extends Immich's native functions through the following components:</p>
<ul>
<li><strong>inference-gateway</strong>: A gateway service written in Go, responsible for intelligently routing Immich’s machine learning requests</li>
<li><strong>mt-photos-ai</strong>: An AI service based on Python and FastAPI, integrating RapidOCR and cn-clip models</li>
<li>Immich feature extensions, including OCR text recognition search, single media AI data reprocessing, OCR full-text vector and CLIP vector score hybrid ranking</li>
<li>Add zhparser Chinese word segmentation to PostgreSQL</li>
</ul>
<h2>Main Features</h2>
<h3>1. OCR Text Recognition and Search</h3>
<ul>
<li>Uses RapidOCR to recognize text in images</li>
<li>Supports Chinese-English mixed text recognition</li>
<li>Implements search functionality based on the text content in images</li>
</ul>
<h3>2. CLIP Image Vector Processing</h3>
<ul>
<li>Implements more accurate Chinese image-to-text matching based on the cn-clip model</li>
<li>Supports semantic search, improving search accuracy</li>
</ul>
<h3>3. Single Media AI Data Reprocessing</h3>
<ul>
<li>Supports regenerating OCR data for a single image/video</li>
<li>Supports regenerating CLIP vector data for a single image/video</li>
<li>Provides manual refresh capability for cases where recognition results are inaccurate</li>
</ul>
<h2>System Architecture</h2>
<pre><code>┌─────────────┐      ┌──────────────────┐      ┌───────────────┐
│             │      │                  │      │               │
│   Immich    │─────▶│ inference-gateway│─────▶│  Immich ML    │
│   Server    │      │    (Go Gateway)  │      │   Server      │
│             │      │                  │      │               │
└─────────────┘      └──────────────────┘      └───────────────┘
                              │
                              │ OCR/CLIP requests
                              ▼
                     ┌──────────────────┐
                     │                  │
                     │   mt-photos-ai   │
                     │  (Python Service)│
                     │                  │
                     └──────────────────┘
</code></pre>
<h2>Component Details</h2>
<h3>inference-gateway</h3>
<p>A gateway service written in Go, main responsibilities:</p>
<ul>
<li>Receives machine learning requests from Immich</li>
<li>Forwards OCR and CLIP requests to the mt-photos-ai service based on request type</li>
<li>Forwards other machine learning requests (such as face recognition) to Immich's native ML service</li>
<li>Handles authentication and data format conversion</li>
</ul>
<h3>mt-photos-ai</h3>
<p>An AI service written in Python and FastAPI, provides:</p>
<ul>
<li>OCR text recognition API (based on RapidOCR)</li>
<li>CLIP vector processing API (based on cn-clip)</li>
<li>Supports GPU acceleration</li>
</ul>
<h2>Deployment Instructions</h2>
<h3>Environment Requirements</h3>
<ul>
<li>Docker and Docker Compose</li>
<li>NVIDIA GPU (optional, but recommended for accelerated processing)</li>
<li>Sufficient storage space</li>
</ul>
<h3>Configuration Instructions</h3>
<ol>
<li><strong>inference-gateway Configuration</strong></li>
</ol>
<p>Main environment variables:</p>
<pre><code>IMMICH_API=http://localhost:3003  # Immich API address
MT_PHOTOS_API=http://localhost:8060  # mt-photos-ai service address
MT_PHOTOS_API_KEY=mt_photos_ai_extra  # API key
PORT=8080  # Gateway listen port
</code></pre>
<ol start="2">
<li><strong>mt-photos-ai Configuration</strong></li>
</ol>
<p>Main environment variables:</p>
<pre><code>CLIP_MODEL=ViT-B-16  # CLIP model name
CLIP_DOWNLOAD_ROOT=./models/clip  # Model download path
DEVICE=cuda  # Or cpu, inference device
HTTP_PORT=8060  # Service listen port
</code></pre>
<h3>Deployment Steps</h3>
<ol>
<li>Clone the repository:</li>
</ol>
<pre><code class="language-bash">git clone https://github.com/your-username/immich-all-in-one.git
cd immich-all-in-one
</code></pre>
<ol start="2">
<li>Start the services:</li>
</ol>
<pre><code class="language-bash">docker-compose up -d
</code></pre>
<h2>Usage Instructions</h2>
<ol>
<li><strong>Configure Immich to Use Custom ML Service</strong></li>
</ol>
<p>In Immich's configuration file, point the ML service address to the inference-gateway:</p>
<pre><code>MACHINE_LEARNING_URL=http://inference-gateway:8080
</code></pre>
<ol start="2">
<li><strong>Using OCR Search</strong></li>
</ol>
<ul>
<li>In the Immich search bar, use the <code>ocr:</code> prefix for OCR search</li>
<li>For example: <code>ocr:invoice</code> will search for photos containing the word &quot;invoice&quot; in the image</li>
</ul>
<ol start="3">
<li><strong>Single Media AI Data Reprocessing</strong></li>
</ol>
<ul>
<li>On the photo details page, click the menu options</li>
<li>Select &quot;Regenerate OCR Data&quot; or &quot;Regenerate CLIP Vector&quot;</li>
<li>The system will reprocess the AI data for that photo</li>
</ul>
<h2>Development Guide</h2>
<h3>inference-gateway (Go)</h3>
<p>Compile and run:</p>
<pre><code class="language-bash">cd inference-gateway
go build
./inference-gateway
</code></pre>
<h3>mt-photos-ai (Python)</h3>
<p>Set up development environment:</p>
<pre><code class="language-bash">cd mt-photos-ai
pip install -r requirements.txt
python -m app.main
</code></pre>
<h2>License</h2>
<p>This project is open source under the MIT License.</p>
<h2>Acknowledgements</h2>
<ul>
<li><a href="https://github.com/immich-app/immich">Immich</a> - Open-source self-hosted photo and video backup solution</li>
<li><a href="https://github.com/RapidAI/RapidOCR">RapidOCR</a> - Cross-platform OCR library based on PaddleOCR</li>
<li><a href="https://github.com/OFA-Sys/Chinese-CLIP">cn-clip</a> - Chinese multimodal contrastive learning pre-training model</li>
</ul>
<hr />
<p>Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx">Open Ai Tx</a> | Last indexed: 2025-06-09</p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Statcounter and other scripts can be added here -->
</body>
</html>