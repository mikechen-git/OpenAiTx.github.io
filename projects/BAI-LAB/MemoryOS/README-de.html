<!DOCTYPE html>
<html lang="de">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MemoryOS - BAI-LAB/MemoryOS de</title>
    <meta name="title" content="MemoryOS - BAI-LAB/MemoryOS de | MemoryOS 🎉 Wenn dir unser Projekt gefällt, gib uns bitte einen Stern ⭐ auf GitHub für die neuesten Updates. **MemoryOS** wurde entwickelt, um ein Speicherbetri...">
    <meta name="description" content="BAI-LAB/MemoryOS - GitHub repository de documentation and information | MemoryOS 🎉 Wenn dir unser Projekt gefällt, gib uns bitte einen Stern ⭐ auf GitHub für die neuesten Updates. **MemoryOS** wurde entwickelt, um ein Speicherbetri...">
    <meta name="keywords" content="BAI-LAB, MemoryOS, GitHub, repository, de documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/BAI-LAB/MemoryOS/README-de.html">
    <meta property="og:title" content="MemoryOS - BAI-LAB/MemoryOS de | MemoryOS 🎉 Wenn dir unser Projekt gefällt, gib uns bitte einen Stern ⭐ auf GitHub für die neuesten Updates. **MemoryOS** wurde entwickelt, um ein Speicherbetri...">
    <meta property="og:description" content="BAI-LAB/MemoryOS - GitHub repository de documentation and information | MemoryOS 🎉 Wenn dir unser Projekt gefällt, gib uns bitte einen Stern ⭐ auf GitHub für die neuesten Updates. **MemoryOS** wurde entwickelt, um ein Speicherbetri...">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/BAI-LAB/MemoryOS" id="githubRepoLink" target="_blank">BAI-LAB/MemoryOS</a>
<h1 style="display: none;">MemoryOS 🎉 Wenn dir unser Projekt gefällt, gib uns bitte einen Stern ⭐ auf GitHub für die neuesten Updates. **MemoryOS** wurde entwickelt, um ein Speicherbetri...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <h1>MemoryOS</h1>
<div align="center">
  <img src="https://raw.githubusercontent.com/BAI-LAB/MemoryOS/main/logo_1.png" alt="logo" width="400"/>
</div>
<p align="center">
  <a href="https://arxiv.org/abs/2506.06326">
    <img src="https://img.shields.io/badge/Arxiv-paper-red" alt="Mem0 Discord">
  </a>
  <a href="https://github.com/user-attachments/assets/d195e740-1249-4eb1-962a-2c0d99a38c39">
    <img src="https://img.shields.io/badge/Wechat-群二维码-green" alt="Mem0 PyPI - Downloads">
  </a>
  <a href="https://youtu.be/y9Igs0FnX_M" target="blank">
    <img src="https://img.shields.io/badge/Demo-Video-red" alt="Npm package">
  </a>
    <a href="https://www.apache.org/licenses/LICENSE-2.0" target="_blank">
    <img src="https://img.shields.io/badge/License-Apache_2.0-blue" alt="License: Apache 2.0">
  </a>
</p>
<h5 align="center"> 🎉 Wenn dir unser Projekt gefällt, gib uns bitte einen Stern ⭐ auf GitHub für die neuesten Updates.</h5>
**MemoryOS** wurde entwickelt, um ein Speicherbetriebssystem für personalisierte KI-Agenten bereitzustellen, das kohärentere, persönlichere und kontextbewusstere Interaktionen ermöglicht. Inspiriert von Speicherverwaltungsprinzipien aus Betriebssystemen, verfolgt es eine hierarchische Speicherarchitektur mit vier Kernmodulen: Speicherung, Aktualisierung, Abruf und Generierung, um eine umfassende und effiziente Speicherverwaltung zu erreichen. Im LoCoMo-Benchmark erreichte das Modell durchschnittliche Verbesserungen von **49,11%** und **46,18%** bei F1- und BLEU-1-Scores.
<h2>📣 Neueste Nachrichten</h2>
<ul>
<li><em><mark>[neu]</mark></em> 🔥  <strong>[2025-06-15]</strong>:🛠️ Open-Source-Release von <strong>MemoryOS-MCP</strong>! Jetzt auf Agenten-Clients konfigurierbar für nahtlose Integration und Anpassung. <a href="#memoryos_mcp-getting-started">👉 查看</a></li>
<li><strong>[2025-05-30]</strong>: Erste Version von <strong>MemoryOS</strong> veröffentlicht! Mit Kurzzeit-, Mittelzeit- und Langzeit-Persona-Speicher sowie automatisierter Aktualisierung von Nutzerprofil und Wissen.</li>
</ul>
<h2>Demo</h2>
<p><a href="https://youtu.be/y9Igs0FnX_M"><img src="https://img.youtube.com/vi/y9Igs0FnX_M/maxresdefault.jpg" alt="Watch the video" /></a></p>
<h2>Systemarchitektur</h2>
<p><img src="https://github.com/user-attachments/assets/09200494-03a9-4b7d-9ffa-ef646d9d51f0" alt="image" /></p>
<h2>Projektstruktur</h2>
<pre><code>memoryos/
├── __init__.py            # Initialisiert das MemoryOS-Paket
├── __pycache__/           # Python-Cache-Verzeichnis (automatisch generiert)
├── long_term.py           # Verwaltung des Langzeit-Persona-Speichers (Nutzerprofil, Wissen)
├── memoryos.py            # Hauptklasse für MemoryOS, koordiniert alle Komponenten
├── mid_term.py            # Verwaltung des Mittelzeitspeichers, Konsolidierung von Kurzzeitinteraktionen
├── prompts.py             # Enthält Prompts für LLM-Interaktionen (z.B. Zusammenfassung, Analyse)
├── retriever.py           # Ruft relevante Informationen aus allen Speicherebenen ab
├── short_term.py          # Verwaltung des Kurzzeitspeichers für aktuelle Interaktionen
├── updater.py             # Verarbeitet Speicheraktualisierungen, inkl. Übertragung von Informationen zwischen Ebenen
└── utils.py               # Hilfsfunktionen, die in der gesamten Bibliothek verwendet werden
</code></pre>
<h2>Funktionsweise</h2>
<ol>
<li><strong>Initialisierung:</strong> <code>Memoryos</code> wird mit Nutzer- und Assistenten-IDs, API-Schlüsseln, Daten-Speicherpfaden und verschiedenen Kapazitäts-/Schwellwerteinstellungen initialisiert. Es wird ein dedizierter Speicher für jeden Nutzer und Assistenten eingerichtet.</li>
<li><strong>Speichern von Erinnerungen:</strong> Nutzereingaben und Agentenantworten werden als QA-Paare hinzugefügt. Diese werden zunächst im Kurzzeitspeicher abgelegt.</li>
<li><strong>Verarbeitung von Kurzzeit- zu Mittelzeitspeicher:</strong> Wenn der Kurzzeitspeicher voll ist, verarbeitet das <code>Updater</code>-Modul diese Interaktionen, fasst sie zu sinnvollen Segmenten zusammen und speichert sie im Mittelzeitspeicher.</li>
<li><strong>Mittelzeitanalyse &amp; LPM-Updates:</strong> Mittelzeitspeichersegmente akkumulieren „Hitze“ basierend auf Faktoren wie Besuchshäufigkeit und Interaktionslänge. Wenn die Hitze eines Segments einen Schwellenwert überschreitet, wird dessen Inhalt analysiert:
<ul>
<li>Erkenntnisse zum Nutzerprofil werden extrahiert und zur Aktualisierung des Langzeit-Nutzerprofils verwendet.</li>
<li>Spezifische Nutzerfakten werden dem Langzeitwissen des Nutzers hinzugefügt.</li>
<li>Relevante Informationen für den Assistenten werden der Langzeit-Wissensbasis des Assistenten hinzugefügt.</li>
</ul>
</li>
<li><strong>Antwortgenerierung:</strong> Wenn eine Nutzeranfrage eingeht:
<ul>
<li>Das <code>Retriever</code>-Modul ruft relevanten Kontext aus der Kurzzeithistorie, Mittelzeitspeichersegmenten, dem Nutzerprofil &amp; Wissen sowie der Wissensbasis des Assistenten ab.</li>
<li>Dieser umfassende Kontext wird zusammen mit der Nutzeranfrage genutzt, um über ein LLM eine kohärente und fundierte Antwort zu generieren.</li>
</ul>
</li>
</ol>
<h2>MemoryOS_PYPI Schnellstart</h2>
<h3>Voraussetzungen</h3>
<ul>
<li>Python &gt;= 3.10</li>
<li>pip install -i https://pypi.org/simple/ MemoryOS-BaiJia</li>
</ul>
<h3>Installation</h3>
<pre><code class="language-bash">conda create -n MemoryOS python=3.10
conda activate MemoryOS
pip install -i https://pypi.org/simple/ MemoryOS-BaiJia
</code></pre>
<h3>Grundlegende Verwendung</h3>
<pre><code class="language-python">
import os
from memoryos import Memoryos

# --- Grundkonfiguration ---
USER_ID = &quot;demo_user&quot;
ASSISTANT_ID = &quot;demo_assistant&quot;
API_KEY = &quot;YOUR_OPENAI_API_KEY&quot;  # Ersetze durch deinen Schlüssel
BASE_URL = &quot;&quot;  # Optional: bei Nutzung eines eigenen OpenAI-Endpunkts
DATA_STORAGE_PATH = &quot;./simple_demo_data&quot;
LLM_MODEL = &quot;gpt-4o-mini&quot;

def simple_demo():
    print(&quot;MemoryOS Simple Demo&quot;)
    
    # 1. Initialisiere MemoryOS
    print(&quot;Initialisiere MemoryOS...&quot;)
    try:
        memo = Memoryos(
            user_id=USER_ID,
            openai_api_key=API_KEY,
            openai_base_url=BASE_URL,
            data_storage_path=DATA_STORAGE_PATH,
            llm_model=LLM_MODEL,
            assistant_id=ASSISTANT_ID,
            short_term_capacity=7,  
            mid_term_heat_threshold=5,  
            retrieval_queue_capacity=7,
            long_term_knowledge_capacity=100
        )
        print(&quot;MemoryOS erfolgreich initialisiert!\n&quot;)
    except Exception as e:
        print(f&quot;Fehler: {e}&quot;)
        return

    # 2. Füge einige Erinnerungen hinzu
    print(&quot;Füge einige Erinnerungen hinzu...&quot;)
    
    memo.add_memory(
        user_input=&quot;Hi! Ich bin Tom, ich arbeite als Data Scientist in San Francisco.&quot;,
        agent_response=&quot;Hallo Tom! Schön, dich kennenzulernen. Data Science ist ein spannendes Feld. Mit welchen Daten arbeitest du?&quot;
    )
     
    test_query = &quot;Was weißt du noch über meinen Beruf?&quot;
    print(f&quot;Benutzer: {test_query}&quot;)
    
    response = memo.get_response(
        query=test_query,
    )
    
    print(f&quot;Assistent: {response}&quot;)

if __name__ == &quot;__main__&quot;:
    simple_demo()
</code></pre>
<h2>MemoryOS-MCP Schnellstart</h2>
<h3>🔧 Kernfunktionen</h3>
<h4>1. <code>add_memory</code></h4>
<p>Speichert den Inhalt des Gesprächs zwischen Nutzer und KI-Assistent im Speichersystem, um einen persistenten Dialogverlauf und Kontextaufzeichnung zu ermöglichen.</p>
<h4>2. <code>retrieve_memory</code></h4>
<p>Ruft auf Basis einer Anfrage relevante historische Dialoge, Nutzerpräferenzen und Wissensinformationen aus dem Speichersystem ab, um dem KI-Assistenten zu helfen, die Bedürfnisse und den Hintergrund des Nutzers zu verstehen.</p>
<h4>3. <code>get_user_profile</code></h4>
<p>Erstellt ein Nutzerprofil aus der Analyse historischer Dialoge, einschließlich Persönlichkeitsmerkmalen, Interessenpräferenzen und relevantem Wissenshintergrund.</p>
<h3>1. Abhängigkeiten installieren</h3>
<pre><code class="language-bash">cd memoryos-mcp
pip install -r requirements.txt
</code></pre>
<h3>2. Konfiguration</h3>
<p>Bearbeite <code>config.json</code>：</p>
<pre><code class="language-json">{
  &quot;user_id&quot;: &quot;deine Nutzer-ID&quot;,
  &quot;openai_api_key&quot;: &quot;dein OpenAI API-Schlüssel&quot;,
  &quot;openai_base_url&quot;: &quot;https://api.openai.com/v1&quot;,
  &quot;data_storage_path&quot;: &quot;./memoryos_data&quot;,
  &quot;assistant_id&quot;: &quot;assistant_id&quot;,
  &quot;llm_model&quot;: &quot;gpt-4o-mini&quot;
}
</code></pre>
<h3>3. Server starten</h3>
<pre><code class="language-bash">python server_new.py --config config.json
</code></pre>
<h3>4. Testen</h3>
<pre><code class="language-bash">python test_comprehensive.py
</code></pre>
<h3>5. Konfiguration auf Cline und anderen Clients</h3>
<p>Kopiere die mcp.json-Datei und stelle sicher, dass der Dateipfad korrekt ist.</p>
<pre><code class="language-bash">command&quot;: &quot;/root/miniconda3/envs/memos/bin/python&quot;
# Dies sollte auf den Python-Interpreter deiner virtuellen Umgebung angepasst werden
</code></pre>
<h2>Beitrag leisten</h2>
<p>Beiträge sind willkommen! Bitte zögere nicht, Issues oder Pull Requests einzureichen.</p>
<h2>Zitieren</h2>
<p>Wenn du mehr Details lesen möchtest, klicke hier: <a href="https://arxiv.org/abs/2506.06326">Vollständigen Artikel lesen</a></p>
<p>Wenn du dieses Projekt nützlich findest, zitiere bitte unsere Arbeit:</p>
<pre><code class="language-bibtex">@misc{kang2025memoryosaiagent,
      title={Memory OS of AI Agent}, 
      author={Jiazheng Kang and Mingming Ji and Zhe Zhao and Ting Bai},
      year={2025},
      eprint={2506.06326},
## Kontakt

BAI AI ist eine von Frau Prof. Ting Bai an der Beijing University of Posts and Telecommunications geleitete Forschungsgruppe, die sich der Entwicklung eines emotional reichen und außergewöhnlich gedächtnisstarken Gehirns für Silizium-basierte Menschen widmet.&lt;br&gt;
Kooperation und Anregungen: baiting@bupt.edu.cn&lt;br&gt;
Folgen Sie gerne dem offiziellen WeChat-Kanal „BAI Agent“ und treten Sie der WeChat-Gruppe bei, um sich auszutauschen!  
&lt;div style=&quot;display: flex; justify-content: center; gap: 20px;&quot;&gt;
  &lt;img src=&quot;https://github.com/user-attachments/assets/42651f49-f1f7-444d-9455-718e13ed75e9&quot; alt=&quot;BAI Agent WeChat-Kanal&quot; width=&quot;250&quot;/&gt;
  &lt;img src=&quot;https://github.com/user-attachments/assets/6b15a873-9e9a-44ee-b0b3-64f488fbd5d8&quot; alt=&quot;WeChat-Gruppen-QR-Code&quot; width=&quot;300&quot;/&gt;
&lt;/div&gt;



---


Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-06-15


---
</code></pre>

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
</body>
</html>