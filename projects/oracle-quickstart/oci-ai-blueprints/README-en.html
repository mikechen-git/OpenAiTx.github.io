<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>oci-ai-blueprints - oracle-quickstart/oci-ai-blueprints</title>
    <meta name="title" content="oci-ai-blueprints - oracle-quickstart/oci-ai-blueprints">
    <meta name="description" content="oracle-quickstart/oci-ai-blueprints - GitHub repository en documentation and informationOCI AI Blueprints Deploy, scale, and monitor AI workloads with the OCI AI Blueprints platform, and reduce your GPU onboarding time from weeks to minutes. OCI AI...">
    <meta name="keywords" content="oracle-quickstart, oci-ai-blueprints, GitHub, repository, en documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/oracle-quickstart/oci-ai-blueprints/README-en.html">
    <meta property="og:title" content="oci-ai-blueprints - oracle-quickstart/oci-ai-blueprints">
    <meta property="og:description" content="oracle-quickstart/oci-ai-blueprints - GitHub repository en documentation and information">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/oracle-quickstart/oci-ai-blueprints" id="githubRepoLink" target="_blank">oracle-quickstart/oci-ai-blueprints</a>
<h1 style="display: none;">OCI AI Blueprints Deploy, scale, and monitor AI workloads with the OCI AI Blueprints platform, and reduce your GPU onboarding time from weeks to minutes. OCI AI...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <h1>OCI AI Blueprints</h1>
<p><strong>Deploy, scale, and monitor AI workloads with the OCI AI Blueprints platform, and reduce your GPU onboarding time from weeks to minutes.</strong></p>
<p>OCI AI Blueprints is a streamlined, no-code solution for deploying and managing Generative AI workloads on Kubernetes Engine (OKE). By providing opinionated hardware recommendations, pre-packaged software stacks, and out-of-the-box observability tooling, OCI AI Blueprints helps you get your AI applications running quickly and efficiently—without wrestling with the complexities of infrastructure decisions, software compatibility, and MLOps best practices.</p>
<p><a href="https://raw.githubusercontent.com/oracle-quickstart/oci-ai-blueprints/main/GETTING_STARTED_README.md"><img src="https://raw.githubusercontent.com/oracle-quickstart/oci-ai-blueprints/refs/heads/main/docs/images/install.svg" alt="Install OCI AI Blueprints" /></a></p>
<h2>Table of Contents</h2>
<p><strong>Getting Started</strong></p>
<ul>
<li><a href="https://raw.githubusercontent.com/oracle-quickstart/oci-ai-blueprints/main/GETTING_STARTED_README.md">Install AI Blueprints</a></li>
<li><a href="https://raw.githubusercontent.com/oracle-quickstart/oci-ai-blueprints/main/docs/usage_guide.md">Access AI Blueprints Portal and API</a></li>
</ul>
<p><strong>About OCI AI Blueprints</strong></p>
<ul>
<li><a href="https://raw.githubusercontent.com/oracle-quickstart/oci-ai-blueprints/main/docs/about.md">What is OCI AI Blueprints?</a></li>
<li><a href="https://raw.githubusercontent.com/oracle-quickstart/oci-ai-blueprints/main/docs/about.md">Why use OCI AI Blueprints?</a></li>
<li><a href="https://raw.githubusercontent.com/oracle-quickstart/oci-ai-blueprints/main/docs/about.md">Features</a></li>
<li><a href="#blueprints">List of Blueprints</a></li>
<li><a href="https://raw.githubusercontent.com/oracle-quickstart/oci-ai-blueprints/main/docs/about.md">FAQ</a></li>
<li><a href="https://github.com/oracle-quickstart/oci-ai-blueprints/blob/vkammari/doc_improvements/docs/about/README.md#frequently-asked-questions-faq">Support &amp; Contact</a></li>
</ul>
<p><strong>API Reference</strong></p>
<ul>
<li><a href="https://raw.githubusercontent.com/oracle-quickstart/oci-ai-blueprints/main/docs/api_documentation.md">API Reference Documentation</a></li>
</ul>
<p><strong>Additional Resources</strong></p>
<ul>
<li><a href="https://raw.githubusercontent.com/oracle-quickstart/oci-ai-blueprints/main/docs/custom_blueprints">Publish Custom Blueprints</a></li>
<li><a href="https://raw.githubusercontent.com/oracle-quickstart/oci-ai-blueprints/main/docs/installing_new_updates.md">Installing Updates</a></li>
<li><a href="https://raw.githubusercontent.com/oracle-quickstart/oci-ai-blueprints/main/docs/iam_policies.md">IAM Policies</a></li>
<li><a href="https://raw.githubusercontent.com/oracle-quickstart/oci-ai-blueprints/main/docs/about.md">Repository Contents</a></li>
<li><a href="https://raw.githubusercontent.com/oracle-quickstart/oci-ai-blueprints/main/docs/known_issues.md">Known Issues</a></li>
</ul>
<h2>Getting Started</h2>
<p>Install OCI AI Blueprints by clicking on the button below:</p>
<p><a href="https://raw.githubusercontent.com/oracle-quickstart/oci-ai-blueprints/main/GETTING_STARTED_README.md"><img src="https://raw.githubusercontent.com/oracle-quickstart/oci-ai-blueprints/refs/heads/main/docs/images/install.svg" alt="Install OCI AI Blueprints" /></a></p>
<h2>Blueprints</h2>
<p>Blueprints go beyond basic Terraform templates. Each blueprint:</p>
<ul>
<li>Offers validated hardware suggestions (e.g., optimal shapes, CPU/GPU configurations),</li>
<li>Includes end-to-end application stacks customized for different GenAI use cases, and</li>
<li>Comes with monitoring, logging, and auto-scaling configured out of the box.</li>
</ul>
<p>After you install OCI AI Blueprints to an OKE cluster in your tenancy, you can deploy these pre-built blueprints:</p>
<p>| Blueprint                                                                                     | Description                                                                                                                              |
| --------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------- |
| <a href="https://raw.githubusercontent.com/oracle-quickstart/oci-ai-blueprints/main/docs/sample_blueprints/llm_inference_with_vllm/README.md"><strong>LLM &amp; VLM Inference with vLLM</strong></a> | Deploy Llama 2/3/3.1 7B/8B models using NVIDIA GPU shapes and the vLLM inference engine with auto-scaling.                               |
| <a href="https://raw.githubusercontent.com/oracle-quickstart/oci-ai-blueprints/main/docs/sample_blueprints/lora-benchmarking"><strong>Fine-Tuning Benchmarking</strong></a>                    | Run MLCommons quantized Llama-2 70B LoRA finetuning on A100 for performance benchmarking.                                                |
| <a href="https://raw.githubusercontent.com/oracle-quickstart/oci-ai-blueprints/main/docs/sample_blueprints/lora-fine-tuning"><strong>LoRA Fine-Tuning</strong></a>                             | LoRA fine-tuning of custom or HuggingFace models using any dataset. Includes flexible hyperparameter tuning.                             |
| <a href="https://raw.githubusercontent.com/oracle-quickstart/oci-ai-blueprints/main/docs/sample_blueprints/gpu-health-check"><strong>Health Check</strong></a>                                 | Comprehensive evaluation of GPU performance to ensure optimal hardware readiness before initiating any intensive computational workload. |
| <a href="https://raw.githubusercontent.com/oracle-quickstart/oci-ai-blueprints/main/docs/sample_blueprints/cpu-inference"><strong>CPU Inference</strong></a>                                   | Leverage Ollama to test CPU-based inference with models like Mistral, Gemma, and more.                                                   |
| <a href="https://raw.githubusercontent.com/oracle-quickstart/oci-ai-blueprints/main/docs/sample_blueprints/multi-node-inference/"><strong>Multi-node Inference with RDMA and vLLM</strong></a> | Deploy Llama-405B sized LLMs across multiple nodes with RDMA using H100 nodes with vLLM and LeaderWorkerSet.                             |
| <a href="https://raw.githubusercontent.com/oracle-quickstart/oci-ai-blueprints/main/docs/sample_blueprints/auto_scaling/"><strong>Autoscaling Inference with vLLM</strong></a>                 | Serve LLMs with auto-scaling using KEDA, which scales to multiple GPUs and nodes using application metrics like inference latency.       |
| <a href="https://raw.githubusercontent.com/oracle-quickstart/oci-ai-blueprints/main/docs/sample_blueprints/mig_multi_instance_gpu/"><strong>LLM Inference with MIG</strong></a>                | Deploy LLMs to a fraction of a GPU with Nvidia’s multi-instance GPUs and serve them with vLLM.                                           |
| <a href="https://raw.githubusercontent.com/oracle-quickstart/oci-ai-blueprints/main/docs/sample_blueprints/teams"><strong>Job Queuing</strong></a>                                             | Take advantage of job queuing and enforce resource quotas and fair sharing between teams.                                                |</p>
<h2>Support &amp; Contact</h2>
<p>If you have any questions, issues, or feedback, contact <a href="mailto:vishnu.kammari@oracle.com">vishnu.kammari@oracle.com</a> or <a href="mailto:grant.neuman@oracle.com">grant.neuman@oracle.com</a>.</p>
<hr />
<p>Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx">Open Ai Tx</a> | Last indexed: 2025-06-07</p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
</body>
</html>