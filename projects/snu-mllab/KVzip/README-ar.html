<!DOCTYPE html><html lang="en"><head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>KVzip: ضغط ذاكرة KV للكاش مستقل عن الاستعلام مع إعادة بناء السياق - snu-mllab/KVzip</title>

    <!-- Primary Meta Tags -->
    <meta name="title" content="KVzip: ضغط ذاكرة KV للكاش مستقل عن الاستعلام مع إعادة بناء السياق - snu-mllab/KVzip">
    <meta name="description" content="Query-agnostic KV cache eviction: 3–4× reduction in memory and 2× decrease in latency (Qwen3/2.5, Gemma3, LLaMA3)">
    <meta name="keywords" content="snu-mllab, KVzip, GitHub, repository, documentation, Python">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">

    <!-- Open Graph -->
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/view.html?user=snu-mllab&amp;project=KVzip&amp;lang=ar">
    <meta property="og:title" content="KVzip: ضغط ذاكرة KV للكاش مستقل عن الاستعلام مع إعادة بناء السياق - snu-mllab/KVzip">
    <meta property="og:description" content="Query-agnostic KV cache eviction: 3–4× reduction in memory and 2× decrease in latency (Qwen3/2.5, Gemma3, LLaMA3)">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">

    <!-- Favicon -->
    <link rel="icon" type="image/jpeg" href="icon.jpg">
    <link rel="apple-touch-icon" href="icon.jpg">

    <!-- Marked.js for Markdown rendering -->
    <script type="text/javascript" async="" src="https://www.statcounter.com/counter/recorder.js"></script><script src="js/marked.min.js?v=20250613"></script>
    <!-- Highlight.js for code syntax highlighting -->
    <link rel="stylesheet" href="css/github.min.css?v=20250613">
    <script src="js/highlight.min.js?v=20250613"></script>
    <!-- Custom CSS -->
    <link rel="stylesheet" href="view.css?v=20250613">
    <style>
        /* Layout */
        body {
            display: flex;
            flex-direction: column;
            min-height: 100vh;
        }

        .main-container {
            margin: 0 auto;
            width: 100%;
            max-width: 980px;
            padding: 0 20px;
        }

        @media (max-width: 768px) {
            .main-container {
                padding: 0 15px;
            }
        }

        /* Image size restrictions */
        .markdown-body img {
            max-width: 100%;
            height: auto;
        }

        /* Existing styles */
        .header {
            text-align: center;
            margin-bottom: 30px;
            padding: 20px;
            background-color: #f6f8fa;
            border-bottom: 1px solid #e1e4e8;
            position: relative;
        }

        .back-button {
            position: absolute;
            left: 20px;
            top: 50%;
            transform: translateY(-50%);
            color: #0366d6;
            text-decoration: none;
            display: flex;
            align-items: center;
            font-size: 14px;
            padding: 5px 10px;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            background-color: #fff;
        }

        .back-button:hover {
            background-color: #f6f8fa;
            border-color: #0366d6;
        }

        .back-button::before {
            content: "←";
            margin-right: 5px;
            font-size: 16px;
        }

        .header .links {
            margin-top: 10px;
            font-size: 16px;
        }

        .header .links a {
            color: #0366d6;
            text-decoration: none;
            margin-left: 5px;
        }

        .header .links a:hover {
            text-decoration: underline;
        }
        
        /* Language badges styles */
        .language-badges {
            margin-top: 15px;
            text-align: center;
        }
        .language-badges a {
            display: inline-block;
            margin: 2px;
            text-decoration: none;
        }
        .language-badges img {
            height: 20px;
            border-radius: 3px;
        }
        .language-badges a:hover img {
            opacity: 0.8;
        }
    </style>
</head>

<body>
    <div class="header">
        <a href="javascript:history.back()" class="back-button">Back</a>
        <div class="links">
            GitHub Repository: <a href="https://github.com/snu-mllab/KVzip" id="githubRepoLink" target="_blank">snu-mllab/KVzip</a>
        </div>
        <div class="language-badges" id="languageBadges"><a href="https://openaitx.github.io/view.html?user=snu-mllab&amp;project=KVzip&amp;lang=en"><img src="https://img.shields.io/badge/EN-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=snu-mllab&amp;project=KVzip&amp;lang=zh-CN"><img src="https://img.shields.io/badge/简中-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=snu-mllab&amp;project=KVzip&amp;lang=zh-TW"><img src="https://img.shields.io/badge/繁中-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=snu-mllab&amp;project=KVzip&amp;lang=ja"><img src="https://img.shields.io/badge/日本語-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=snu-mllab&amp;project=KVzip&amp;lang=ko"><img src="https://img.shields.io/badge/한국어-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=snu-mllab&amp;project=KVzip&amp;lang=th"><img src="https://img.shields.io/badge/ไทย-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=snu-mllab&amp;project=KVzip&amp;lang=fr"><img src="https://img.shields.io/badge/Français-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=snu-mllab&amp;project=KVzip&amp;lang=de"><img src="https://img.shields.io/badge/Deutsch-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=snu-mllab&amp;project=KVzip&amp;lang=es"><img src="https://img.shields.io/badge/Español-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=snu-mllab&amp;project=KVzip&amp;lang=it"><img src="https://img.shields.io/badge/Italiano-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=snu-mllab&amp;project=KVzip&amp;lang=ru"><img src="https://img.shields.io/badge/Русский-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=snu-mllab&amp;project=KVzip&amp;lang=pt"><img src="https://img.shields.io/badge/Português-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=snu-mllab&amp;project=KVzip&amp;lang=nl"><img src="https://img.shields.io/badge/Nederlands-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=snu-mllab&amp;project=KVzip&amp;lang=pl"><img src="https://img.shields.io/badge/Polski-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=snu-mllab&amp;project=KVzip&amp;lang=ar"><img src="https://img.shields.io/badge/العربية-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=snu-mllab&amp;project=KVzip&amp;lang=tr"><img src="https://img.shields.io/badge/Türkçe-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=snu-mllab&amp;project=KVzip&amp;lang=vi"><img src="https://img.shields.io/badge/Tiếng Việt-white" alt="version"></a></div>
    </div>

    <div class="main-container">
        <div class="markdown-body" id="content"><h1>KVzip: ضغط ذاكرة KV للكاش مستقل عن الاستعلام مع إعادة بناء السياق</h1>
<p>[<a href="https://arxiv.org/abs/2505.23416">ورقة بحثية</a>] [<a href="https://janghyun1230.github.io/kvzip/">مدونة</a>] </p>
<img src="https://raw.githubusercontent.com/snu-mllab/KVzip/main/images/method.png" width="800">

<h2>ما الجديد؟</h2>
<ul>
<li>يقوم KVzip بضغط ذاكرة KV للكاش لدعم <strong>استعلامات مستقبلية متنوعة</strong>.</li>
<li>[معتمد على السياق] تحقيق <strong>تقليل بحجم ذاكرة KV بمقدار 3–4×</strong> و <strong>تقليل زمن فك التشفير بمقدار 2×</strong>، مع أدنى تدهور في الأداء.</li>
<li>[غير معتمد على السياق] تحسين ضغط KV على مستوى الرؤوس بأسلوب <a href="https://github.com/mit-han-lab/duo-attention">DuoAttention</a>، باستخدام فقط <strong>بضع تمريرات أمامية خلال دقيقة واحدة</strong> لتحسين درجات أهمية الرؤوس (أسرع 100 مرة).</li>
<li>تشغيل demo.py:</li>
</ul>
<img src="https://raw.githubusercontent.com/snu-mllab/KVzip/main/images/demo.png" width="800">


<h3>تقييم الأداء في إعداد مستقل عن الاستعلام</h3>
<ul>
<li>المهام: <a href="https://huggingface.co/datasets/rajpurkar/squad">SQuAD</a>، <a href="https://github.com/gkamradt/LLMTest_NeedleInAHaystack">NIAH</a>، <a href="https://github.com/microsoft/MInference/tree/main/scbench">SCBench</a>، <a href="https://huggingface.co/datasets/openai/gsm8k/viewer/main/train?row=7294">GSM8K</a>. </li>
<li>النموذج: <a href="https://huggingface.co/Qwen/Qwen2.5-7B-Instruct">Qwen2.5-7B-Instruct-1M</a></li>
</ul>
<img src="https://raw.githubusercontent.com/snu-mllab/KVzip/main/images/benchmark.png" width="800">


<h2>التثبيت</h2>
<p>استخدمنا CUDA 12.1 و Python 3.10</p>
<pre><code class="language-bash hljs"><span class="hljs-built_in">cd</span> KVzip
pip install -r requirements.txt
pip install flash-attn==2.7.4.post1 --no-build-isolation
make i
</code></pre>
<ul>
<li>لاستخدام التكميم <a href="https://github.com/mit-han-lab/omniserve">QServe</a>، يرجى اتباع <a href="https://github.com/snu-mllab/KVzip/tree/main/model/quant_model"><code>./model/quant_model</code></a>.</li>
</ul>
<h3>مجموعة البيانات</h3>
<ul>
<li>يرجى تحميل مجموعة بيانات SCBench المعالجة مسبقًا من <a href="https://drive.google.com/file/d/1cqoR6pxxFcjFqvPZkuAmF-fBSAlAbjbN/view?usp=share_link">Google Drive</a>.</li>
<li>إذا قمت بتحميل الملفات غير مضغوطة، فقط انقل مجلد scbench.</li>
</ul>
<pre><code class="language-bash hljs"><span class="hljs-built_in">mv</span> scbench.zip kvzip/data/
<span class="hljs-built_in">cd</span> kvzip/data
unzip scbench.zip  
</code></pre>
<h2>بداية سريعة</h2>
<pre><code class="language-python hljs"><span class="hljs-keyword">from</span> model <span class="hljs-keyword">import</span> ModelKVzip

model = ModelKVzip(<span class="hljs-string">"Qwen/Qwen2.5-7B-Instruct-1M"</span>)
context = <span class="hljs-string">"This is my basic profile. My name is Kim living in Seoul. My major is computer science."</span>
queries = [<span class="hljs-string">"What is my name?"</span>, <span class="hljs-string">"Do I live in Seoul?"</span>]

kv = model.prefill(context, load_score=<span class="hljs-literal">False</span>)  <span class="hljs-comment"># تعبئة ذاكرة KV + تقييم الأهمية</span>
kv.prune(ratio=<span class="hljs-number">0.3</span>)  <span class="hljs-comment"># نسبة الضغط، التخلص من 70% من KV</span>

<span class="hljs-keyword">for</span> q <span class="hljs-keyword">in</span> queries:
    query_ids = model.apply_template(q)
    output = model.generate(query_ids, kv=kv, update_cache=<span class="hljs-literal">False</span>)  <span class="hljs-comment"># استدلال فعال</span>
    <span class="hljs-built_in">print</span>(q, output)
</code></pre>
<ul>
<li>النماذج المدعومة مدرجة في <a href="https://github.com/snu-mllab/KVzip/blob/main/model/load.py"><code>model/load.py</code></a>، بما في ذلك <strong>LLaMA3، Qwen2.5/3، Gemma3</strong>.</li>
<li>ضبط <code>load_score=True</code> لإلغاء تحميل ضغط الذاكرة. هذا يتيح التخلص من KV مستقل عن السياق، مع تنازل في نسبة الضغط عند <code>ratio=0.6</code>.</li>
<li>بعد التوليد، يتم التخلص انتقائيًا من أزواج KV المرتبطة بالاستعلامات والرموز المولدة من الكاش للمعالجة اللاحقة. اضبط <code>update_cache=True</code> لتمكين الاستدلال متعدد الجولات، مع الاحتفاظ بسجلات التفاعل الكاملة طوال الاستدلال.</li>
</ul>
<h2>قياس الذاكرة ووقت الحوسبة</h2>
<h3>التخلص المعتمد على السياق</h3>
<pre><code class="language-bash hljs">python -B test.py -m [model_name] -d [data_name] --kv_type evict --ratio 0.3
</code></pre>
<ul>
<li>الكود أعلاه يقارن أيضًا بين المخرجات الناتجة باستخدام ذاكرة KV كاملة مقابل مضغوطة.</li>
<li>للاختبار السريع، استخدم <code>-d squad</code>. للاختبار في سياق طويل، استخدم <code>-d scbench_kv</code>.<ul>
<li>أسماء البيانات المتاحة: <a href="https://github.com/snu-mllab/KVzip/blob/main/data/load.py"><code>data/load.py</code></a>.</li>
<li>أسماء النماذج المتاحة: <a href="https://github.com/snu-mllab/KVzip/blob/main/model/load.py"><code>model/load.py</code></a>، مثل llama3.1-8b، qwen2.5-7b (أو Qwen/Qwen2.5-7B-Instruct-1M).</li>
</ul>
</li>
<li>قمنا بتكييف نواة CUDA من <a href="https://github.com/FFY0/AdaKV/tree/main">AdaKV</a>، تدعم تخصيص ميزانية غير متجانسة للرؤوس.<ul>
<li>حاليًا، لا يحتوي كودنا على نواة محسنة لـ Gemma3 التي تستخدم ذاكرة KV ثابتة، لذلك لا يحقق الكود كفاءة فعلية. ومع ذلك، يمكن تقييم أداء النموذج باستخدام الانتباه المخفض مع أخذ عينات KV (<code>--kv_type retain</code>).</li>
</ul>
</li>
</ul>
<h3>التخلص غير المعتمد على السياق (بدون تحميل ضغط وقت التشغيل)</h3>
<ul>
<li>استخدم العلامة <code>--level head</code> مع <code>--ratio 0.6</code> (موصى به).<ul>
<li>نقوم بإزالة جميع أزواج KV المرتبطة برأس معين مع الاحتفاظ بأزواج KV الخاصة بنظام المطالبة والاستعلام.</li>
<li>درجات الرؤوس المحسوبة مسبقًا متوفرة لـ LLaMA3.1-8B و Qwen2.5-7/14B في <code>./utils/head_score</code>.</li>
</ul>
</li>
<li>لحساب درجات الرؤوس لنماذج أخرى:<pre><code class="language-bash hljs">python -B test.py -m [model_name] -d scbench_qa_eng --save_head_score
</code></pre>
<ul>
<li>سيتم حفظ النتائج في <code>./utils/head_score</code>.</li>
<li>إذا كنت تستهدف مهمة ترميز، نوصي أيضًا بتشغيل الأمر مع <code>-d scbench_repoqa</code>. هذا يسمح للنموذج باستخدام درجات الرأس القصوى من اللغتين الطبيعية والبرمجية، مما يحسن الأداء.</li>
</ul>
</li>
<li>يمكن دمج هذه الدرجات بسهولة مع محرك الاستدلال المحسن لـ <a href="https://github.com/mit-han-lab/duo-attention">DuoAttention</a> عن طريق استبدال بيانات درجات الرأس الخاصة بهم ببياناتنا.</li>
</ul>
<h2>التقييم</h2>
<ul>
<li>لتوليد ردود النموذج مع نسب ضغط KV تتراوح من 0.1 إلى 1.0:<pre><code class="language-bash hljs">python -B eval.py -m [model_name] -d [data_name] --kv_type retain --num 100
</code></pre>
<ul>
<li>سيتم حفظ النتائج في <code>./results/[data_name]</code>.</li>
<li>مجموعات البيانات المدعومة مدرجة في <code>data/load.py</code>.</li>
</ul>
</li>
<li>لحساب مقاييس التقييم من النتائج المولدة:<pre><code class="language-bash hljs">python -B -m results.parse -m [model_name] -d [data_name]
</code></pre>
</li>
</ul>
<h2>التطبيق على نماذج جديدة</h2>
<p>لدمج KVzip مع نموذج جديد، ستحتاج إلى تحديث الملفات التالية:</p>
<ul>
<li><code>attention/attn.py</code><br>تعديل منطق تمرير الانتباه الأمامي حسب الحاجة. في بعض الحالات، قد يكون مطلوبًا تحديث <code>kvcache.py</code> و <code>score.py</code>.</li>
<li><code>model/monkeypatch.py</code><br>تنفيذ تصحيح القرد الخاص بالنموذج للدمج.</li>
<li><code>model/template.py</code><br>تعريف مطالبة نظام النموذج وقوالب تنسيق المحادثة.</li>
</ul>
<h2>الاقتباس</h2>
<pre><code class="language-bibtex">@article{kim2025kvzip,
        title={KVzip: Query-Agnostic KV Cache Compression with Context Reconstruction},
        author={Kim, Jang-Hyun and Kim, Jinuk and Kwon, Sangwoo and Lee, Jae W and Yun, Sangdoo and Song, Hyun Oh},
        journal={arXiv preprint arXiv:2505.23416},
        year={2025}
}
</code></pre>
<h2>الترخيص</h2>
<p>رخصة MIT</p>
<hr>
<p>Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx">Open Ai Tx</a> | Last indexed: 2025-06-11</p>
<hr>
</div>
    </div>

    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async=""></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
    <script src="view.js?v=20250613"></script>


</body></html>