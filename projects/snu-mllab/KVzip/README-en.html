<!DOCTYPE html><html lang="en"><head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>KVzip: Query-Agnostic KV Cache Compression with Context Reconstruction - snu-mllab/KVzip</title>

    <!-- Primary Meta Tags -->
    <meta name="title" content="KVzip: Query-Agnostic KV Cache Compression with Context Reconstruction - snu-mllab/KVzip">
    <meta name="description" content="snu-mllab/KVzip - GitHub repository documentation and information">
    <meta name="keywords" content="snu-mllab, KVzip, GitHub, repository, documentation, ">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">

    <!-- Open Graph -->
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/view.html?user=snu-mllab&amp;project=KVzip&amp;lang=en">
    <meta property="og:title" content="KVzip: Query-Agnostic KV Cache Compression with Context Reconstruction - snu-mllab/KVzip">
    <meta property="og:description" content="snu-mllab/KVzip - GitHub repository documentation and information">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">

    <!-- Favicon -->
    <link rel="icon" type="image/jpeg" href="icon.jpg">
    <link rel="apple-touch-icon" href="icon.jpg">

    <!-- Marked.js for Markdown rendering -->
    <script type="text/javascript" async="" src="https://www.statcounter.com/counter/recorder.js"></script><script src="js/marked.min.js?v=20250613"></script>
    <!-- Highlight.js for code syntax highlighting -->
    <link rel="stylesheet" href="css/github.min.css?v=20250613">
    <script src="js/highlight.min.js?v=20250613"></script>
    <!-- Custom CSS -->
    <link rel="stylesheet" href="view.css?v=20250613">
    <style>
        /* Layout */
        body {
            display: flex;
            flex-direction: column;
            min-height: 100vh;
        }

        .main-container {
            margin: 0 auto;
            width: 100%;
            max-width: 980px;
            padding: 0 20px;
        }

        @media (max-width: 768px) {
            .main-container {
                padding: 0 15px;
            }
        }

        /* Image size restrictions */
        .markdown-body img {
            max-width: 100%;
            height: auto;
        }

        /* Existing styles */
        .header {
            text-align: center;
            margin-bottom: 30px;
            padding: 20px;
            background-color: #f6f8fa;
            border-bottom: 1px solid #e1e4e8;
            position: relative;
        }

        .back-button {
            position: absolute;
            left: 20px;
            top: 50%;
            transform: translateY(-50%);
            color: #0366d6;
            text-decoration: none;
            display: flex;
            align-items: center;
            font-size: 14px;
            padding: 5px 10px;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            background-color: #fff;
        }

        .back-button:hover {
            background-color: #f6f8fa;
            border-color: #0366d6;
        }

        .back-button::before {
            content: "←";
            margin-right: 5px;
            font-size: 16px;
        }

        .header .links {
            margin-top: 10px;
            font-size: 16px;
        }

        .header .links a {
            color: #0366d6;
            text-decoration: none;
            margin-left: 5px;
        }

        .header .links a:hover {
            text-decoration: underline;
        }
        
        /* Language badges styles */
        .language-badges {
            margin-top: 15px;
            text-align: center;
        }
        .language-badges a {
            display: inline-block;
            margin: 2px;
            text-decoration: none;
        }
        .language-badges img {
            height: 20px;
            border-radius: 3px;
        }
        .language-badges a:hover img {
            opacity: 0.8;
        }
    </style>
</head>

<body>
    <div class="header">
        <a href="javascript:history.back()" class="back-button">Back</a>
        <div class="links">
            GitHub Repository: <a href="https://github.com/snu-mllab/KVzip" id="githubRepoLink" target="_blank">snu-mllab/KVzip</a>
        </div>
        <div class="language-badges" id="languageBadges"><a href="https://openaitx.github.io/view.html?user=snu-mllab&amp;project=KVzip&amp;lang=en"><img src="https://img.shields.io/badge/EN-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=snu-mllab&amp;project=KVzip&amp;lang=zh-CN"><img src="https://img.shields.io/badge/简中-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=snu-mllab&amp;project=KVzip&amp;lang=zh-TW"><img src="https://img.shields.io/badge/繁中-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=snu-mllab&amp;project=KVzip&amp;lang=ja"><img src="https://img.shields.io/badge/日本語-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=snu-mllab&amp;project=KVzip&amp;lang=ko"><img src="https://img.shields.io/badge/한국어-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=snu-mllab&amp;project=KVzip&amp;lang=th"><img src="https://img.shields.io/badge/ไทย-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=snu-mllab&amp;project=KVzip&amp;lang=fr"><img src="https://img.shields.io/badge/Français-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=snu-mllab&amp;project=KVzip&amp;lang=de"><img src="https://img.shields.io/badge/Deutsch-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=snu-mllab&amp;project=KVzip&amp;lang=es"><img src="https://img.shields.io/badge/Español-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=snu-mllab&amp;project=KVzip&amp;lang=it"><img src="https://img.shields.io/badge/Italiano-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=snu-mllab&amp;project=KVzip&amp;lang=ru"><img src="https://img.shields.io/badge/Русский-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=snu-mllab&amp;project=KVzip&amp;lang=pt"><img src="https://img.shields.io/badge/Português-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=snu-mllab&amp;project=KVzip&amp;lang=nl"><img src="https://img.shields.io/badge/Nederlands-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=snu-mllab&amp;project=KVzip&amp;lang=pl"><img src="https://img.shields.io/badge/Polski-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=snu-mllab&amp;project=KVzip&amp;lang=ar"><img src="https://img.shields.io/badge/العربية-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=snu-mllab&amp;project=KVzip&amp;lang=tr"><img src="https://img.shields.io/badge/Türkçe-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=snu-mllab&amp;project=KVzip&amp;lang=vi"><img src="https://img.shields.io/badge/Tiếng Việt-white" alt="version"></a></div>
    </div>

    <div class="main-container">
        <div class="markdown-body" id="content"><h1>KVzip: Query-Agnostic KV Cache Compression with Context Reconstruction</h1>
<p>[<a href="https://arxiv.org/abs/2505.23416">Paper</a>] [<a href="https://janghyun1230.github.io/kvzip/">Blog</a>] </p>
<img src="https://raw.githubusercontent.com/snu-mllab/KVzip/main/images/method.png" width="800">

<h2>What's New?</h2>
<ul>
<li>KVzip compresses the KV cache to support <strong>diverse future queries</strong>.</li>
<li>[Context-dependent] Achieve a <strong>3–4× reduction in KV cache size</strong> and a <strong>2× decrease in decoding latency</strong>, with minimal performance degradation.</li>
<li>[Context-independent] Enhance <a href="https://github.com/mit-han-lab/duo-attention">DuoAttention</a>-style head-level KV compression, using only <strong>a few forward passes within one minute</strong> for head-level importance-score optimization (100x faster).</li>
<li>Run demo.py:</li>
</ul>
<img src="https://raw.githubusercontent.com/snu-mllab/KVzip/main/images/demo.png" width="800">


<h3>Benchmarking on query-agnostic setting</h3>
<ul>
<li>Tasks: <a href="https://huggingface.co/datasets/rajpurkar/squad">SQuAD</a>, <a href="https://github.com/gkamradt/LLMTest_NeedleInAHaystack">NIAH</a>, <a href="https://github.com/microsoft/MInference/tree/main/scbench">SCBench</a>, <a href="https://huggingface.co/datasets/openai/gsm8k/viewer/main/train?row=7294">GSM8K</a>. </li>
<li>Model: <a href="https://huggingface.co/Qwen/Qwen2.5-7B-Instruct">Qwen2.5-7B-Instruct-1M</a></li>
</ul>
<img src="https://raw.githubusercontent.com/snu-mllab/KVzip/main/images/benchmark.png" width="800">


<h2>Installation</h2>
<p>We used CUDA 12.1 and Python 3.10</p>
<pre><code class="language-bash hljs"><span class="hljs-built_in">cd</span> KVzip
pip install -r requirements.txt
pip install flash-attn==2.7.4.post1 --no-build-isolation
make i
</code></pre>
<ul>
<li>To use <a href="https://github.com/mit-han-lab/omniserve">QServe</a> quantization, please follow <a href="https://github.com/snu-mllab/KVzip/tree/main/model/quant_model"><code>./model/quant_model</code></a>.</li>
</ul>
<h3>Dataset</h3>
<ul>
<li>Please download the preprocessed SCBench dataset from <a href="https://drive.google.com/file/d/1cqoR6pxxFcjFqvPZkuAmF-fBSAlAbjbN/view?usp=share_link">Google Drive</a>.</li>
<li>If you download the unzipped the files, simply move the scbench folder.</li>
</ul>
<pre><code class="language-bash hljs"><span class="hljs-built_in">mv</span> scbench.zip kvzip/data/
<span class="hljs-built_in">cd</span> kvzip/data
unzip scbench.zip  
</code></pre>
<h2>Quick Start</h2>
<pre><code class="language-python hljs"><span class="hljs-keyword">from</span> model <span class="hljs-keyword">import</span> ModelKVzip

model = ModelKVzip(<span class="hljs-string">"Qwen/Qwen2.5-7B-Instruct-1M"</span>)
context = <span class="hljs-string">"This is my basic profile. My name is Kim living in Seoul. My major is computer science."</span>
queries = [<span class="hljs-string">"What is my name?"</span>, <span class="hljs-string">"Do I live in Seoul?"</span>]

kv = model.prefill(context, load_score=<span class="hljs-literal">False</span>)  <span class="hljs-comment"># prefill KV cache + importance scoring</span>
kv.prune(ratio=<span class="hljs-number">0.3</span>)  <span class="hljs-comment"># compression ratio, evict 70% KV</span>

<span class="hljs-keyword">for</span> q <span class="hljs-keyword">in</span> queries:
    query_ids = model.apply_template(q)
    output = model.generate(query_ids, kv=kv, update_cache=<span class="hljs-literal">False</span>)  <span class="hljs-comment"># efficient inference</span>
    <span class="hljs-built_in">print</span>(q, output)
</code></pre>
<ul>
<li>Supported models are listed in <a href="https://github.com/snu-mllab/KVzip/blob/main/model/load.py"><code>model/load.py</code></a>, including <strong>LLaMA3, Qwen2.5/3, Gemma3</strong>.</li>
<li>Set <code>load_score=True</code> to eliminate compression overhead. This enables context-independent KV eviction, with a trade-off in compression ratio of <code>ratio=0.6</code>.</li>
<li>After generation, KV pairs corresponding to the queries and generated tokens are selectively evicted from the cache for further processing. Set <code>update_cache=True</code> to enable multi-turn inference, retaining full interaction histories throughout the inference.</li>
</ul>
<h2>Profiling Memory and Computation Time</h2>
<h3>Context-dependent eviction</h3>
<pre><code class="language-bash hljs">python -B test.py -m [model_name] -d [data_name] --kv_type evict --ratio 0.3
</code></pre>
<ul>
<li>The code above also compares outputs generated with full versus pruned KV caches.</li>
<li>To quick test, use <code>-d squad</code>. For long-context testing, use <code>-d scbench_kv</code>.<ul>
<li>Available data names: <a href="https://github.com/snu-mllab/KVzip/blob/main/data/load.py"><code>data/load.py</code></a>.</li>
<li>Available model names: <a href="https://github.com/snu-mllab/KVzip/blob/main/model/load.py"><code>model/load.py</code></a>, e.g., llama3.1-8b, qwen2.5-7b (or Qwen/Qwen2.5-7B-Instruct-1M).</li>
</ul>
</li>
<li>We adapt CUDA kernel from <a href="https://github.com/FFY0/AdaKV/tree/main">AdaKV</a>, supporting non-uniform head budget allocation.<ul>
<li>Currently, our code lacks an optimized kernel for Gemma3 which uses static KV cache, so the code does not yield actual efficiency gains. However, model performance can still be evaluated using reduced attention with KV subsampling (<code>--kv_type retain</code>).</li>
</ul>
</li>
</ul>
<h3>Context-independent eviction (no runtime compression overhead)</h3>
<ul>
<li>Use the <code>--level head</code> flag with <code>--ratio 0.6</code> (recommended).<ul>
<li>We remove all context KV pairs associated with a specific head while retaining system prompt and query KV pairs.</li>
<li>Precomputed head scores are available for LLaMA3.1-8B and Qwen2.5-7/14B in <code>./utils/head_score</code>.</li>
</ul>
</li>
<li>To compute head scores for other models:<pre><code class="language-bash hljs">python -B test.py -m [model_name] -d scbench_qa_eng --save_head_score
</code></pre>
<ul>
<li>Results will be saved in <code>./utils/head_score</code>.</li>
<li>If targeting a coding task, we recommend additionally running the command with <code>-d scbench_repoqa</code>. This allows the model to use the max head scores from both natural and coding languages, which improves performance.</li>
</ul>
</li>
<li>These scores can be seamlessly integrated with <a href="https://github.com/mit-han-lab/duo-attention">DuoAttention</a>'s optimized inference engine by replacing their head score data with ours.</li>
</ul>
<h2>Evaluation</h2>
<ul>
<li>To generate model responses with KV compression ratios ranging from 0.1 to 1.0:<pre><code class="language-bash hljs">python -B eval.py -m [model_name] -d [data_name] --kv_type retain --num 100
</code></pre>
<ul>
<li>Results will be saved in <code>./results/[data_name]</code>.</li>
<li>Supported datasets are listed in <code>data/load.py</code>.</li>
</ul>
</li>
<li>To compute evaluation metrics from generated results:<pre><code class="language-bash hljs">python -B -m results.parse -m [model_name] -d [data_name]
</code></pre>
</li>
</ul>
<h2>Applying to New Models</h2>
<p>To integrate KVzip for a new model, you will need to update the following files:</p>
<ul>
<li><code>attention/attn.py</code><br>Modify the attention forward pass logic as needed. In certain cases, updates to kvcache.py and score.py may also be required.</li>
<li><code>model/monkeypatch.py</code><br>Implement model-specific monkey patching for integration.</li>
<li><code>model/template.py</code><br>Define the model's system prompt and chat formatting templates.</li>
</ul>
<h2>Citation</h2>
<pre><code class="language-bibtex">@article{kim2025kvzip,
        title={KVzip: Query-Agnostic KV Cache Compression with Context Reconstruction},
        author={Kim, Jang-Hyun and Kim, Jinuk and Kwon, Sangwoo and Lee, Jae W and Yun, Sangdoo and Song, Hyun Oh},
        journal={arXiv preprint arXiv:2505.23416},
        year={2025}
}
</code></pre>
<h2>License</h2>
<p>MIT License</p>
<hr>
<p>Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx">Open Ai Tx</a> | Last indexed: 2025-06-11</p>
<hr>
</div>
    </div>

    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async=""></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
    <script src="view.js?v=20250613"></script>


</body></html>