<!DOCTYPE html>
<html lang="de">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>awsome-distributed-training - aws-samples/awsome-distributed-training de</title>
    <meta name="title" content="awsome-distributed-training - aws-samples/awsome-distributed-training de | ML Training Referenzarchitekturen &amp; Tests Warnung Wir führen derzeit eine umfassende Umstrukturierung dieses Repositories durch, insbesondere im Bereich der...">
    <meta name="description" content="aws-samples/awsome-distributed-training - GitHub repository de documentation and information | ML Training Referenzarchitekturen &amp; Tests Warnung Wir führen derzeit eine umfassende Umstrukturierung dieses Repositories durch, insbesondere im Bereich der...">
    <meta name="keywords" content="aws-samples, awsome-distributed-training, GitHub, repository, de documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/aws-samples/awsome-distributed-training/README-de.html">
    <meta property="og:title" content="awsome-distributed-training - aws-samples/awsome-distributed-training de | ML Training Referenzarchitekturen &amp; Tests Warnung Wir führen derzeit eine umfassende Umstrukturierung dieses Repositories durch, insbesondere im Bereich der...">
    <meta property="og:description" content="aws-samples/awsome-distributed-training - GitHub repository de documentation and information | ML Training Referenzarchitekturen &amp; Tests Warnung Wir führen derzeit eine umfassende Umstrukturierung dieses Repositories durch, insbesondere im Bereich der...">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/aws-samples/awsome-distributed-training" id="githubRepoLink" target="_blank">aws-samples/awsome-distributed-training</a>
<h1 style="display: none;">ML Training Referenzarchitekturen &amp; Tests Warnung Wir führen derzeit eine umfassende Umstrukturierung dieses Repositories durch, insbesondere im Bereich der...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <h1>ML Training Referenzarchitekturen &amp; Tests <!-- omit from toc --></h1>
<blockquote>
<p><strong>Warnung</strong>
Wir führen derzeit eine umfassende Umstrukturierung dieses Repositories durch, insbesondere im Bereich der Testfälle. Wenn Sie die vorherige Verzeichnisstruktur und veraltete Testfälle verwenden möchten, siehe bitte <a href="https://github.com/aws-samples/awsome-distributed-training/releases/tag/v1.1.0">v1.1.0</a>.</p>
</blockquote>
<p>Dieses Repository enthält Referenzarchitekturen und Testfälle für verteiltes Modelltraining mit <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-hyperpod.html">Amazon SageMaker Hyperpod</a>, <a href="https://docs.aws.amazon.com/parallelcluster/latest/ug/what-is-aws-parallelcluster.html">AWS ParallelCluster</a>, <a href="https://docs.aws.amazon.com/batch/latest/userguide/what-is-batch.html">AWS Batch</a> und <a href="https://docs.aws.amazon.com/eks/latest/userguide/getting-started-console.html">Amazon EKS</a>. Die Testfälle decken verschiedene Typen und Größen von Modellen sowie unterschiedliche Frameworks und parallele Optimierungen ab (Pytorch DDP/FSDP, MegatronLM, NemoMegatron...).</p>
<p>Die Hauptkomponenten dieses Verzeichnisses sind:</p>
<pre><code class="language-bash">reference-architectures/
|-- 1.architectures/               # CloudFormation-Vorlagen für Referenzarchitektur
|-- 2.ami_and_containers/          # Skripte zur Erstellung von AMIs und Container-Images
|-- 3.test_cases/                  # Referenz-Testfälle und/oder Benchmark-Skripte
|-- 4.validation_observability/    # Tools zur Leistungsüberwachung oder Fehlerbehebung
`-- ...
</code></pre>
<p><strong>HINWEIS</strong>: Die Architekturen sind so konzipiert, dass sie mit dem S3-Bucket und VPC funktionieren, die mit den Referenzvorlagen <code>1.architectures/0.s3/</code> und <code>1.architectures/1.vpc_network/</code> erstellt wurden. <em>Es wird dringend empfohlen, diese beiden Vorlagen <strong>vor</strong> der Bereitstellung einer der Referenzarchitekturen zu deployen.</em></p>
<h2>0. Workshops</h2>
<p>Sie können dem untenstehenden Workshop folgen, um Modelle auf AWS zu trainieren. Jeder enthält Beispiele für mehrere Testfälle sowie wichtige Informationen zum Betrieb eines Clusters für LLM-Training.</p>
<p>| Name                                                                           | Kommentare
| ------------------------------------------------------------------------------ | ------------------------------------------------------------------- |
| <a href="https://catalog.workshops.aws/sagemaker-hyperpod/en-US">Amazon SageMaker HyperPod</a>   | Workshop für SageMaker HyperPod, zeigt, wie man es bereitstellt und überwacht |
| <a href="https://catalog.workshops.aws/ml-on-aws-parallelcluster">AWS ParallelCluster</a> | Ähnlicher Workshop wie HyperPod, aber für ParallelCluster          |
| <a href="https://catalog.workshops.aws/sagemaker-hyperpod-eks">Amazon SageMaker HyperPod EKS</a>   | Workshop für SageMaker HyperPod EKS, zeigt, wie man es bereitstellt und überwacht |</p>
<h2>1. Architekturen</h2>
<p>Architekturen befinden sich in <code>1.architectures</code> und bestehen aus Dienst- und Hilfsarchitekturen.</p>
<p>| Name                                                               | Kategorie | Verwendung                                         |
| ------------------------------------------------------------------ | -------- | ------------------------------------------------- |
| <a href="https://raw.githubusercontent.com/aws-samples/awsome-distributed-training/main/1.architectures/0.s3"><code>0.s3</code></a>                                   | Speicher  | Erstellen eines S3-Buckets                         |
| <a href="https://raw.githubusercontent.com/aws-samples/awsome-distributed-training/main/1.architectures/1.vpc_network"><code>1.vpc_network</code></a>                 | Netzwerk  | Erstellen eines VPC mit Subnetzen und erforderlichen Ressourcen |
| <a href="https://raw.githubusercontent.com/aws-samples/awsome-distributed-training/main/1.architectures/2.aws-parallelcluster"><code>2.aws-parallelcluster</code></a> | Compute  | Clustervorlagen für GPU- und benutzerdefiniertes Silizium-Training |
| <a href="https://raw.githubusercontent.com/aws-samples/awsome-distributed-training/main/1.architectures/3.aws-batch"><code>3.aws-batch</code></a>                     | Compute  | AWS Batch Vorlage für verteiltes Training         |
| <a href="https://raw.githubusercontent.com/aws-samples/awsome-distributed-training/main/1.architectures/4.amazon-eks"><code>4.amazon-eks</code></a>                   | Compute  | Manifestdateien für Training mit Amazon EKS        |
| <a href="https://raw.githubusercontent.com/aws-samples/awsome-distributed-training/main/1.architectures/5.sagemaker-hyperpod"><code>5.sagemaker-hyperpod</code></a>   | Compute  | SageMaker HyperPod Vorlage für verteiltes Training|</p>
<p>Weitere werden folgen, Sie können gerne neue hinzufügen (z.B. Ray?). Sie finden auch <a href="https://raw.githubusercontent.com/aws-samples/awsome-distributed-training/main/1.architectures/efa-cheatsheet.md">Dokumentation</a> zu EFA und den empfohlenen Umgebungsvariablen.</p>
<h2>2. Benutzerdefinierte Amazon Machine Images</h2>
<p>Benutzerdefinierte Machine Images können mit <a href="www.packer.io">Packer</a> für AWS ParallelCluster, Amazon EKS und einfache EC2-Instanzen erstellt werden. Diese Images basieren auf Ansible-Rollen und Playbooks.</p>
<h2>3. Testfälle</h2>
<p>Testfälle sind nach Framework organisiert und decken verschiedene Szenarien des verteilten Trainings ab. Jeder Testfall enthält die notwendigen Skripte und Konfigurationen für verteilte Trainingsjobs.</p>
<h3>PyTorch Testfälle</h3>
<ul>
<li><a href="https://raw.githubusercontent.com/aws-samples/awsome-distributed-training/main/3.test_cases/pytorch/FSDP"><code>FSDP/</code></a> - Vollständig geshardete Data Parallel Trainingsbeispiele</li>
<li><a href="https://raw.githubusercontent.com/aws-samples/awsome-distributed-training/main/3.test_cases/pytorch/megatron-lm"><code>megatron-lm/</code></a> - Megatron-LM verteilte Trainingsbeispiele</li>
<li><a href="https://raw.githubusercontent.com/aws-samples/awsome-distributed-training/main/3.test_cases/pytorch/nemo-launcher"><code>nemo-launcher/</code></a> - NeMo Launcher Beispiele für verteiltes Training. Dieser Testfall ist nur für NeMo Version 1.0.</li>
<li><a href="https://raw.githubusercontent.com/aws-samples/awsome-distributed-training/main/3.test_cases/pytorch/nemo-run"><code>nemo-run/</code></a> - NeMo Framework verteilte Trainingsbeispiele. Dieser Testfall ist für NeMo Version 2.0+.</li>
<li><a href="https://raw.githubusercontent.com/aws-samples/awsome-distributed-training/main/3.test_cases/pytorch/neuronx-distributed"><code>neuronx-distributed/</code></a> - AWS Trainium verteilte Trainingsbeispiele</li>
<li><a href="https://raw.githubusercontent.com/aws-samples/awsome-distributed-training/main/3.test_cases/pytorch/mosaicml-composer"><code>mosaicml-composer/</code></a> - MosaicML Composer Beispiele</li>
<li><a href="https://raw.githubusercontent.com/aws-samples/awsome-distributed-training/main/3.test_cases/pytorch/picotron"><code>picotron/</code></a> - PicoTron verteilte Trainingsbeispiele</li>
<li><a href="https://raw.githubusercontent.com/aws-samples/awsome-distributed-training/main/3.test_cases/pytorch/torchtitan"><code>torchtitan/</code></a> - TorchTitan Beispiele</li>
<li><a href="https://raw.githubusercontent.com/aws-samples/awsome-distributed-training/main/3.test_cases/pytorch/cpu-ddp"><code>cpu-ddp/</code></a> - CPU-basierte Distributed Data Parallel Beispiele</li>
<li><a href="https://raw.githubusercontent.com/aws-samples/awsome-distributed-training/main/3.test_cases/pytorch/bionemo"><code>bionemo/</code></a> - BioNeMo verteilte Trainingsbeispiele</li>
</ul>
<h3>JAX Testfälle</h3>
<ul>
<li><a href="https://raw.githubusercontent.com/aws-samples/awsome-distributed-training/main/3.test_cases/jax"><code>jax/</code></a> - JAX-basierte verteilte Trainingsbeispiele mit PaxML</li>
</ul>
<p>Jeder Testfall enthält:</p>
<ul>
<li>Trainingsskripte und Konfigurationen</li>
<li>Container-Definitionen (wenn anwendbar)</li>
<li>Startskripte für verschiedene Clustertypen</li>
<li>Leistungsüberwachungs- und Validierungstools</li>
</ul>
<h2>4. Validierungsskripte</h2>
<p>Hilfsskripte und Micro-Benchmark-Beispiele sind unter <code>4.validation_scripts/</code> zu finden. Der EFA Prometheus Exporter befindet sich in diesem <a href="https://raw.githubusercontent.com/aws-samples/awsome-distributed-training/main/4.validation_and_observability/3.efa-node-exporter">Verzeichnis</a></p>
<p>| Name                                                                                    | Kommentare                                                      |
| --------------------------------------------------------------------------------------- | --------------------------------------------------------------- |
| <a href="https://raw.githubusercontent.com/aws-samples/awsome-distributed-training/main/4.validation_and_observability/1.pytorch-env-validation"><code>1.pytorch-env-validation</code></a> | Validiert Ihre PyTorch Umgebung                                 |
| <a href="https://raw.githubusercontent.com/aws-samples/awsome-distributed-training/main/4.validation_and_observability/3.efa-node-exporter"><code>3.efa-node-exporter</code></a>           | Node Exporter mit Amazon EFA Monitoring-Modulen                |
| <a href="https://raw.githubusercontent.com/aws-samples/awsome-distributed-training/main/4.validation_and_observability/4.prometheus-grafana"><code>4.prometheus-grafana</code></a>         | Bereitstellungs-Assets zur Überwachung von SageMaker Hyperpod Clustern |
| <a href="https://raw.githubusercontent.com/aws-samples/awsome-distributed-training/main/4.validation_and_observability/5.nsight"><code>5.nsight</code></a>                                 | Zeigt, wie Nvidia Nsight Systems ausgeführt wird, um Ihre Workloads zu profilieren |
| <a href="https://raw.githubusercontent.com/aws-samples/awsome-distributed-training/main/1.architectures/efa-versions.py"><code>efa-versions.py</code></a>                                  | Ermittelt die Versionen der Nvidia-Bibliotheken, Treiber und EFA-Treiber |</p>
<h2>5. CI</h2>
<p>Integrationstests sind in <a href="https://docs.pytest.org">pytest</a> geschrieben. Einfach ausführen:</p>
<pre><code class="language-bash">pytest .
</code></pre>
<p>Alternativ können Sie Tests ohne stdout-Capturing ausführen und alle Docker-Images sowie andere Artefakte behalten.</p>
<pre><code class="language-bash">pytest -s --keep-artifacts=t
</code></pre>
<h2>6. Beitragende</h2>
<p>Vielen Dank an alle Beitragenden für den Aufbau, die Überprüfung und das Testen.</p>
<p><a href="https://github.com/aws-samples/awsome-distributed-training/graphs/contributors"><img src="https://contrib.rocks/image?repo=aws-samples/awsome-distributed-training" alt="Beitragende" /></a></p>
<h2>7. Sternverlauf</h2>
<p><a href="https://star-history.com/#aws-samples/awsome-distributed-training&amp;Date"><img src="https://api.star-history.com/svg?repos=aws-samples/awsome-distributed-training&amp;type=Date" alt="Sternverlauf Diagramm" /></a></p>
<hr />
<p>Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx">Open Ai Tx</a> | Last indexed: 2025-06-11</p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
</body>
</html>