<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>awsome-distributed-training - aws-samples/awsome-distributed-training</title>
    <meta name="title" content="awsome-distributed-training - aws-samples/awsome-distributed-training">
    <meta name="description" content="aws-samples/awsome-distributed-training - GitHub repository fr documentation and informationArchitectures de référence &amp; tests pour l'entraînement ML Avertissement Nous procédons actuellement à une refonte majeure de ce dépôt, en particulier sur la section des cas de test. Si vous préférez utiliser l’ancienne structure de répertoires et les cas de test obsolètes, veuillez vous référer à v1.1.0. Ce dépôt contient des architectures de référence et des cas de test pour l'entraînement distribué de modèles avec Amazon SageMaker Hyperpod, AWS ParallelCluster, AWS Batch et Amazon EKS. Les cas de test couvrent différents types et tailles de modèles ainsi que différents frameworks et optimisations parallèles (Pytorch DDP/FSDP, MegatronLM, NemoMegatron...). Les composants principaux de ce répertoire sont : reference-architectures/ |-- 1.architectures/ # Templates CloudFormation pour architectures de référence |-- 2.ami_and_containers/ # Scripts pour créer des AMI et images conteneurs |-- 3.test_cases/ # Cas de test de référence et/ou scripts de benchmark |-- 4.validation_observability/ # Outils pour mesurer la performance ou dépanner `-- ......">
    <meta name="keywords" content="aws-samples, awsome-distributed-training, GitHub, repository, fr documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/aws-samples/awsome-distributed-training/README-fr.html">
    <meta property="og:title" content="awsome-distributed-training - aws-samples/awsome-distributed-training">
    <meta property="og:description" content="aws-samples/awsome-distributed-training - GitHub repository fr documentation and information">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/aws-samples/awsome-distributed-training" id="githubRepoLink" target="_blank">aws-samples/awsome-distributed-training</a>
<br>
<h1 style="display: none;">Architectures de référence &amp; tests pour l'entraînement ML Avertissement Nous procédons actuellement à une refonte majeure de ce dépôt, en particulier sur la section des cas de test. Si vous préférez utiliser l’ancienne structure de répertoires et les cas de test obsolètes, veuillez vous référer à v1.1.0. Ce dépôt contient des architectures de référence et des cas de test pour l'entraînement distribué de modèles avec Amazon SageMaker Hyperpod, AWS ParallelCluster, AWS Batch et Amazon EKS. Les cas de test couvrent différents types et tailles de modèles ainsi que différents frameworks et optimisations parallèles (Pytorch DDP/FSDP, MegatronLM, NemoMegatron...). Les composants principaux de ce répertoire sont : reference-architectures/ |-- 1.architectures/ # Templates CloudFormation pour architectures de référence |-- 2.ami_and_containers/ # Scripts pour créer des AMI et images conteneurs |-- 3.test_cases/ # Cas de test de référence et/ou scripts de benchmark |-- 4.validation_observability/ # Outils pour mesurer la performance ou dépanner `-- ......</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <h1>Architectures de référence &amp; tests pour l'entraînement ML <!-- omit from toc --></h1>
<blockquote>
<p><strong>Avertissement</strong><br />
Nous procédons actuellement à une refonte majeure de ce dépôt, en particulier sur la section des cas de test. Si vous préférez utiliser l’ancienne structure de répertoires et les cas de test obsolètes, veuillez vous référer à <a href="https://github.com/aws-samples/awsome-distributed-training/releases/tag/v1.1.0">v1.1.0</a>.</p>
</blockquote>
<p>Ce dépôt contient des architectures de référence et des cas de test pour l'entraînement distribué de modèles avec <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-hyperpod.html">Amazon SageMaker Hyperpod</a>, <a href="https://docs.aws.amazon.com/parallelcluster/latest/ug/what-is-aws-parallelcluster.html">AWS ParallelCluster</a>, <a href="https://docs.aws.amazon.com/batch/latest/userguide/what-is-batch.html">AWS Batch</a> et <a href="https://docs.aws.amazon.com/eks/latest/userguide/getting-started-console.html">Amazon EKS</a>. Les cas de test couvrent différents types et tailles de modèles ainsi que différents frameworks et optimisations parallèles (Pytorch DDP/FSDP, MegatronLM, NemoMegatron...).</p>
<p>Les composants principaux de ce répertoire sont :</p>
<pre><code class="language-bash">reference-architectures/
|-- 1.architectures/               # Templates CloudFormation pour architectures de référence
|-- 2.ami_and_containers/          # Scripts pour créer des AMI et images conteneurs
|-- 3.test_cases/                  # Cas de test de référence et/ou scripts de benchmark
|-- 4.validation_observability/    # Outils pour mesurer la performance ou dépanner
`-- ...
</code></pre>
<p><strong>NOTE</strong> : les architectures sont conçues pour fonctionner avec le bucket S3 et le VPC créés via les templates de référence <code>1.architectures/0.s3/</code> et <code>1.architectures/1.vpc_network/</code>. <em>Il est fortement recommandé de déployer ces deux templates <strong>avant</strong> de déployer toute architecture de référence.</em></p>
<h2>0. Ateliers</h2>
<p>Vous pouvez suivre les ateliers ci-dessous pour entraîner des modèles sur AWS. Chacun contient des exemples pour plusieurs cas de test ainsi que des conseils sur l’exploitation d’un cluster pour l’entraînement de LLM.</p>
<p>| Nom                                                                                  | Commentaires                                                      |
| ------------------------------------------------------------------------------------ | ---------------------------------------------------------------- |
| <a href="https://catalog.workshops.aws/sagemaker-hyperpod/en-US">Amazon SageMaker HyperPod</a>  | Atelier pour SageMaker HyperPod, montre comment le déployer et le surveiller |
| <a href="https://catalog.workshops.aws/ml-on-aws-parallelcluster">AWS ParallelCluster</a>       | Atelier similaire à HyperPod mais sur ParallelCluster            |
| <a href="https://catalog.workshops.aws/sagemaker-hyperpod-eks">Amazon SageMaker HyperPod EKS</a> | Atelier pour SageMaker HyperPod EKS, montre comment le déployer et le surveiller |</p>
<h2>1. Architectures</h2>
<p>Les architectures sont situées dans <code>1.architectures</code> et comprennent des utilitaires et des architectures liées aux services.</p>
<p>| Nom                                                                 | Catégorie | Usage                                               |
| ------------------------------------------------------------------ | -------- | --------------------------------------------------- |
| <a href="https://raw.githubusercontent.com/aws-samples/awsome-distributed-training/main/1.architectures/0.s3"><code>0.s3</code></a>                       | Stockage  | Créer un bucket S3                                 |
| <a href="https://raw.githubusercontent.com/aws-samples/awsome-distributed-training/main/1.architectures/1.vpc_network"><code>1.vpc_network</code></a>       | Réseau    | Créer un VPC avec sous-réseaux et ressources requises |
| <a href="https://raw.githubusercontent.com/aws-samples/awsome-distributed-training/main/1.architectures/2.aws-parallelcluster"><code>2.aws-parallelcluster</code></a> | Calcul    | Templates de cluster pour entraînement GPU &amp; silicium personnalisé |
| <a href="https://raw.githubusercontent.com/aws-samples/awsome-distributed-training/main/1.architectures/3.aws-batch"><code>3.aws-batch</code></a>           | Calcul    | Template AWS Batch pour entraînement distribué         |
| <a href="https://raw.githubusercontent.com/aws-samples/awsome-distributed-training/main/1.architectures/4.amazon-eks"><code>4.amazon-eks</code></a>           | Calcul    | Fichiers manifeste pour entraîner avec Amazon EKS     |
| <a href="https://raw.githubusercontent.com/aws-samples/awsome-distributed-training/main/1.architectures/5.sagemaker-hyperpod"><code>5.sagemaker-hyperpod</code></a> | Calcul    | Template SageMaker HyperPod pour entraînement distribué |</p>
<p>D’autres viendront, n’hésitez pas à en ajouter de nouveaux (ex. Ray ?). Vous trouverez aussi la <a href="https://raw.githubusercontent.com/aws-samples/awsome-distributed-training/main/1.architectures/efa-cheatsheet.md">documentation</a> pour EFA et les variables d’environnement recommandées.</p>
<h2>2. Images Amazon Machine personnalisées</h2>
<p>Des images machines personnalisées peuvent être construites avec <a href="www.packer.io">Packer</a> pour AWS ParallelCluster, Amazon EKS et EC2 simple. Ces images sont basées sur des rôles et playbooks Ansible.</p>
<h2>3. Cas de test</h2>
<p>Les cas de test sont organisés par framework et couvrent divers scénarios d'entraînement distribué. Chaque cas de test inclut les scripts et configurations nécessaires pour exécuter des jobs d'entraînement distribués.</p>
<h3>Cas de test PyTorch</h3>
<ul>
<li><a href="https://raw.githubusercontent.com/aws-samples/awsome-distributed-training/main/3.test_cases/pytorch/FSDP"><code>FSDP/</code></a> - Exemples d'entraînement Fully Sharded Data Parallel</li>
<li><a href="https://raw.githubusercontent.com/aws-samples/awsome-distributed-training/main/3.test_cases/pytorch/megatron-lm"><code>megatron-lm/</code></a> - Exemples d'entraînement distribué Megatron-LM</li>
<li><a href="https://raw.githubusercontent.com/aws-samples/awsome-distributed-training/main/3.test_cases/pytorch/nemo-launcher"><code>nemo-launcher/</code></a> - Exemples NeMo Launcher pour entraînement distribué. Cas de test pour NeMo version 1.0 uniquement.</li>
<li><a href="https://raw.githubusercontent.com/aws-samples/awsome-distributed-training/main/3.test_cases/pytorch/nemo-run"><code>nemo-run/</code></a> - Exemples d'entraînement distribué framework NeMo. Cas de test pour NeMo version 2.0+.</li>
<li><a href="https://raw.githubusercontent.com/aws-samples/awsome-distributed-training/main/3.test_cases/pytorch/neuronx-distributed"><code>neuronx-distributed/</code></a> - Exemples d'entraînement distribué AWS Trainium</li>
<li><a href="https://raw.githubusercontent.com/aws-samples/awsome-distributed-training/main/3.test_cases/pytorch/mosaicml-composer"><code>mosaicml-composer/</code></a> - Exemples MosaicML Composer</li>
<li><a href="https://raw.githubusercontent.com/aws-samples/awsome-distributed-training/main/3.test_cases/pytorch/picotron"><code>picotron/</code></a> - Exemples d'entraînement distribué PicoTron</li>
<li><a href="https://raw.githubusercontent.com/aws-samples/awsome-distributed-training/main/3.test_cases/pytorch/torchtitan"><code>torchtitan/</code></a> - Exemples TorchTitan</li>
<li><a href="https://raw.githubusercontent.com/aws-samples/awsome-distributed-training/main/3.test_cases/pytorch/cpu-ddp"><code>cpu-ddp/</code></a> - Exemples Distributed Data Parallel sur CPU</li>
<li><a href="https://raw.githubusercontent.com/aws-samples/awsome-distributed-training/main/3.test_cases/pytorch/bionemo"><code>bionemo/</code></a> - Exemples d'entraînement distribué BioNeMo</li>
</ul>
<h3>Cas de test JAX</h3>
<ul>
<li><a href="https://raw.githubusercontent.com/aws-samples/awsome-distributed-training/main/3.test_cases/jax"><code>jax/</code></a> - Exemples d'entraînement distribué basé sur JAX avec PaxML</li>
</ul>
<p>Chaque cas de test inclut :</p>
<ul>
<li>Scripts et configurations d’entraînement</li>
<li>Définitions de conteneurs (le cas échéant)</li>
<li>Scripts de lancement pour différents types de clusters</li>
<li>Outils de surveillance de performance et de validation</li>
</ul>
<h2>4. Scripts de validation</h2>
<p>Les scripts utilitaires et exemples de micro-benchmarks sont placés sous <code>4.validation_scripts/</code>. L’exportateur Prometheus EFA se trouve dans ce <a href="https://raw.githubusercontent.com/aws-samples/awsome-distributed-training/main/4.validation_and_observability/3.efa-node-exporter">répertoire</a></p>
<p>| Nom                                                                                              | Commentaires                                                     |
| ------------------------------------------------------------------------------------------------ | ---------------------------------------------------------------- |
| <a href="https://raw.githubusercontent.com/aws-samples/awsome-distributed-training/main/4.validation_and_observability/1.pytorch-env-validation"><code>1.pytorch-env-validation</code></a> | Valide votre environnement PyTorch                              |
| <a href="https://raw.githubusercontent.com/aws-samples/awsome-distributed-training/main/4.validation_and_observability/3.efa-node-exporter"><code>3.efa-node-exporter</code></a>         | Exportateur de nœud avec modules de surveillance Amazon EFA     |
| <a href="https://raw.githubusercontent.com/aws-samples/awsome-distributed-training/main/4.validation_and_observability/4.prometheus-grafana"><code>4.prometheus-grafana</code></a>         | Actifs de déploiement pour surveiller les clusters SageMaker Hyperpod |
| <a href="https://raw.githubusercontent.com/aws-samples/awsome-distributed-training/main/4.validation_and_observability/5.nsight"><code>5.nsight</code></a>                                 | Montre comment utiliser Nvidia Nsight Systems pour profiler votre charge de travail |
| <a href="https://raw.githubusercontent.com/aws-samples/awsome-distributed-training/main/1.architectures/efa-versions.py"><code>efa-versions.py</code></a>                                   | Récupère les versions des bibliothèques Nvidia, drivers et drivers EFA |</p>
<h2>5. CI</h2>
<p>Les tests d’intégration sont écrits en <a href="https://docs.pytest.org">pytest</a>. Il suffit d’exécuter :</p>
<pre><code class="language-bash">pytest .
</code></pre>
<p>Alternativement, vous pouvez lancer les tests sans capturer la sortie stdout et en conservant toutes les images docker et autres artefacts.</p>
<pre><code class="language-bash">pytest -s --keep-artifacts=t
</code></pre>
<h2>6. Contributeurs</h2>
<p>Merci à tous les contributeurs pour leur travail de construction, revue et test.</p>
<p><a href="https://github.com/aws-samples/awsome-distributed-training/graphs/contributors"><img src="https://contrib.rocks/image?repo=aws-samples/awsome-distributed-training" alt="Contributeurs" /></a></p>
<h2>7. Historique des étoiles</h2>
<p><a href="https://star-history.com/#aws-samples/awsome-distributed-training&amp;Date"><img src="https://api.star-history.com/svg?repos=aws-samples/awsome-distributed-training&amp;type=Date" alt="Graphique historique des étoiles" /></a></p>
<hr />
<p>Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx">Open Ai Tx</a> | Last indexed: 2025-06-11</p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Statcounter and other scripts can be added here -->
</body>
</html>