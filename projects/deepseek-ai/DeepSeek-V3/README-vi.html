<!DOCTYPE html>
<html lang="vi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DeepSeek-V3 - deepseek-ai/DeepSeek-V3</title>
    <meta name="title" content="DeepSeek-V3 - deepseek-ai/DeepSeek-V3">
    <meta name="description" content="deepseek-ai/DeepSeek-V3 - GitHub repository vi documentation and informationPaper Link👁️ Mục lục Giới thiệu Tóm tắt mô hình Tải xuống mô hình Kết quả đánh giá Trang web Chat &amp; Nền tảng API Chạy cục bộ Giấy phép Trích dẫn Liên hệ 1....">
    <meta name="keywords" content="deepseek-ai, DeepSeek-V3, GitHub, repository, vi documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/deepseek-ai/DeepSeek-V3/README-vi.html">
    <meta property="og:title" content="DeepSeek-V3 - deepseek-ai/DeepSeek-V3">
    <meta property="og:description" content="deepseek-ai/DeepSeek-V3 - GitHub repository vi documentation and information">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/deepseek-ai/DeepSeek-V3" id="githubRepoLink" target="_blank">deepseek-ai/DeepSeek-V3</a>
<h1 style="display: none;">Paper Link👁️ Mục lục Giới thiệu Tóm tắt mô hình Tải xuống mô hình Kết quả đánh giá Trang web Chat &amp; Nền tảng API Chạy cục bộ Giấy phép Trích dẫn Liên hệ 1....</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <!-- markdownlint-disable first-line-h1 -->
<!-- markdownlint-disable html -->
<!-- markdownlint-disable no-duplicate-header -->
<div align="center">
  <img src="https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/logo.svg?raw=true" width="60%" alt="DeepSeek-V3" />
</div>
<hr>
<div align="center" style="line-height: 1;">
  <a href="https://www.deepseek.com/"><img alt="Homepage"
    src="https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/badge.svg?raw=true"/></a>
  <a href="https://chat.deepseek.com/"><img alt="Chat"
    src="https://img.shields.io/badge/🤖%20Chat-DeepSeek%20V3-536af5?color=536af5&logoColor=white"/></a>
  <a href="https://huggingface.co/deepseek-ai"><img alt="Hugging Face"
    src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-DeepSeek%20AI-ffc107?color=ffc107&logoColor=white"/></a>
  <br>
  <a href="https://discord.gg/Tc7c45Zzu5"><img alt="Discord"
    src="https://img.shields.io/badge/Discord-DeepSeek%20AI-7289da?logo=discord&logoColor=white&color=7289da"/></a>
  <a href="https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/qr.jpeg?raw=true"><img alt="Wechat"
    src="https://img.shields.io/badge/WeChat-DeepSeek%20AI-brightgreen?logo=wechat&logoColor=white"/></a>
  <a href="https://twitter.com/deepseek_ai"><img alt="Twitter Follow"
    src="https://img.shields.io/badge/Twitter-deepseek_ai-white?logo=x&logoColor=white"/></a>
  <br>
  <a href="https://github.com/deepseek-ai/DeepSeek-V3/blob/main/LICENSE-CODE"><img alt="Code License"
    src="https://img.shields.io/badge/Code_License-MIT-f5de53?&color=f5de53"/></a>
  <a href="https://github.com/deepseek-ai/DeepSeek-V3/blob/main/LICENSE-MODEL"><img alt="Model License"
    src="https://img.shields.io/badge/Model_License-Model_Agreement-f5de53?&color=f5de53"/></a>
  <br>
  <a href="https://arxiv.org/pdf/2412.19437"><b>Paper Link</b>👁️</a>
</div>
<h2>Mục lục</h2>
<ol>
<li><a href="#1-gi%E1%BB%9Bi-thi%E1%BB%87u">Giới thiệu</a></li>
<li><a href="#2-t%C3%B3m-t%E1%BA%AFt-m%C3%B4-h%C3%ACnh">Tóm tắt mô hình</a></li>
<li><a href="#3-t%E1%BA%A3i-xu%E1%BB%91ng-m%C3%B4-h%C3%ACnh">Tải xuống mô hình</a></li>
<li><a href="#4-k%E1%BA%BFt-qu%E1%BA%A3-%C4%91%C3%A1nh-gi%C3%A1">Kết quả đánh giá</a></li>
<li><a href="#5-trang-web-chat--n%E1%BB%81n-t%E1%BA%A3ng-api">Trang web Chat &amp; Nền tảng API</a></li>
<li><a href="#6-ch%E1%BA%A1y-c%E1%BB%A5c-b%E1%BB%99">Chạy cục bộ</a></li>
<li><a href="#7-gi%E1%BA%A5y-ph%C3%A9p">Giấy phép</a></li>
<li><a href="#8-tr%C3%ADch-d%E1%BA%ABn">Trích dẫn</a></li>
<li><a href="#9-li%C3%AAn-h%E1%BB%87">Liên hệ</a></li>
</ol>
<h2>1. Giới thiệu</h2>
<p>Chúng tôi giới thiệu DeepSeek-V3, một mô hình ngôn ngữ Mixture-of-Experts (MoE) mạnh mẽ với tổng số 671 tỷ tham số, trong đó 37 tỷ tham số được kích hoạt cho mỗi token.<br />
Để đạt được suy luận hiệu quả và huấn luyện tiết kiệm chi phí, DeepSeek-V3 áp dụng kiến trúc Multi-head Latent Attention (MLA) và DeepSeekMoE, đã được xác thực kỹ lưỡng trong DeepSeek-V2.<br />
Hơn nữa, DeepSeek-V3 tiên phong với chiến lược cân bằng tải không cần auxiliary-loss và đặt mục tiêu huấn luyện dự đoán đa token (multi-token prediction) nhằm nâng cao hiệu suất.<br />
Chúng tôi huấn luyện sơ bộ DeepSeek-V3 trên 14,8 nghìn tỷ token đa dạng và chất lượng cao, sau đó tiến hành các giai đoạn Fine-Tuning Giám sát và Học tăng cường để khai thác tối đa khả năng của mô hình.<br />
Các đánh giá toàn diện cho thấy DeepSeek-V3 vượt trội hơn các mô hình mã nguồn mở khác và đạt hiệu năng tương đương với các mô hình mã nguồn đóng hàng đầu.<br />
Mặc dù đạt hiệu suất xuất sắc, DeepSeek-V3 chỉ cần 2,788 triệu giờ GPU H800 cho toàn bộ quá trình huấn luyện.<br />
Ngoài ra, quá trình huấn luyện của mô hình này rất ổn định.<br />
Trong suốt quá trình huấn luyện, chúng tôi không gặp phải bất kỳ sự cố mất mát không thể phục hồi nào hoặc phải rollback.</p>
<p align="center">
  <img width="80%" src="figures/benchmark.png">
</p>
<h2>2. Tóm tắt mô hình</h2>
<hr />
<p><strong>Kiến trúc: Chiến lược cân bằng tải và mục tiêu huấn luyện đột phá</strong></p>
<ul>
<li>Dựa trên kiến trúc hiệu quả của DeepSeek-V2, chúng tôi tiên phong với chiến lược cân bằng tải không cần auxiliary-loss, giúp giảm thiểu suy giảm hiệu suất phát sinh từ việc cân bằng tải.</li>
<li>Chúng tôi nghiên cứu mục tiêu Dự đoán Đa Token (Multi-Token Prediction - MTP) và chứng minh lợi ích của nó đối với hiệu suất mô hình.<br />
Nó cũng có thể được sử dụng cho quá trình suy luận gia tốc (speculative decoding).</li>
</ul>
<hr />
<p><strong>Huấn luyện sơ bộ: Hướng tới hiệu quả tối ưu</strong></p>
<ul>
<li>Chúng tôi thiết kế khung huấn luyện hỗn hợp chính xác FP8 và lần đầu tiên xác thực tính khả thi cũng như hiệu quả của huấn luyện FP8 trên mô hình siêu lớn.</li>
<li>Thông qua đồng thiết kế thuật toán, framework và phần cứng, chúng tôi vượt qua nút thắt cổ chai truyền thông trong huấn luyện MoE đa node, gần như đạt được sự chồng lấp hoàn toàn giữa tính toán và truyền thông.<br />
Điều này nâng cao hiệu quả huấn luyện và giảm chi phí, cho phép mở rộng quy mô mô hình mà không tăng thêm chi phí.</li>
<li>Với chi phí chỉ 2,664 triệu giờ GPU H800, chúng tôi hoàn tất huấn luyện sơ bộ DeepSeek-V3 trên 14,8T token, tạo ra mô hình nền tảng mã nguồn mở mạnh nhất hiện nay. Các giai đoạn huấn luyện tiếp theo chỉ cần thêm 0,1 triệu giờ GPU.</li>
</ul>
<hr />
<p><strong>Sau huấn luyện: Chưng cất tri thức từ DeepSeek-R1</strong></p>
<ul>
<li>Chúng tôi giới thiệu phương pháp sáng tạo để chưng cất khả năng suy luận từ mô hình Chain-of-Thought (CoT) chuỗi dài, cụ thể từ một trong các mô hình dòng DeepSeek R1, vào các LLM chuẩn, đặc biệt là DeepSeek-V3. Quy trình của chúng tôi tích hợp khéo léo các mẫu xác minh và phản chiếu của R1 vào DeepSeek-V3, cải thiện đáng kể hiệu suất suy luận. Đồng thời, chúng tôi cũng kiểm soát được phong cách và độ dài đầu ra của DeepSeek-V3.</li>
</ul>
<hr />
<h2>3. Tải xuống mô hình</h2>
<div align="center">
<p>| <strong>Mô hình</strong> | <strong>#Tổng tham số</strong> | <strong>#Tham số kích hoạt</strong> | <strong>Chiều dài ngữ cảnh</strong> | <strong>Tải xuống</strong> |
| :------------: | :------------: | :------------: | :------------: | :------------: |
| DeepSeek-V3-Base | 671B | 37B | 128K   | <a href="https://huggingface.co/deepseek-ai/DeepSeek-V3-Base">🤗 Hugging Face</a>   |
| DeepSeek-V3   | 671B | 37B |  128K   | <a href="https://huggingface.co/deepseek-ai/DeepSeek-V3">🤗 Hugging Face</a>   |</p>
</div>
<blockquote>
<p>[!CHÚ Ý]
Tổng dung lượng các mô hình DeepSeek-V3 trên Hugging Face là 685B, bao gồm 671B trọng số mô hình chính và 14B trọng số của Module Multi-Token Prediction (MTP).</p>
</blockquote>
<p>Để đảm bảo hiệu năng tối ưu và tính linh hoạt, chúng tôi hợp tác với các cộng đồng mã nguồn mở và nhà cung cấp phần cứng để cung cấp nhiều phương thức chạy mô hình cục bộ. Tham khảo hướng dẫn từng bước tại Mục 6: <a href="#6-ch%E1%BA%A1y-c%E1%BB%A5c-b%E1%BB%99">Chạy cục bộ</a>.</p>
<p>Dành cho các nhà phát triển muốn tìm hiểu sâu hơn, hãy khám phá <a href="./README_WEIGHTS.md">README_WEIGHTS.md</a> để biết chi tiết về trọng số Mô hình chính và các Module Multi-Token Prediction (MTP). Lưu ý rằng hỗ trợ MTP hiện đang được phát triển tích cực trong cộng đồng, và chúng tôi hoan nghênh đóng góp, phản hồi của bạn.</p>
<h2>4. Kết quả đánh giá</h2>
<h3>Mô hình nền tảng (Base Model)</h3>
<h4>Bộ benchmark tiêu chuẩn</h4>
<div align="center">
<p>|  | Benchmark (Metric) | # Shots | DeepSeek-V2 | Qwen2.5 72B | LLaMA3.1 405B | DeepSeek-V3 |
|---|-------------------|----------|--------|-------------|---------------|---------|
| | Architecture | - | MoE | Dense | Dense | MoE |
| | # Activated Params | - | 21B | 72B | 405B | 37B |
| | # Total Params | - | 236B | 72B | 405B | 671B |
| English | Pile-test (BPB) | - | 0.606 | 0.638 | <strong>0.542</strong> | 0.548 |
| | BBH (EM) | 3-shot | 78.8 | 79.8 | 82.9 | <strong>87.5</strong> |
| | MMLU (Acc.) | 5-shot | 78.4 | 85.0 | 84.4 | <strong>87.1</strong> |
| | MMLU-Redux (Acc.) | 5-shot | 75.6 | 83.2 | 81.3 | <strong>86.2</strong> |
| | MMLU-Pro (Acc.) | 5-shot | 51.4 | 58.3 | 52.8 | <strong>64.4</strong> |
| | DROP (F1) | 3-shot | 80.4 | 80.6 | 86.0 | <strong>89.0</strong> |
| | ARC-Easy (Acc.) | 25-shot | 97.6 | 98.4 | 98.4 | <strong>98.9</strong> |
| | ARC-Challenge (Acc.) | 25-shot | 92.2 | 94.5 | <strong>95.3</strong> | <strong>95.3</strong> |
| | HellaSwag (Acc.) | 10-shot | 87.1 | 84.8 | <strong>89.2</strong> | 88.9 |
| | PIQA (Acc.) | 0-shot | 83.9 | 82.6 | <strong>85.9</strong> | 84.7 |
| | WinoGrande (Acc.) | 5-shot | <strong>86.3</strong> | 82.3 | 85.2 | 84.9 |
| | RACE-Middle (Acc.) | 5-shot | 73.1 | 68.1 | <strong>74.2</strong> | 67.1 |
| | RACE-High (Acc.) | 5-shot | 52.6 | 50.3 | <strong>56.8</strong> | 51.3 |
| | TriviaQA (EM) | 5-shot | 80.0 | 71.9 | 82.7 | <strong>82.9</strong> |
| | NaturalQuestions (EM) | 5-shot | 38.6 | 33.2 | <strong>41.5</strong> | 40.0 |
| | AGIEval (Acc.) | 0-shot | 57.5 | 75.8 | 60.6 | <strong>79.6</strong> |
| Code | HumanEval (Pass@1) | 0-shot | 43.3 | 53.0 | 54.9 | <strong>65.2</strong> |
| | MBPP (Pass@1) | 3-shot | 65.0 | 72.6 | 68.4 | <strong>75.4</strong> |
| | LiveCodeBench-Base (Pass@1) | 3-shot | 11.6 | 12.9 | 15.5 | <strong>19.4</strong> |
| | CRUXEval-I (Acc.) | 2-shot | 52.5 | 59.1 | 58.5 | <strong>67.3</strong> |
| | CRUXEval-O (Acc.) | 2-shot | 49.8 | 59.9 | 59.9 | <strong>69.8</strong> |
| Math | GSM8K (EM) | 8-shot | 81.6 | 88.3 | 83.5 | <strong>89.3</strong> |
| | MATH (EM) | 4-shot | 43.4 | 54.4 | 49.0 | <strong>61.6</strong> |
| | MGSM (EM) | 8-shot | 63.6 | 76.2 | 69.9 | <strong>79.8</strong> |
| | CMath (EM) | 3-shot | 78.7 | 84.5 | 77.3 | <strong>90.7</strong> |
| Chinese | CLUEWSC (EM) | 5-shot | 82.0 | 82.5 | <strong>83.0</strong> | 82.7 |
| | C-Eval (Acc.) | 5-shot | 81.4 | 89.2 | 72.5 | <strong>90.1</strong> |
| | CMMLU (Acc.) | 5-shot | 84.0 | <strong>89.5</strong> | 73.7 | 88.8 |
| | CMRC (EM) | 1-shot | <strong>77.4</strong> | 75.8 | 76.0 | 76.3 |
| | C3 (Acc.) | 0-shot | 77.4 | 76.7 | <strong>79.7</strong> | 78.6 |
| | CCPM (Acc.) | 0-shot | <strong>93.0</strong> | 88.5 | 78.6 | 92.0 |
| Multilingual | MMMLU-non-English (Acc.) | 5-shot | 64.0 | 74.8 | 73.8 | <strong>79.4</strong> |</p>
</div>
<blockquote>
<p>[!CHÚ Ý]
Kết quả tốt nhất được in đậm. Các điểm số có chênh lệch không vượt quá 0,3 được coi là cùng mức. DeepSeek-V3 đạt hiệu năng tốt nhất trên phần lớn benchmark, đặc biệt ở các bài toán toán học và lập trình.
Tham khảo bài báo của chúng tôi để biết chi tiết đánh giá.</p>
</blockquote>
<h4>Cửa sổ ngữ cảnh</h4>
<p align="center">
  <img width="80%" src="figures/niah.png">
</p>
<p>Kết quả đánh giá trên các bài kiểm tra <code>Needle In A Haystack</code> (NIAH). DeepSeek-V3 hoạt động tốt ở tất cả các chiều dài cửa sổ ngữ cảnh lên tới <strong>128K</strong>.</p>
<h3>Mô hình Chat</h3>
<h4>Bộ benchmark tiêu chuẩn (Các mô hình lớn hơn 67B)</h4>
<div align="center">
<p>| | <strong>Benchmark (Metric)</strong> | <strong>DeepSeek V2-0506</strong> | <strong>DeepSeek V2.5-0905</strong> | <strong>Qwen2.5 72B-Inst.</strong> | <strong>Llama3.1 405B-Inst.</strong> | <strong>Claude-3.5-Sonnet-1022</strong> | <strong>GPT-4o 0513</strong> | <strong>DeepSeek V3</strong> |
|---|---------------------|---------------------|----------------------|---------------------|----------------------|---------------------------|----------------|----------------|
| | Architecture | MoE | MoE | Dense | Dense | - | - | MoE |
| | # Activated Params | 21B | 21B | 72B | 405B | - | - | 37B |
| | # Total Params | 236B | 236B | 72B | 405B | - | - | 671B |
| English | MMLU (EM) | 78.2 | 80.6 | 85.3 | <strong>88.6</strong> | <strong>88.3</strong> | 87.2 | <strong>88.5</strong> |
| | MMLU-Redux (EM) | 77.9 | 80.3 | 85.6 | 86.2 | <strong>88.9</strong> | 88.0 | <strong>89.1</strong> |
| | MMLU-Pro (EM) | 58.5 | 66.2 | 71.6 | 73.3 | <strong>78.0</strong> | 72.6 | 75.9 |
| | DROP (3-shot F1) | 83.0 | 87.8 | 76.7 | 88.7 | 88.3 | 83.7 | <strong>91.6</strong> |
| | IF-Eval (Prompt Strict) | 57.7 | 80.6 | 84.1 | 86.0 | <strong>86.5</strong> | 84.3 | 86.1 |
| | GPQA-Diamond (Pass@1) | 35.3 | 41.3 | 49.0 | 51.1 | <strong>65.0</strong> | 49.9 | 59.1 |
| | SimpleQA (Correct) | 9.0 | 10.2 | 9.1 | 17.1 | 28.4 | <strong>38.2</strong> | 24.9 |
| | FRAMES (Acc.) | 66.9 | 65.4 | 69.8 | 70.0 | 72.5 | <strong>80.5</strong> | 73.3 |
| | LongBench v2 (Acc.) | 31.6 | 35.4 | 39.4 | 36.1 | 41.0 | 48.1 | <strong>48.7</strong> |
| Code | HumanEval-Mul (Pass@1) | 69.3 | 77.4 | 77.3 | 77.2 | 81.7 | 80.5 | <strong>82.6</strong> |
| | LiveCodeBench (Pass@1-COT) | 18.8 | 29.2 | 31.1 | 28.4 | 36.3 | 33.4 | <strong>40.5</strong> |
| | LiveCodeBench (Pass@1) | 20.3 | 28.4 | 28.7 | 30.1 | 32.8 | 34.2 | <strong>37.6</strong> |
| | Codeforces (Percentile) | 17.5 | 35.6 | 24.8 | 25.3 | 20.3 | 23.6 | <strong>51.6</strong> |
| | SWE Verified (Resolved) | - | 22.6 | 23.8 | 24.5 | <strong>50.8</strong> | 38.8 | 42.0 |
| | Aider-Edit (Acc.) | 60.3 | 71.6 | 65.4 | 63.9 | <strong>84.2</strong> | 72.9 | 79.7 |
| | Aider-Polyglot (Acc.) | - | 18.2 | 7.6 | 5.8 | 45.3 | 16.0 | <strong>49.6</strong> |
| Math | AIME 2024 (Pass@1) | 4.6 | 16.7 | 23.3 | 23.3 | 16.0 | 9.3 | <strong>39.2</strong> |
| | MATH-500 (EM) | 56.3 | 74.7 | 80.0 | 73.8 | 78.3 | 74.6 | <strong>90.2</strong> |
| | CNMO 2024 (Pass@1) | 2.8 | 10.8 | 15.9 | 6.8 | 13.1 | 10.8 | <strong>43.2</strong> |
| Chinese | CLUEWSC (EM) | 89.9 | 90.4 | <strong>91.4</strong> | 84.7 | 85.4 | 87.9 | 90.9 |
| | C-Eval (EM) | 78.6 | 79.5 | 86.1 | 61.5 | 76.7 | 76.0 | <strong>86.5</strong> |
| | C-SimpleQA (Correct) | 48.5 | 54.1 | 48.4 | 50.4 | 51.3 | 59.3 | <strong>64.8</strong> |</p>
</div>
<blockquote>
<p>[!CHÚ Ý]
Tất cả các mô hình được đánh giá với cấu hình giới hạn độ dài đầu ra ở mức 8K. Các benchmark có ít hơn 1000 mẫu sẽ được kiểm tra nhiều lần với các giá trị temperature khác nhau để đảm bảo kết quả cuối cùng ổn định. DeepSeek-V3 là mô hình mã nguồn mở có hiệu năng tốt nhất, đồng thời cạnh tranh mạnh với các mô hình mã nguồn đóng hàng đầu.</p>
</blockquote>
<h4>Đánh giá sinh đầu ra mở</h4>
<div align="center">
<p>| Mô hình | Arena-Hard | AlpacaEval 2.0 |
|-------|------------|----------------|
| DeepSeek-V2.5-0905 | 76.2 | 50.5 |
| Qwen2.5-72B-Instruct | 81.2 | 49.1 |
| LLaMA-3.1 405B | 69.3 | 40.5 |
| GPT-4o-0513 | 80.4 | 51.1 |
| Claude-Sonnet-3.5-1022 | 85.2 | 52.0 |
| DeepSeek-V3 | <strong>85.5</strong> | <strong>70.0</strong> |</p>
</div>
<blockquote>
<p>[!CHÚ Ý]
Đánh giá hội thoại tiếng Anh mở. Với AlpacaEval 2.0, chúng tôi sử dụng tỉ lệ thắng kiểm soát độ dài làm tiêu chí.</p>
</blockquote>
<h2>5. Trang web Chat &amp; Nền tảng API</h2>
<p>Bạn có thể trò chuyện với DeepSeek-V3 trên trang web chính thức của DeepSeek: <a href="https://chat.deepseek.com/sign_in">chat.deepseek.com</a></p>
<p>Chúng tôi cũng cung cấp API tương thích OpenAI tại DeepSeek Platform: <a href="https://platform.deepseek.com/">platform.deepseek.com</a></p>
<h2>6. Chạy cục bộ</h2>
<p>DeepSeek-V3 có thể triển khai cục bộ với các phần cứng và phần mềm mã nguồn mở sau:</p>
<ol>
<li><strong>DeepSeek-Infer Demo</strong>: Cung cấp demo nhẹ cho suy luận FP8 và BF16.</li>
<li><strong>SGLang</strong>: Hỗ trợ đầy đủ mô hình DeepSeek-V3 ở cả hai chế độ suy luận BF16 và FP8, Multi-Token Prediction <a href="https://github.com/sgl-project/sglang/issues/2591">sắp ra mắt</a>.</li>
<li><strong>LMDeploy</strong>: Cho phép suy luận hiệu quả FP8 và BF16 cho triển khai cục bộ và đám mây.</li>
<li><strong>TensorRT-LLM</strong>: Hiện hỗ trợ suy luận BF16 và lượng tử hóa INT4/8, hỗ trợ FP8 sẽ ra mắt sớm.</li>
<li><strong>vLLM</strong>: Hỗ trợ mô hình DeepSeek-V3 với chế độ FP8 và BF16 cho song song tensor và song song pipeline.</li>
<li><strong>LightLLM</strong>: Hỗ trợ triển khai đơn node hoặc đa node hiệu quả cho FP8 và BF16.</li>
<li><strong>AMD GPU</strong>: Cho phép chạy mô hình DeepSeek-V3 trên GPU AMD qua SGLang ở cả chế độ BF16 và FP8.</li>
<li><strong>Huawei Ascend NPU</strong>: Hỗ trợ chạy DeepSeek-V3 trên thiết bị Huawei Ascend.</li>
</ol>
<p>Vì huấn luyện FP8 được áp dụng gốc trong framework của chúng tôi, chúng tôi chỉ cung cấp trọng số FP8. Nếu bạn cần trọng số BF16 để thử nghiệm, hãy dùng script chuyển đổi đi kèm.</p>
<p>Ví dụ chuyển đổi trọng số FP8 sang BF16:</p>
<pre><code class="language-shell">cd inference
python fp8_cast_bf16.py --input-fp8-hf-path /path/to/fp8_weights --output-bf16-hf-path /path/to/bf16_weights
</code></pre>
<blockquote>
<p>[!CHÚ Ý]
Hugging Face Transformers chưa được hỗ trợ trực tiếp.</p>
</blockquote>
<h3>6.1 Suy luận với DeepSeek-Infer Demo (chỉ là ví dụ)</h3>
<h4>Yêu cầu hệ thống</h4>
<blockquote>
<p>[!CHÚ Ý]
Chỉ hỗ trợ Linux với Python 3.10. Không hỗ trợ Mac và Windows.</p>
</blockquote>
<p>Phụ thuộc:</p>
<pre><code class="language-pip-requirements">torch==2.4.1
triton==3.0.0
transformers==4.46.3
safetensors==0.4.5
</code></pre>
<h4>Chuẩn bị trọng số mô hình &amp; mã demo</h4>
<p>Đầu tiên, clone kho GitHub DeepSeek-V3 của chúng tôi:</p>
<pre><code class="language-shell">git clone https://github.com/deepseek-ai/DeepSeek-V3.git
</code></pre>
<p>Di chuyển tới thư mục <code>inference</code> và cài đặt các phụ thuộc trong <code>requirements.txt</code>. Cách dễ nhất là dùng trình quản lý như <code>conda</code> hoặc <code>uv</code> để tạo môi trường ảo mới và cài đặt phụ thuộc.</p>
<pre><code class="language-shell">cd DeepSeek-V3/inference
pip install -r requirements.txt
</code></pre>
<p>Tải trọng số mô hình từ Hugging Face và đặt vào thư mục <code>/path/to/DeepSeek-V3</code>.</p>
<h4>Chuyển đổi trọng số mô hình</h4>
<p>Chuyển đổi trọng số mô hình Hugging Face sang định dạng cụ thể:</p>
<pre><code class="language-shell">python convert.py --hf-ckpt-path /path/to/DeepSeek-V3 --save-path /path/to/DeepSeek-V3-Demo --n-experts 256 --model-parallel 16
</code></pre>
<h4>Chạy</h4>
<p>Bây giờ bạn có thể chat với DeepSeek-V3:</p>
<pre><code class="language-shell">torchrun --nnodes 2 --nproc-per-node 8 --node-rank $RANK --master-addr $ADDR generate.py --ckpt-path /path/to/DeepSeek-V3-Demo --config configs/config_671B.json --interactive --temperature 0.7 --max-new-tokens 200
</code></pre>
<p>Hoặc suy luận hàng loạt trên file cho trước:</p>
<pre><code class="language-shell">torchrun --nnodes 2 --nproc-per-node 8 --node-rank $RANK --master-addr $ADDR generate.py --ckpt-path /path/to/DeepSeek-V3-Demo --config configs/config_671B.json --input-file $FILE
</code></pre>
<h3>6.2 Suy luận với SGLang (khuyến nghị)</h3>
<p><a href="https://github.com/sgl-project/sglang">SGLang</a> hiện hỗ trợ <a href="https://lmsys.org/blog/2024-09-04-sglang-v0-3/#deepseek-multi-head-latent-attention-mla-throughput-optimizations">tối ưu hóa MLA</a>, <a href="https://lmsys.org/blog/2024-12-04-sglang-v0-4/#data-parallelism-attention-for-deepseek-models">DP Attention</a>, FP8 (W8A8), FP8 KV Cache, và Torch Compile, mang lại độ trễ và thông lượng hàng đầu trong số các framework mã nguồn mở.</p>
<p>Đặc biệt, <a href="https://github.com/sgl-project/sglang/releases/tag/v0.4.1">SGLang v0.4.1</a> hỗ trợ đầy đủ chạy DeepSeek-V3 trên cả <strong>GPU NVIDIA và AMD</strong>, giúp giải pháp này rất linh hoạt và mạnh mẽ.</p>
<p>SGLang còn hỗ trợ <a href="https://github.com/sgl-project/sglang/tree/main/benchmark/deepseek_v3#example-serving-with-2-h208">song song tensor đa node</a>, cho phép bạn chạy mô hình này trên nhiều máy kết nối mạng.</p>
<p>Multi-Token Prediction (MTP) đang được phát triển, theo dõi tiến độ tại <a href="https://github.com/sgl-project/sglang/issues/2591">kế hoạch tối ưu hóa</a>.</p>
<p>Hướng dẫn khởi chạy từ nhóm SGLang: https://github.com/sgl-project/sglang/tree/main/benchmark/deepseek_v3</p>
<h3>6.3 Suy luận với LMDeploy (khuyến nghị)</h3>
<p><a href="https://github.com/InternLM/lmdeploy">LMDeploy</a>, framework suy luận và phục vụ hiệu suất cao, linh hoạt dành cho mô hình ngôn ngữ lớn, hiện hỗ trợ DeepSeek-V3. Cung cấp cả xử lý pipeline ngoại tuyến và triển khai trực tuyến, tích hợp mượt mà với workflow dựa trên PyTorch.</p>
<p>Hướng dẫn chi tiết từng bước sử dụng LMDeploy với DeepSeek-V3 tại: https://github.com/InternLM/lmdeploy/issues/2960</p>
<h3>6.4 Suy luận với TRT-LLM (khuyến nghị)</h3>
<p><a href="https://github.com/NVIDIA/TensorRT-LLM">TensorRT-LLM</a> hiện hỗ trợ mô hình DeepSeek-V3, cung cấp các tùy chọn chính xác như BF16 và INT4/INT8 weight-only. Hỗ trợ FP8 đang được phát triển và sẽ phát hành sớm. Bạn có thể truy cập branch tùy chỉnh TRTLLM dành riêng cho DeepSeek-V3 tại: https://github.com/NVIDIA/TensorRT-LLM/tree/main/examples/deepseek_v3.</p>
<h3>6.5 Suy luận với vLLM (khuyến nghị)</h3>
<p><a href="https://github.com/vllm-project/vllm">vLLM</a> v0.6.6 hỗ trợ suy luận DeepSeek-V3 cho chế độ FP8 và BF16 trên cả GPU NVIDIA và AMD. Ngoài các kỹ thuật tiêu chuẩn, vLLM cung cấp <em>pipeline parallelism</em> giúp chạy mô hình trên nhiều máy nối mạng. Xem hướng dẫn chi tiết tại <a href="https://docs.vllm.ai/en/latest/serving/distributed_serving.html">vLLM instructions</a>. Theo dõi <a href="https://github.com/vllm-project/vllm/issues/11539">kế hoạch mở rộng</a>.</p>
<h3>6.6 Suy luận với LightLLM (khuyến nghị)</h3>
<p><a href="https://github.com/ModelTC/lightllm/tree/main">LightLLM</a> v1.0.1 hỗ trợ triển khai song song tensor một máy và nhiều máy cho DeepSeek-R1 (FP8/BF16) và cung cấp triển khai hỗn hợp chính xác, với nhiều chế độ lượng tử hóa liên tục được tích hợp. Xem chi tiết tại <a href="https://lightllm-en.readthedocs.io/en/latest/getting_started/quickstart.html">LightLLM instructions</a>. Ngoài ra, LightLLM cung cấp triển khai PD-disaggregation cho DeepSeek-V2, và phiên bản cho DeepSeek-V3 đang được phát triển.</p>
<h3>6.7 Suy luận khuyến nghị với GPU AMD</h3>
<p>Hợp tác với đội ngũ AMD, chúng tôi đã đạt hỗ trợ Day-One cho GPU AMD sử dụng SGLang, tương thích đầy đủ cả FP8 và BF16. Xem hướng dẫn chi tiết tại <a href="#63-inference-with-lmdeploy-recommended">SGLang instructions</a>.</p>
<h3>6.8 Suy luận khuyến nghị với Huawei Ascend NPU</h3>
<p>Framework <a href="https://www.hiascend.com/en/software/mindie">MindIE</a> từ cộng đồng Huawei Ascend đã thích ứng thành công phiên bản BF16 của DeepSeek-V3. Hướng dẫn từng bước cho Ascend NPUs tại <a href="https://modelers.cn/models/MindIE/deepseekv3">đây</a>.</p>
<h2>7. Giấy phép</h2>
<p>Kho mã nguồn này được cấp phép theo <a href="LICENSE-CODE">Giấy phép MIT</a>. Việc sử dụng các mô hình DeepSeek-V3 Base/Chat tuân theo <a href="LICENSE-MODEL">Giấy phép Mô hình</a>. Dòng DeepSeek-V3 (bao gồm Base và Chat) hỗ trợ sử dụng thương mại.</p>
<h2>8. Trích dẫn</h2>
<pre><code>@misc{deepseekai2024deepseekv3technicalreport,
      title={DeepSeek-V3 Technical Report}, 
      author={DeepSeek-AI},
      year={2024},
      eprint={2412.19437},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.19437}, 
}
</code></pre>
<h2>9. Liên hệ</h2>
<p>Nếu bạn có bất kỳ câu hỏi nào, vui lòng tạo issue hoặc liên hệ với chúng tôi qua <a href="service@deepseek.com">service@deepseek.com</a>.</p>
<hr />
<p><a href="https://github.com/OpenAiTx/OpenAiTx">Powered By OpenAiTx</a></p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
</body>
</html>