<!DOCTYPE html>
<html lang="ar">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DeepSeek-V3 - deepseek-ai/DeepSeek-V3</title>
    <meta name="title" content="DeepSeek-V3 - deepseek-ai/DeepSeek-V3">
    <meta name="description" content="deepseek-ai/DeepSeek-V3 - GitHub repository ar documentation and informationرابط الورقة العلمية👁️ جدول المحتويات المقدمة ملخص النموذج تنزيل النماذج نتائج التقييم موقع الدردشة ومنصة API كيفية التشغيل محليًا الترخيص الاستشهاد التواصل 1. ...">
    <meta name="keywords" content="deepseek-ai, DeepSeek-V3, GitHub, repository, ar documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/deepseek-ai/DeepSeek-V3/README-ar.html">
    <meta property="og:title" content="DeepSeek-V3 - deepseek-ai/DeepSeek-V3">
    <meta property="og:description" content="deepseek-ai/DeepSeek-V3 - GitHub repository ar documentation and information">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/deepseek-ai/DeepSeek-V3" id="githubRepoLink" target="_blank">deepseek-ai/DeepSeek-V3</a>
<h1 style="display: none;">رابط الورقة العلمية👁️ جدول المحتويات المقدمة ملخص النموذج تنزيل النماذج نتائج التقييم موقع الدردشة ومنصة API كيفية التشغيل محليًا الترخيص الاستشهاد التواصل 1. ...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <!-- markdownlint-disable first-line-h1 -->
<!-- markdownlint-disable html -->
<!-- markdownlint-disable no-duplicate-header -->
<div align="center">
  <img src="https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/logo.svg?raw=true" width="60%" alt="DeepSeek-V3" />
</div>
<hr>
<div align="center" style="line-height: 1;">
  <a href="https://www.deepseek.com/"><img alt="Homepage"
    src="https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/badge.svg?raw=true"/></a>
  <a href="https://chat.deepseek.com/"><img alt="Chat"
    src="https://img.shields.io/badge/🤖%20Chat-DeepSeek%20V3-536af5?color=536af5&logoColor=white"/></a>
  <a href="https://huggingface.co/deepseek-ai"><img alt="Hugging Face"
    src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-DeepSeek%20AI-ffc107?color=ffc107&logoColor=white"/></a>
  <br>
  <a href="https://discord.gg/Tc7c45Zzu5"><img alt="Discord"
    src="https://img.shields.io/badge/Discord-DeepSeek%20AI-7289da?logo=discord&logoColor=white&color=7289da"/></a>
  <a href="https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/qr.jpeg?raw=true"><img alt="Wechat"
    src="https://img.shields.io/badge/WeChat-DeepSeek%20AI-brightgreen?logo=wechat&logoColor=white"/></a>
  <a href="https://twitter.com/deepseek_ai"><img alt="Twitter Follow"
    src="https://img.shields.io/badge/Twitter-deepseek_ai-white?logo=x&logoColor=white"/></a>
  <br>
  <a href="https://github.com/deepseek-ai/DeepSeek-V3/blob/main/LICENSE-CODE"><img alt="Code License"
    src="https://img.shields.io/badge/Code_License-MIT-f5de53?&color=f5de53"/></a>
  <a href="https://github.com/deepseek-ai/DeepSeek-V3/blob/main/LICENSE-MODEL"><img alt="Model License"
    src="https://img.shields.io/badge/Model_License-Model_Agreement-f5de53?&color=f5de53"/></a>
  <br>
  <a href="https://arxiv.org/pdf/2412.19437"><b>رابط الورقة العلمية</b>👁️</a>
</div>
<h2>جدول المحتويات</h2>
<ol>
<li><a href="#1-%D8%A7%D9%84%D9%85%D9%82%D8%AF%D9%85%D8%A9">المقدمة</a></li>
<li><a href="#2-%D9%85%D9%84%D8%AE%D8%B5-%D8%A7%D9%84%D9%86%D9%85%D9%88%D8%B0%D8%AC">ملخص النموذج</a></li>
<li><a href="#3-%D8%AA%D9%86%D8%B2%D9%8A%D9%84-%D8%A7%D9%84%D9%86%D9%85%D8%A7%D8%B0%D8%AC">تنزيل النماذج</a></li>
<li><a href="#4-%D9%86%D8%AA%D8%A7%D8%A6%D8%AC-%D8%A7%D9%84%D8%AA%D9%82%D9%8A%D9%8A%D9%85">نتائج التقييم</a></li>
<li><a href="#5-%D9%85%D9%88%D9%82%D8%B9-%D8%A7%D9%84%D8%AF%D8%B1%D8%AF%D8%B4%D8%A9--%D9%85%D9%86%D8%B5%D8%A9-api">موقع الدردشة ومنصة API</a></li>
<li><a href="#6-%D9%83%D9%8A%D9%81%D9%8A%D8%A9-%D8%A7%D9%84%D8%AA%D8%B4%D8%BA%D9%8A%D9%84-%D9%85%D8%AD%D9%84%D9%8A%D9%8B%D8%A7">كيفية التشغيل محليًا</a></li>
<li><a href="#7-%D8%A7%D9%84%D8%AA%D8%B1%D8%AE%D9%8A%D8%B5">الترخيص</a></li>
<li><a href="#8-%D8%A7%D9%84%D8%A7%D8%B3%D8%AA%D8%B4%D9%87%D8%A7%D8%AF">الاستشهاد</a></li>
<li><a href="#9-%D8%A7%D9%84%D8%AA%D9%88%D8%A7%D8%B5%D9%84">التواصل</a></li>
</ol>
<h2>1. المقدمة</h2>
<p>نقدم لكم DeepSeek-V3، وهو نموذج لغوي قوي من نوع Mixture-of-Experts (MoE) بعدد إجمالي من المعاملات يبلغ 671 مليار، مع تفعيل 37 مليار معامل لكل رمز.<br />
لتحقيق استدلال فعال وتدريب منخفض التكلفة، يعتمد DeepSeek-V3 على معماريتي Multi-head Latent Attention (MLA) وDeepSeekMoE، واللتين تم التحقق منهما بدقة في DeepSeek-V2.<br />
علاوة على ذلك، كان DeepSeek-V3 سبّاقًا في تطبيق استراتيجية موازنة التحميل بدون خسارة مساعدة، وحدد هدف تدريب لتوقع متعدد الرموز لتحسين الأداء.<br />
قمنا بتدريب DeepSeek-V3 مسبقًا على 14.8 تريليون رمز متنوع وعالي الجودة، تلا ذلك مراحل Fine-Tuning بإشراف وتعزيز التعلم (Reinforcement Learning) لاستغلال قدراته بالكامل.<br />
تكشف التقييمات الشاملة أن DeepSeek-V3 يتفوق على النماذج مفتوحة المصدر الأخرى ويحقق أداءً مماثلاً لأفضل النماذج مغلقة المصدر.
ورغم أدائه الممتاز، يتطلب DeepSeek-V3 فقط 2.788 مليون ساعة GPU من نوع H800 للتدريب الكامل.
بالإضافة إلى ذلك، فإن عملية التدريب كانت مستقرة بشكل ملحوظ.
خلال كامل عملية التدريب، لم نواجه أي ارتفاعات غير قابلة للاسترداد في الخسارة ولم نقم بأي عمليات استرجاع (Rollback).</p>
<p align="center">
  <img width="80%" src="figures/benchmark.png">
</p>
<h2>2. ملخص النموذج</h2>
<hr />
<p><strong>المعمارية: استراتيجية موازنة تحميل وهدف تدريبي مبتكر</strong></p>
<ul>
<li>بالاعتماد على معمارية DeepSeek-V2 الفعالة، قمنا بابتكار استراتيجية موازنة تحميل بدون خسارة مساعدة، مما يقلل من تدهور الأداء الناتج عن تشجيع موازنة التحميل.</li>
<li>بحثنا هدف توقع متعدد الرموز (Multi-Token Prediction - MTP) وأثبتنا فائدته في أداء النموذج.
كما يمكن استخدامه في فك التشفير التخميني لتسريع الاستدلال.</li>
</ul>
<hr />
<p><strong>التدريب المسبق: نحو كفاءة تدريب قصوى</strong></p>
<ul>
<li>صممنا إطار تدريب بدقة مختلطة FP8، ولأول مرة تحققنا من جدوى وفعالية تدريب FP8 على نموذج واسع النطاق للغاية.</li>
<li>من خلال التصميم المشترك للخوارزميات والأطر والأجهزة، تغلبنا على عنق الزجاجة في الاتصال أثناء تدريب MoE عبر العقد، واقتربنا من تداخل كامل بين الحسابات والاتصالات.
وقد عزز ذلك بشكل كبير من كفاءة التدريب وخفض التكاليف، مما أتاح لنا توسيع حجم النموذج دون تكلفة إضافية.</li>
<li>بتكلفة اقتصادية تبلغ فقط 2.664 مليون ساعة GPU من نوع H800، أكملنا التدريب المسبق لـ DeepSeek-V3 على 14.8 تريليون رمز، مما أنتج أقوى نموذج أساسي مفتوح المصدر حاليًا. وتحتاج مراحل التدريب اللاحقة فقط إلى 0.1 مليون ساعة GPU.</li>
</ul>
<hr />
<p><strong>ما بعد التدريب: تقطير المعرفة من DeepSeek-R1</strong></p>
<ul>
<li>قدمنا منهجية مبتكرة لتقطير قدرات الاستدلال من نموذج سلسلة التفكير الطويلة (CoT)، وتحديدًا من أحد نماذج DeepSeek R1، إلى النماذج اللغوية القياسية، وخاصة DeepSeek-V3. حيث يدمج خط العمل الخاص بنا أنماط التحقق والتفكير الخاصة بـ R1 في DeepSeek-V3 ويحسن بشكل ملحوظ أداء الاستدلال لديه. وفي الوقت نفسه، حافظنا على التحكم في نمط وطول إخراج DeepSeek-V3.</li>
</ul>
<hr />
<h2>3. تنزيل النماذج</h2>
<div align="center">
<p>| <strong>النموذج</strong> | <strong>إجمالي المعاملات</strong> | <strong>المعاملات المفعلة</strong> | <strong>طول السياق</strong> | <strong>التنزيل</strong> |
| :------------: | :------------: | :------------: | :------------: | :------------: |
| DeepSeek-V3-Base | 671B | 37B | 128K   | <a href="https://huggingface.co/deepseek-ai/DeepSeek-V3-Base">🤗 Hugging Face</a>   |
| DeepSeek-V3   | 671B | 37B |  128K   | <a href="https://huggingface.co/deepseek-ai/DeepSeek-V3">🤗 Hugging Face</a>   |</p>
</div>
<blockquote>
<p>[!NOTE]
الحجم الكلي لنماذج DeepSeek-V3 على Hugging Face هو 685 مليار، ويتضمن 671 مليار من أوزان النموذج الرئيسي و14 مليار من أوزان وحدة توقع متعدد الرموز (MTP).</p>
</blockquote>
<p>لضمان أداء مثالي ومرونة، تعاونا مع مجتمعات المصادر المفتوحة وبائعي العتاد لتوفير طرق متعددة لتشغيل النموذج محليًا. للاطلاع على الإرشادات خطوة بخطوة، راجع القسم 6: <a href="#6-%D9%83%D9%8A%D9%81%D9%8A%D8%A9-%D8%A7%D9%84%D8%AA%D8%B4%D8%BA%D9%8A%D9%84-%D9%85%D8%AD%D9%84%D9%8A%D9%8B%D8%A7">كيفية التشغيل محليًا</a>.</p>
<p>للمطورين الراغبين في التعمق، ننصح باستكشاف <a href="./README_WEIGHTS.md">README_WEIGHTS.md</a> للحصول على تفاصيل حول أوزان النموذج الرئيسي ووحدات توقع متعدد الرموز (MTP). يرجى ملاحظة أن دعم MTP قيد التطوير النشط من قِبل المجتمع، ونرحب بمساهماتكم وملاحظاتكم.</p>
<h2>4. نتائج التقييم</h2>
<h3>النموذج الأساسي</h3>
<h4>مقاييس التقييم القياسية</h4>
<div align="center">
<p>|  | المعيار (المقياس) | عدد اللقطات | DeepSeek-V2 | Qwen2.5 72B | LLaMA3.1 405B | DeepSeek-V3 |
|---|-------------------|----------|--------|-------------|---------------|---------|
| | المعمارية | - | MoE | Dense | Dense | MoE |
| | المعاملات المفعلة | - | 21B | 72B | 405B | 37B |
| | إجمالي المعاملات | - | 236B | 72B | 405B | 671B |
| الإنجليزية | Pile-test (BPB) | - | 0.606 | 0.638 | <strong>0.542</strong> | 0.548 |
| | BBH (EM) | 3-shot | 78.8 | 79.8 | 82.9 | <strong>87.5</strong> |
| | MMLU (Acc.) | 5-shot | 78.4 | 85.0 | 84.4 | <strong>87.1</strong> |
| | MMLU-Redux (Acc.) | 5-shot | 75.6 | 83.2 | 81.3 | <strong>86.2</strong> |
| | MMLU-Pro (Acc.) | 5-shot | 51.4 | 58.3 | 52.8 | <strong>64.4</strong> |
| | DROP (F1) | 3-shot | 80.4 | 80.6 | 86.0 | <strong>89.0</strong> |
| | ARC-Easy (Acc.) | 25-shot | 97.6 | 98.4 | 98.4 | <strong>98.9</strong> |
| | ARC-Challenge (Acc.) | 25-shot | 92.2 | 94.5 | <strong>95.3</strong> | <strong>95.3</strong> |
| | HellaSwag (Acc.) | 10-shot | 87.1 | 84.8 | <strong>89.2</strong> | 88.9 |
| | PIQA (Acc.) | 0-shot | 83.9 | 82.6 | <strong>85.9</strong> | 84.7 |
| | WinoGrande (Acc.) | 5-shot | <strong>86.3</strong> | 82.3 | 85.2 | 84.9 |
| | RACE-Middle (Acc.) | 5-shot | 73.1 | 68.1 | <strong>74.2</strong> | 67.1 |
| | RACE-High (Acc.) | 5-shot | 52.6 | 50.3 | <strong>56.8</strong> | 51.3 |
| | TriviaQA (EM) | 5-shot | 80.0 | 71.9 | 82.7 | <strong>82.9</strong> |
| | NaturalQuestions (EM) | 5-shot | 38.6 | 33.2 | <strong>41.5</strong> | 40.0 |
| | AGIEval (Acc.) | 0-shot | 57.5 | 75.8 | 60.6 | <strong>79.6</strong> |
| البرمجة | HumanEval (Pass@1) | 0-shot | 43.3 | 53.0 | 54.9 | <strong>65.2</strong> |
| | MBPP (Pass@1) | 3-shot | 65.0 | 72.6 | 68.4 | <strong>75.4</strong> |
| | LiveCodeBench-Base (Pass@1) | 3-shot | 11.6 | 12.9 | 15.5 | <strong>19.4</strong> |
| | CRUXEval-I (Acc.) | 2-shot | 52.5 | 59.1 | 58.5 | <strong>67.3</strong> |
| | CRUXEval-O (Acc.) | 2-shot | 49.8 | 59.9 | 59.9 | <strong>69.8</strong> |
| الرياضيات | GSM8K (EM) | 8-shot | 81.6 | 88.3 | 83.5 | <strong>89.3</strong> |
| | MATH (EM) | 4-shot | 43.4 | 54.4 | 49.0 | <strong>61.6</strong> |
| | MGSM (EM) | 8-shot | 63.6 | 76.2 | 69.9 | <strong>79.8</strong> |
| | CMath (EM) | 3-shot | 78.7 | 84.5 | 77.3 | <strong>90.7</strong> |
| الصينية | CLUEWSC (EM) | 5-shot | 82.0 | 82.5 | <strong>83.0</strong> | 82.7 |
| | C-Eval (Acc.) | 5-shot | 81.4 | 89.2 | 72.5 | <strong>90.1</strong> |
| | CMMLU (Acc.) | 5-shot | 84.0 | <strong>89.5</strong> | 73.7 | 88.8 |
| | CMRC (EM) | 1-shot | <strong>77.4</strong> | 75.8 | 76.0 | 76.3 |
| | C3 (Acc.) | 0-shot | 77.4 | 76.7 | <strong>79.7</strong> | 78.6 |
| | CCPM (Acc.) | 0-shot | <strong>93.0</strong> | 88.5 | 78.6 | 92.0 |
| متعدد اللغات | MMMLU-non-English (Acc.) | 5-shot | 64.0 | 74.8 | 73.8 | <strong>79.4</strong> |</p>
</div>
<blockquote>
<p>[!NOTE]
تم إبراز أفضل النتائج بالخط العريض. تعتبر الدرجات التي لا يتجاوز الفارق بينها 0.3 ضمن نفس المستوى. يحقق DeepSeek-V3 الأداء الأفضل في معظم المعايير، خاصة في مهام الرياضيات والبرمجة.
لمزيد من التفاصيل حول التقييم، يرجى مراجعة الورقة العلمية.</p>
</blockquote>
<h4>نافذة السياق</h4>
<p align="center">
  <img width="80%" src="figures/niah.png">
</p>
<p>نتائج التقييم على اختبارات &quot;Needle In A Haystack&quot; (NIAH). يُظهر DeepSeek-V3 أداءً جيدًا عبر جميع أطوال نافذة السياق حتى <strong>128K</strong>.</p>
<h3>نموذج الدردشة</h3>
<h4>مقاييس التقييم القياسية (نماذج أكبر من 67 مليار)</h4>
<div align="center">
<p>| | <strong>المعيار (المقياس)</strong> | <strong>DeepSeek V2-0506</strong> | <strong>DeepSeek V2.5-0905</strong> | <strong>Qwen2.5 72B-Inst.</strong> | <strong>Llama3.1 405B-Inst.</strong> | <strong>Claude-3.5-Sonnet-1022</strong> | <strong>GPT-4o 0513</strong> | <strong>DeepSeek V3</strong> |
|---|---------------------|---------------------|----------------------|---------------------|----------------------|---------------------------|----------------|----------------|
| | المعمارية | MoE | MoE | Dense | Dense | - | - | MoE |
| | المعاملات المفعلة | 21B | 21B | 72B | 405B | - | - | 37B |
| | إجمالي المعاملات | 236B | 236B | 72B | 405B | - | - | 671B |
| الإنجليزية | MMLU (EM) | 78.2 | 80.6 | 85.3 | <strong>88.6</strong> | <strong>88.3</strong> | 87.2 | <strong>88.5</strong> |
| | MMLU-Redux (EM) | 77.9 | 80.3 | 85.6 | 86.2 | <strong>88.9</strong> | 88.0 | <strong>89.1</strong> |
| | MMLU-Pro (EM) | 58.5 | 66.2 | 71.6 | 73.3 | <strong>78.0</strong> | 72.6 | 75.9 |
| | DROP (3-shot F1) | 83.0 | 87.8 | 76.7 | 88.7 | 88.3 | 83.7 | <strong>91.6</strong> |
| | IF-Eval (Prompt Strict) | 57.7 | 80.6 | 84.1 | 86.0 | <strong>86.5</strong> | 84.3 | 86.1 |
| | GPQA-Diamond (Pass@1) | 35.3 | 41.3 | 49.0 | 51.1 | <strong>65.0</strong> | 49.9 | 59.1 |
| | SimpleQA (Correct) | 9.0 | 10.2 | 9.1 | 17.1 | 28.4 | <strong>38.2</strong> | 24.9 |
| | FRAMES (Acc.) | 66.9 | 65.4 | 69.8 | 70.0 | 72.5 | <strong>80.5</strong> | 73.3 |
| | LongBench v2 (Acc.) | 31.6 | 35.4 | 39.4 | 36.1 | 41.0 | 48.1 | <strong>48.7</strong> |
| البرمجة | HumanEval-Mul (Pass@1) | 69.3 | 77.4 | 77.3 | 77.2 | 81.7 | 80.5 | <strong>82.6</strong> |
| | LiveCodeBench (Pass@1-COT) | 18.8 | 29.2 | 31.1 | 28.4 | 36.3 | 33.4 | <strong>40.5</strong> |
| | LiveCodeBench (Pass@1) | 20.3 | 28.4 | 28.7 | 30.1 | 32.8 | 34.2 | <strong>37.6</strong> |
| | Codeforces (Percentile) | 17.5 | 35.6 | 24.8 | 25.3 | 20.3 | 23.6 | <strong>51.6</strong> |
| | SWE Verified (Resolved) | - | 22.6 | 23.8 | 24.5 | <strong>50.8</strong> | 38.8 | 42.0 |
| | Aider-Edit (Acc.) | 60.3 | 71.6 | 65.4 | 63.9 | <strong>84.2</strong> | 72.9 | 79.7 |
| | Aider-Polyglot (Acc.) | - | 18.2 | 7.6 | 5.8 | 45.3 | 16.0 | <strong>49.6</strong> |
| الرياضيات | AIME 2024 (Pass@1) | 4.6 | 16.7 | 23.3 | 23.3 | 16.0 | 9.3 | <strong>39.2</strong> |
| | MATH-500 (EM) | 56.3 | 74.7 | 80.0 | 73.8 | 78.3 | 74.6 | <strong>90.2</strong> |
| | CNMO 2024 (Pass@1) | 2.8 | 10.8 | 15.9 | 6.8 | 13.1 | 10.8 | <strong>43.2</strong> |
| الصينية | CLUEWSC (EM) | 89.9 | 90.4 | <strong>91.4</strong> | 84.7 | 85.4 | 87.9 | 90.9 |
| | C-Eval (EM) | 78.6 | 79.5 | 86.1 | 61.5 | 76.7 | 76.0 | <strong>86.5</strong> |
| | C-SimpleQA (Correct) | 48.5 | 54.1 | 48.4 | 50.4 | 51.3 | 59.3 | <strong>64.8</strong> |</p>
</div>
<blockquote>
<p>[!NOTE]
تم تقييم جميع النماذج في وضع يحد من طول الإخراج إلى 8 آلاف رمز. بالنسبة للمعايير التي تحتوي على أقل من 1000 عينة، تم إجراء اختبارات متعددة باستخدام درجات حرارة مختلفة للحصول على نتائج نهائية قوية. يُعد DeepSeek-V3 أفضل نموذج مفتوح المصدر أداءً، كما يظهر أداءً تنافسياً مقابل النماذج مغلقة المصدر الرائدة.</p>
</blockquote>
<h4>تقييم التوليد المفتوح</h4>
<div align="center">
<p>| النموذج | Arena-Hard | AlpacaEval 2.0 |
|-------|------------|----------------|
| DeepSeek-V2.5-0905 | 76.2 | 50.5 |
| Qwen2.5-72B-Instruct | 81.2 | 49.1 |
| LLaMA-3.1 405B | 69.3 | 40.5 |
| GPT-4o-0513 | 80.4 | 51.1 |
| Claude-Sonnet-3.5-1022 | 85.2 | 52.0 |
| DeepSeek-V3 | <strong>85.5</strong> | <strong>70.0</strong> |</p>
</div>
<blockquote>
<p>[!NOTE]
تقييمات محادثة مفتوحة باللغة الإنجليزية. بالنسبة لـ AlpacaEval 2.0، نستخدم معدل الفوز المتحكم في الطول كمقياس.</p>
</blockquote>
<h2>5. موقع الدردشة ومنصة API</h2>
<p>يمكنك الدردشة مع DeepSeek-V3 على الموقع الرسمي: <a href="https://chat.deepseek.com/sign_in">chat.deepseek.com</a></p>
<p>كما نوفر واجهة API متوافقة مع OpenAI على منصة DeepSeek: <a href="https://platform.deepseek.com/">platform.deepseek.com</a></p>
<h2>6. كيفية التشغيل محليًا</h2>
<p>يمكن نشر DeepSeek-V3 محليًا باستخدام العتاد التالي وبرمجيات مجتمعات المصدر المفتوح:</p>
<ol>
<li><strong>عرض DeepSeek-Infer التجريبي</strong>: نوفر عرضًا بسيطًا وخفيفًا للاستدلال بدقة FP8 وBF16.</li>
<li><strong>SGLang</strong>: يدعم نموذج DeepSeek-V3 بشكل كامل في أوضاع الاستدلال BF16 وFP8، مع دعم لتوقع متعدد الرموز <a href="https://github.com/sgl-project/sglang/issues/2591">قريبًا</a>.</li>
<li><strong>LMDeploy</strong>: يتيح استدلال فعال بدقة FP8 وBF16 للنشر المحلي والسحابي.</li>
<li><strong>TensorRT-LLM</strong>: يدعم حاليًا استدلال BF16 والتكميم إلى INT4/8، مع دعم FP8 قريبًا.</li>
<li><strong>vLLM</strong>: يدعم نموذج DeepSeek-V3 بأوضاع FP8 وBF16 للتوازي على مستوى الموتر وخط الأنابيب.</li>
<li><strong>LightLLM</strong>: يدعم النشر الأحادي أو المتعدد للعقد بكفاءة لكل من FP8 وBF16.</li>
<li><strong>معالجات AMD الرسومية</strong>: يتيح تشغيل النموذج على بطاقات AMD عبر SGLang في أوضاع BF16 وFP8.</li>
<li><strong>وحدات هواوي Ascend NPU</strong>: يدعم تشغيل DeepSeek-V3 على أجهزة هواوي Ascend.</li>
</ol>
<p>نظرًا لاعتماد التدريب بدقة FP8 في إطار عملنا، فإننا نوفر فقط أوزان FP8. إذا كنت بحاجة إلى أوزان BF16 للتجارب، يمكنك استخدام سكريبت التحويل المقدم.</p>
<p>فيما يلي مثال لتحويل أوزان FP8 إلى BF16:</p>
<pre><code class="language-shell">cd inference
python fp8_cast_bf16.py --input-fp8-hf-path /path/to/fp8_weights --output-bf16-hf-path /path/to/bf16_weights
</code></pre>
<blockquote>
<p>[!NOTE]
لم يتم دعم مكتبة Transformers الخاصة بـ Hugging Face بشكل مباشر حتى الآن.</p>
</blockquote>
<h3>6.1 الاستدلال باستخدام عرض DeepSeek-Infer التجريبي (للاختبار فقط)</h3>
<h4>متطلبات النظام</h4>
<blockquote>
<p>[!NOTE]
لينكس مع بايثون 3.10 فقط. لا يتم دعم ماك أو ويندوز.</p>
</blockquote>
<p>المتطلبات:</p>
<pre><code class="language-pip-requirements">torch==2.4.1
triton==3.0.0
transformers==4.46.3
safetensors==0.4.5
</code></pre>
<h4>إعداد أوزان النموذج وكود العرض</h4>
<p>أولاً، استنسخ مستودع DeepSeek-V3 من GitHub:</p>
<pre><code class="language-shell">git clone https://github.com/deepseek-ai/DeepSeek-V3.git
</code></pre>
<p>انتقل إلى مجلد <code>inference</code> وقم بتثبيت المتطلبات المذكورة في <code>requirements.txt</code>. أسهل طريقة هي استخدام مدير حزم مثل <code>conda</code> أو <code>uv</code> لإنشاء بيئة افتراضية جديدة وتثبيت المتطلبات.</p>
<pre><code class="language-shell">cd DeepSeek-V3/inference
pip install -r requirements.txt
</code></pre>
<p>نزّل أوزان النموذج من Hugging Face وضعها في مجلد <code>/path/to/DeepSeek-V3</code>.</p>
<h4>تحويل أوزان النموذج</h4>
<p>حوّل أوزان النموذج من Hugging Face إلى تنسيق محدد:</p>
<pre><code class="language-shell">python convert.py --hf-ckpt-path /path/to/DeepSeek-V3 --save-path /path/to/DeepSeek-V3-Demo --n-experts 256 --model-parallel 16
</code></pre>
<h4>التشغيل</h4>
<p>بعد ذلك يمكنك الدردشة مع DeepSeek-V3:</p>
<pre><code class="language-shell">torchrun --nnodes 2 --nproc-per-node 8 --node-rank $RANK --master-addr $ADDR generate.py --ckpt-path /path/to/DeepSeek-V3-Demo --config configs/config_671B.json --interactive --temperature 0.7 --max-new-tokens 200
</code></pre>
<p>أو إجراء استدلال دفعي على ملف معين:</p>
<pre><code class="language-shell">torchrun --nnodes 2 --nproc-per-node 8 --node-rank $RANK --master-addr $ADDR generate.py --ckpt-path /path/to/DeepSeek-V3-Demo --config configs/config_671B.json --input-file $FILE
</code></pre>
<h3>6.2 الاستدلال باستخدام SGLang (موصى به)</h3>
<p>يدعم <a href="https://github.com/sgl-project/sglang">SGLang</a> حاليًا <a href="https://lmsys.org/blog/2024-09-04-sglang-v0-3/#deepseek-multi-head-latent-attention-mla-throughput-optimizations">تحسينات MLA</a>، <a href="https://lmsys.org/blog/2024-12-04-sglang-v0-4/#data-parallelism-attention-for-deepseek-models">انتباه التوازي البياني</a>، FP8 (W8A8)، ذاكرة FP8 KV، وTorch Compile، مما يوفر زمن استجابة وأداء عالي بين الأطر مفتوحة المصدر.</p>
<p>جدير بالذكر أن <a href="https://github.com/sgl-project/sglang/releases/tag/v0.4.1">SGLang v0.4.1</a> يدعم تشغيل DeepSeek-V3 بالكامل على كل من بطاقات NVIDIA وAMD، مما يجعله حلًا قويًا ومرنًا للغاية.</p>
<p>يدعم SGLang أيضًا <a href="https://github.com/sgl-project/sglang/tree/main/benchmark/deepseek_v3#example-serving-with-2-h208">توازي التنسور متعدد العقد</a>، مما يتيح لك تشغيل النموذج على عدة أجهزة متصلة بالشبكة.</p>
<p>توقع متعدد الرموز (MTP) قيد التطوير، ويمكن متابعة التقدم في <a href="https://github.com/sgl-project/sglang/issues/2591">خطة التحسين</a>.</p>
<p>إرشادات التشغيل من فريق SGLang: https://github.com/sgl-project/sglang/tree/main/benchmark/deepseek_v3</p>
<h3>6.3 الاستدلال باستخدام LMDeploy (موصى به)</h3>
<p>يدعم <a href="https://github.com/InternLM/lmdeploy">LMDeploy</a>، وهو إطار استدلال قوي ومرن للنماذج اللغوية الكبيرة، نموذج DeepSeek-V3 الآن. ويوفر معالجة خط الأنابيب غير المتصلة ونشرًا عبر الإنترنت، مع تكامل سهل مع تدفقات عمل PyTorch.</p>
<p>للحصول على تعليمات مفصلة خطوة بخطوة لتشغيل DeepSeek-V3 مع LMDeploy، يرجى الرجوع إلى: https://github.com/InternLM/lmdeploy/issues/2960</p>
<h3>6.4 الاستدلال باستخدام TRT-LLM (موصى به)</h3>
<p>يدعم <a href="https://github.com/NVIDIA/TensorRT-LLM">TensorRT-LLM</a> الآن نموذج DeepSeek-V3، مع خيارات دقة مثل BF16 وINT4/INT8 فقط للأوزان. دعم FP8 قيد التنفيذ وسيتم إصداره قريبًا. يمكنك الوصول إلى الفرع المخصص من TRTLLM لدعم DeepSeek-V3 من خلال الرابط التالي: https://github.com/NVIDIA/TensorRT-LLM/tree/main/examples/deepseek_v3.</p>
<h3>6.5 الاستدلال باستخدام vLLM (موصى به)</h3>
<p>يدعم <a href="https://github.com/vllm-project/vllm">vLLM</a> v0.6.6 استدلال DeepSeek-V3 بأوضاع FP8 وBF16 على كل من NVIDIA وAMD. وبالإضافة إلى التقنيات القياسية، يوفر vLLM <em>توازي خط الأنابيب</em> لتشغيل النموذج على عدة أجهزة متصلة بالشبكة. لمزيد من الإرشادات، يرجى الرجوع إلى <a href="https://docs.vllm.ai/en/latest/serving/distributed_serving.html">تعليمات vLLM</a>. كما يمكنكم متابعة <a href="https://github.com/vllm-project/vllm/issues/11539">خطة التحسين</a>.</p>
<h3>6.6 الاستدلال باستخدام LightLLM (موصى به)</h3>
<p>يدعم <a href="https://github.com/ModelTC/lightllm/tree/main">LightLLM</a> v1.0.1 النشر المتوازي على مستوى التنسور لجهاز واحد أو عدة أجهزة لـ DeepSeek-R1 (FP8/BF16)، ويوفر نشر بدقة مختلطة مع المزيد من أوضاع التكميم المتكاملة باستمرار. للمزيد، راجع <a href="https://lightllm-en.readthedocs.io/en/latest/getting_started/quickstart.html">تعليمات LightLLM</a>. كما يوفر LightLLM نشر PD-disaggregation لـ DeepSeek-V2، وتنفيذ هذه الميزة لـ DeepSeek-V3 قيد التطوير.</p>
<h3>6.7 الاستدلال الموصى به على معالجات AMD</h3>
<p>بالتعاون مع فريق AMD، تم تحقيق دعم Day-One لمعالجات AMD باستخدام SGLang، مع توافق كامل لكل من FP8 وBF16. لمزيد من الإرشادات، راجع <a href="#63-%D8%A7%D9%84%D8%A7%D8%B3%D8%AA%D8%AF%D9%84%D8%A7%D9%84-%D8%A8%D8%A7%D8%B3%D8%AA%D8%AE%D8%AF%D8%A7%D9%85-lmdeploy-%D9%85%D9%88%D8%B5%D9%89-%D8%A8%D9%87">تعليمات SGLang</a>.</p>
<h3>6.8 الاستدلال الموصى به على وحدات هواوي Ascend NPU</h3>
<p>تمكن إطار <a href="https://www.hiascend.com/en/software/mindie">MindIE</a> من مجتمع هواوي Ascend من تكييف نسخة BF16 من DeepSeek-V3 بنجاح. لإرشادات خطوة بخطوة حول أجهزة Ascend، يرجى اتباع <a href="https://modelers.cn/models/MindIE/deepseekv3">التعليمات هنا</a>.</p>
<h2>7. الترخيص</h2>
<p>هذا المستودع مرخص بموجب <a href="LICENSE-CODE">رخصة MIT</a>. استخدام نماذج DeepSeek-V3 Base/Chat يخضع لـ <a href="LICENSE-MODEL">رخصة النموذج</a>. تدعم سلسلة DeepSeek-V3 (بما في ذلك Base وChat) الاستخدام التجاري.</p>
<h2>8. الاستشهاد</h2>
<pre><code>@misc{deepseekai2024deepseekv3technicalreport,
      title={DeepSeek-V3 Technical Report}, 
      author={DeepSeek-AI},
      year={2024},
      eprint={2412.19437},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.19437}, 
}
</code></pre>
<h2>9. التواصل</h2>
<p>إذا كانت لديك أي أسئلة، يرجى فتح تذكرة أو التواصل معنا عبر البريد الإلكتروني <a href="service@deepseek.com">service@deepseek.com</a>.</p>
<hr />
<p><a href="https://github.com/OpenAiTx/OpenAiTx">Powered By OpenAiTx</a></p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
</body>
</html>