<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SinGAN - tamarott/SinGAN zh-TW</title>
    <meta name="title" content="SinGAN - tamarott/SinGAN zh-TW | SinGAN 專案 | Arxiv | CVF | 補充資料 | 演講 (ICCV`19) 論文官方 pytorch 實現：&quot;SinGAN: Learning a Generative Model from a Single Natural Image&quot; ICCV 2019 最佳論文獎 (Marr ...">
    <meta name="description" content="tamarott/SinGAN - GitHub repository zh-TW documentation and information | SinGAN 專案 | Arxiv | CVF | 補充資料 | 演講 (ICCV`19) 論文官方 pytorch 實現：&quot;SinGAN: Learning a Generative Model from a Single Natural Image&quot; ICCV 2019 最佳論文獎 (Marr ...">
    <meta name="keywords" content="tamarott, SinGAN, GitHub, repository, zh-TW documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/tamarott/SinGAN/README-zh-TW.html">
    <meta property="og:title" content="SinGAN - tamarott/SinGAN zh-TW | SinGAN 專案 | Arxiv | CVF | 補充資料 | 演講 (ICCV`19) 論文官方 pytorch 實現：&quot;SinGAN: Learning a Generative Model from a Single Natural Image&quot; ICCV 2019 最佳論文獎 (Marr ...">
    <meta property="og:description" content="tamarott/SinGAN - GitHub repository zh-TW documentation and information | SinGAN 專案 | Arxiv | CVF | 補充資料 | 演講 (ICCV`19) 論文官方 pytorch 實現：&quot;SinGAN: Learning a Generative Model from a Single Natural Image&quot; ICCV 2019 最佳論文獎 (Marr ...">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div style="position: fixed; top: 2px; left: 2px; z-index: 2000; background: rgba(255,255,255,0.95); border-radius: 6px; box-shadow: 0 2px 8px rgba(0,0,0,0.06); padding: 4px 14px; font-size: 15px; color: #222; font-family: 'Segoe UI', Arial, sans-serif; font-weight: 500; letter-spacing: 0.5px;">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" style="color: #0366d6; text-decoration: none; font-weight: 600;">Open AI Tx</a>
    </div>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/tamarott/SinGAN" id="githubRepoLink" target="_blank">tamarott/SinGAN</a>
<h1 style="display: none;">SinGAN 專案 | Arxiv | CVF | 補充資料 | 演講 (ICCV`19) 論文官方 pytorch 實現：&quot;SinGAN: Learning a Generative Model from a Single Natural Image&quot; ICCV 2019 最佳論文獎 (Marr ...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <h1>SinGAN</h1>
<p><a href="https://tamarott.github.io/SinGAN.htm">專案</a> | <a href="https://arxiv.org/pdf/1905.01164.pdf">Arxiv</a> | <a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Shaham_SinGAN_Learning_a_Generative_Model_From_a_Single_Natural_Image_ICCV_2019_paper.pdf">CVF</a> | <a href="https://openaccess.thecvf.com/content_ICCV_2019/supplemental/Shaham_SinGAN_Learning_a_ICCV_2019_supplemental.pdf">補充資料</a> | <a href="https://youtu.be/mdAcPe74tZI?t=3191">演講 (ICCV`19)</a></p>
<h3>論文官方 pytorch 實現：&quot;SinGAN: Learning a Generative Model from a Single Natural Image&quot;</h3>
<h4>ICCV 2019 最佳論文獎 (Marr prize)</h4>
<h2>從<em>單一</em>影像隨機取樣</h2>
<p>使用 SinGAN，您可以從單一自然影像訓練出生成模型，然後從該影像產生隨機樣本，例如：</p>
<p><img src="https://raw.githubusercontent.com/tamarott/SinGAN/master/imgs/teaser.PNG" alt="" /></p>
<h2>SinGAN 的應用</h2>
<p>SinGAN 也可用於多種影像操作任務，例如：
<img src="https://raw.githubusercontent.com/tamarott/SinGAN/master/imgs/manipulation.PNG" alt="" />
這是透過將影像注入已訓練好的模型來實現。詳情請參考我們<a href="https://arxiv.org/pdf/1905.01164.pdf">論文</a>第 4 節。</p>
<h3>引用</h3>
<p>如果您在研究中使用本程式碼，請引用我們的論文：</p>
<pre><code>@inproceedings{rottshaham2019singan,
  title={SinGAN: Learning a Generative Model from a Single Natural Image},
  author={Rott Shaham, Tamar and Dekel, Tali and Michaeli, Tomer},
  booktitle={Computer Vision (ICCV), IEEE International Conference on},
  year={2019}
}
</code></pre>
<h2>程式碼</h2>
<h3>安裝相依套件</h3>
<pre><code>python -m pip install -r requirements.txt
</code></pre>
<p>本程式碼經 Python 3.6、torch 1.4 測試。</p>
<p>請注意：目前僅支援 torch 1.4 或更早版本，這是由於優化方案所致。</p>
<p>如需支援新版 torch，可嘗試此倉庫：https://github.com/kligvasser/SinGAN（結果不一定與官方實現完全一致）。</p>
<h3>訓練</h3>
<p>若要在自有影像上訓練 SinGAN 模型，請將欲訓練影像置於 Input/Images 資料夾下，並執行</p>
<pre><code>python main_train.py --input_name &lt;input_file_name&gt;
</code></pre>
<p>這也會使用訓練完成的模型自最粗尺度 (n=0) 開始產生隨機樣本。</p>
<p>若欲於 CPU 設備執行，請在呼叫 <code>main_train.py</code> 時指定 <code>--not_cuda</code></p>
<h3>隨機取樣</h3>
<p>若要從任意起始生成尺度產生隨機樣本，請先依上述步驟於欲用影像上訓練 SinGAN 模型，然後執行</p>
<pre><code>python random_samples.py --input_name &lt;training_image_file_name&gt; --mode random_samples --gen_start_scale &lt;generation start scale number&gt;
</code></pre>
<p>注意：若要使用完整模型，請將 generation start scale 設為 0；若要自第二尺度起始，請設為 1，依此類推。</p>
<h3>任意尺寸的隨機取樣</h3>
<p>若要產生任意尺寸的隨機樣本，請先依上述步驟於欲用影像上訓練 SinGAN 模型，然後執行</p>
<pre><code>python random_samples.py --input_name &lt;training_image_file_name&gt; --mode random_samples_arbitrary_sizes --scale_h &lt;horizontal scaling factor&gt; --scale_v &lt;vertical scaling factor&gt;
</code></pre>
<h3>從單一影像生成動畫</h3>
<p>若要從單一影像產生短動畫，請執行</p>
<pre><code>python animation.py --input_name &lt;input_file_name&gt; 
</code></pre>
<p>這將自動以噪聲填補模式啟動新訓練階段。</p>
<h3>融合</h3>
<p>若要將貼上的物件與影像融合（請參見<a href="https://arxiv.org/pdf/1905.01164.pdf">論文</a>圖 13 範例），請先在欲用背景影像上訓練 SinGAN 模型（如前述），然後將經簡單貼上的參考影像及其二值遮罩存至 &quot;Input/Harmonization&quot; 目錄下（可參考範例影像）。執行指令</p>
<pre><code>python harmonization.py --input_name &lt;training_image_file_name&gt; --ref_name &lt;naively_pasted_reference_image_file_name&gt; --harmonization_start_scale &lt;scale to inject&gt;

</code></pre>
<p>請注意，注入的尺度不同將產生不同的融合效果。最粗的注入尺度為 1。</p>
<h3>編輯</h3>
<p>若要編輯影像（請參見<a href="https://arxiv.org/pdf/1905.01164.pdf">論文</a>圖 12 範例），請先於欲用非編輯影像上訓練 SinGAN 模型（如前述），然後將簡單編輯結果存為參考影像於 &quot;Input/Editing&quot; 目錄下，並附上對應二值圖（可參考範例影像）。執行指令</p>
<pre><code>python editing.py --input_name &lt;training_image_file_name&gt; --ref_name &lt;edited_image_file_name&gt; --editing_start_scale &lt;scale to inject&gt;
</code></pre>
<pre><code>遮罩與未遮罩的輸出都會被儲存。
同樣地，不同的注入層級會產生不同的編輯效果。最粗的注入層級為 1。

### 由繪畫轉換為影像

要將繪畫轉換為寫實影像（參見[我們的論文](https://arxiv.org/pdf/1905.01164.pdf)中的圖 11），請先在目標影像上訓練 SinGAN 模型（如上所述），然後將你的繪畫儲存在 &quot;Input/Paint&quot; 資料夾下，並執行以下指令：

</code></pre>
<p>python paint2image.py --input_name &lt;training_image_file_name&gt; --ref_name &lt;paint_image_file_name&gt; --paint_start_scale <scale to inject></p>
<pre><code>
同樣地，不同的注入層級會產生不同的編輯效果。最粗的注入層級為 1。

進階選項：將 quantization_flag 設為 True，只對模型的注入層級進行再訓練，以獲得前一層上採樣生成影像的色彩量化版本。對某些影像而言，這可能會導致更寫實的結果。

### 超解析度
若要對影像進行超解析度，請執行：
</code></pre>
<p>python SR.py --input_name &lt;LR_image_file_name&gt;</p>
<pre><code>這將自動訓練一個對應 4 倍上採樣倍率的 SinGAN 模型（若尚未存在）。
如需不同的超解析度倍率，請在呼叫函式時使用參數 `--sr_factor` 指定。
SinGAN 在 BSD100 資料集上的結果可於 'Downloads' 資料夾下載。

## 其他資料與功能

### 單張影像 Fréchet Inception Distance（SIFID 分數）
要計算真實影像與其對應生成樣本之間的 SIFID，請執行：
</code></pre>
<p>python SIFID/sifid_score.py --path2real <real images path> --path2fake <fake images path></p>
<pre><code>請確保每個生成影像的檔名與其對應的真實影像檔名完全相同。影像應以 `.jpg` 格式儲存。

### 超解析度結果
SinGAN 在 BSD100 資料集上的超解析度結果可於 'Downloads' 資料夾下載。

### 使用者研究
用於使用者研究的資料可於 Downloads 資料夾找到。

real 資料夾：50 張真實影像，隨機選自 [places database](http://places.csail.mit.edu/)

fake_high_variance 資料夾：對每張真實影像自 n=N 起的隨機樣本

fake_mid_variance 資料夾：對每張真實影像自 n=N-1 起的隨機樣本

更多細節請參見我們[論文](https://arxiv.org/pdf/1905.01164.pdf)的第 3.1 節。
</code></pre>
<hr />
<p>Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx">Open Ai Tx</a> | Last indexed: 2025-06-29</p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
</body>
</html>