<!DOCTYPE html>
<html lang="nl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SinGAN - tamarott/SinGAN nl</title>
    <meta name="title" content="SinGAN - tamarott/SinGAN nl | SinGAN Project | Arxiv | CVF | Supplementary materials | Talk (ICCV`19) Officiële PyTorch-implementatie van het artikel: &quot;SinGAN: Learning a Generative Mod...">
    <meta name="description" content="tamarott/SinGAN - GitHub repository nl documentation and information | SinGAN Project | Arxiv | CVF | Supplementary materials | Talk (ICCV`19) Officiële PyTorch-implementatie van het artikel: &quot;SinGAN: Learning a Generative Mod...">
    <meta name="keywords" content="tamarott, SinGAN, GitHub, repository, nl documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/tamarott/SinGAN/README-nl.html">
    <meta property="og:title" content="SinGAN - tamarott/SinGAN nl | SinGAN Project | Arxiv | CVF | Supplementary materials | Talk (ICCV`19) Officiële PyTorch-implementatie van het artikel: &quot;SinGAN: Learning a Generative Mod...">
    <meta property="og:description" content="tamarott/SinGAN - GitHub repository nl documentation and information | SinGAN Project | Arxiv | CVF | Supplementary materials | Talk (ICCV`19) Officiële PyTorch-implementatie van het artikel: &quot;SinGAN: Learning a Generative Mod...">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div style="position: fixed; top: 2px; left: 2px; z-index: 2000; background: rgba(255,255,255,0.95); border-radius: 6px; box-shadow: 0 2px 8px rgba(0,0,0,0.06); padding: 4px 14px; font-size: 15px; color: #222; font-family: 'Segoe UI', Arial, sans-serif; font-weight: 500; letter-spacing: 0.5px;">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" style="color: #0366d6; text-decoration: none; font-weight: 600;">Open AI Tx</a>
    </div>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/tamarott/SinGAN" id="githubRepoLink" target="_blank">tamarott/SinGAN</a>
<h1 style="display: none;">SinGAN Project | Arxiv | CVF | Supplementary materials | Talk (ICCV`19) Officiële PyTorch-implementatie van het artikel: &quot;SinGAN: Learning a Generative Mod...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <h1>SinGAN</h1>
<p><a href="https://tamarott.github.io/SinGAN.htm">Project</a> | <a href="https://arxiv.org/pdf/1905.01164.pdf">Arxiv</a> | <a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Shaham_SinGAN_Learning_a_Generative_Model_From_a_Single_Natural_Image_ICCV_2019_paper.pdf">CVF</a> | <a href="https://openaccess.thecvf.com/content_ICCV_2019/supplemental/Shaham_SinGAN_Learning_a_ICCV_2019_supplemental.pdf">Supplementary materials</a> | <a href="https://youtu.be/mdAcPe74tZI?t=3191">Talk (ICCV`19)</a></p>
<h3>Officiële PyTorch-implementatie van het artikel: &quot;SinGAN: Learning a Generative Model from a Single Natural Image&quot;</h3>
<h4>ICCV 2019 Best paper award (Marr prijs)</h4>
<h2>Willekeurige samples van een <em>enkele</em> afbeelding</h2>
<p>Met SinGAN kun je een generatief model trainen op basis van één enkele natuurlijke afbeelding, en vervolgens willekeurige samples genereren van de gegeven afbeelding, bijvoorbeeld:</p>
<p><img src="https://raw.githubusercontent.com/tamarott/SinGAN/master/imgs/teaser.PNG" alt="" /></p>
<h2>Toepassingen van SinGAN</h2>
<p>SinGAN kan ook worden gebruikt voor verschillende beeldbewerkingsdoeleinden, bijvoorbeeld:
<img src="https://raw.githubusercontent.com/tamarott/SinGAN/master/imgs/manipulation.PNG" alt="" />
Dit wordt gedaan door een afbeelding te injecteren in het reeds getrainde model. Zie sectie 4 in ons <a href="https://arxiv.org/pdf/1905.01164.pdf">artikel</a> voor meer details.</p>
<h3>Referentie</h3>
<p>Als je deze code gebruikt voor je onderzoek, citeer dan ons artikel:</p>
<pre><code>@inproceedings{rottshaham2019singan,
  title={SinGAN: Learning a Generative Model from a Single Natural Image},
  author={Rott Shaham, Tamar and Dekel, Tali and Michaeli, Tomer},
  booktitle={Computer Vision (ICCV), IEEE International Conference on},
  year={2019}
}
</code></pre>
<h2>Code</h2>
<h3>Afhankelijkheden installeren</h3>
<pre><code>python -m pip install -r requirements.txt
</code></pre>
<p>Deze code is getest met python 3.6, torch 1.4</p>
<p>Let op: de code ondersteunt momenteel alleen torch 1.4 of ouder vanwege het optimalisatieschema.</p>
<p>Voor latere torch-versies kun je deze repository proberen: https://github.com/kligvasser/SinGAN (de resultaten zullen niet noodzakelijk identiek zijn aan de officiële implementatie).</p>
<h3>Trainen</h3>
<p>Om een SinGAN-model te trainen op je eigen afbeelding, plaats je de gewenste trainingsafbeelding onder Input/Images en voer je uit</p>
<pre><code>python main_train.py --input_name &lt;input_file_name&gt;
</code></pre>
<p>Dit gebruikt ook het resulterende getrainde model om willekeurige samples te genereren vanaf de grofste schaal (n=0).</p>
<p>Om deze code op een CPU-machine uit te voeren, geef je <code>--not_cuda</code> op bij het aanroepen van <code>main_train.py</code></p>
<h3>Willekeurige samples</h3>
<p>Om willekeurige samples te genereren vanaf elke gewenste generatieschaal, train eerst het SinGAN-model op de gewenste afbeelding (zoals hierboven beschreven), voer vervolgens uit</p>
<pre><code>python random_samples.py --input_name &lt;training_image_file_name&gt; --mode random_samples --gen_start_scale &lt;generation start scale number&gt;
</code></pre>
<p>Let op: om het volledige model te gebruiken, stel je de generation start scale in op 0, om te starten vanaf de tweede schaal stel je hem in op 1, enzovoort.</p>
<h3>Willekeurige samples van willekeurige grootte</h3>
<p>Om willekeurige samples van willekeurige grootte te genereren, train eerst het SinGAN-model op de gewenste afbeelding (zoals hierboven beschreven), voer vervolgens uit</p>
<pre><code>python random_samples.py --input_name &lt;training_image_file_name&gt; --mode random_samples_arbitrary_sizes --scale_h &lt;horizontal scaling factor&gt; --scale_v &lt;vertical scaling factor&gt;
</code></pre>
<h3>Animatie uit één enkele afbeelding</h3>
<p>Om een korte animatie te genereren uit een enkele afbeelding, voer uit</p>
<pre><code>python animation.py --input_name &lt;input_file_name&gt; 
</code></pre>
<p>Dit zal automatisch een nieuwe trainingsfase starten met noise padding-modus.</p>
<h3>Harmonisatie</h3>
<p>Om een geplakt object te harmoniseren in een afbeelding (Zie voorbeeld in Fig. 13 in <a href="https://arxiv.org/pdf/1905.01164.pdf">ons artikel</a>), train eerst het SinGAN-model op de gewenste achtergrondafbeelding (zoals hierboven beschreven), sla vervolgens de simpelweg geplakte referentieafbeelding en het bijbehorende binaire masker op onder &quot;Input/Harmonization&quot; (zie opgeslagen afbeeldingen voor een voorbeeld). Voer het commando uit</p>
<pre><code>python harmonization.py --input_name &lt;training_image_file_name&gt; --ref_name &lt;naively_pasted_reference_image_file_name&gt; --harmonization_start_scale &lt;scale to inject&gt;

</code></pre>
<p>Let op dat verschillende injectieschalen verschillende harmonisatie-effecten opleveren. De grofste injectieschaal is gelijk aan 1.</p>
<h3>Bewerken</h3>
<p>Om een afbeelding te bewerken, (Zie voorbeeld in Fig. 12 in <a href="https://arxiv.org/pdf/1905.01164.pdf">ons artikel</a>), train eerst het SinGAN-model op de gewenste onbewerkte afbeelding (zoals hierboven beschreven), sla vervolgens de simpele bewerking op als referentieafbeelding onder &quot;Input/Editing&quot; met een bijbehorende binaire map (zie opgeslagen afbeeldingen voor een voorbeeld). Voer het commando uit</p>
<pre><code>python editing.py --input_name &lt;training_image_file_name&gt; --ref_name &lt;edited_image_file_name&gt; --editing_start_scale &lt;scale to inject&gt;
</code></pre>
<pre><code>zowel de gemaskeerde als ongemaskeerde output zullen worden opgeslagen.
Ook hier zal een andere injectieschaal verschillende bewerkingseffecten opleveren. De grofste injectieschaal is gelijk aan 1.

###  Paint to Image

Om een schilderij om te zetten in een realistisch beeld (zie voorbeeld in Fig. 11 in [onze paper](https://arxiv.org/pdf/1905.01164.pdf)), train eerst het SinGAN-model op het gewenste beeld (zoals hierboven beschreven), sla vervolgens je schilderij op onder &quot;Input/Paint&quot;, en voer het volgende commando uit

</code></pre>
<p>python paint2image.py --input_name &lt;training_image_file_name&gt; --ref_name &lt;paint_image_file_name&gt; --paint_start_scale <scale to inject></p>
<pre><code>Ook hier zal een andere injectieschaal verschillende bewerkingseffecten opleveren. De grofste injectieschaal is gelijk aan 1.

Geavanceerde optie: Specificeer quantization_flag als True, om *alleen* het injectieniveau van het model opnieuw te trainen, om een kleur-gekwantiseerde versie te krijgen van de opgeëxtrapoleerde gegenereerde beelden van de vorige schaal. Voor sommige beelden kan dit tot realistischere resultaten leiden.

### Superresolutie
Om een beeld te vergroten (superresolutie), voer het volgende uit:
</code></pre>
<p>python SR.py --input_name &lt;LR_image_file_name&gt;</p>
<pre><code>Dit traint automatisch een SinGAN-model dat overeenkomt met een 4x upsampling factor (indien nog niet aanwezig).
Voor andere SR-factoren kun je deze specificeren met de parameter `--sr_factor` bij het aanroepen van de functie.
SinGAN's resultaten op de BSD100 dataset kunnen worden gedownload uit de map 'Downloads'.

## Extra Data en Functies

### Single Image Fréchet Inception Distance (SIFID-score)
Om de SIFID tussen echte beelden en hun corresponderende nep-samples te berekenen, voer:
</code></pre>
<p>python SIFID/sifid_score.py --path2real <real images path> --path2fake <fake images path></p>
<pre><code>Zorg ervoor dat elk nepbeeld exact dezelfde bestandsnaam heeft als het corresponderende echte beeld. Afbeeldingen moeten worden opgeslagen in `.jpg`-formaat.

### Superresolutie Resultaten
SinGAN's SR-resultaten op de BSD100 dataset kunnen worden gedownload uit de map 'Downloads'.

### Gebruikersstudie
De data die is gebruikt voor de gebruikersstudie is te vinden in de map Downloads.

real folder: 50 echte afbeeldingen, willekeurig geselecteerd uit de [places database](http://places.csail.mit.edu/)

fake_high_variance folder: willekeurige samples startend vanaf n=N voor elk van de echte beelden

fake_mid_variance folder: willekeurige samples startend vanaf n=N-1 voor elk van de echte beelden

Voor meer details, zie sectie 3.1 in onze [paper](https://arxiv.org/pdf/1905.01164.pdf)
</code></pre>
<hr />
<p>Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx">Open Ai Tx</a> | Last indexed: 2025-06-29</p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
</body>
</html>