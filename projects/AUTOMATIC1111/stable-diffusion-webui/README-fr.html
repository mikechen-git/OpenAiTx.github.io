<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>stable-diffusion-webui - AUTOMATIC1111/stable-diffusion-webui</title>
    <meta name="title" content="stable-diffusion-webui - AUTOMATIC1111/stable-diffusion-webui">
    <meta name="description" content="AUTOMATIC1111/stable-diffusion-webui - GitHub repository fr documentation and informationInterface Web Stable Diffusion Une interface web pour Stable Diffusion, implémentée avec la bibliothèque Gradio. Fonctionnalités Présentation détaillée des fonc...">
    <meta name="keywords" content="AUTOMATIC1111, stable-diffusion-webui, GitHub, repository, fr documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/AUTOMATIC1111/stable-diffusion-webui/README-fr.html">
    <meta property="og:title" content="stable-diffusion-webui - AUTOMATIC1111/stable-diffusion-webui">
    <meta property="og:description" content="AUTOMATIC1111/stable-diffusion-webui - GitHub repository fr documentation and information">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui" id="githubRepoLink" target="_blank">AUTOMATIC1111/stable-diffusion-webui</a>
<h1 style="display: none;">Interface Web Stable Diffusion Une interface web pour Stable Diffusion, implémentée avec la bibliothèque Gradio. Fonctionnalités Présentation détaillée des fonc...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <h1>Interface Web Stable Diffusion</h1>
<p>Une interface web pour Stable Diffusion, implémentée avec la bibliothèque Gradio.</p>
<p><img src="screenshot.png" alt="" /></p>
<h2>Fonctionnalités</h2>
<p><a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features">Présentation détaillée des fonctionnalités avec images</a> :</p>
<ul>
<li>Modes originaux txt2img et img2img</li>
<li>Script d'installation et d'exécution en un clic (il faut quand même installer Python et Git)</li>
<li>Outpainting</li>
<li>Inpainting</li>
<li>Color Sketch (croquis en couleur)</li>
<li>Matrice de prompts</li>
<li>Upscale Stable Diffusion</li>
<li>Attention, spécification des parties du texte auxquelles le modèle doit prêter plus d'attention
<ul>
<li>un homme en <code>((smoking))</code> - mettra plus d'attention sur &quot;smoking&quot;</li>
<li>un homme en <code>(smoking:1.21)</code> - syntaxe alternative</li>
<li>sélectionnez du texte et appuyez sur <code>Ctrl+Up</code> ou <code>Ctrl+Down</code> (ou <code>Command+Up</code> ou <code>Command+Down</code> sur MacOS) pour ajuster automatiquement l'attention sur le texte sélectionné (code contribué par un utilisateur anonyme)</li>
</ul>
</li>
<li>Loopback, traitement img2img plusieurs fois</li>
<li>Tracé X/Y/Z, pour générer un graphe 3D d'images avec différents paramètres</li>
<li>Textual Inversion
<ul>
<li>autant d'embeddings que souhaité et noms personnalisés</li>
<li>utilisation de multiples embeddings avec différents nombres de vecteurs par token</li>
<li>fonctionne avec des nombres à virgule flottante en demi-précision</li>
<li>entraînement des embeddings sur 8 Go (aussi des retours de fonctionnement sur 6 Go)</li>
</ul>
</li>
<li>Onglet &quot;Extras&quot; avec :
<ul>
<li>GFPGAN, réseau de neurones pour corriger les visages</li>
<li>CodeFormer, outil de restauration du visage en alternative à GFPGAN</li>
<li>RealESRGAN, upscaler neuronal</li>
<li>ESRGAN, upscaler neuronal avec de nombreux modèles tiers</li>
<li>SwinIR et Swin2SR (<a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/pull/2092">voir ici</a>), upscalers neuronaux</li>
<li>LDSR, super résolution par diffusion latente</li>
</ul>
</li>
<li>Options de redimensionnement du ratio d'aspect</li>
<li>Sélection de la méthode d'échantillonnage
<ul>
<li>Ajustement de la valeur eta du sampler (multiplicateur de bruit)</li>
<li>Options avancées de configuration du bruit</li>
</ul>
</li>
<li>Interruption du traitement à tout moment</li>
<li>Prise en charge de cartes vidéo 4 Go (retours aussi sur 2 Go)</li>
<li>Graines correctes pour les lots</li>
<li>Validation en direct de la longueur des tokens du prompt</li>
<li>Paramètres de génération
<ul>
<li>les paramètres utilisés pour générer une image sont enregistrés avec cette image</li>
<li>dans les chunks PNG pour PNG, dans l'EXIF pour JPEG</li>
<li>glisser l'image dans l'onglet PNG info pour restaurer les paramètres de génération et les copier automatiquement dans l'UI</li>
<li>désactivable dans les paramètres</li>
<li>glisser-déposer une image/texte-paramètres dans la boîte de prompt</li>
</ul>
</li>
<li>Bouton &quot;Lire les paramètres de génération&quot;, charge les paramètres du prompt dans l'UI</li>
<li>Page de paramètres</li>
<li>Exécution de code Python arbitraire depuis l'UI (doit être lancé avec <code>--allow-code</code> pour activer)</li>
<li>Astuces au survol de la souris pour la plupart des éléments UI</li>
<li>Possibilité de modifier les valeurs par défaut/min/max/pas pour les éléments UI via un fichier de config texte</li>
<li>Prise en charge du tiling, case à cocher pour générer des images carrelables comme des textures</li>
<li>Barre de progression et aperçu en direct de la génération d'image
<ul>
<li>Possibilité d'utiliser un réseau de neurones séparé pour les aperçus, avec très peu de VRAM ou de calcul requis</li>
</ul>
</li>
<li>Négatif prompt, un champ texte supplémentaire pour spécifier ce que vous ne voulez pas voir dans l'image générée</li>
<li>Styles, possibilité d'enregistrer une partie du prompt et de l'appliquer facilement via un menu déroulant</li>
<li>Variations, générer la même image avec de petites différences</li>
<li>Redimensionnement de graine, générer la même image à une résolution légèrement différente</li>
<li>CLIP interrogator, bouton pour deviner le prompt à partir d'une image</li>
<li>Édition de prompt, possibilité de changer le prompt en cours de génération, par exemple commencer avec une pastèque puis passer à une fille anime en cours de route</li>
<li>Traitement par lots, traitement d'un groupe de fichiers via img2img</li>
<li>Img2img Alternative, méthode inversée d'Euler pour le contrôle cross-attention</li>
<li>Correction haute résolution, option pratique pour produire des images haute résolution en un clic sans les distorsions habituelles</li>
<li>Rechargement des checkpoints à la volée</li>
<li>Fusion de checkpoints, onglet permettant de fusionner jusqu'à 3 checkpoints en un seul</li>
<li><a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Custom-Scripts">Scripts personnalisés</a> avec de nombreuses extensions communautaires</li>
<li><a href="https://energy-based-model.github.io/Compositional-Visual-Generation-with-Composable-Diffusion-Models/">Composable-Diffusion</a>, possibilité d'utiliser plusieurs prompts simultanément
<ul>
<li>séparez les prompts avec un <code>AND</code> majuscule</li>
<li>prend aussi en charge les poids de prompt : <code>un chat :1.2 AND un chien AND un pingouin :2.2</code></li>
</ul>
</li>
<li>Pas de limite de tokens pour les prompts (la diffusion stable originale limite à 75 tokens)</li>
<li>Intégration DeepDanbooru, création de tags style danbooru pour les prompts anime</li>
<li><a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Xformers">xformers</a>, augmentation majeure de la vitesse pour certaines cartes (ajouter <code>--xformers</code> aux arguments de ligne de commande)</li>
<li>via extension : <a href="https://github.com/yfszzx/stable-diffusion-webui-images-browser">Onglet Historique</a> : visualisez, gérez et supprimez facilement les images dans l'UI</li>
<li>Option &quot;Générer indéfiniment&quot;</li>
<li>Onglet Entraînement
<ul>
<li>options pour hypernetworks et embeddings</li>
<li>Prétraitement des images : recadrage, effet miroir, autotagging via BLIP ou deepdanbooru (pour l'anime)</li>
</ul>
</li>
<li>Clip skip</li>
<li>Hypernetworks</li>
<li>Loras (identiques aux Hypernetworks mais plus élégants)</li>
<li>Une UI séparée où vous pouvez choisir, avec aperçu, les embeddings, hypernetworks ou Loras à ajouter à votre prompt</li>
<li>Possibilité de sélectionner un autre VAE à charger dans les paramètres</li>
<li>Estimation du temps restant dans la barre de progression</li>
<li>API</li>
<li>Prise en charge du <a href="https://github.com/runwayml/stable-diffusion#inpainting-with-stable-diffusion">modèle d'inpainting dédié</a> de RunwayML</li>
<li>via extension : <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui-aesthetic-gradients">Aesthetic Gradients</a>, générer des images avec une esthétique spécifique via des embeddings d'images clip (implémentation de <a href="https://github.com/vicgalle/stable-diffusion-aesthetic-gradients">https://github.com/vicgalle/stable-diffusion-aesthetic-gradients</a>)</li>
<li>Prise en charge de <a href="https://github.com/Stability-AI/stablediffusion">Stable Diffusion 2.0</a> - voir <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features#stable-diffusion-20">wiki</a> pour les instructions</li>
<li>Prise en charge de <a href="https://arxiv.org/abs/2211.06679">Alt-Diffusion</a> - voir <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features#alt-diffusion">wiki</a> pour les instructions</li>
<li>Plus aucune lettre interdite !</li>
<li>Chargement des checkpoints au format safetensors</li>
<li>Restriction de résolution assouplie : les dimensions de l'image générée doivent être un multiple de 8 (au lieu de 64)</li>
<li>Licence désormais incluse !</li>
<li>Réorganisation des éléments de l'UI depuis l'écran des paramètres</li>
<li>Prise en charge de <a href="https://huggingface.co/segmind/SSD-1B">Segmind Stable Diffusion</a></li>
</ul>
<h2>Installation et Exécution</h2>
<p>Assurez-vous que les <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Dependencies">dépendances requises</a> sont installées et suivez les instructions selon votre matériel :</p>
<ul>
<li><a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-NVidia-GPUs">NVidia</a> (recommandé)</li>
<li><a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-AMD-GPUs">AMD</a> GPUs</li>
<li><a href="https://github.com/openvinotoolkit/stable-diffusion-webui/wiki/Installation-on-Intel-Silicon">CPUs Intel, GPUs Intel (intégrés et dédiés)</a> (page wiki externe)</li>
<li><a href="https://github.com/wangshuai09/stable-diffusion-webui/wiki/Install-and-run-on-Ascend-NPUs">Ascend NPUs</a> (page wiki externe)</li>
</ul>
<p>Alternativement, utilisez des services en ligne (comme Google Colab) :</p>
<ul>
<li><a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Online-Services">Liste des services en ligne</a></li>
</ul>
<h3>Installation sur Windows 10/11 avec GPU NVidia via le package de release</h3>
<ol>
<li>Téléchargez <code>sd.webui.zip</code> depuis <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/releases/tag/v1.0.0-pre">v1.0.0-pre</a> et extrayez son contenu.</li>
<li>Exécutez <code>update.bat</code>.</li>
<li>Exécutez <code>run.bat</code>.</li>
</ol>
<blockquote>
<p>Pour plus de détails, voir <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-NVidia-GPUs">Install-and-Run-on-NVidia-GPUs</a></p>
</blockquote>
<h3>Installation automatique sur Windows</h3>
<ol>
<li>Installez <a href="https://www.python.org/downloads/release/python-3106/">Python 3.10.6</a> (les versions plus récentes de Python ne sont pas compatibles avec torch), en cochant &quot;Add Python to PATH&quot;.</li>
<li>Installez <a href="https://git-scm.com/download/win">git</a>.</li>
<li>Téléchargez le dépôt stable-diffusion-webui, par exemple via la commande <code>git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git</code>.</li>
<li>Exécutez <code>webui-user.bat</code> depuis l'Explorateur Windows en tant qu'utilisateur normal (non administrateur).</li>
</ol>
<h3>Installation automatique sur Linux</h3>
<ol>
<li>Installez les dépendances :</li>
</ol>
<pre><code class="language-bash"># Basé sur Debian :
sudo apt install wget git python3 python3-venv libgl1 libglib2.0-0
# Basé sur Red Hat :
sudo dnf install wget git python3 gperftools-libs libglvnd-glx
# Basé sur openSUSE :
sudo zypper install wget git python3 libtcmalloc4 libglvnd
# Basé sur Arch :
sudo pacman -S wget git python3
</code></pre>
<p>Si votre système est très récent, vous devez installer python3.11 ou python3.10 :</p>
<pre><code class="language-bash"># Ubuntu 24.04
sudo add-apt-repository ppa:deadsnakes/ppa
sudo apt update
sudo apt install python3.11

# Manjaro/Arch
sudo pacman -S yay
yay -S python311 # ne pas confondre avec le package python3.11

# Uniquement pour 3.11
# Puis configurez la variable d'environnement dans le script de lancement
export python_cmd=&quot;python3.11&quot;
# ou dans webui-user.sh
python_cmd=&quot;python3.11&quot;
</code></pre>
<ol start="2">
<li>Placez-vous dans le dossier où vous souhaitez installer le webui et exécutez la commande suivante :</li>
</ol>
<pre><code class="language-bash">wget -q https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/webui.sh
</code></pre>
<p>Ou clonez simplement le dépôt où vous le souhaitez :</p>
<pre><code class="language-bash">git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui
</code></pre>
<ol start="3">
<li>Exécutez <code>webui.sh</code>.</li>
<li>Consultez <code>webui-user.sh</code> pour les options.</li>
</ol>
<h3>Installation sur Apple Silicon</h3>
<p>Consultez les instructions <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Installation-on-Apple-Silicon">ici</a>.</p>
<h2>Contribution</h2>
<p>Pour savoir comment contribuer à ce dépôt : <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing">Contributing</a></p>
<h2>Documentation</h2>
<p>La documentation a été déplacée de ce README vers le <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki">wiki du projet</a>.</p>
<p>Pour permettre à Google et autres moteurs de recherche d'indexer le wiki, voici un lien vers le <a href="https://github-wiki-see.page/m/AUTOMATIC1111/stable-diffusion-webui/wiki">wiki crawlable</a> (pas destiné à la lecture humaine).</p>
<h2>Crédits</h2>
<p>Les licences des codes utilisés sont disponibles dans l'écran <code>Paramètres -&gt; Licences</code>, et aussi dans le fichier <code>html/licenses.html</code>.</p>
<ul>
<li>Stable Diffusion - https://github.com/Stability-AI/stablediffusion, https://github.com/CompVis/taming-transformers, https://github.com/mcmonkey4eva/sd3-ref</li>
<li>k-diffusion - https://github.com/crowsonkb/k-diffusion.git</li>
<li>Spandrel - https://github.com/chaiNNer-org/spandrel implémentant
<ul>
<li>GFPGAN - https://github.com/TencentARC/GFPGAN.git</li>
<li>CodeFormer - https://github.com/sczhou/CodeFormer</li>
<li>ESRGAN - https://github.com/xinntao/ESRGAN</li>
<li>SwinIR - https://github.com/JingyunLiang/SwinIR</li>
<li>Swin2SR - https://github.com/mv-lab/swin2sr</li>
</ul>
</li>
<li>LDSR - https://github.com/Hafiidz/latent-diffusion</li>
<li>MiDaS - https://github.com/isl-org/MiDaS</li>
<li>Idées d'optimisations - https://github.com/basujindal/stable-diffusion</li>
<li>Optimisation de couche Cross Attention - Doggettx - https://github.com/Doggettx/stable-diffusion, idée originale pour l'édition de prompt.</li>
<li>Optimisation de couche Cross Attention - InvokeAI, lstein - https://github.com/invoke-ai/InvokeAI (à l'origine http://github.com/lstein/stable-diffusion)</li>
<li>Optimisation sub-quadratique de couche Cross Attention - Alex Birch (https://github.com/Birch-san/diffusers/pull/1), Amin Rezaei (https://github.com/AminRezaei0x443/memory-efficient-attention)</li>
<li>Textual Inversion - Rinon Gal - https://github.com/rinongal/textual_inversion (nous n'utilisons pas son code, mais ses idées)</li>
<li>Idée pour SD upscale - https://github.com/jquesnelle/txt2imghd</li>
<li>Génération de bruit pour outpainting mk2 - https://github.com/parlance-zz/g-diffuser-bot</li>
<li>Idée et code emprunté pour CLIP interrogator - https://github.com/pharmapsychotic/clip-interrogator</li>
<li>Idée pour Composable Diffusion - https://github.com/energy-based-model/Compositional-Visual-Generation-with-Composable-Diffusion-Models-PyTorch</li>
<li>xformers - https://github.com/facebookresearch/xformers</li>
<li>DeepDanbooru - interrogateur pour diffuseurs anime https://github.com/KichangKim/DeepDanbooru</li>
<li>Échantillonnage en précision float32 depuis un UNet float16 - marunine pour l'idée, Birch-san pour l'exemple d'implémentation Diffusers (https://github.com/Birch-san/diffusers-play/tree/92feee6)</li>
<li>Instruct pix2pix - Tim Brooks (star), Aleksander Holynski (star), Alexei A. Efros (no star) - https://github.com/timothybrooks/instruct-pix2pix</li>
<li>Conseil de sécurité - RyotaK</li>
<li>Échantillonneur UniPC - Wenliang Zhao - https://github.com/wl-zhao/UniPC</li>
<li>TAESD - Ollin Boer Bohan - https://github.com/madebyollin/taesd</li>
<li>LyCORIS - KohakuBlueleaf</li>
<li>Restart sampling - lambertae - https://github.com/Newbeeer/diffusion_restart_sampling</li>
<li>Hypertile - tfernd - https://github.com/tfernd/HyperTile</li>
<li>Script Gradio initial - posté sur 4chan par un utilisateur anonyme. Merci à l'utilisateur anonyme.</li>
<li>(Vous)</li>
</ul>
<hr />
<p><a href="https://github.com/OpenAiTx/OpenAiTx">Powered By OpenAiTx</a></p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
</body>
</html>