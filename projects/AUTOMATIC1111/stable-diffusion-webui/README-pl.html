<!DOCTYPE html>
<html lang="pl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>stable-diffusion-webui - AUTOMATIC1111/stable-diffusion-webui</title>
    <meta name="title" content="stable-diffusion-webui - AUTOMATIC1111/stable-diffusion-webui">
    <meta name="description" content="AUTOMATIC1111/stable-diffusion-webui - GitHub repository pl documentation and informationStable Diffusion web UI Interfejs internetowy dla Stable Diffusion, zaimplementowany przy użyciu biblioteki Gradio. Funkcje Szczegółowy przegląd funkcji ze zrzu...">
    <meta name="keywords" content="AUTOMATIC1111, stable-diffusion-webui, GitHub, repository, pl documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/AUTOMATIC1111/stable-diffusion-webui/README-pl.html">
    <meta property="og:title" content="stable-diffusion-webui - AUTOMATIC1111/stable-diffusion-webui">
    <meta property="og:description" content="AUTOMATIC1111/stable-diffusion-webui - GitHub repository pl documentation and information">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui" id="githubRepoLink" target="_blank">AUTOMATIC1111/stable-diffusion-webui</a>
<h1 style="display: none;">Stable Diffusion web UI Interfejs internetowy dla Stable Diffusion, zaimplementowany przy użyciu biblioteki Gradio. Funkcje Szczegółowy przegląd funkcji ze zrzu...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <h1>Stable Diffusion web UI</h1>
<p>Interfejs internetowy dla Stable Diffusion, zaimplementowany przy użyciu biblioteki Gradio.</p>
<p><img src="screenshot.png" alt="" /></p>
<h2>Funkcje</h2>
<p><a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features">Szczegółowy przegląd funkcji ze zrzutami ekranu</a>:</p>
<ul>
<li>Oryginalne tryby txt2img i img2img</li>
<li>Skrypt instalacji i uruchamiania jednym kliknięciem (należy wcześniej zainstalować Pythona i git)</li>
<li>Outpainting</li>
<li>Inpainting</li>
<li>Color Sketch</li>
<li>Prompt Matrix</li>
<li>Stable Diffusion Upscale</li>
<li>Attention – możliwość wskazania fragmentów tekstu, na które model powinien zwrócić większą uwagę
<ul>
<li>a man in a <code>((tuxedo))</code> – większa uwaga na smoking</li>
<li>a man in a <code>(tuxedo:1.21)</code> – alternatywna składnia</li>
<li>zaznacz tekst i naciśnij <code>Ctrl+Góra</code> lub <code>Ctrl+Dół</code> (lub <code>Command+Góra</code> / <code>Command+Dół</code> na MacOS), by automatycznie regulować uwagę na zaznaczony tekst (kod współtworzony przez anonimowego użytkownika)</li>
</ul>
</li>
<li>Loopback – wielokrotne przetwarzanie img2img</li>
<li>Wykres X/Y/Z – sposób rysowania trójwymiarowych wykresów obrazów z różnymi parametrami</li>
<li>Textual Inversion
<ul>
<li>dowolna liczba embeddingów i dowolne nazwy</li>
<li>możliwość użycia wielu embeddingów z różną liczbą wektorów na token</li>
<li>obsługa liczb zmiennoprzecinkowych o połowicznej precyzji</li>
<li>trening embeddingów na 8GB VRAM (są też doniesienia o pracy na 6GB)</li>
</ul>
</li>
<li>Zakładka Extras z:
<ul>
<li>GFPGAN – sieć neuronowa poprawiająca twarze</li>
<li>CodeFormer – narzędzie do rekonstrukcji twarzy, alternatywa dla GFPGAN</li>
<li>RealESRGAN – sieć neuronowa do powiększania obrazów</li>
<li>ESRGAN – sieć neuronowa do powiększania obrazów z wieloma modelami zewnętrznymi</li>
<li>SwinIR i Swin2SR (<a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/pull/2092">szczegóły</a>), sieci neuronowe do powiększania obrazów</li>
<li>LDSR – powiększanie superrozdzielczości za pomocą latent diffusion</li>
</ul>
</li>
<li>Opcje zmiany proporcji przy skalowaniu</li>
<li>Wybór metody próbkowania
<ul>
<li>Regulacja wartości eta samplera (mnożnik szumu)</li>
<li>Zaawansowane opcje ustawień szumu</li>
</ul>
</li>
<li>Możliwość przerwania przetwarzania w dowolnym momencie</li>
<li>Obsługa kart graficznych 4GB VRAM (są też doniesienia o 2GB)</li>
<li>Poprawne nasiona dla batchy</li>
<li>Walidacja długości promptu w czasie rzeczywistym</li>
<li>Parametry generowania
<ul>
<li>parametry użyte do wygenerowania obrazu są zapisywane z tym obrazem</li>
<li>w chunkach PNG dla PNG, w EXIF dla JPEG</li>
<li>przeciągnij obrazek do zakładki PNG info, by przywrócić parametry generowania i automatycznie skopiować je do UI</li>
<li>można wyłączyć w ustawieniach</li>
<li>przeciągnij i upuść obrazek/parametry tekstowe do promptboxa</li>
</ul>
</li>
<li>Przycisk &quot;Read Generation Parameters&quot; ładuje parametry promptu do UI</li>
<li>Strona ustawień</li>
<li>Uruchamianie dowolnego kodu Pythona z UI (należy uruchomić z <code>--allow-code</code>)</li>
<li>Podpowiedzi po najechaniu myszką dla większości elementów UI</li>
<li>Możliwość zmiany wartości domyślnych/min/maks/kroku elementów UI przez plik tekstowy konfiguracyjny</li>
<li>Obsługa tilingu – opcja tworzenia obrazów możliwych do kafelkowania jak tekstury</li>
<li>Pasek postępu i podgląd generowanego obrazu na żywo
<ul>
<li>Możliwość użycia oddzielnej sieci neuronowej do podglądu przy minimalnym użyciu VRAM i mocy obliczeniowej</li>
</ul>
</li>
<li>Negative prompt – dodatkowe pole tekstowe pozwalające określić, czego nie chcesz widzieć na obrazie</li>
<li>Style – możliwość zapisania fragmentu promptu i późniejszego, łatwego użycia przez rozwijane menu</li>
<li>Wariacje – generowanie tych samych obrazów z drobnymi różnicami</li>
<li>Seed resizing – generowanie tego samego obrazu w lekko innej rozdzielczości</li>
<li>CLIP interrogator – przycisk próbujący odgadnąć prompt z obrazu</li>
<li>Prompt Editing – możliwość zmiany promptu w trakcie generacji, np. rozpoczęcie od arbuza i przejście do dziewczyny z anime w połowie procesu</li>
<li>Batch Processing – przetwarzanie grupy plików przy użyciu img2img</li>
<li>Img2img Alternative – odwrotna metoda Eulera kontroli cross-attention</li>
<li>Highres Fix – opcja wygenerowania obrazów w wysokiej rozdzielczości jednym kliknięciem bez typowych zniekształceń</li>
<li>Przeładowanie checkpointów bez restartu</li>
<li>Checkpoint Merger – zakładka pozwalająca połączyć do 3 checkpointów w jeden</li>
<li><a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Custom-Scripts">Skrypty niestandardowe</a> z wieloma rozszerzeniami społeczności</li>
<li><a href="https://energy-based-model.github.io/Compositional-Visual-Generation-with-Composable-Diffusion-Models/">Composable-Diffusion</a> – możliwość używania wielu promptów jednocześnie
<ul>
<li>oddziel prompty wielkimi literami <code>AND</code></li>
<li>obsługa wag promptów: <code>a cat :1.2 AND a dog AND a penguin :2.2</code></li>
</ul>
</li>
<li>Brak limitu tokenów w promptach (oryginalny stable diffusion pozwalał na 75 tokenów)</li>
<li>Integracja DeepDanbooru – generuje tagi w stylu danbooru dla promptów anime</li>
<li><a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Xformers">xformers</a> – znaczne przyspieszenie dla wybranych kart (dodaj <code>--xformers</code> do argumentów linii poleceń)</li>
<li>przez rozszerzenie: <a href="https://github.com/yfszzx/stable-diffusion-webui-images-browser">Zakładka historii</a>: wygodne przeglądanie, usuwanie i zarządzanie obrazami z poziomu UI</li>
<li>Opcja &quot;Generate forever&quot;</li>
<li>Zakładka treningu
<ul>
<li>opcje hypernetworków i embeddingów</li>
<li>Preprocessing obrazów: kadrowanie, odbijanie lustrzane, autotagowanie przez BLIP lub deepdanbooru (dla anime)</li>
</ul>
</li>
<li>Clip skip</li>
<li>Hypernetworks</li>
<li>Loras (jak Hypernetworks, ale bardziej przejrzyste)</li>
<li>Oddzielny UI pozwalający wybierać (z podglądem) embeddingi, hypernetworki lub Loras do promptu</li>
<li>Możliwość wyboru innego VAE z poziomu ustawień</li>
<li>Szacowany czas zakończenia w pasku postępu</li>
<li>API</li>
<li>Obsługa dedykowanego <a href="https://github.com/runwayml/stable-diffusion#inpainting-with-stable-diffusion">modelu inpaintingu</a> od RunwayML</li>
<li>przez rozszerzenie: <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui-aesthetic-gradients">Aesthetic Gradients</a> – generowanie obrazów o określonej estetyce przy użyciu embedów obrazów z CLIP (implementacja <a href="https://github.com/vicgalle/stable-diffusion-aesthetic-gradients">https://github.com/vicgalle/stable-diffusion-aesthetic-gradients</a>)</li>
<li>Wsparcie dla <a href="https://github.com/Stability-AI/stablediffusion">Stable Diffusion 2.0</a> – instrukcje w <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features#stable-diffusion-20">wiki</a></li>
<li>Wsparcie dla <a href="https://arxiv.org/abs/2211.06679">Alt-Diffusion</a> – instrukcje w <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features#alt-diffusion">wiki</a></li>
<li>Teraz bez żadnych niepożądanych znaków!</li>
<li>Ładowanie checkpointów w formacie safetensors</li>
<li>Złagodzone ograniczenie rozdzielczości: wymiary wygenerowanego obrazu muszą być wielokrotnością 8 (zamiast 64)</li>
<li>Teraz z licencją!</li>
<li>Przestawianie elementów w UI z poziomu ustawień</li>
<li>Wsparcie dla <a href="https://huggingface.co/segmind/SSD-1B">Segmind Stable Diffusion</a></li>
</ul>
<h2>Instalacja i uruchamianie</h2>
<p>Upewnij się, że spełnione są wymagane <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Dependencies">zależności</a> i postępuj według instrukcji dla:</p>
<ul>
<li><a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-NVidia-GPUs">NVidia</a> (zalecane)</li>
<li><a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-AMD-GPUs">AMD</a> GPU</li>
<li><a href="https://github.com/openvinotoolkit/stable-diffusion-webui/wiki/Installation-on-Intel-Silicon">Intel CPU, Intel GPU (zintegrowane i dedykowane)</a> (zewnętrzna wiki)</li>
<li><a href="https://github.com/wangshuai09/stable-diffusion-webui/wiki/Install-and-run-on-Ascend-NPUs">Ascend NPU</a> (zewnętrzna wiki)</li>
</ul>
<p>Alternatywnie można korzystać z usług online (np. Google Colab):</p>
<ul>
<li><a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Online-Services">Lista usług online</a></li>
</ul>
<h3>Instalacja na Windows 10/11 z kartą NVidia przy użyciu paczki release</h3>
<ol>
<li>Pobierz <code>sd.webui.zip</code> z <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/releases/tag/v1.0.0-pre">v1.0.0-pre</a> i wypakuj zawartość.</li>
<li>Uruchom <code>update.bat</code>.</li>
<li>Uruchom <code>run.bat</code>.</li>
</ol>
<blockquote>
<p>Szczegóły w <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-NVidia-GPUs">Install-and-Run-on-NVidia-GPUs</a></p>
</blockquote>
<h3>Automatyczna instalacja na Windows</h3>
<ol>
<li>Zainstaluj <a href="https://www.python.org/downloads/release/python-3106/">Python 3.10.6</a> (nowsze wersje nie obsługują torch), zaznaczając &quot;Add Python to PATH&quot;.</li>
<li>Zainstaluj <a href="https://git-scm.com/download/win">git</a>.</li>
<li>Pobierz repozytorium stable-diffusion-webui, np. uruchamiając <code>git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git</code>.</li>
<li>Uruchom <code>webui-user.bat</code> z Eksploratora Windows jako zwykły (nie administrator) użytkownik.</li>
</ol>
<h3>Automatyczna instalacja na Linux</h3>
<ol>
<li>Zainstaluj zależności:</li>
</ol>
<pre><code class="language-bash"># Dystrybucje Debian:
sudo apt install wget git python3 python3-venv libgl1 libglib2.0-0
# Dystrybucje Red Hat:
sudo dnf install wget git python3 gperftools-libs libglvnd-glx
# openSUSE:
sudo zypper install wget git python3 libtcmalloc4 libglvnd
# Arch:
sudo pacman -S wget git python3
</code></pre>
<p>Jeśli Twój system jest bardzo nowy, zainstaluj python3.11 lub python3.10:</p>
<pre><code class="language-bash"># Ubuntu 24.04
sudo add-apt-repository ppa:deadsnakes/ppa
sudo apt update
sudo apt install python3.11

# Manjaro/Arch
sudo pacman -S yay
yay -S python311 # nie mylić z pakietem python3.11

# Tylko dla 3.11
# Następnie ustaw zmienną środowiskową w skrypcie startowym
export python_cmd=&quot;python3.11&quot;
# lub w webui-user.sh
python_cmd=&quot;python3.11&quot;
</code></pre>
<ol start="2">
<li>Przejdź do katalogu, w którym chcesz zainstalować webui i wykonaj polecenie:</li>
</ol>
<pre><code class="language-bash">wget -q https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/webui.sh
</code></pre>
<p>Lub po prostu sklonuj repozytorium gdzie chcesz:</p>
<pre><code class="language-bash">git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui
</code></pre>
<ol start="3">
<li>Uruchom <code>webui.sh</code>.</li>
<li>Sprawdź <code>webui-user.sh</code> pod kątem opcji.</li>
</ol>
<h3>Instalacja na Apple Silicon</h3>
<p>Instrukcje znajdziesz <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Installation-on-Apple-Silicon">tutaj</a>.</p>
<h2>Współtworzenie</h2>
<p>Jak dodać kod do tego repozytorium: <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing">Contributing</a></p>
<h2>Dokumentacja</h2>
<p>Dokumentacja została przeniesiona z tego README do <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki">wiki projektu</a>.</p>
<p>Aby Google i inne wyszukiwarki mogły indeksować wiki, poniżej znajduje się link do (nie dla ludzi) <a href="https://github-wiki-see.page/m/AUTOMATIC1111/stable-diffusion-webui/wiki">crawlable wiki</a>.</p>
<h2>Zasługi</h2>
<p>Licencje dla zapożyczonego kodu znajdują się w ekranie <code>Ustawienia -&gt; Licencje</code> oraz w pliku <code>html/licenses.html</code>.</p>
<ul>
<li>Stable Diffusion - https://github.com/Stability-AI/stablediffusion, https://github.com/CompVis/taming-transformers, https://github.com/mcmonkey4eva/sd3-ref</li>
<li>k-diffusion - https://github.com/crowsonkb/k-diffusion.git</li>
<li>Spandrel - https://github.com/chaiNNer-org/spandrel implementujący
<ul>
<li>GFPGAN - https://github.com/TencentARC/GFPGAN.git</li>
<li>CodeFormer - https://github.com/sczhou/CodeFormer</li>
<li>ESRGAN - https://github.com/xinntao/ESRGAN</li>
<li>SwinIR - https://github.com/JingyunLiang/SwinIR</li>
<li>Swin2SR - https://github.com/mv-lab/swin2sr</li>
</ul>
</li>
<li>LDSR - https://github.com/Hafiidz/latent-diffusion</li>
<li>MiDaS - https://github.com/isl-org/MiDaS</li>
<li>Pomysły na optymalizacje - https://github.com/basujindal/stable-diffusion</li>
<li>Optymalizacja warstwy Cross Attention - Doggettx - https://github.com/Doggettx/stable-diffusion, oryginalny pomysł na edycję promptu.</li>
<li>Optymalizacja warstwy Cross Attention - InvokeAI, lstein - https://github.com/invoke-ai/InvokeAI (oryginalnie http://github.com/lstein/stable-diffusion)</li>
<li>Sub-kwadratowa optymalizacja Cross Attention – Alex Birch (https://github.com/Birch-san/diffusers/pull/1), Amin Rezaei (https://github.com/AminRezaei0x443/memory-efficient-attention)</li>
<li>Textual Inversion – Rinon Gal – https://github.com/rinongal/textual_inversion (nie używamy jego kodu, ale jego pomysły)</li>
<li>Pomysł na SD upscale – https://github.com/jquesnelle/txt2imghd</li>
<li>Generowanie szumu do outpaintingu mk2 – https://github.com/parlance-zz/g-diffuser-bot</li>
<li>CLIP interrogator – pomysł i zapożyczenie fragmentów kodu – https://github.com/pharmapsychotic/clip-interrogator</li>
<li>Pomysł na Composable Diffusion – https://github.com/energy-based-model/Compositional-Visual-Generation-with-Composable-Diffusion-Models-PyTorch</li>
<li>xformers – https://github.com/facebookresearch/xformers</li>
<li>DeepDanbooru – interrogator dla anime diffusers https://github.com/KichangKim/DeepDanbooru</li>
<li>Próbkowanie w float32 z float16 UNet – marunine (pomysł), Birch-san (przykład Diffusers implementation) (https://github.com/Birch-san/diffusers-play/tree/92feee6)</li>
<li>Instruct pix2pix – Tim Brooks (star), Aleksander Holynski (star), Alexei A. Efros (no star) – https://github.com/timothybrooks/instruct-pix2pix</li>
<li>Porady bezpieczeństwa – RyotaK</li>
<li>UniPC sampler – Wenliang Zhao – https://github.com/wl-zhao/UniPC</li>
<li>TAESD – Ollin Boer Bohan – https://github.com/madebyollin/taesd</li>
<li>LyCORIS – KohakuBlueleaf</li>
<li>Restart sampling – lambertae – https://github.com/Newbeeer/diffusion_restart_sampling</li>
<li>Hypertile – tfernd – https://github.com/tfernd/HyperTile</li>
<li>Początkowy skrypt Gradio – opublikowany na 4chan przez anonimowego użytkownika. Dziękujemy anonimowemu użytkownikowi.</li>
<li>(Ty)</li>
</ul>
<hr />
<p><a href="https://github.com/OpenAiTx/OpenAiTx">Powered By OpenAiTx</a></p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
</body>
</html>