<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>stable-diffusion-webui - AUTOMATIC1111/stable-diffusion-webui</title>
    <meta name="title" content="stable-diffusion-webui - AUTOMATIC1111/stable-diffusion-webui">
    <meta name="description" content="AUTOMATIC1111/stable-diffusion-webui - GitHub repository es documentation and informationInterfaz web de Stable Diffusion Una interfaz web para Stable Diffusion, implementada utilizando la librería Gradio. Características Demostración detallada de c...">
    <meta name="keywords" content="AUTOMATIC1111, stable-diffusion-webui, GitHub, repository, es documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/AUTOMATIC1111/stable-diffusion-webui/README-es.html">
    <meta property="og:title" content="stable-diffusion-webui - AUTOMATIC1111/stable-diffusion-webui">
    <meta property="og:description" content="AUTOMATIC1111/stable-diffusion-webui - GitHub repository es documentation and information">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui" id="githubRepoLink" target="_blank">AUTOMATIC1111/stable-diffusion-webui</a>
<h1 style="display: none;">Interfaz web de Stable Diffusion Una interfaz web para Stable Diffusion, implementada utilizando la librería Gradio. Características Demostración detallada de c...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <h1>Interfaz web de Stable Diffusion</h1>
<p>Una interfaz web para Stable Diffusion, implementada utilizando la librería Gradio.</p>
<p><img src="screenshot.png" alt="" /></p>
<h2>Características</h2>
<p><a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features">Demostración detallada de características con imágenes</a>:</p>
<ul>
<li>Modos originales txt2img e img2img</li>
<li>Script de instalación y ejecución con un solo clic (pero aún debes instalar python y git)</li>
<li>Outpainting</li>
<li>Inpainting</li>
<li>Boceto de color</li>
<li>Matriz de prompts</li>
<li>Escalado Stable Diffusion Upscale</li>
<li>Atención, especifica partes del texto a las que el modelo debe prestar más atención
<ul>
<li>un hombre en un <code>((smoking))</code> - prestará más atención al smoking</li>
<li>un hombre en un <code>(smoking:1.21)</code> - sintaxis alternativa</li>
<li>selecciona el texto y presiona <code>Ctrl+Arriba</code> o <code>Ctrl+Abajo</code> (o <code>Command+Arriba</code> o <code>Command+Abajo</code> si estás en MacOS) para ajustar automáticamente la atención al texto seleccionado (código contribuido por un usuario anónimo)</li>
</ul>
</li>
<li>Loopback, ejecuta el procesamiento img2img múltiples veces</li>
<li>Gráfica X/Y/Z, una manera de dibujar una gráfica tridimensional de imágenes con diferentes parámetros</li>
<li>Inversión textual
<ul>
<li>ten tantos embeddings como quieras y usa los nombres que prefieras</li>
<li>usa múltiples embeddings con diferente cantidad de vectores por token</li>
<li>funciona con números de punto flotante de media precisión</li>
<li>entrena embeddings en 8GB (también se han reportado 6GB funcionando)</li>
</ul>
</li>
<li>Pestaña Extras con:
<ul>
<li>GFPGAN, red neuronal que arregla rostros</li>
<li>CodeFormer, herramienta de restauración facial como alternativa a GFPGAN</li>
<li>RealESRGAN, escalador neuronal</li>
<li>ESRGAN, escalador neuronal con muchos modelos de terceros</li>
<li>SwinIR y Swin2SR (<a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/pull/2092">ver aquí</a>), escaladores neuronales</li>
<li>LDSR, superresolución de difusión latente</li>
</ul>
</li>
<li>Opciones de cambio de relación de aspecto</li>
<li>Selección de método de muestreo
<ul>
<li>Ajusta los valores eta del muestreador (multiplicador de ruido)</li>
<li>Más opciones avanzadas de configuración de ruido</li>
</ul>
</li>
<li>Interrumpe el procesamiento en cualquier momento</li>
<li>Soporte para tarjetas de video de 4GB (también se reporta funcionamiento con 2GB)</li>
<li>Semillas correctas para lotes</li>
<li>Validación en vivo de longitud de tokens del prompt</li>
<li>Parámetros de generación
<ul>
<li>los parámetros usados para generar las imágenes se guardan con la imagen</li>
<li>en chunks PNG para PNG, en EXIF para JPEG</li>
<li>puedes arrastrar la imagen a la pestaña PNG info para restaurar los parámetros de generación y copiarlos automáticamente en la IU</li>
<li>se puede desactivar en configuración</li>
<li>arrastra y suelta una imagen/texto-parámetros en la caja de prompts</li>
</ul>
</li>
<li>Botón Leer Parámetros de Generación, carga los parámetros de la caja de prompts a la IU</li>
<li>Página de configuración</li>
<li>Ejecuta código Python arbitrario desde la IU (debe ejecutarse con <code>--allow-code</code> para habilitarlo)</li>
<li>Sugerencias al pasar el mouse sobre la mayoría de los elementos de la IU</li>
<li>Es posible cambiar valores por defecto/mín/máx/paso de los elementos de la IU mediante archivo de configuración de texto</li>
<li>Soporte de mosaicos, una casilla para crear imágenes que pueden ser usadas como texturas repetibles</li>
<li>Barra de progreso y vista previa en vivo de la generación de imagen
<ul>
<li>Puede usar una red neuronal separada para producir previsualizaciones con casi nada de requerimiento de VRAM o cómputo</li>
</ul>
</li>
<li>Prompt negativo, un campo de texto extra que te permite listar lo que no quieres ver en la imagen generada</li>
<li>Estilos, una forma de guardar partes de prompts y aplicarlos fácilmente desde el menú desplegable después</li>
<li>Variaciones, una forma de generar la misma imagen pero con pequeñas diferencias</li>
<li>Redimensionado de semilla, una forma de generar la misma imagen pero con una resolución ligeramente diferente</li>
<li>Interrogador CLIP, un botón que intenta adivinar el prompt a partir de una imagen</li>
<li>Edición de prompt, una forma de cambiar el prompt a mitad de la generación, por ejemplo, para empezar haciendo una sandía y cambiar a chica anime a mitad del proceso</li>
<li>Procesamiento por lotes, procesa un grupo de archivos usando img2img</li>
<li>Alternativa img2img, método inverso de Euler para control de atención cruzada</li>
<li>Highres Fix, opción conveniente para producir imágenes de alta resolución en un clic sin distorsiones habituales</li>
<li>Recarga de checkpoints al vuelo</li>
<li>Combinador de checkpoints, pestaña que permite combinar hasta 3 checkpoints en uno</li>
<li><a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Custom-Scripts">Scripts personalizados</a> con muchas extensiones de la comunidad</li>
<li><a href="https://energy-based-model.github.io/Compositional-Visual-Generation-with-Composable-Diffusion-Models/">Composable-Diffusion</a>, una forma de usar múltiples prompts al mismo tiempo
<ul>
<li>separa los prompts usando <code>AND</code> en mayúsculas</li>
<li>también soporta pesos para los prompts: <code>un gato :1.2 AND un perro AND un pingüino :2.2</code></li>
</ul>
</li>
<li>Sin límite de tokens para prompts (la versión original de stable diffusion permite hasta 75 tokens)</li>
<li>Integración DeepDanbooru, crea etiquetas al estilo danbooru para prompts de anime</li>
<li><a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Xformers">xformers</a>, gran aumento de velocidad para ciertas tarjetas: (añadir <code>--xformers</code> a los argumentos de la línea de comandos)</li>
<li>vía extensión: <a href="https://github.com/yfszzx/stable-diffusion-webui-images-browser">Pestaña de Historial</a>: visualiza, dirige y elimina imágenes cómodamente desde la IU</li>
<li>Opción de generar indefinidamente</li>
<li>Pestaña de entrenamiento
<ul>
<li>opciones de hypernetworks y embeddings</li>
<li>Preprocesamiento de imágenes: recorte, espejado, autotagging usando BLIP o deepdanbooru (para anime)</li>
</ul>
</li>
<li>Clip skip</li>
<li>Hypernetworks</li>
<li>Loras (igual que Hypernetworks pero más bonitas)</li>
<li>Una IU separada donde puedes elegir, con previsualización, qué embeddings, hypernetworks o Loras añadir a tu prompt</li>
<li>Puede seleccionarse cargar un VAE diferente desde la pantalla de configuración</li>
<li>Tiempo estimado de finalización en la barra de progreso</li>
<li>API</li>
<li>Soporte para modelo dedicado de <a href="https://github.com/runwayml/stable-diffusion#inpainting-with-stable-diffusion">inpainting</a> de RunwayML</li>
<li>vía extensión: <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui-aesthetic-gradients">Aesthetic Gradients</a>, una forma de generar imágenes con una estética específica usando embeddings de imágenes clip (implementación de <a href="https://github.com/vicgalle/stable-diffusion-aesthetic-gradients">https://github.com/vicgalle/stable-diffusion-aesthetic-gradients</a>)</li>
<li>Soporte para <a href="https://github.com/Stability-AI/stablediffusion">Stable Diffusion 2.0</a> - ver <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features#stable-diffusion-20">wiki</a> para instrucciones</li>
<li>Soporte para <a href="https://arxiv.org/abs/2211.06679">Alt-Diffusion</a> - ver <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features#alt-diffusion">wiki</a> para instrucciones</li>
<li>¡Ahora sin ninguna letra prohibida!</li>
<li>Cargar checkpoints en formato safetensors</li>
<li>Restricción de resolución suavizada: las dimensiones de la imagen generada deben ser múltiplos de 8 en vez de 64</li>
<li>¡Ahora con licencia!</li>
<li>Reordenar elementos en la IU desde la pantalla de configuración</li>
<li>Soporte para <a href="https://huggingface.co/segmind/SSD-1B">Segmind Stable Diffusion</a></li>
</ul>
<h2>Instalación y Ejecución</h2>
<p>Asegúrate de cumplir con las <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Dependencies">dependencias</a> requeridas y sigue las instrucciones disponibles para:</p>
<ul>
<li><a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-NVidia-GPUs">NVidia</a> (recomendado)</li>
<li>GPUs <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-AMD-GPUs">AMD</a>.</li>
<li><a href="https://github.com/openvinotoolkit/stable-diffusion-webui/wiki/Installation-on-Intel-Silicon">CPUs Intel, GPUs Intel (integradas y discretas)</a> (página wiki externa)</li>
<li><a href="https://github.com/wangshuai09/stable-diffusion-webui/wiki/Install-and-run-on-Ascend-NPUs">Ascend NPUs</a> (página wiki externa)</li>
</ul>
<p>Alternativamente, usa servicios en línea (como Google Colab):</p>
<ul>
<li><a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Online-Services">Lista de servicios en línea</a></li>
</ul>
<h3>Instalación en Windows 10/11 con GPUs NVidia usando el paquete de lanzamiento</h3>
<ol>
<li>Descarga <code>sd.webui.zip</code> desde <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/releases/tag/v1.0.0-pre">v1.0.0-pre</a> y extrae su contenido.</li>
<li>Ejecuta <code>update.bat</code>.</li>
<li>Ejecuta <code>run.bat</code>.</li>
</ol>
<blockquote>
<p>Para más detalles, ver <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-NVidia-GPUs">Install-and-Run-on-NVidia-GPUs</a></p>
</blockquote>
<h3>Instalación automática en Windows</h3>
<ol>
<li>Instala <a href="https://www.python.org/downloads/release/python-3106/">Python 3.10.6</a> (Versiones más nuevas de Python no son compatibles con torch), marcando &quot;Add Python to PATH&quot;.</li>
<li>Instala <a href="https://git-scm.com/download/win">git</a>.</li>
<li>Descarga el repositorio stable-diffusion-webui, por ejemplo ejecutando <code>git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git</code>.</li>
<li>Ejecuta <code>webui-user.bat</code> desde el Explorador de Windows como usuario normal (no administrador).</li>
</ol>
<h3>Instalación automática en Linux</h3>
<ol>
<li>Instala las dependencias:</li>
</ol>
<pre><code class="language-bash"># Basado en Debian:
sudo apt install wget git python3 python3-venv libgl1 libglib2.0-0
# Basado en Red Hat:
sudo dnf install wget git python3 gperftools-libs libglvnd-glx
# Basado en openSUSE:
sudo zypper install wget git python3 libtcmalloc4 libglvnd
# Basado en Arch:
sudo pacman -S wget git python3
</code></pre>
<p>Si tu sistema es muy nuevo, necesitas instalar python3.11 o python3.10:</p>
<pre><code class="language-bash"># Ubuntu 24.04
sudo add-apt-repository ppa:deadsnakes/ppa
sudo apt update
sudo apt install python3.11

# Manjaro/Arch
sudo pacman -S yay
yay -S python311 # no confundir con el paquete python3.11

# Solo para 3.11
# Luego configura la variable de entorno en el script de lanzamiento
export python_cmd=&quot;python3.11&quot;
# o en webui-user.sh
python_cmd=&quot;python3.11&quot;
</code></pre>
<ol start="2">
<li>Navega al directorio donde quieres instalar la webui y ejecuta el siguiente comando:</li>
</ol>
<pre><code class="language-bash">wget -q https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/webui.sh
</code></pre>
<p>O simplemente clona el repositorio donde quieras:</p>
<pre><code class="language-bash">git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui
</code></pre>
<ol start="3">
<li>Ejecuta <code>webui.sh</code>.</li>
<li>Revisa <code>webui-user.sh</code> para opciones.</li>
</ol>
<h3>Instalación en Apple Silicon</h3>
<p>Encuentra las instrucciones <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Installation-on-Apple-Silicon">aquí</a>.</p>
<h2>Contribuir</h2>
<p>Así es como puedes añadir código a este repositorio: <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing">Contributing</a></p>
<h2>Documentación</h2>
<p>La documentación se trasladó desde este README al <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki">wiki</a> del proyecto.</p>
<p>Con el fin de que Google y otros motores de búsqueda indexen el wiki, aquí tienes un enlace al (no para humanos) <a href="https://github-wiki-see.page/m/AUTOMATIC1111/stable-diffusion-webui/wiki">wiki rastreable</a>.</p>
<h2>Créditos</h2>
<p>Las licencias del código utilizado se pueden encontrar en la pantalla <code>Settings -&gt; Licenses</code>, y también en el archivo <code>html/licenses.html</code>.</p>
<ul>
<li>Stable Diffusion - https://github.com/Stability-AI/stablediffusion, https://github.com/CompVis/taming-transformers, https://github.com/mcmonkey4eva/sd3-ref</li>
<li>k-diffusion - https://github.com/crowsonkb/k-diffusion.git</li>
<li>Spandrel - https://github.com/chaiNNer-org/spandrel implementando
<ul>
<li>GFPGAN - https://github.com/TencentARC/GFPGAN.git</li>
<li>CodeFormer - https://github.com/sczhou/CodeFormer</li>
<li>ESRGAN - https://github.com/xinntao/ESRGAN</li>
<li>SwinIR - https://github.com/JingyunLiang/SwinIR</li>
<li>Swin2SR - https://github.com/mv-lab/swin2sr</li>
</ul>
</li>
<li>LDSR - https://github.com/Hafiidz/latent-diffusion</li>
<li>MiDaS - https://github.com/isl-org/MiDaS</li>
<li>Ideas para optimizaciones - https://github.com/basujindal/stable-diffusion</li>
<li>Optimización de la capa Cross Attention - Doggettx - https://github.com/Doggettx/stable-diffusion, idea original para edición de prompt.</li>
<li>Optimización de la capa Cross Attention - InvokeAI, lstein - https://github.com/invoke-ai/InvokeAI (originalmente http://github.com/lstein/stable-diffusion)</li>
<li>Optimización subcuadrática de la capa Cross Attention - Alex Birch (https://github.com/Birch-san/diffusers/pull/1), Amin Rezaei (https://github.com/AminRezaei0x443/memory-efficient-attention)</li>
<li>Inversión textual - Rinon Gal - https://github.com/rinongal/textual_inversion (no usamos su código, pero sí sus ideas).</li>
<li>Idea para SD upscale - https://github.com/jquesnelle/txt2imghd</li>
<li>Generación de ruido para outpainting mk2 - https://github.com/parlance-zz/g-diffuser-bot</li>
<li>Idea del interrogador CLIP y parte del código - https://github.com/pharmapsychotic/clip-interrogator</li>
<li>Idea para Composable Diffusion - https://github.com/energy-based-model/Compositional-Visual-Generation-with-Composable-Diffusion-Models-PyTorch</li>
<li>xformers - https://github.com/facebookresearch/xformers</li>
<li>DeepDanbooru - interrogador para difusores de anime https://github.com/KichangKim/DeepDanbooru</li>
<li>Muestreo en precisión float32 desde un UNet en float16 - marunine por la idea, Birch-san por el ejemplo de implementación Diffusers (https://github.com/Birch-san/diffusers-play/tree/92feee6)</li>
<li>Instruct pix2pix - Tim Brooks (star), Aleksander Holynski (star), Alexei A. Efros (no star) - https://github.com/timothybrooks/instruct-pix2pix</li>
<li>Consejos de seguridad - RyotaK</li>
<li>Muestreador UniPC - Wenliang Zhao - https://github.com/wl-zhao/UniPC</li>
<li>TAESD - Ollin Boer Bohan - https://github.com/madebyollin/taesd</li>
<li>LyCORIS - KohakuBlueleaf</li>
<li>Reinicio de muestreo - lambertae - https://github.com/Newbeeer/diffusion_restart_sampling</li>
<li>Hypertile - tfernd - https://github.com/tfernd/HyperTile</li>
<li>Script inicial de Gradio - publicado en 4chan por un usuario Anónimo. Gracias, usuario Anónimo.</li>
<li>(Tú)</li>
</ul>
<hr />
<p><a href="https://github.com/OpenAiTx/OpenAiTx">Powered By OpenAiTx</a></p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
</body>
</html>