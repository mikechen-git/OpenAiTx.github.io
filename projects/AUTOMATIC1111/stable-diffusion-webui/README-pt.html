<!DOCTYPE html>
<html lang="pt">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>stable-diffusion-webui - AUTOMATIC1111/stable-diffusion-webui</title>
    <meta name="title" content="stable-diffusion-webui - AUTOMATIC1111/stable-diffusion-webui">
    <meta name="description" content="AUTOMATIC1111/stable-diffusion-webui - GitHub repository pt documentation and informationStable Diffusion web UI Uma interface web para Stable Diffusion, implementada usando a biblioteca Gradio. Funcionalidades Apresentação detalhada de funcionalida...">
    <meta name="keywords" content="AUTOMATIC1111, stable-diffusion-webui, GitHub, repository, pt documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/AUTOMATIC1111/stable-diffusion-webui/README-pt.html">
    <meta property="og:title" content="stable-diffusion-webui - AUTOMATIC1111/stable-diffusion-webui">
    <meta property="og:description" content="AUTOMATIC1111/stable-diffusion-webui - GitHub repository pt documentation and information">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui" id="githubRepoLink" target="_blank">AUTOMATIC1111/stable-diffusion-webui</a>
<h1 style="display: none;">Stable Diffusion web UI Uma interface web para Stable Diffusion, implementada usando a biblioteca Gradio. Funcionalidades Apresentação detalhada de funcionalida...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <h1>Stable Diffusion web UI</h1>
<p>Uma interface web para Stable Diffusion, implementada usando a biblioteca Gradio.</p>
<p><img src="screenshot.png" alt="" /></p>
<h2>Funcionalidades</h2>
<p><a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features">Apresentação detalhada de funcionalidades com imagens</a>:</p>
<ul>
<li>Modos originais txt2img e img2img</li>
<li>Script de instalação e execução com um clique (mas ainda é necessário instalar python e git)</li>
<li>Outpainting</li>
<li>Inpainting</li>
<li>Color Sketch</li>
<li>Prompt Matrix</li>
<li>Stable Diffusion Upscale</li>
<li>Atenção, especifique partes do texto para as quais o modelo deve prestar mais atenção
<ul>
<li>um homem em um <code>((smoking))</code> - dará mais atenção ao smoking</li>
<li>um homem em um <code>(smoking:1.21)</code> - sintaxe alternativa</li>
<li>selecione o texto e pressione <code>Ctrl+Up</code> ou <code>Ctrl+Down</code> (ou <code>Command+Up</code> ou <code>Command+Down</code> se estiver no MacOS) para ajustar automaticamente a atenção ao texto selecionado (código contribuído por usuário anônimo)</li>
</ul>
</li>
<li>Loopback, processa img2img múltiplas vezes</li>
<li>X/Y/Z plot, uma forma de desenhar um gráfico 3D de imagens com diferentes parâmetros</li>
<li>Textual Inversion
<ul>
<li>tenha quantos embeddings quiser e use os nomes que desejar para eles</li>
<li>use múltiplos embeddings com diferentes números de vetores por token</li>
<li>funciona com números de ponto flutuante de meia precisão</li>
<li>treine embeddings com 8GB (também há relatos de 6GB funcionando)</li>
</ul>
</li>
<li>Aba Extras com:
<ul>
<li>GFPGAN, rede neural que corrige rostos</li>
<li>CodeFormer, ferramenta de restauração facial alternativa ao GFPGAN</li>
<li>RealESRGAN, upscaler de rede neural</li>
<li>ESRGAN, upscaler de rede neural com muitos modelos de terceiros</li>
<li>SwinIR e Swin2SR (<a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/pull/2092">veja aqui</a>), upscalers de rede neural</li>
<li>LDSR, upscaling de super-resolução por difusão latente</li>
</ul>
</li>
<li>Opções de redimensionamento de proporção de aspecto</li>
<li>Seleção do método de amostragem
<ul>
<li>Ajuste dos valores eta do sampler (multiplicador de ruído)</li>
<li>Mais opções avançadas de configuração de ruído</li>
</ul>
</li>
<li>Interrompa o processamento a qualquer momento</li>
<li>Suporte a placas de vídeo de 4GB (também há relatos de 2GB funcionando)</li>
<li>Sementes corretas para lotes</li>
<li>Validação ao vivo do comprimento do prompt em tokens</li>
<li>Parâmetros de geração
<ul>
<li>os parâmetros usados para gerar imagens são salvos junto com a imagem</li>
<li>em chunks PNG para PNG, em EXIF para JPEG</li>
<li>pode arrastar a imagem para a aba PNG info para restaurar os parâmetros de geração e copiá-los automaticamente para a interface</li>
<li>pode ser desativado nas configurações</li>
<li>arraste e solte uma imagem/texto-parâmetros na caixa de prompt</li>
</ul>
</li>
<li>Botão Ler Parâmetros de Geração, carrega parâmetros da caixa de prompt para a interface</li>
<li>Página de configurações</li>
<li>Execução de código python arbitrário pela interface (deve rodar com <code>--allow-code</code> para habilitar)</li>
<li>Dicas ao passar o mouse na maioria dos elementos da interface</li>
<li>Possível alterar valores padrões/mín/máx/passo dos elementos da interface via configuração de texto</li>
<li>Suporte a tiling, uma caixa de seleção para criar imagens que podem ser usadas como texturas</li>
<li>Barra de progresso e visualização ao vivo da geração de imagem
<ul>
<li>Pode usar uma rede neural separada para produzir prévias sem quase nenhum uso de VRAM ou computação</li>
</ul>
</li>
<li>Prompt negativo, um campo de texto extra para listar o que não deseja ver na imagem gerada</li>
<li>Estilos, um modo de salvar parte do prompt e aplicá-lo facilmente pelo menu suspenso depois</li>
<li>Variações, um modo de gerar a mesma imagem com pequenas diferenças</li>
<li>Redimensionamento de seed, uma forma de gerar a mesma imagem em resolução levemente diferente</li>
<li>CLIP interrogator, um botão que tenta adivinhar o prompt a partir de uma imagem</li>
<li>Edição de Prompt, modo de mudar o prompt durante a geração, por exemplo para começar criando uma melancia e trocar para garota de anime no meio</li>
<li>Processamento em lote, processa um grupo de arquivos usando img2img</li>
<li>Img2img Alternativo, método reverso de Euler para controle de cross attention</li>
<li>Highres Fix, opção conveniente para produzir imagens em alta resolução com um clique sem distorções usuais</li>
<li>Recarregamento de checkpoints em tempo real</li>
<li>Mesclador de checkpoints, aba que permite mesclar até 3 checkpoints em um só</li>
<li><a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Custom-Scripts">Scripts personalizados</a> com várias extensões da comunidade</li>
<li><a href="https://energy-based-model.github.io/Compositional-Visual-Generation-with-Composable-Diffusion-Models/">Composable-Diffusion</a>, modo de usar múltiplos prompts ao mesmo tempo
<ul>
<li>separe prompts usando <code>AND</code> em maiúsculas</li>
<li>também suporta pesos para prompts: <code>um gato :1.2 AND um cachorro AND um pinguim :2.2</code></li>
</ul>
</li>
<li>Sem limite de tokens para prompts (o stable diffusion original permite até 75 tokens)</li>
<li>Integração com DeepDanbooru, gera tags no estilo danbooru para prompts de anime</li>
<li><a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Xformers">xformers</a>, grande aumento de velocidade para placas selecionadas: (adicione <code>--xformers</code> nos argumentos de linha de comando)</li>
<li>via extensão: <a href="https://github.com/yfszzx/stable-diffusion-webui-images-browser">Aba de Histórico</a>: visualize, direcione e apague imagens convenientemente pela interface</li>
<li>Opção Gerar para sempre</li>
<li>Aba de Treinamento
<ul>
<li>opções de hypernetworks e embeddings</li>
<li>Pré-processamento de imagens: corte, espelhamento, autotagging usando BLIP ou deepdanbooru (para anime)</li>
</ul>
</li>
<li>Clip skip</li>
<li>Hypernetworks</li>
<li>Loras (igual Hypernetworks, mas mais bonitos)</li>
<li>Uma interface separada onde você pode escolher, com pré-visualização, quais embeddings, hypernetworks ou Loras adicionar ao seu prompt</li>
<li>Pode selecionar para carregar um VAE diferente na tela de configurações</li>
<li>Tempo estimado de conclusão na barra de progresso</li>
<li>API</li>
<li>Suporte ao <a href="https://github.com/runwayml/stable-diffusion#inpainting-with-stable-diffusion">modelo dedicado de inpainting</a> da RunwayML</li>
<li>via extensão: <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui-aesthetic-gradients">Aesthetic Gradients</a>, modo de gerar imagens com estética específica usando embeddings de imagens clip (implementação de <a href="https://github.com/vicgalle/stable-diffusion-aesthetic-gradients">https://github.com/vicgalle/stable-diffusion-aesthetic-gradients</a>)</li>
<li>Suporte ao <a href="https://github.com/Stability-AI/stablediffusion">Stable Diffusion 2.0</a> - veja <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features#stable-diffusion-20">wiki</a> para instruções</li>
<li>Suporte ao <a href="https://arxiv.org/abs/2211.06679">Alt-Diffusion</a> - veja <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features#alt-diffusion">wiki</a> para instruções</li>
<li>Agora sem letras ruins!</li>
<li>Carregue checkpoints no formato safetensors</li>
<li>Restrição de resolução facilitada: as dimensões da imagem gerada devem ser múltiplos de 8 ao invés de 64</li>
<li>Agora com licença!</li>
<li>Reordene elementos na interface pelas configurações</li>
<li>Suporte ao <a href="https://huggingface.co/segmind/SSD-1B">Segmind Stable Diffusion</a></li>
</ul>
<h2>Instalação e Execução</h2>
<p>Certifique-se de que as <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Dependencies">dependências</a> necessárias estão atendidas e siga as instruções disponíveis para:</p>
<ul>
<li><a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-NVidia-GPUs">NVidia</a> (recomendado)</li>
<li><a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-AMD-GPUs">AMD</a> GPUs.</li>
<li><a href="https://github.com/openvinotoolkit/stable-diffusion-webui/wiki/Installation-on-Intel-Silicon">CPUs Intel, GPUs Intel (integradas e dedicadas)</a> (página wiki externa)</li>
<li><a href="https://github.com/wangshuai09/stable-diffusion-webui/wiki/Install-and-run-on-Ascend-NPUs">Ascend NPUs</a> (página wiki externa)</li>
</ul>
<p>Alternativamente, utilize serviços online (como Google Colab):</p>
<ul>
<li><a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Online-Services">Lista de Serviços Online</a></li>
</ul>
<h3>Instalação no Windows 10/11 com GPUs NVidia usando pacote de release</h3>
<ol>
<li>Baixe o <code>sd.webui.zip</code> de <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/releases/tag/v1.0.0-pre">v1.0.0-pre</a> e extraia seu conteúdo.</li>
<li>Execute <code>update.bat</code>.</li>
<li>Execute <code>run.bat</code>.</li>
</ol>
<blockquote>
<p>Para mais detalhes, veja <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-NVidia-GPUs">Install-and-Run-on-NVidia-GPUs</a></p>
</blockquote>
<h3>Instalação Automática no Windows</h3>
<ol>
<li>Instale o <a href="https://www.python.org/downloads/release/python-3106/">Python 3.10.6</a> (Versões mais novas do Python não suportam torch), marcando &quot;Add Python to PATH&quot;.</li>
<li>Instale o <a href="https://git-scm.com/download/win">git</a>.</li>
<li>Baixe o repositório stable-diffusion-webui, por exemplo rodando <code>git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git</code>.</li>
<li>Execute <code>webui-user.bat</code> no Windows Explorer como usuário normal, não administrador.</li>
</ol>
<h3>Instalação Automática no Linux</h3>
<ol>
<li>Instale as dependências:</li>
</ol>
<pre><code class="language-bash"># Baseado em Debian:
sudo apt install wget git python3 python3-venv libgl1 libglib2.0-0
# Baseado em Red Hat:
sudo dnf install wget git python3 gperftools-libs libglvnd-glx
# Baseado em openSUSE:
sudo zypper install wget git python3 libtcmalloc4 libglvnd
# Baseado em Arch:
sudo pacman -S wget git python3
</code></pre>
<p>Se o seu sistema for muito novo, é necessário instalar python3.11 ou python3.10:</p>
<pre><code class="language-bash"># Ubuntu 24.04
sudo add-apt-repository ppa:deadsnakes/ppa
sudo apt update
sudo apt install python3.11

# Manjaro/Arch
sudo pacman -S yay
yay -S python311 # não confunda com o pacote python3.11

# Somente para 3.11
# Então configure a variável de ambiente no script de inicialização
export python_cmd=&quot;python3.11&quot;
# ou em webui-user.sh
python_cmd=&quot;python3.11&quot;
</code></pre>
<ol start="2">
<li>Navegue até o diretório onde deseja instalar a webui e execute o comando:</li>
</ol>
<pre><code class="language-bash">wget -q https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/webui.sh
</code></pre>
<p>Ou apenas clone o repositório onde quiser:</p>
<pre><code class="language-bash">git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui
</code></pre>
<ol start="3">
<li>Execute <code>webui.sh</code>.</li>
<li>Verifique <code>webui-user.sh</code> para opções.</li>
</ol>
<h3>Instalação no Apple Silicon</h3>
<p>Encontre as instruções <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Installation-on-Apple-Silicon">aqui</a>.</p>
<h2>Contribuindo</h2>
<p>Veja como adicionar código neste repositório: <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing">Contribuindo</a></p>
<h2>Documentação</h2>
<p>A documentação foi movida deste README para o <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki">wiki do projeto</a>.</p>
<p>Para fins de indexação pelo Google e outros mecanismos de busca, aqui está um link para o (não destinado a humanos) <a href="https://github-wiki-see.page/m/AUTOMATIC1111/stable-diffusion-webui/wiki">wiki rastreável</a>.</p>
<h2>Créditos</h2>
<p>Licenças de códigos utilizados podem ser encontradas na tela <code>Configurações -&gt; Licenças</code>, e também no arquivo <code>html/licenses.html</code>.</p>
<ul>
<li>Stable Diffusion - https://github.com/Stability-AI/stablediffusion, https://github.com/CompVis/taming-transformers, https://github.com/mcmonkey4eva/sd3-ref</li>
<li>k-diffusion - https://github.com/crowsonkb/k-diffusion.git</li>
<li>Spandrel - https://github.com/chaiNNer-org/spandrel implementando
<ul>
<li>GFPGAN - https://github.com/TencentARC/GFPGAN.git</li>
<li>CodeFormer - https://github.com/sczhou/CodeFormer</li>
<li>ESRGAN - https://github.com/xinntao/ESRGAN</li>
<li>SwinIR - https://github.com/JingyunLiang/SwinIR</li>
<li>Swin2SR - https://github.com/mv-lab/swin2sr</li>
</ul>
</li>
<li>LDSR - https://github.com/Hafiidz/latent-diffusion</li>
<li>MiDaS - https://github.com/isl-org/MiDaS</li>
<li>Ideias para otimizações - https://github.com/basujindal/stable-diffusion</li>
<li>Otimização da camada Cross Attention - Doggettx - https://github.com/Doggettx/stable-diffusion, ideia original para edição de prompt.</li>
<li>Otimização da camada Cross Attention - InvokeAI, lstein - https://github.com/invoke-ai/InvokeAI (originalmente http://github.com/lstein/stable-diffusion)</li>
<li>Otimização Cross Attention sub-quadrática - Alex Birch (https://github.com/Birch-san/diffusers/pull/1), Amin Rezaei (https://github.com/AminRezaei0x443/memory-efficient-attention)</li>
<li>Textual Inversion - Rinon Gal - https://github.com/rinongal/textual_inversion (não usamos o código dele, mas usamos suas ideias).</li>
<li>Ideia para SD upscale - https://github.com/jquesnelle/txt2imghd</li>
<li>Geração de ruído para outpainting mk2 - https://github.com/parlance-zz/g-diffuser-bot</li>
<li>CLIP interrogator ideia e parte do código - https://github.com/pharmapsychotic/clip-interrogator</li>
<li>Ideia para Composable Diffusion - https://github.com/energy-based-model/Compositional-Visual-Generation-with-Composable-Diffusion-Models-PyTorch</li>
<li>xformers - https://github.com/facebookresearch/xformers</li>
<li>DeepDanbooru - interrogador para difusores de anime https://github.com/KichangKim/DeepDanbooru</li>
<li>Amostragem em precisão float32 de um UNet float16 - marunine pela ideia, Birch-san pelo exemplo da implementação Diffusers (https://github.com/Birch-san/diffusers-play/tree/92feee6)</li>
<li>Instruct pix2pix - Tim Brooks (estrela), Aleksander Holynski (estrela), Alexei A. Efros (sem estrela) - https://github.com/timothybrooks/instruct-pix2pix</li>
<li>Conselho de segurança - RyotaK</li>
<li>UniPC sampler - Wenliang Zhao - https://github.com/wl-zhao/UniPC</li>
<li>TAESD - Ollin Boer Bohan - https://github.com/madebyollin/taesd</li>
<li>LyCORIS - KohakuBlueleaf</li>
<li>Restart sampling - lambertae - https://github.com/Newbeeer/diffusion_restart_sampling</li>
<li>Hypertile - tfernd - https://github.com/tfernd/HyperTile</li>
<li>Script inicial Gradio - postado no 4chan por um usuário anônimo. Obrigado, usuário anônimo.</li>
<li>(Você)</li>
</ul>
<hr />
<p><a href="https://github.com/OpenAiTx/OpenAiTx">Powered By OpenAiTx</a></p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
</body>
</html>