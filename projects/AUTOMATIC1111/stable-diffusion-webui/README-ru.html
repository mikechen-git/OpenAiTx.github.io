<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>stable-diffusion-webui - AUTOMATIC1111/stable-diffusion-webui ru</title>
    <meta name="title" content="stable-diffusion-webui - AUTOMATIC1111/stable-diffusion-webui ru | Stable Diffusion web UI Веб-интерфейс для Stable Diffusion, реализованный с использованием библиотеки Gradio. Возможности Детальный обзор возможностей с изображ...">
    <meta name="description" content="AUTOMATIC1111/stable-diffusion-webui - GitHub repository ru documentation and information | Stable Diffusion web UI Веб-интерфейс для Stable Diffusion, реализованный с использованием библиотеки Gradio. Возможности Детальный обзор возможностей с изображ...">
    <meta name="keywords" content="AUTOMATIC1111, stable-diffusion-webui, GitHub, repository, ru documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/AUTOMATIC1111/stable-diffusion-webui/README-ru.html">
    <meta property="og:title" content="stable-diffusion-webui - AUTOMATIC1111/stable-diffusion-webui ru | Stable Diffusion web UI Веб-интерфейс для Stable Diffusion, реализованный с использованием библиотеки Gradio. Возможности Детальный обзор возможностей с изображ...">
    <meta property="og:description" content="AUTOMATIC1111/stable-diffusion-webui - GitHub repository ru documentation and information | Stable Diffusion web UI Веб-интерфейс для Stable Diffusion, реализованный с использованием библиотеки Gradio. Возможности Детальный обзор возможностей с изображ...">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div style="position: fixed; top: 2px; left: 2px; z-index: 2000; background: rgba(255,255,255,0.95); border-radius: 6px; box-shadow: 0 2px 8px rgba(0,0,0,0.06); padding: 4px 14px; font-size: 15px; color: #222; font-family: 'Segoe UI', Arial, sans-serif; font-weight: 500; letter-spacing: 0.5px;">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" style="color: #0366d6; text-decoration: none; font-weight: 600;">Open AI Tx</a>
    </div>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui" id="githubRepoLink" target="_blank">AUTOMATIC1111/stable-diffusion-webui</a>
<h1 style="display: none;">Stable Diffusion web UI Веб-интерфейс для Stable Diffusion, реализованный с использованием библиотеки Gradio. Возможности Детальный обзор возможностей с изображ...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <h1>Stable Diffusion web UI</h1>
<p>Веб-интерфейс для Stable Diffusion, реализованный с использованием библиотеки Gradio.</p>
<p><img src="screenshot.png" alt="" /></p>
<h2>Возможности</h2>
<p><a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features">Детальный обзор возможностей с изображениями</a>:</p>
<ul>
<li>Оригинальные режимы txt2img и img2img</li>
<li>Скрипт установки и запуска в один клик (но всё равно необходимо установить python и git)</li>
<li>Outpainting</li>
<li>Inpainting</li>
<li>Color Sketch</li>
<li>Prompt Matrix</li>
<li>Stable Diffusion Upscale</li>
<li>Внимание, возможность указать части текста, на которые модель должна обратить больше внимания
<ul>
<li>a man in a <code>((tuxedo))</code> — больше внимания к фразе tuxedo</li>
<li>a man in a <code>(tuxedo:1.21)</code> — альтернативный синтаксис</li>
<li>выделите текст и нажмите <code>Ctrl+Up</code> или <code>Ctrl+Down</code> (или <code>Command+Up</code> или <code>Command+Down</code> на MacOS), чтобы автоматически изменить уровень внимания к выделенному тексту (код предоставлен анонимным пользователем)</li>
</ul>
</li>
<li>Loopback, многократная обработка изображения через img2img</li>
<li>X/Y/Z plot, трёхмерная визуализация изображений с разными параметрами</li>
<li>Textual Inversion
<ul>
<li>неограниченное количество эмбеддингов с любыми именами</li>
<li>поддержка нескольких эмбеддингов с разным количеством векторов на токен</li>
<li>работает с половинной точностью чисел с плавающей запятой</li>
<li>обучение эмбеддингов на 8 ГБ (также имеются сообщения о работе на 6 ГБ)</li>
</ul>
</li>
<li>Вкладка Extras с:
<ul>
<li>GFPGAN, нейросеть для исправления лиц</li>
<li>CodeFormer, инструмент восстановления лиц в качестве альтернативы GFPGAN</li>
<li>RealESRGAN, нейросетевой апскейлер</li>
<li>ESRGAN, нейросетевой апскейлер с поддержкой множества сторонних моделей</li>
<li>SwinIR и Swin2SR (<a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/pull/2092">см. здесь</a>), нейросетевые апскейлеры</li>
<li>LDSR, латентное диффузионное сверхразрешение</li>
</ul>
</li>
<li>Опции изменения соотношения сторон при изменении размера</li>
<li>Выбор метода сэмплирования
<ul>
<li>Настройка значения eta для сэмплера (множитель шума)</li>
<li>Дополнительные опции для настройки шума</li>
</ul>
</li>
<li>Возможность прервать процесс в любое время</li>
<li>Поддержка видеокарт 4 ГБ (имеются сообщения о работе на 2 ГБ)</li>
<li>Корректные сиды для пакетов изображений</li>
<li>Проверка длины токенов промпта в реальном времени</li>
<li>Параметры генерации
<ul>
<li>параметры, использованные для генерации, сохраняются вместе с изображением</li>
<li>в PNG chunk для PNG, в EXIF для JPEG</li>
<li>можно перетащить изображение во вкладку PNG info для восстановления параметров генерации и автоматического копирования их в интерфейс</li>
<li>может быть отключено в настройках</li>
<li>поддержка drag-and-drop изображения/текста-параметров в окно промпта</li>
</ul>
</li>
<li>Кнопка Read Generation Parameters, загружает параметры из promptbox в UI</li>
<li>Страница настроек</li>
<li>Запуск произвольного python-кода из UI (необходимо запускать с <code>--allow-code</code>)</li>
<li>Подсказки при наведении мыши на большинство элементов UI</li>
<li>Возможность изменять значения по умолчанию/min/max/step для элементов UI через текстовую конфигурацию</li>
<li>Поддержка тайлинга — чекбокс для создания текстурируемых изображений</li>
<li>Прогресс-бар и предварительный просмотр изображения в реальном времени
<ul>
<li>Можно использовать отдельную нейросеть для предпросмотра, почти не требующую VRAM и вычислений</li>
</ul>
</li>
<li>Negative prompt — дополнительное текстовое поле для указания того, что вы не хотите видеть на изображении</li>
<li>Стили — возможность сохранять часть промпта и быстро применять их через выпадающий список</li>
<li>Вариации — генерация похожих изображений с небольшими отличиями</li>
<li>Seed resizing — генерация того же изображения при слегка изменённом разрешении</li>
<li>CLIP interrogator — кнопка, пытающаяся угадать промпт по изображению</li>
<li>Редактирование промпта — возможность изменять промпт во время генерации, например, начать с арбуза и перейти к аниме-девушке</li>
<li>Пакетная обработка — обработка группы файлов через img2img</li>
<li>Img2img Alternative — обратный метод Эйлера для управления cross-attention</li>
<li>Highres Fix — быстрый способ получить изображение высокого разрешения без обычных искажений</li>
<li>Горячая перезагрузка контрольных точек</li>
<li>Объединение контрольных точек (Checkpoint Merger) — вкладка для слияния до 3 чекпоинтов в один</li>
<li><a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Custom-Scripts">Пользовательские скрипты</a> с множеством расширений от сообщества</li>
<li><a href="https://energy-based-model.github.io/Compositional-Visual-Generation-with-Composable-Diffusion-Models/">Composable-Diffusion</a> — одновременное использование нескольких промптов
<ul>
<li>разделяйте промпты с помощью заглавного <code>AND</code></li>
<li>поддержка весов для промптов: <code>a cat :1.2 AND a dog AND a penguin :2.2</code></li>
</ul>
</li>
<li>Нет лимита на количество токенов в промпте (оригинальный stable diffusion позволяет до 75 токенов)</li>
<li>Интеграция DeepDanbooru — автоматическая генерация тегов в стиле danbooru для аниме-промптов</li>
<li><a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Xformers">xformers</a> — значительный прирост скорости для определённых видеокарт (добавьте <code>--xformers</code> в параметры командной строки)</li>
<li>через расширение: <a href="https://github.com/yfszzx/stable-diffusion-webui-images-browser">History tab</a>: удобный просмотр, управление и удаление изображений прямо из UI</li>
<li>Опция бесконечной генерации</li>
<li>Вкладка Training
<ul>
<li>опции для гиперсетей и эмбеддингов</li>
<li>Предобработка изображений: обрезка, отражение, автотегирование с использованием BLIP или deepdanbooru (для аниме)</li>
</ul>
</li>
<li>Clip skip</li>
<li>Гиперсети (Hypernetworks)</li>
<li>Loras (то же, что и Hypernetworks, но более удобные)</li>
<li>Отдельный интерфейс для выбора с предпросмотром, какие эмбеддинги, гиперсети или Loras добавить в промпт</li>
<li>Возможность выбрать другой VAE в настройках</li>
<li>Прогнозируемое время завершения в прогресс-баре</li>
<li>API</li>
<li>Поддержка специализированной <a href="https://github.com/runwayml/stable-diffusion#inpainting-with-stable-diffusion">inpainting-модели</a> от RunwayML</li>
<li>через расширение: <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui-aesthetic-gradients">Aesthetic Gradients</a> — генерация изображений с определённой эстетикой с помощью clip-эмбеддингов (реализация <a href="https://github.com/vicgalle/stable-diffusion-aesthetic-gradients">https://github.com/vicgalle/stable-diffusion-aesthetic-gradients</a>)</li>
<li>Поддержка <a href="https://github.com/Stability-AI/stablediffusion">Stable Diffusion 2.0</a> — инструкции см. на <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features#stable-diffusion-20">wiki</a></li>
<li>Поддержка <a href="https://arxiv.org/abs/2211.06679">Alt-Diffusion</a> — инструкции см. на <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features#alt-diffusion">wiki</a></li>
<li>Теперь без &quot;плохих букв&quot;!</li>
<li>Загрузка чекпоинтов в формате safetensors</li>
<li>Ослаблено ограничение разрешения: теперь размеры изображения должны быть кратны 8, а не 64</li>
<li>Теперь с лицензией!</li>
<li>Перестановка элементов UI из настроек</li>
<li>Поддержка <a href="https://huggingface.co/segmind/SSD-1B">Segmind Stable Diffusion</a></li>
</ul>
<h2>Установка и запуск</h2>
<p>Убедитесь, что выполнены все необходимые <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Dependencies">зависимости</a>, и следуйте инструкциям для:</p>
<ul>
<li><a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-NVidia-GPUs">NVidia</a> (рекомендуется)</li>
<li><a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-AMD-GPUs">AMD</a> GPU.</li>
<li><a href="https://github.com/openvinotoolkit/stable-diffusion-webui/wiki/Installation-on-Intel-Silicon">Intel CPU, Intel GPU (интегрированные и дискретные)</a> (внешняя wiki-страница)</li>
<li><a href="https://github.com/wangshuai09/stable-diffusion-webui/wiki/Install-and-run-on-Ascend-NPUs">Ascend NPU</a> (внешняя wiki-страница)</li>
</ul>
<p>Или используйте онлайн-сервисы (например, Google Colab):</p>
<ul>
<li><a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Online-Services">Список онлайн-сервисов</a></li>
</ul>
<h3>Установка на Windows 10/11 с NVidia-GPU через релиз-пакет</h3>
<ol>
<li>Скачайте <code>sd.webui.zip</code> из <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/releases/tag/v1.0.0-pre">v1.0.0-pre</a> и распакуйте содержимое.</li>
<li>Запустите <code>update.bat</code>.</li>
<li>Запустите <code>run.bat</code>.</li>
</ol>
<blockquote>
<p>Подробнее см. <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-NVidia-GPUs">Install-and-Run-on-NVidia-GPUs</a></p>
</blockquote>
<h3>Автоматическая установка на Windows</h3>
<ol>
<li>Установите <a href="https://www.python.org/downloads/release/python-3106/">Python 3.10.6</a> (Более новая версия Python не поддерживает torch), отметьте &quot;Add Python to PATH&quot;.</li>
<li>Установите <a href="https://git-scm.com/download/win">git</a>.</li>
<li>Скачайте репозиторий stable-diffusion-webui, например, выполнив <code>git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git</code>.</li>
<li>Запустите <code>webui-user.bat</code> из проводника Windows как обычный пользователь (не от администратора).</li>
</ol>
<h3>Автоматическая установка на Linux</h3>
<ol>
<li>Установите зависимости:</li>
</ol>
<pre><code class="language-bash"># На базе Debian:
sudo apt install wget git python3 python3-venv libgl1 libglib2.0-0
# На базе Red Hat:
sudo dnf install wget git python3 gperftools-libs libglvnd-glx
# На базе openSUSE:
sudo zypper install wget git python3 libtcmalloc4 libglvnd
# На базе Arch:
sudo pacman -S wget git python3
</code></pre>
<p>Если ваша система очень новая, установите python3.11 или python3.10:</p>
<pre><code class="language-bash"># Ubuntu 24.04
sudo add-apt-repository ppa:deadsnakes/ppa
sudo apt update
sudo apt install python3.11

# Manjaro/Arch
sudo pacman -S yay
yay -S python311 # не путать с пакетом python3.11

# Только для 3.11
# Затем установите переменную окружения в launch-скрипте
export python_cmd=&quot;python3.11&quot;
# или в webui-user.sh
python_cmd=&quot;python3.11&quot;
</code></pre>
<ol start="2">
<li>Перейдите в каталог, куда хотите установить webui, и выполните команду:</li>
</ol>
<pre><code class="language-bash">wget -q https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/webui.sh
</code></pre>
<p>Или просто клонируйте репозиторий куда хотите:</p>
<pre><code class="language-bash">git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui
</code></pre>
<ol start="3">
<li>Запустите <code>webui.sh</code>.</li>
<li>Проверьте <code>webui-user.sh</code> на наличие опций.</li>
</ol>
<h3>Установка на Apple Silicon</h3>
<p>Инструкции найдёте <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Installation-on-Apple-Silicon">здесь</a>.</p>
<h2>Вклад в проект</h2>
<p>Как внести свой код в этот репозиторий: <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing">Contributing</a></p>
<h2>Документация</h2>
<p>Документация была перенесена из этого README в <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki">wiki проекта</a>.</p>
<p>Чтобы Google и другие поисковики могли индексировать wiki, вот ссылка на (не для людей) <a href="https://github-wiki-see.page/m/AUTOMATIC1111/stable-diffusion-webui/wiki">crawlable wiki</a>.</p>
<h2>Благодарности</h2>
<p>Лицензии на заимствованный код можно найти в экране <code>Settings -&gt; Licenses</code>, а также в файле <code>html/licenses.html</code>.</p>
<ul>
<li>Stable Diffusion - https://github.com/Stability-AI/stablediffusion, https://github.com/CompVis/taming-transformers, https://github.com/mcmonkey4eva/sd3-ref</li>
<li>k-diffusion - https://github.com/crowsonkb/k-diffusion.git</li>
<li>Spandrel - https://github.com/chaiNNer-org/spandrel реализует
<ul>
<li>GFPGAN - https://github.com/TencentARC/GFPGAN.git</li>
<li>CodeFormer - https://github.com/sczhou/CodeFormer</li>
<li>ESRGAN - https://github.com/xinntao/ESRGAN</li>
<li>SwinIR - https://github.com/JingyunLiang/SwinIR</li>
<li>Swin2SR - https://github.com/mv-lab/swin2sr</li>
</ul>
</li>
<li>LDSR - https://github.com/Hafiidz/latent-diffusion</li>
<li>MiDaS - https://github.com/isl-org/MiDaS</li>
<li>Идеи для оптимизации - https://github.com/basujindal/stable-diffusion</li>
<li>Оптимизация слоя Cross Attention - Doggettx - https://github.com/Doggettx/stable-diffusion, оригинальная идея для редактирования промпта.</li>
<li>Оптимизация слоя Cross Attention - InvokeAI, lstein - https://github.com/invoke-ai/InvokeAI (изначально http://github.com/lstein/stable-diffusion)</li>
<li>Sub-quadratic Cross Attention layer optimization - Alex Birch (https://github.com/Birch-san/diffusers/pull/1), Amin Rezaei (https://github.com/AminRezaei0x443/memory-efficient-attention)</li>
<li>Textual Inversion - Rinon Gal - https://github.com/rinongal/textual_inversion (мы не используем его код, но используем его идеи).</li>
<li>Идея для SD upscale - https://github.com/jquesnelle/txt2imghd</li>
<li>Генерация шума для outpainting mk2 - https://github.com/parlance-zz/g-diffuser-bot</li>
<li>Идея и часть кода CLIP interrogator - https://github.com/pharmapsychotic/clip-interrogator</li>
<li>Идея для Composable Diffusion - https://github.com/energy-based-model/Compositional-Visual-Generation-with-Composable-Diffusion-Models-PyTorch</li>
<li>xformers - https://github.com/facebookresearch/xformers</li>
<li>DeepDanbooru — interrogator для anime diffusers https://github.com/KichangKim/DeepDanbooru</li>
<li>Сэмплирование в float32 precision из float16 UNet — marunine за идею, Birch-san за пример реализации в Diffusers (https://github.com/Birch-san/diffusers-play/tree/92feee6)</li>
<li>Instruct pix2pix — Tim Brooks (star), Aleksander Holynski (star), Alexei A. Efros (no star) — https://github.com/timothybrooks/instruct-pix2pix</li>
<li>Советы по безопасности — RyotaK</li>
<li>UniPC sampler — Wenliang Zhao — https://github.com/wl-zhao/UniPC</li>
<li>TAESD — Ollin Boer Bohan — https://github.com/madebyollin/taesd</li>
<li>LyCORIS — KohakuBlueleaf</li>
<li>Restart sampling — lambertae — https://github.com/Newbeeer/diffusion_restart_sampling</li>
<li>Hypertile — tfernd — https://github.com/tfernd/HyperTile</li>
<li>Начальный скрипт Gradio — выложен на 4chan анонимным пользователем. Спасибо, анонимный пользователь.</li>
<li>(Вы)</li>
</ul>
<hr />
<p><a href="https://github.com/OpenAiTx/OpenAiTx">Powered By OpenAiTx</a></p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
</body>
</html>