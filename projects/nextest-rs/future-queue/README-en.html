<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>future-queue - nextest-rs/future-queue en</title>
    <meta name="title" content="future-queue - nextest-rs/future-queue en | future-queue future_queue provides ways to run several futures: concurrently in the order they're spawned with global limits and with an optional group specifie...">
    <meta name="description" content="nextest-rs/future-queue - GitHub repository en documentation and information | future-queue future_queue provides ways to run several futures: concurrently in the order they're spawned with global limits and with an optional group specifie...">
    <meta name="keywords" content="nextest-rs, future-queue, GitHub, repository, en documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/nextest-rs/future-queue/README-en.html">
    <meta property="og:title" content="future-queue - nextest-rs/future-queue en | future-queue future_queue provides ways to run several futures: concurrently in the order they're spawned with global limits and with an optional group specifie...">
    <meta property="og:description" content="nextest-rs/future-queue - GitHub repository en documentation and information | future-queue future_queue provides ways to run several futures: concurrently in the order they're spawned with global limits and with an optional group specifie...">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div style="position: fixed; top: 2px; left: 2px; z-index: 2000; background: rgba(255,255,255,0.95); border-radius: 6px; box-shadow: 0 2px 8px rgba(0,0,0,0.06); padding: 4px 14px; font-size: 15px; color: #222; font-family: 'Segoe UI', Arial, sans-serif; font-weight: 500; letter-spacing: 0.5px;">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" style="color: #0366d6; text-decoration: none; font-weight: 600;">Open AI Tx</a>
    </div>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/nextest-rs/future-queue" id="githubRepoLink" target="_blank">nextest-rs/future-queue</a>
<h1 style="display: none;">future-queue future_queue provides ways to run several futures: concurrently in the order they're spawned with global limits and with an optional group specifie...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <h1>future-queue</h1>
<p><a href="https://crates.io/crates/future-queue"><img src="https://img.shields.io/crates/v/future-queue" alt="future-queue on crates.io" /></a>
<a href="https://docs.rs/future-queue/"><img src="https://img.shields.io/badge/docs-latest-brightgreen.svg" alt="Documentation (latest release)" /></a>
<a href="https://nextest-rs.github.io/future-queue/rustdoc/future_queue"><img src="https://img.shields.io/badge/docs-main-purple" alt="Documentation (main)" /></a>
<a href="https://raw.githubusercontent.com/nextest-rs/future-queue/main/CHANGELOG.md"><img src="https://img.shields.io/badge/changelog-latest-blue" alt="Changelog" /></a>
<a href="https://raw.githubusercontent.com/nextest-rs/future-queue/main/LICENSE-APACHE"><img src="https://img.shields.io/badge/license-Apache-green.svg" alt="License" /></a>
<a href="https://raw.githubusercontent.com/nextest-rs/future-queue/main/LICENSE-MIT"><img src="https://img.shields.io/badge/license-MIT-green.svg" alt="License" /></a></p>
<p><code>future_queue</code> provides ways to run several futures:</p>
<ul>
<li>concurrently</li>
<li>in the order they're spawned</li>
<li>with global limits</li>
<li>and with an optional group specified for each future, with its own limits.</li>
</ul>
<p>This crate is part of the <a href="https://github.com/nextest-rs">nextest organization</a> on GitHub, and is designed to serve the needs of <a href="https://nexte.st">cargo-nextest</a>.</p>
<h2>Motivation</h2>
<p>Async programming in Rust often uses an adaptor called <a href="https://docs.rs/futures/latest/futures/stream/trait.StreamExt.html#method.buffer_unordered"><code>buffer_unordered</code></a>: this adaptor takes a stream of futures[^1], and executes all the futures limited to a maximum amount of concurrency.</p>
<ul>
<li>Futures are started in the order the stream returns them in.</li>
<li>Once started, futures are polled simultaneously, and completed future outputs are returned in arbitrary order (hence the <code>unordered</code>).</li>
</ul>
<p>Common use cases for <code>buffer_unordered</code> include:</p>
<ul>
<li>Sending network requests concurrently, but limiting the amount of concurrency to avoid overwhelming the remote server.</li>
<li>Running tests with a tool like <a href="https://nexte.st">cargo-nextest</a>.</li>
</ul>
<p><code>buffer_unordered</code> works well for many use cases. However, one issue with it is that it treats all futures as equally taxing: there's no way to say that some futures consume more resources than others, or that some subsets of futures should be mutually excluded from others.</p>
<p>For nextest in particular, some tests can be much heavier than others, and fewer of those tests should be run simultaneously. Also, some tests need to be mutually excluded from others, or other concurrency limits placed on them.</p>
<p>[^1]: This adaptor takes a stream of futures for maximum generality. In practice this is often an <em>iterator</em> of futures, converted over using <a href="https://docs.rs/futures/latest/futures/stream/fn.iter.html"><code>stream::iter</code></a>.</p>
<h2>About this crate</h2>
<p>This crate provides two adaptors on streams.</p>
<h3>1. The <code>future_queue</code> adaptor</h3>
<p>The <a href="https://raw.githubusercontent.com/nextest-rs/future-queue/main/StreamExt::future_queue"><code>future_queue</code></a> adaptor can run several futures simultaneously, limiting the concurrency to a maximum <em>weight</em>.</p>
<p>Rather than taking a stream of futures, this adaptor takes a stream of <code>(usize, F)</code> pairs, where the <code>usize</code> indicates the weight of each future, and <code>F</code> is <code>FnOnce(FutureQueueContext) -&gt; impl Future</code>. This adaptor will schedule and buffer futures to be run until queueing the next future will exceed the maximum weight.</p>
<ul>
<li>The maximum weight is never exceeded while futures are being run.</li>
<li>If the weight of an individual future is greater than the maximum weight, its weight will be set to the maximum weight.</li>
</ul>
<p>Once all possible futures are scheduled, this adaptor will wait until some of the currently executing futures complete, and the current weight of running futures drops below the maximum weight, before scheduling new futures.</p>
<p>The weight of a future can be zero, in which case it doesn't count towards the maximum weight.</p>
<p>If all weights are 1, then <code>future_queue</code> is exactly the same as <code>buffer_unordered</code>.</p>
<h4>Examples</h4>
<pre><code class="language-rust">use futures::{channel::oneshot, stream, StreamExt as _};
use future_queue::{StreamExt as _};

let (send_one, recv_one) = oneshot::channel();
let (send_two, recv_two) = oneshot::channel();

let stream_of_futures = stream::iter(
    vec![(1, recv_one), (2, recv_two)],
).map(|(weight, future)| {
    (weight, move |_cx| future)
});
let mut queue = stream_of_futures.future_queue(10);

send_two.send(&quot;hello&quot;)?;
assert_eq!(queue.next().await, Some(Ok(&quot;hello&quot;)));

send_one.send(&quot;world&quot;)?;
assert_eq!(queue.next().await, Some(Ok(&quot;world&quot;)));

assert_eq!(queue.next().await, None);
</code></pre>
<h3>2. The <code>future_queue_grouped</code> adaptor</h3>
<p>The <a href="https://raw.githubusercontent.com/nextest-rs/future-queue/main/StreamExt::future_queue_grouped"><code>future_queue_grouped</code></a> adaptor is like <code>future_queue</code>, except it is possible to specify an optional <em>group</em> for each future. Each group has a maximum weight, and a future will only be scheduled if both the maximum weight and the group weight aren't exceeded.</p>
<p>The adaptor is as fair as possible under the given constraints: it will schedule futures in the order they're returned by the stream, without doing any reordering based on weight. When a future from a group completes, queued up futures in this group will be preferentially scheduled before any other futures from the provided stream.</p>
<p>Like with <a href="https://raw.githubusercontent.com/nextest-rs/future-queue/main/StreamExt::future_queue"><code>future_queue</code></a>:</p>
<ul>
<li>The maximum global and group weights is never exceeded while futures are being run.</li>
<li>While accounting against global weights, if the weight of an individual future is greater than the maximum weight, its weight will be set to the maximum weight.</li>
<li><em>If a future belongs to a group:</em> While accounting against the group weight, if its weight is greater than the maximum group weight, its weight will be set to the maximum group weight.</li>
</ul>
<h4>Examples</h4>
<pre><code class="language-rust">use futures::{channel::oneshot, stream, StreamExt as _};
use future_queue::{FutureQueueContext, StreamExt as _};

let (send_one, recv_one) = oneshot::channel();
let (send_two, recv_two) = oneshot::channel();

let stream_of_futures = stream::iter(
    vec![
        (1, Some(&quot;group1&quot;), recv_one),
        (2, None, recv_two),
    ],
).map(|(weight, group, future)| {
    (weight, group, move |_cx| future)
});
let mut queue = stream_of_futures.future_queue_grouped(10, [(&quot;group1&quot;, 5)]);

send_two.send(&quot;hello&quot;)?;
assert_eq!(queue.next().await, Some(Ok(&quot;hello&quot;)));

send_one.send(&quot;world&quot;)?;
assert_eq!(queue.next().await, Some(Ok(&quot;world&quot;)));

assert_eq!(queue.next().await, None);
</code></pre>
<h2>Minimum supported Rust version (MSRV)</h2>
<p>The minimum supported Rust version is <strong>Rust 1.70.</strong> At any time, at least the last six months of Rust stable releases are supported.</p>
<p>While this crate is a pre-release (0.x.x) it may have its MSRV bumped in a patch release. Once this crate has reached 1.x, any MSRV bump will be accompanied with a new minor version.</p>
<h2>Notes</h2>
<p>This crate used to be called <code>buffer-unordered-weighted</code>. It was renamed to <code>future-queue</code> to be more descriptive about what the crate does rather than how it's implemented.</p>
<h2>Contributing</h2>
<p>See the <a href="https://raw.githubusercontent.com/nextest-rs/future-queue/main/CONTRIBUTING.md">CONTRIBUTING</a> file for how to help out.</p>
<h2>License</h2>
<p>This project is available under the terms of either the <a href="https://raw.githubusercontent.com/nextest-rs/future-queue/main/LICENSE-APACHE">Apache 2.0 license</a> or the <a href="https://raw.githubusercontent.com/nextest-rs/future-queue/main/LICENSE-MIT">MIT license</a>.</p>
<p>The code is derived from <a href="https://github.com/rust-lang/futures-rs">futures-rs</a>, and is used under the Apache 2.0 and MIT licenses.</p>
<!--
README.md is generated from README.tpl by cargo readme. To regenerate, run from the repository root:

./scripts/regenerate-readmes.sh
-->
<hr />
<p>Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx">Open Ai Tx</a> | Last indexed: 2025-06-07</p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
</body>
</html>