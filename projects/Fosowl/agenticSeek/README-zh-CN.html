<!DOCTYPE html><html lang="en"><head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AgenticSeek：本地私有的 Manus 替代方案 - Fosowl/agenticSeek</title>

    <!-- Primary Meta Tags -->
    <meta name="title" content="AgenticSeek：本地私有的 Manus 替代方案 - Fosowl/agenticSeek">
    <meta name="description" content="Fosowl/agenticSeek - GitHub repository zh-CN documentation and information">
    <meta name="keywords" content="Fosowl, agenticSeek, GitHub, repository, zh-CN documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">

    <!-- Open Graph -->
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/Fosowl/agenticSeek/README-zh-CN.html">
    <meta property="og:title" content="AgenticSeek：本地私有的 Manus 替代方案 - Fosowl/agenticSeek">
    <meta property="og:description" content="Fosowl/agenticSeek - GitHub repository zh-CN documentation and information">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">

    <!-- Favicon -->
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">

    <!-- Marked.js for Markdown rendering -->
    <script type="text/javascript" async="" src="https://www.statcounter.com/counter/recorder.js"></script><script src="/js/marked.min.js?v=20250613"></script>
    <!-- Highlight.js for code syntax highlighting -->
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <!-- Custom CSS -->
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        /* Layout */
        body {
            display: flex;
            flex-direction: column;
            min-height: 100vh;
        }

        .main-container {
            margin: 0 auto;
            width: 100%;
            max-width: 980px;
            padding: 0 20px;
        }

        @media (max-width: 768px) {
            .main-container {
                padding: 0 15px;
            }
        }

        /* Image size restrictions */
        .markdown-body img {
            max-width: 100%;
            height: auto;
        }

        /* Existing styles */
        .header {
            text-align: center;
            margin-bottom: 30px;
            padding: 20px;
            background-color: #f6f8fa;
            border-bottom: 1px solid #e1e4e8;
            position: relative;
        }

        .back-button {
            position: absolute;
            left: 20px;
            top: 50%;
            transform: translateY(-50%);
            color: #0366d6;
            text-decoration: none;
            display: flex;
            align-items: center;
            font-size: 14px;
            padding: 5px 10px;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            background-color: #fff;
        }

        .back-button:hover {
            background-color: #f6f8fa;
            border-color: #0366d6;
        }

        .back-button::before {
            content: "←";
            margin-right: 5px;
            font-size: 16px;
        }

        .header .links {
            margin-top: 10px;
            font-size: 16px;
        }

        .header .links a {
            color: #0366d6;
            text-decoration: none;
            margin-left: 5px;
        }

        .header .links a:hover {
            text-decoration: underline;
        }
        
        /* Language badges styles */
        .language-badges {
            margin-top: 15px;
            text-align: center;
        }
        .language-badges a {
            display: inline-block;
            margin: 2px;
            text-decoration: none;
        }
        .language-badges img {
            height: 20px;
            border-radius: 3px;
        }
        .language-badges a:hover img {
            opacity: 0.8;
        }
    </style>
</head>

<body>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/Fosowl/agenticSeek" id="githubRepoLink" target="_blank">Fosowl/agenticSeek</a>
        </div>
        <div class="language-badges" id="languageBadges"><a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=en"><img src="https://img.shields.io/badge/EN-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=zh-CN"><img src="https://img.shields.io/badge/简中-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=zh-TW"><img src="https://img.shields.io/badge/繁中-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=ja"><img src="https://img.shields.io/badge/日本語-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=ko"><img src="https://img.shields.io/badge/한국어-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=th"><img src="https://img.shields.io/badge/ไทย-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=fr"><img src="https://img.shields.io/badge/Français-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=de"><img src="https://img.shields.io/badge/Deutsch-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=es"><img src="https://img.shields.io/badge/Español-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=it"><img src="https://img.shields.io/badge/Italiano-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=ru"><img src="https://img.shields.io/badge/Русский-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=pt"><img src="https://img.shields.io/badge/Português-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=nl"><img src="https://img.shields.io/badge/Nederlands-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=pl"><img src="https://img.shields.io/badge/Polski-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=ar"><img src="https://img.shields.io/badge/العربية-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=tr"><img src="https://img.shields.io/badge/Türkçe-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=vi"><img src="https://img.shields.io/badge/Tiếng Việt-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=hi"><img src="https://img.shields.io/badge/हिंदी-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=fa"><img src="https://img.shields.io/badge/فارسی-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=id"><img src="https://img.shields.io/badge/Bahasa Indonesia-white" alt="version"></a></div>
    </div>

    <div class="main-container">
        <div class="markdown-body" id="content"><h1>AgenticSeek：本地私有的 Manus 替代方案</h1>
<p align="center">
<img align="center" src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/agentic_seek_logo.png" width="300" height="300" alt="Agentic Seek Logo">
</p><p>

</p><p>  English | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_CHS.md">中文</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_CHT.md">繁體中文</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_FR.md">Français</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_JP.md">日本語</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_PTBR.md">Português (Brasil)</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_ES.md">Español</a></p>
<p><em>一个*<em>100% 本地化的 Manus AI 替代方案</em></em>，此语音驱动的 AI 助手可自主浏览网页、编写代码、规划任务，所有数据都保存在您的设备上。为本地推理模型量身定制，完全在您的硬件上运行，确保数据隐私，无需依赖云端。*</p>
<p><a href="https://fosowl.github.io/agenticSeek.html"><img src="https://img.shields.io/static/v1?label=Website&amp;message=AgenticSeek&amp;color=blue&amp;style=flat-square" alt="访问 AgenticSeek"></a> <img src="https://img.shields.io/badge/license-GPL--3.0-green" alt="License"> <a href="https://discord.gg/8hGDaME3TC"><img src="https://img.shields.io/badge/Discord-Join%20Us-7289DA?logo=discord&amp;logoColor=white" alt="Discord"></a> <a href="https://x.com/Martin993886460"><img src="https://img.shields.io/twitter/url/https/twitter.com/fosowl.svg?style=social&amp;label=Update%20%40Fosowl" alt="Twitter"></a> <a href="https://github.com/Fosowl/agenticSeek/stargazers"><img src="https://img.shields.io/github/stars/Fosowl/agenticSeek?style=social" alt="GitHub stars"></a></p>
<h3>为什么选择 AgenticSeek？</h3>
<ul>
<li><p>🔒 完全本地&amp;私有 —— 所有内容在您的计算机上运行，无云端、无数据共享。您的文件、对话和搜索都保持私密。</p>
</li>
<li><p>🌐 智能网页浏览 —— AgenticSeek 能自主上网搜索、阅读、提取信息、填写网页表单，全程免手动操作。</p>
</li>
<li><p>💻 自主编程助手 —— 需要代码？它能编写、调试并运行 Python、C、Go、Java 等多种程序，无需人工干预。</p>
</li>
<li><p>🧠 智能代理选择 —— 您只需提问，它会自动选择最适合的 AI 代理处理任务，就像有一支专家团队随时待命。</p>
</li>
<li><p>📋 规划并执行复杂任务 —— 从行程规划到复杂项目，能将大任务拆分为步骤，利用多智能体高效完成。</p>
</li>
<li><p>🎙️ 语音驱动 —— 干净、快速、未来感十足的语音与语音转文字功能，让您像在科幻电影中那样与个人 AI 对话。（开发中）</p>
</li>
</ul>
<h3><strong>演示</strong></h3>
<blockquote>
<p><em>你能搜索 agenticSeek 项目，了解需要哪些技能，然后打开 CV_candidates.zip，告诉我哪个最匹配该项目吗</em></p>
</blockquote>
<p><a href="https://github.com/user-attachments/assets/b8ca60e9-7b3b-4533-840e-08f9ac426316">https://github.com/user-attachments/assets/b8ca60e9-7b3b-4533-840e-08f9ac426316</a></p>
<p>免责声明：该演示及所有出现的文件（如：CV_candidates.zip）均为虚构。我们不是公司，仅寻求开源贡献者而非候选人。</p>
<blockquote>
<p>🛠⚠️️ <strong>项目正在积极开发中</strong></p>
</blockquote>
<blockquote>
<p>🙏 本项目起初只是一个副业项目，没有明确的路线图和资金支持。它超出了我的预期并登上了 GitHub Trending。非常感谢您的贡献、反馈与耐心。</p>
</blockquote>
<h2>前置条件</h2>
<p>在开始之前，请确保已安装以下软件：</p>
<ul>
<li><strong>Git：</strong> 用于克隆仓库。<a href="https://git-scm.com/downloads">下载 Git</a></li>
<li><strong>Python 3.10.x：</strong> 强烈建议使用 Python 3.10.x 版本。其他版本可能会导致依赖错误。<a href="https://www.python.org/downloads/release/python-3100/">下载 Python 3.10</a>（请选择 3.10.x 版本）。</li>
<li><strong>Docker Engine &amp; Docker Compose：</strong> 用于运行如 SearxNG 等捆绑服务。<ul>
<li>安装 Docker Desktop（包含 Docker Compose V2）：<a href="https://docs.docker.com/desktop/install/windows-install/">Windows</a> | <a href="https://docs.docker.com/desktop/install/mac-install/">Mac</a> | <a href="https://docs.docker.com/desktop/install/linux-install/">Linux</a></li>
<li>或者在 Linux 上分别安装 Docker Engine 和 Docker Compose：<a href="https://docs.docker.com/engine/install/">Docker Engine</a> | <a href="https://docs.docker.com/compose/install/">Docker Compose</a>（请确保安装 Compose V2，例如 <code>sudo apt-get install docker-compose-plugin</code>）。</li>
</ul>
</li>
</ul>
<h3>1. <strong>克隆仓库并进行设置</strong></h3>
<pre><code class="language-sh hljs language-bash">git <span class="hljs-built_in">clone</span> https://github.com/Fosowl/agenticSeek.git
<span class="hljs-built_in">cd</span> agenticSeek
<span class="hljs-built_in">mv</span> .env.example .<span class="hljs-built_in">env</span>
</code></pre>
<h3>2. 修改 .env 文件内容</h3>
<pre><code class="language-sh hljs language-bash">SEARXNG_BASE_URL=<span class="hljs-string">"http://127.0.0.1:8080"</span>
REDIS_BASE_URL=<span class="hljs-string">"redis://redis:6379/0"</span>
WORK_DIR=<span class="hljs-string">"/Users/mlg/Documents/workspace_for_ai"</span>
OLLAMA_PORT=<span class="hljs-string">"11434"</span>
LM_STUDIO_PORT=<span class="hljs-string">"1234"</span>
CUSTOM_ADDITIONAL_LLM_PORT=<span class="hljs-string">"11435"</span>
OPENAI_API_KEY=<span class="hljs-string">'optional'</span>
DEEPSEEK_API_KEY=<span class="hljs-string">'optional'</span>
OPENROUTER_API_KEY=<span class="hljs-string">'optional'</span>
TOGETHER_API_KEY=<span class="hljs-string">'optional'</span>
GOOGLE_API_KEY=<span class="hljs-string">'optional'</span>
ANTHROPIC_API_KEY=<span class="hljs-string">'optional'</span>
</code></pre>
<p>根据需要用您自己的值更新 <code>.env</code> 文件：</p>
<ul>
<li><strong>SEARXNG_BASE_URL</strong>：保持不变</li>
<li><strong>REDIS_BASE_URL</strong>：保持不变</li>
<li><strong>WORK_DIR</strong>：本地机器上的工作目录路径。AgenticSeek 可以读取和操作这些文件。</li>
<li><strong>OLLAMA_PORT</strong>：Ollama 服务端口号。</li>
<li><strong>LM_STUDIO_PORT</strong>：LM Studio 服务端口号。</li>
<li><strong>CUSTOM_ADDITIONAL_LLM_PORT</strong>：任何自定义 LLM 服务的端口号。</li>
</ul>
<p><strong>API Key 完全可选，针对选择本地运行 LLM 的用户。该项目的主要目标即为此。如果硬件足够请留空。</strong></p>
<h3>3. <strong>启动 Docker</strong></h3>
<p>确保您的系统已安装并运行 Docker。可用以下命令启动 Docker：</p>
<ul>
<li><p><strong>在 Linux/macOS 上：</strong><br>  打开终端并运行：</p>
<pre><code class="language-sh hljs language-bash">sudo systemctl start docker
</code></pre>
<p>  或者在应用程序菜单中启动 Docker Desktop（如已安装）。</p>
</li>
<li><p><strong>在 Windows 上：</strong><br>  从开始菜单启动 Docker Desktop。</p>
</li>
</ul>
<p>可通过以下命令验证 Docker 是否运行：</p>
<pre><code class="language-sh hljs language-bash">docker info
</code></pre>
<p>如果显示有关 Docker 安装的信息，则说明运行正常。</p>
<p>本地提供商的汇总见下表 <a href="#list-of-local-providers">Local Providers</a>。</p>
<p>下一步：<a href="#start-services-and-run">本地运行 AgenticSeek</a></p>
<p><em>如遇问题，请参阅 <a href="#troubleshooting">故障排查</a> 部分。</em><br><em>如您的硬件无法本地运行 LLM，请参考 <a href="#setup-to-run-with-an-api">API 运行设置</a>。</em><br><em>如需详细 <code>config.ini</code> 配置说明，请参见 <a href="#config">Config Section</a>。</em></p>
<hr>
<h2>本地运行 LLM 设置</h2>
<p><strong>硬件要求：</strong></p>
<p>如需本地运行 LLM，需具备足够的硬件资源。最低需有可运行 Magistral、Qwen 或 Deepseek 14B 的 GPU。详细的模型/性能建议请参见 FAQ。</p>
<p><strong>设置本地提供商</strong></p>
<p>启动本地提供商，例如使用 ollama：</p>
<pre><code class="language-sh hljs language-bash">ollama serve
</code></pre>
<p>下方列出本地支持的提供商。</p>
<p><strong>更新 config.ini</strong></p>
<p>修改 config.ini，将 provider_name 设置为受支持的提供商，将 provider_model 设置为该提供商支持的 LLM。推荐推理模型如 <em>Magistral</em> 或 <em>Deepseek</em>。</p>
<p>所需硬件请参考 README 最后的 <strong>FAQ</strong>。</p>
<pre><code class="language-sh hljs language-bash">[MAIN]
is_local = True <span class="hljs-comment"># 是否本地运行，或使用远程提供商</span>
provider_name = ollama <span class="hljs-comment"># 或 lm-studio、openai 等</span>
provider_model = deepseek-r1:14b <span class="hljs-comment"># 选择适合硬件的模型</span>
provider_server_address = 127.0.0.1:11434
agent_name = Jarvis <span class="hljs-comment"># AI 名称</span>
recover_last_session = True <span class="hljs-comment"># 是否恢复上次会话</span>
save_session = True <span class="hljs-comment"># 是否记住当前会话</span>
speak = False <span class="hljs-comment"># 文本转语音</span>
listen = False <span class="hljs-comment"># 语音转文本，仅 CLI，实验性</span>
jarvis_personality = False <span class="hljs-comment"># 是否使用更“Jarvis”风格的个性（实验性）</span>
languages = en zh <span class="hljs-comment"># 支持的语言列表，TTS 默认使用第一个</span>
[BROWSER]
headless_browser = True <span class="hljs-comment"># 除非在主机 CLI 使用，否则保持不变</span>
stealth_mode = True <span class="hljs-comment"># 使用 undetected selenium 降低被浏览器检测的概率</span>
</code></pre>
<p><strong>注意事项</strong>：</p>
<ul>
<li><p><code>config.ini</code> 文件格式不支持注释。<br>请勿直接复制示例配置中的注释，否则会报错。请手动根据需求修改 <code>config.ini</code>，并去除所有注释。</p>
</li>
<li><p>如使用 LM-studio 本地运行 LLM，不要将 provider_name 设置为 <code>openai</code>，请设为 <code>lm-studio</code>。</p>
</li>
<li><p>某些提供商（如 lm-studio）需要在 IP 前加 <code>http://</code>，如 <code>http://127.0.0.1:1234</code></p>
</li>
</ul>
<p><strong>本地提供商列表</strong></p>
<table>
<thead>
<tr>
<th>提供商</th>
<th>本地？</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>ollama</td>
<td>是</td>
<td>通过 ollama 作为 LLM 提供商，轻松本地运行 LLM</td>
</tr>
<tr>
<td>lm-studio</td>
<td>是</td>
<td>使用 LM studio 本地运行 LLM（<code>provider_name</code> 设为 <code>lm-studio</code>）</td>
</tr>
<tr>
<td>openai</td>
<td>是</td>
<td>使用 openai 兼容 API（如 llama.cpp server）</td>
</tr>
</tbody></table>
<p>下一步：<a href="#Start-services-and-Run">启动服务并运行 AgenticSeek</a></p>
<p><em>如遇问题，请参阅 <a href="#troubleshooting">故障排查</a> 部分。</em><br><em>如您的硬件无法本地运行 LLM，请参考 <a href="#setup-to-run-with-an-api">API 运行设置</a>。</em><br><em>如需详细 <code>config.ini</code> 配置说明，请参见 <a href="#config">Config Section</a>。</em></p>
<h2>使用 API 运行设置</h2>
<p>此方式使用外部云端 LLM 提供商。您需要从所选服务获取 API key。</p>
<p><strong>1. 选择 API 提供商并获取 API Key：</strong></p>
<p>参见下方 <a href="#list-of-api-providers">API 提供商列表</a>。访问其官网注册并获得 API key。</p>
<p><strong>2. 将 API Key 设为环境变量：</strong></p>
<ul>
<li><strong>Linux/macOS:</strong><br>打开终端，使用 <code>export</code> 命令。建议添加到 shell 配置文件（如 <code>~/.bashrc</code>、<code>~/.zshrc</code>）以便持久生效。<pre><code class="language-sh hljs language-bash"><span class="hljs-built_in">export</span> PROVIDER_API_KEY=<span class="hljs-string">"your_api_key_here"</span>
<span class="hljs-comment"># 将 PROVIDER_API_KEY 替换为具体变量名，如 OPENAI_API_KEY、GOOGLE_API_KEY</span>
</code></pre>
TogetherAI 示例：<pre><code class="language-sh hljs language-bash"><span class="hljs-built_in">export</span> TOGETHER_API_KEY=<span class="hljs-string">"xxxxxxxxxxxxxxxxxxxxxx"</span>
</code></pre>
</li>
<li><strong>Windows:</strong></li>
<li><strong>命令提示符（当前会话临时生效）：</strong><pre><code class="language-cmd">set PROVIDER_API_KEY=your_api_key_here
</code></pre>
</li>
<li><strong>PowerShell（当前会话临时生效）：</strong><pre><code class="language-powershell">$env:PROVIDER_API_KEY="your_api_key_here"
</code></pre>
</li>
<li><strong>永久生效：</strong> 在 Windows 搜索栏中搜索“环境变量”，点击“编辑系统环境变量”，然后点击“环境变量...”按钮。添加一个新的用户变量，名称为相应的变量名（如 <code>OPENAI_API_KEY</code>），值为你的密钥。</li>
</ul>
<p><em>（详见常见问题：<a href="#how-do-i-set-api-keys">如何设置 API 密钥？</a>）</em></p>
<p><strong>3. 更新 <code>config.ini</code>：</strong></p>
<pre><code class="language-ini hljs"><span class="hljs-section">[MAIN]</span>
<span class="hljs-attr">is_local</span> = <span class="hljs-literal">False</span>
<span class="hljs-attr">provider_name</span> = openai <span class="hljs-comment"># 或 google, deepseek, togetherAI, huggingface</span>
<span class="hljs-attr">provider_model</span> = gpt-<span class="hljs-number">3.5</span>-turbo <span class="hljs-comment"># 或 gemini-1.5-flash, deepseek-chat, mistralai/Mixtral-8x7B-Instruct-v0.1 等</span>
provider_server_address = <span class="hljs-comment"># 当 is_local = False 时通常忽略或可留空，大多数 API 均如此</span>
<span class="hljs-comment"># ... 其他设置 ...</span>
</code></pre>
<p><em>警告：</em> 请确保 <code>config.ini</code> 的值中没有尾随空格。</p>
<p><strong>API 提供商列表</strong></p>
<table>
<thead>
<tr>
<th>提供商</th>
<th><code>provider_name</code></th>
<th>本地？</th>
<th>描述</th>
<th>API 密钥链接（示例）</th>
</tr>
</thead>
<tbody><tr>
<td>OpenAI</td>
<td><code>openai</code></td>
<td>否</td>
<td>通过 OpenAI 的 API 使用 ChatGPT 模型。</td>
<td><a href="https://platform.openai.com/signup">platform.openai.com/signup</a></td>
</tr>
<tr>
<td>Google Gemini</td>
<td><code>google</code></td>
<td>否</td>
<td>通过 Google AI Studio 使用 Google Gemini 模型。</td>
<td><a href="https://aistudio.google.com/keys">aistudio.google.com/keys</a></td>
</tr>
<tr>
<td>Deepseek</td>
<td><code>deepseek</code></td>
<td>否</td>
<td>通过 Deepseek 的 API 使用 Deepseek 模型。</td>
<td><a href="https://platform.deepseek.com">platform.deepseek.com</a></td>
</tr>
<tr>
<td>Hugging Face</td>
<td><code>huggingface</code></td>
<td>否</td>
<td>通过 Hugging Face Inference API 使用模型。</td>
<td><a href="https://huggingface.co/settings/tokens">huggingface.co/settings/tokens</a></td>
</tr>
<tr>
<td>TogetherAI</td>
<td><code>togetherAI</code></td>
<td>否</td>
<td>通过 TogetherAI API 使用多种开源模型。</td>
<td><a href="https://api.together.ai/settings/api-keys">api.together.ai/settings/api-keys</a></td>
</tr>
</tbody></table>
<p><em>注意：</em></p>
<ul>
<li>我们不建议在复杂网页浏览和任务规划场景下使用 <code>gpt-4o</code> 或其他 OpenAI 模型，因为当前的提示词优化主要面向 Deepseek 等模型。</li>
<li>在编码/bash 任务中，Gemini 可能无法严格遵循为 Deepseek 优化的格式化提示，可能会出现问题。</li>
<li>当 <code>is_local = False</code> 时，<code>config.ini</code> 中的 <code>provider_server_address</code> 一般不会被使用，因为各提供商库中通常已硬编码了 API 端点。</li>
</ul>
<p>下一步：<a href="#Start-services-and-Run">启动服务并运行 AgenticSeek</a></p>
<p><em>如遇问题请参见 <strong>已知问题</strong> 部分</em></p>
<p><em>详细配置文件说明请参见 <strong>Config</strong> 部分。</em></p>
<hr>
<h2>启动服务并运行</h2>
<p>默认情况下，AgenticSeek 完全在 Docker 中运行。</p>
<p>启动所需服务。这将启动 docker-compose.yml 中的所有服务，包括：</p>
<ul>
<li>searxng</li>
<li>redis（searxng 需要）</li>
<li>前端</li>
<li>后端（如使用 <code>full</code>）</li>
</ul>
<pre><code class="language-sh hljs language-bash">./start_services.sh full <span class="hljs-comment"># MacOS</span>
start ./start_services.cmd full <span class="hljs-comment"># Window</span>
</code></pre>
<p><strong>警告：</strong> 此步骤将下载并加载所有 Docker 镜像，可能需要长达 30 分钟。启动服务后，请等待后端服务完全运行（你应该在日志中看到 <strong>backend: "GET /health HTTP/1.1" 200 OK</strong>）再发送任何消息。首次运行时后端服务可能需要 5 分钟启动。</p>
<p>访问 <code>http://localhost:3000/</code>，你应该可以看到 Web 界面。</p>
<p><em>服务启动故障排查：</em> 如脚本启动失败，请确保 Docker Engine 已运行且 Docker Compose（V2，<code>docker compose</code>）已正确安装。检查终端输出的错误信息。参见 <a href="#faq-troubleshooting">常见问题：运行 AgenticSeek 或其脚本时报错怎么办？</a></p>
<p><strong>可选：</strong> 在主机上运行（CLI 模式）：</p>
<p>如需用 CLI 界面运行，需要在主机上安装依赖包：</p>
<pre><code class="language-sh hljs language-bash">./install.sh
./install.bat <span class="hljs-comment"># windows</span>
</code></pre>
<p>启动服务：</p>
<pre><code class="language-sh hljs language-bash">./start_services.sh <span class="hljs-comment"># MacOS</span>
start ./start_services.cmd <span class="hljs-comment"># Window</span>
</code></pre>
<p>使用 CLI：<code>python3 cli.py</code></p>
<hr>
<h2>使用方法</h2>
<p>请确保服务已通过 <code>./start_services.sh full</code> 启动，并访问 <code>localhost:3000</code> 打开 Web 界面。</p>
<p>你还可以通过在配置中设置 <code>listen = True</code> 启用语音转文字功能，仅限 CLI 模式。</p>
<p>退出时，只需说或输入 <code>goodbye</code>。</p>
<p>以下是一些使用示例：</p>
<blockquote>
<p><em>用 python 制作一个贪吃蛇游戏！</em></p>
</blockquote>
<blockquote>
<p><em>在网上搜索法国雷恩（Rennes）排名前列的咖啡馆，并保存其中三家的名称和地址到 rennes_cafes.txt 文件。</em></p>
</blockquote>
<blockquote>
<p><em>写一个 Go 程序计算一个数的阶乘，将其保存为 workspace 目录下的 factorial.go</em></p>
</blockquote>
<blockquote>
<p><em>在 summer_pictures 文件夹中查找所有 JPG 文件，用今天的日期重命名，并将重命名后的文件列表保存到 photos_list.txt</em></p>
</blockquote>
<blockquote>
<p><em>在线搜索 2024 年流行的科幻电影，挑选三部今晚观看。将名单保存到 movie_night.txt。</em></p>
</blockquote>
<blockquote>
<p><em>在网上搜索 2025 年最新 AI 新闻文章，选择三篇，用 Python 脚本抓取它们的标题和摘要。将脚本保存为 news_scraper.py，摘要保存到 /home/projects 下的 ai_news.txt</em></p>
</blockquote>
<blockquote>
<p><em>周五，在网上搜索免费股票价格 API，用 <a href="mailto:supersuper7434567@gmail.com">supersuper7434567@gmail.com</a> 注册账号，然后写一个 Python 脚本，利用该 API 获取特斯拉每天的股价，并将结果保存为 stock_prices.csv</em></p>
</blockquote>
<p><em>请注意，自动表单填写功能仍处于实验阶段，可能会失败。</em></p>
<p>当你输入查询后，AgenticSeek 会为任务分配最佳代理。</p>
<p>由于目前为早期原型，代理路由系统可能不会始终根据你的查询分配最合适的代理。</p>
<p>因此，你应尽量明确表达需求，并说明 AI 应如何操作。例如，如果希望它进行网页搜索，不要说：</p>
<p><code>你知道哪些适合单人旅行的好国家吗？</code></p>
<p>而应这样问：</p>
<p><code>请进行网页搜索，找出最适合单人旅行的国家</code></p>
<hr>
<h2><strong>配置在你自己的服务器上运行 LLM</strong></h2>
<p>如果你有一台高性能电脑或服务器，希望从笔记本远程使用它，可以选择用我们的自定义 llm server 在远程服务器上运行 LLM。</p>
<p>在将运行 AI 模型的“服务器”上，获取 IP 地址</p>
<pre><code class="language-sh hljs language-bash">ip a | grep <span class="hljs-string">"inet "</span> | grep -v 127.0.0.1 | awk <span class="hljs-string">'{print $2}'</span> | <span class="hljs-built_in">cut</span> -d/ -f1 <span class="hljs-comment"># 本地 IP</span>
curl https://ipinfo.io/ip <span class="hljs-comment"># 公网 IP</span>
</code></pre>
<p>注意：Windows 或 macOS 请分别用 ipconfig 或 ifconfig 查询 IP 地址。</p>
<p>克隆仓库并进入 <code>server/</code> 文件夹。</p>
<pre><code class="language-sh hljs language-bash">git <span class="hljs-built_in">clone</span> --depth 1 https://github.com/Fosowl/agenticSeek.git
<span class="hljs-built_in">cd</span> agenticSeek/llm_server/
</code></pre>
<p>安装服务器端依赖：</p>
<pre><code class="language-sh hljs language-bash">pip3 install -r requirements.txt
</code></pre>
<p>运行服务器脚本。</p>
<pre><code class="language-sh hljs language-bash">python3 app.py --provider ollama --port 3333
</code></pre>
<p>你可以选择用 <code>ollama</code> 或 <code>llamacpp</code> 作为 LLM 服务。</p>
<p>现在在你的个人电脑上：</p>
<p>修改 <code>config.ini</code>，将 <code>provider_name</code> 设为 <code>server</code>，<code>provider_model</code> 设为 <code>deepseek-r1:xxb</code>。<br>把 <code>provider_server_address</code> 设置为运行模型机器的 IP 地址。</p>
<pre><code class="language-sh hljs language-bash">[MAIN]
is_local = False
provider_name = server
provider_model = deepseek-r1:70b
provider_server_address = x.x.x.x:3333
</code></pre>
<p>下一步：<a href="#Start-services-and-Run">启动服务并运行 AgenticSeek</a>  </p>
<hr>
<h2>语音转文字</h2>
<p>警告：语音转文字目前仅支持 CLI 模式。</p>
<p>请注意，语音转文字目前仅支持英文。</p>
<p>语音转文字功能默认关闭。要启用，请在 config.ini 文件中设置 listen 选项为 True：</p>
<pre><code class="hljs language-ini"><span class="hljs-attr">listen</span> = <span class="hljs-literal">True</span>
</code></pre>
<p>启用后，语音转文字功能会在你说出触发关键词（即代理名称）后开始处理输入。你可以通过修改 <em>config.ini</em> 文件中的 <code>agent_name</code> 值来自定义代理名称：</p>
<pre><code class="hljs language-ini"><span class="hljs-attr">agent_name</span> = Friday
</code></pre>
<p>为了获得最佳识别效果，我们建议使用常见的英文名字作为代理名称，如 "John" 或 "Emma"。</p>
<p>当你看到转录文本开始出现时，大声说出代理的名字以唤醒它（例如，“Friday”）。</p>
<p>请清晰地表达你的请求。</p>
<p>在请求结束时，用确认短语作为信号提示系统继续。确认短语示例包括：</p>
<pre><code class="hljs language-bash"><span class="hljs-string">"do it"</span>, <span class="hljs-string">"go ahead"</span>, <span class="hljs-string">"execute"</span>, <span class="hljs-string">"run"</span>, <span class="hljs-string">"start"</span>, <span class="hljs-string">"thanks"</span>, <span class="hljs-string">"would ya"</span>, <span class="hljs-string">"please"</span>, <span class="hljs-string">"okay?"</span>, <span class="hljs-string">"proceed"</span>, <span class="hljs-string">"continue"</span>, <span class="hljs-string">"go on"</span>, <span class="hljs-string">"do that"</span>, <span class="hljs-string">"go it"</span>, <span class="hljs-string">"do you understand?"</span>
</code></pre>
<h2>配置</h2>
<p>配置示例:</p>
<pre><code class="hljs language-ini"><span class="hljs-section">[MAIN]</span>
<span class="hljs-attr">is_local</span> = <span class="hljs-literal">True</span>
<span class="hljs-attr">provider_name</span> = ollama
<span class="hljs-attr">provider_model</span> = deepseek-r1:<span class="hljs-number">32</span>b
<span class="hljs-attr">provider_server_address</span> = http://<span class="hljs-number">127.0</span>.<span class="hljs-number">0.1</span>:<span class="hljs-number">11434</span> <span class="hljs-comment"># Ollama 示例；LM-Studio 请用 http://127.0.0.1:1234</span>
<span class="hljs-attr">agent_name</span> = Friday
<span class="hljs-attr">recover_last_session</span> = <span class="hljs-literal">False</span>
<span class="hljs-attr">save_session</span> = <span class="hljs-literal">False</span>
<span class="hljs-attr">speak</span> = <span class="hljs-literal">False</span>
<span class="hljs-attr">listen</span> = <span class="hljs-literal">False</span>

<span class="hljs-attr">jarvis_personality</span> = <span class="hljs-literal">False</span>
<span class="hljs-attr">languages</span> = en zh <span class="hljs-comment"># 用于TTS及可能的路由的语言列表。</span>
<span class="hljs-section">[BROWSER]</span>
<span class="hljs-attr">headless_browser</span> = <span class="hljs-literal">False</span>
<span class="hljs-attr">stealth_mode</span> = <span class="hljs-literal">False</span>
</code></pre>
<p><strong><code>config.ini</code> 配置项说明</strong>:</p>
<ul>
<li><strong><code>[MAIN]</code> 部分:</strong><ul>
<li><code>is_local</code>: 若使用本地LLM服务（Ollama、LM-Studio、本地OpenAI兼容服务器）或自托管服务器选项，设为 <code>True</code>。若使用云端API（OpenAI、Google等），设为 <code>False</code>。</li>
<li><code>provider_name</code>: 指定LLM服务提供商。<ul>
<li>本地选项：<code>ollama</code>、<code>lm-studio</code>、<code>openai</code>（本地OpenAI兼容服务器）、<code>server</code>（自托管服务器）。</li>
<li>API选项：<code>openai</code>、<code>google</code>、<code>deepseek</code>、<code>huggingface</code>、<code>togetherAI</code>。</li>
</ul>
</li>
<li><code>provider_model</code>: 选定服务商的具体模型名称或ID（如 Ollama 的 <code>deepseekcoder:6.7b</code>，OpenAI API 的 <code>gpt-3.5-turbo</code>，TogetherAI 的 <code>mistralai/Mixtral-8x7B-Instruct-v0.1</code>）。</li>
<li><code>provider_server_address</code>: 你的LLM服务提供商地址。<ul>
<li>本地服务示例：Ollama 用 <code>http://127.0.0.1:11434</code>，LM-Studio 用 <code>http://127.0.0.1:1234</code>。</li>
<li><code>server</code> 类型：自托管LLM服务器地址（如 <code>http://your_server_ip:3333</code>）。</li>
<li>云端API（<code>is_local = False</code>）：通常忽略或留空，因为API端点通常由客户端库处理。</li>
</ul>
</li>
<li><code>agent_name</code>: AI助手名称（如 Friday）。在启用语音转文本时用作唤醒词。</li>
<li><code>recover_last_session</code>: 设为 <code>True</code> 时尝试恢复上次会话状态，设为 <code>False</code> 时重新开始。</li>
<li><code>save_session</code>: 设为 <code>True</code> 保存当前会话以便恢复，否则为 <code>False</code>。</li>
<li><code>speak</code>: 设为 <code>True</code> 启用文字转语音输出，设为 <code>False</code> 关闭。</li>
<li><code>listen</code>: 设为 <code>True</code> 启用语音转文本输入（仅CLI模式），设为 <code>False</code> 关闭。</li>
<li><code>work_dir</code>: <strong>重要：</strong> AgenticSeek 读写文件的目录。<strong>请确保该路径在你的系统中有效且可访问。</strong></li>
<li><code>jarvis_personality</code>: 设为 <code>True</code> 使用更“Jarvis风格”的系统提示（实验性），设为 <code>False</code> 使用标准提示。</li>
<li><code>languages</code>: 逗号分隔的语言列表（如 <code>en, zh, fr</code>）。用于TTS语音选择（默认第一项），也可辅助LLM路由。为提高效率，请勿设置过多或过于相似的语言。</li>
</ul>
</li>
<li><strong><code>[BROWSER]</code> 部分:</strong><ul>
<li><code>headless_browser</code>: 设为 <code>True</code> 以无界面方式运行自动化浏览器（推荐用于网页界面或非交互场景）；设为 <code>False</code> 显示浏览器窗口（适合CLI模式或调试）。</li>
<li><code>stealth_mode</code>: 设为 <code>True</code> 启用反检测措施，使浏览器自动化更难被检测。可能需要手动安装诸如 anticaptcha 等浏览器扩展。</li>
</ul>
</li>
</ul>
<p>本节总结了支持的LLM服务类型。请在 <code>config.ini</code> 中进行配置。</p>
<p><strong>本地服务（在你自己的硬件上运行）:</strong></p>
<table>
<thead>
<tr>
<th><code>config.ini</code> 配置名称</th>
<th><code>is_local</code></th>
<th>描述</th>
<th>配置章节</th>
</tr>
</thead>
<tbody><tr>
<td><code>ollama</code></td>
<td><code>True</code></td>
<td>使用 Ollama 提供本地LLM服务。</td>
<td><a href="#setup-for-running-llm-locally-on-your-machine">本地LLM运行配置</a></td>
</tr>
<tr>
<td><code>lm-studio</code></td>
<td><code>True</code></td>
<td>使用 LM-Studio 提供本地LLM服务。</td>
<td><a href="#setup-for-running-llm-locally-on-your-machine">本地LLM运行配置</a></td>
</tr>
<tr>
<td><code>openai</code> (本地服务器)</td>
<td><code>True</code></td>
<td>连接本地OpenAI兼容API服务器（如 llama.cpp）。</td>
<td><a href="#setup-for-running-llm-locally-on-your-machine">本地LLM运行配置</a></td>
</tr>
<tr>
<td><code>server</code></td>
<td><code>False</code></td>
<td>连接运行在其他机器上的 AgenticSeek 自托管LLM服务器。</td>
<td><a href="#setup-to-run-the-llm-on-your-own-server">自托管LLM服务器配置</a></td>
</tr>
</tbody></table>
<p><strong>API服务（云端）:</strong></p>
<table>
<thead>
<tr>
<th><code>config.ini</code> 配置名称</th>
<th><code>is_local</code></th>
<th>描述</th>
<th>配置章节</th>
</tr>
</thead>
<tbody><tr>
<td><code>openai</code></td>
<td><code>False</code></td>
<td>使用OpenAI官方API（如 GPT-3.5、GPT-4）。</td>
<td><a href="#setup-to-run-with-an-api">API运行配置</a></td>
</tr>
<tr>
<td><code>google</code></td>
<td><code>False</code></td>
<td>通过API使用Google Gemini模型。</td>
<td><a href="#setup-to-run-with-an-api">API运行配置</a></td>
</tr>
<tr>
<td><code>deepseek</code></td>
<td><code>False</code></td>
<td>使用Deepseek官方API。</td>
<td><a href="#setup-to-run-with-an-api">API运行配置</a></td>
</tr>
<tr>
<td><code>huggingface</code></td>
<td><code>False</code></td>
<td>使用 Hugging Face 推理API。</td>
<td><a href="#setup-to-run-with-an-api">API运行配置</a></td>
</tr>
<tr>
<td><code>togetherAI</code></td>
<td><code>False</code></td>
<td>使用 TogetherAI 的多种开源模型API。</td>
<td><a href="#setup-to-run-with-an-api">API运行配置</a></td>
</tr>
</tbody></table>
<hr>
<h2>故障排查</h2>
<p>遇到问题时，本节将为你提供指导。</p>
<h1>已知问题</h1>
<h2>ChromeDriver 问题</h2>
<p><strong>错误示例:</strong> <code>SessionNotCreatedException: Message: session not created: This version of ChromeDriver only supports Chrome version XXX</code></p>
<ul>
<li><strong>原因:</strong> 你安装的 ChromeDriver 版本与 Google Chrome 浏览器版本不兼容。</li>
<li><strong>解决办法:</strong><ol>
<li><strong>检查 Chrome 版本:</strong> 打开 Google Chrome，进入 <code>设置 &gt; 关于 Chrome</code> 查看版本号（如 "Version 120.0.6099.110"）。</li>
<li><strong>下载匹配的 ChromeDriver:</strong><ul>
<li>Chrome 115及以上版本：访问 <a href="https://googlechromelabs.github.io/chrome-for-testing/">Chrome for Testing (CfT) JSON Endpoints</a>。找到 “stable” 渠道，下载与你的Chrome主版本号对应的ChromeDriver。</li>
<li>旧版本（较少见）：可在 <a href="https://chromedriver.chromium.org/downloads">ChromeDriver - WebDriver for Chrome</a> 页面查找。</li>
<li>下图为 CfT 页面示例：<br><img src="./media/chromedriver_readme.png" alt="从Chrome for Testing页面下载特定版本Chromedriver"></li>
</ul>
</li>
<li><strong>安装 ChromeDriver:</strong><ul>
<li>确保下载的 <code>chromedriver</code>（Windows 下为 <code>chromedriver.exe</code>）放在系统PATH环境变量指定的目录下（如 Linux/macOS的 <code>/usr/local/bin</code>，或Windows下已加入PATH的脚本文件夹）。</li>
<li>或将其放在 <code>agenticSeek</code> 项目的根目录下。</li>
<li>确保驱动为可执行文件（Linux/macOS下可用 <code>chmod +x chromedriver</code>）。</li>
</ul>
</li>
<li>更多信息请参考主安装指南的 <a href="#chromedriver-installation">ChromeDriver 安装</a> 部分。</li>
</ol>
</li>
</ul>
<p>如果本节内容不完整或遇到其他ChromeDriver问题，请搜索现有 <a href="https://github.com/Fosowl/agenticSeek/issues">GitHub Issues</a> 或新建Issue反馈。</p>
<p><code>Exception: Failed to initialize browser: Message: session not created: This version of ChromeDriver only supports Chrome version 113 Current browser version is 134.0.6998.89 with binary path</code></p>
<p>如浏览器与chromedriver版本不匹配，会出现此类问题。</p>
<p>你需要前往以下链接下载最新版：</p>
<p><a href="https://developer.chrome.com/docs/chromedriver/downloads">https://developer.chrome.com/docs/chromedriver/downloads</a></p>
<p>如使用的是 Chrome 115及以上版本，请访问：</p>
<p><a href="https://googlechromelabs.github.io/chrome-for-testing/">https://googlechromelabs.github.io/chrome-for-testing/</a></p>
<p>并下载与你操作系统匹配的chromedriver版本。</p>
<p><img src="./media/chromedriver_readme.png" alt="alt text"></p>
<p>如本节内容不完整请提交Issue。</p>
<h2>连接适配器问题</h2>
<pre><code class="hljs language-php"><span class="hljs-built_in">Exception</span>: Provider lm-studio failed: HTTP request failed: No connection adapters were found <span class="hljs-keyword">for</span> <span class="hljs-string">'127.0.0.1:1234/v1/chat/completions'</span>` (注意：端口可能不同)
</code></pre>
<ul>
<li><strong>原因:</strong> <code>config.ini</code> 中 <code>lm-studio</code>（或其他本地OpenAI兼容服务器）的 <code>provider_server_address</code> 缺少 <code>http://</code> 前缀或指向了错误的端口。</li>
<li><strong>解决办法:</strong><ul>
<li>确保地址包含 <code>http://</code>。LM-Studio 通常默认为 <code>http://127.0.0.1:1234</code>。</li>
<li>正确的 <code>config.ini</code> 配置：<code>provider_server_address = http://127.0.0.1:1234</code>（或你实际的LM-Studio服务器端口）。</li>
</ul>
</li>
</ul>
<h2>未提供 SearxNG 基础URL</h2>
<pre><code class="hljs language-csharp"><span class="hljs-function">raise <span class="hljs-title">ValueError</span>(<span class="hljs-params"><span class="hljs-string">"SearxNG base URL must be provided either as an argument or via the SEARXNG_BASE_URL environment variable."</span></span>)
ValueError: SearxNG <span class="hljs-keyword">base</span> URL must be provided either <span class="hljs-keyword">as</span> an argument <span class="hljs-keyword">or</span> via the SEARXNG_BASE_URL environment variable.`
</span></code></pre>
<h2>常见问题</h2>
<p><strong>Q: 我需要什么硬件？</strong>  </p>
<table>
<thead>
<tr>
<th>模型规模</th>
<th>GPU</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>7B</td>
<td>8GB 显存</td>
<td>⚠️ 不推荐。性能差，易产生幻觉，规划型Agent可能失败。</td>
</tr>
<tr>
<td>14B</td>
<td>12GB 显存（如RTX 3060）</td>
<td>✅ 可用于简单任务。网页浏览和计划任务可能有困难。</td>
</tr>
<tr>
<td>32B</td>
<td>24GB+ 显存（如RTX 4090）</td>
<td>🚀 大部分任务表现良好，但复杂规划仍有挑战。</td>
</tr>
<tr>
<td>70B+</td>
<td>48GB+ 显存</td>
<td>💪 优秀，推荐用于高阶场景。</td>
</tr>
</tbody></table>
<p><strong>Q: 出现错误怎么办？</strong>  </p>
<p>确保本地服务已启动（如执行 <code>ollama serve</code>），<code>config.ini</code> 配置与你的服务商一致，且依赖项已安装。如仍有问题欢迎提交Issue反馈。</p>
<p><strong>Q: 真能100%本地运行吗？</strong>  </p>
<p>是的。配合 Ollama、lm-studio 或 server 服务，所有语音转文本、LLM与TTS模型都可本地运行。非本地选项（如OpenAI等API）为可选。</p>
<p><strong>Q: 我有 Manus，为什么还要用 AgenticSeek？</strong></p>
<p>AgenticSeek 以不依赖外部系统为设计重点，给予你更多控制权、隐私和避免API费用。</p>
<p><strong>Q: 项目背后是谁？</strong></p>
<p>本项目由我和两位朋友共同发起与维护，均来自GitHub开源社区。我们只是热爱技术的个人，并非创业公司或任何组织成员。</p>
<p>除我的个人账号（<a href="https://x.com/Martin993886460%EF%BC%89%E5%A4%96%EF%BC%8C%E4%BB%BB%E4%BD%95%E8%87%AA%E7%A7%B0AgenticSeek%E7%9A%84X%E8%B4%A6%E5%8F%B7%E9%83%BD%E6%98%AF%E5%86%92%E5%85%85%E3%80%82">https://x.com/Martin993886460）外，任何自称AgenticSeek的X账号都是冒充。</a></p>
<h2>参与贡献</h2>
<p>欢迎开发者参与改进AgenticSeek！请查看开放Issue或讨论区。</p>
<p><a href="./docs/CONTRIBUTING.md">贡献指南</a></p>
<p><a href="https://www.star-history.com/#Fosowl/agenticSeek&amp;Date"><img src="https://api.star-history.com/svg?repos=Fosowl/agenticSeek&amp;type=Date" alt="Star History Chart"></a></p>
<h2>维护者:</h2>
<blockquote>
<p><a href="https://github.com/Fosowl">Fosowl</a> | 巴黎时间 </p>
</blockquote>
<blockquote>
<p><a href="https://github.com/antoineVIVIES">antoineVIVIES</a> | 台北时间 </p>
</blockquote>
<blockquote>
<p><a href="https://github.com/steveh8758">steveh8758</a> | 台北时间 </p>
</blockquote>
<h2>特别感谢:</h2>
<blockquote>
<p><a href="https://github.com/tcsenpai">tcsenpai</a> 和 <a href="https://github.com/plitc">plitc</a> 协助后端docker化</p>
</blockquote>
<h2>赞助者:</h2>
<p>每月赞助5美元及以上将在此处展示：</p>
<ul>
<li><strong>tatra-labs</strong></li>
</ul>
<p>Certainly! Please provide the content of Part 4 of 4 for translation.</p>
<hr>
<p>Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx">Open Ai Tx</a> | Last indexed: 2025-06-16</p>
<hr>
</div>
    </div>

    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async=""></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
    


</body></html>