<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>agenticSeek - Fosowl/agenticSeek zh-TW</title>
    <meta name="title" content="agenticSeek - Fosowl/agenticSeek zh-TW | AgenticSeek：私有，本地的 Manus 替代方案 English | 中文 | 繁體中文 | Français | 日本語 | Português (Brasil) | Español 一款100% 本地運行的 Manus AI 替代品，這個支援語音的 AI 助理可自主瀏覽網路、撰寫程式碼、規劃任務，同時所有...">
    <meta name="description" content="Fosowl/agenticSeek - GitHub repository zh-TW documentation and information | AgenticSeek：私有，本地的 Manus 替代方案 English | 中文 | 繁體中文 | Français | 日本語 | Português (Brasil) | Español 一款100% 本地運行的 Manus AI 替代品，這個支援語音的 AI 助理可自主瀏覽網路、撰寫程式碼、規劃任務，同時所有...">
    <meta name="keywords" content="Fosowl, agenticSeek, GitHub, repository, zh-TW documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/Fosowl/agenticSeek/README-zh-TW.html">
    <meta property="og:title" content="agenticSeek - Fosowl/agenticSeek zh-TW | AgenticSeek：私有，本地的 Manus 替代方案 English | 中文 | 繁體中文 | Français | 日本語 | Português (Brasil) | Español 一款100% 本地運行的 Manus AI 替代品，這個支援語音的 AI 助理可自主瀏覽網路、撰寫程式碼、規劃任務，同時所有...">
    <meta property="og:description" content="Fosowl/agenticSeek - GitHub repository zh-TW documentation and information | AgenticSeek：私有，本地的 Manus 替代方案 English | 中文 | 繁體中文 | Français | 日本語 | Português (Brasil) | Español 一款100% 本地運行的 Manus AI 替代品，這個支援語音的 AI 助理可自主瀏覽網路、撰寫程式碼、規劃任務，同時所有...">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/Fosowl/agenticSeek" id="githubRepoLink" target="_blank">Fosowl/agenticSeek</a>
<h1 style="display: none;">AgenticSeek：私有，本地的 Manus 替代方案 English | 中文 | 繁體中文 | Français | 日本語 | Português (Brasil) | Español 一款100% 本地運行的 Manus AI 替代品，這個支援語音的 AI 助理可自主瀏覽網路、撰寫程式碼、規劃任務，同時所有...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <h1>AgenticSeek：私有，本地的 Manus 替代方案</h1>
<p align="center">
<img align="center" src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/agentic_seek_logo.png" width="300" height="300" alt="Agentic Seek Logo">
<p>
<p>English | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_CHS.md">中文</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_CHT.md">繁體中文</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_FR.md">Français</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_JP.md">日本語</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_PTBR.md">Português (Brasil)</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_ES.md">Español</a></p>
<p><em>一款<strong>100% 本地運行的 Manus AI 替代品</strong>，這個支援語音的 AI 助理可自主瀏覽網路、撰寫程式碼、規劃任務，同時所有資料皆儲存在您的裝置上。專為本地推理模型設計，完全在您的硬體上運行，確保絕對隱私及零雲端依賴。</em></p>
<p><a href="https://fosowl.github.io/agenticSeek.html"><img src="https://img.shields.io/static/v1?label=Website&amp;message=AgenticSeek&amp;color=blue&amp;style=flat-square" alt="Visit AgenticSeek" /></a> <img src="https://img.shields.io/badge/license-GPL--3.0-green" alt="License" /> <a href="https://discord.gg/8hGDaME3TC"><img src="https://img.shields.io/badge/Discord-Join%20Us-7289DA?logo=discord&amp;logoColor=white" alt="Discord" /></a> <a href="https://x.com/Martin993886460"><img src="https://img.shields.io/twitter/url/https/twitter.com/fosowl.svg?style=social&amp;label=Update%20%40Fosowl" alt="Twitter" /></a> <a href="https://github.com/Fosowl/agenticSeek/stargazers"><img src="https://img.shields.io/github/stars/Fosowl/agenticSeek?style=social" alt="GitHub stars" /></a></p>
<h3>為什麼選擇 AgenticSeek？</h3>
<ul>
<li><p>🔒 完全本地 &amp; 私有 — 一切都在您的設備上運行，無雲端、無資料分享。您的檔案、對話與搜尋全都保密。</p>
</li>
<li><p>🌐 智慧網頁瀏覽 — AgenticSeek 可自動瀏覽網路：搜尋、閱讀、擷取資訊、自動填表，全程免動手。</p>
</li>
<li><p>💻 自主編程助理 — 需要程式碼？它可在無需監督下撰寫、除錯並執行 Python、C、Go、Java 等程式。</p>
</li>
<li><p>🧠 智慧代理選擇 — 您提問，它自動判斷並選擇最適合的代理人。就像有專家團隊隨時協助您。</p>
</li>
<li><p>📋 規劃與執行複雜任務 — 從旅行規劃到大型專案，能自動拆解步驟並召集多個 AI 代理人完成任務。</p>
</li>
<li><p>🎙️ 語音功能 — 乾淨、快速、未來感的語音與語音轉文字，讓您像在科幻電影中與個人 AI 對話。（開發中）</p>
</li>
</ul>
<h3><strong>演示範例</strong></h3>
<blockquote>
<p><em>你可以搜尋 agenticSeek 專案，了解需要哪些技能，然後打開 CV_candidates.zip 並告訴我哪個最符合專案需求嗎</em></p>
</blockquote>
<p>https://github.com/user-attachments/assets/b8ca60e9-7b3b-4533-840e-08f9ac426316</p>
<p>免責聲明：此演示範例（包括出現的所有檔案，例如 CV_candidates.zip）均為虛構。我們不是企業，我們尋求的是開源貢獻者而非求職者。</p>
<blockquote>
<p>🛠⚠️️ <strong>專案仍在積極開發中</strong></p>
</blockquote>
<blockquote>
<p>🙏 本專案最初僅為副業，沒有任何開發規劃及資金，卻意外登上 GitHub Trending。非常感謝大家的貢獻、回饋與耐心。</p>
</blockquote>
<h2>先決條件</h2>
<p>在開始之前，請確保已安裝以下軟體：</p>
<ul>
<li><strong>Git：</strong> 用於複製程式庫。<a href="https://git-scm.com/downloads">下載 Git</a></li>
<li><strong>Python 3.10.x：</strong> 強烈建議使用 Python 3.10.x 版本，其它版本可能會導致依賴錯誤。<a href="https://www.python.org/downloads/release/python-3100/">下載 Python 3.10</a>（請選擇 3.10.x 版本）。</li>
<li><strong>Docker Engine &amp; Docker Compose：</strong> 用於運行如 SearxNG 等綑綁服務。
<ul>
<li>安裝 Docker Desktop（內含 Docker Compose V2）：<a href="https://docs.docker.com/desktop/install/windows-install/">Windows</a> | <a href="https://docs.docker.com/desktop/install/mac-install/">Mac</a> | <a href="https://docs.docker.com/desktop/install/linux-install/">Linux</a></li>
<li>或者，於 Linux 上分別安裝 Docker Engine 與 Docker Compose：<a href="https://docs.docker.com/engine/install/">Docker Engine</a> | <a href="https://docs.docker.com/compose/install/">Docker Compose</a>（請確保安裝 Compose V2，如 <code>sudo apt-get install docker-compose-plugin</code>）。</li>
</ul>
</li>
</ul>
<h3>1. <strong>複製程式庫並進行設定</strong></h3>
<pre><code class="language-sh">git clone https://github.com/Fosowl/agenticSeek.git
cd agenticSeek
mv .env.example .env
</code></pre>
<h3>2. 修改 .env 檔案內容</h3>
<pre><code class="language-sh">SEARXNG_BASE_URL=&quot;http://127.0.0.1:8080&quot;
REDIS_BASE_URL=&quot;redis://redis:6379/0&quot;
WORK_DIR=&quot;/Users/mlg/Documents/workspace_for_ai&quot;
OLLAMA_PORT=&quot;11434&quot;
LM_STUDIO_PORT=&quot;1234&quot;
CUSTOM_ADDITIONAL_LLM_PORT=&quot;11435&quot;
OPENAI_API_KEY='optional'
DEEPSEEK_API_KEY='optional'
OPENROUTER_API_KEY='optional'
TOGETHER_API_KEY='optional'
GOOGLE_API_KEY='optional'
ANTHROPIC_API_KEY='optional'
</code></pre>
<p>請依需求以您的資訊更新 <code>.env</code> 檔案：</p>
<ul>
<li><strong>SEARXNG_BASE_URL</strong>：保持不變</li>
<li><strong>REDIS_BASE_URL</strong>：保持不變</li>
<li><strong>WORK_DIR</strong>：您本地工作目錄的路徑。AgenticSeek 將能讀取並操作這些檔案。</li>
<li><strong>OLLAMA_PORT</strong>：Ollama 服務的埠號。</li>
<li><strong>LM_STUDIO_PORT</strong>：LM Studio 服務的埠號。</li>
<li><strong>CUSTOM_ADDITIONAL_LLM_PORT</strong>：自訂 LLM 服務的埠號。</li>
</ul>
<p><strong>API Key 對於選擇本地運行 LLM 的用戶完全可選，本專案的主要目標即為本地推理。如您的硬體足夠，可保持空白。</strong></p>
<h3>3. <strong>啟動 Docker</strong></h3>
<p>請確保您的系統已安裝並啟動 Docker。可使用下列指令啟動 Docker：</p>
<ul>
<li><p><strong>於 Linux/macOS 上：</strong><br />
開啟終端機並執行：</p>
<pre><code class="language-sh">sudo systemctl start docker
</code></pre>
<p>或於應用程式選單中啟動 Docker Desktop（若已安裝）。</p>
</li>
<li><p><strong>於 Windows 上：</strong><br />
於「開始」選單啟動 Docker Desktop。</p>
</li>
</ul>
<p>您可透過下列指令確認 Docker 是否運行中：</p>
<pre><code class="language-sh">docker info
</code></pre>
<p>若能看到 Docker 安裝資訊，即表示運行正常。</p>
<p>請參閱下方 <a href="#list-of-local-providers">本地供應者列表</a> 取得摘要。</p>
<p>下一步：<a href="#start-services-and-run">本地運行 AgenticSeek</a></p>
<p><em>若有問題，請參閱 <a href="#troubleshooting">疑難排解</a> 小節。</em>
<em>若您的硬體無法本地運行 LLM，請參閱 <a href="#setup-to-run-with-an-api">API 運行設定</a>。</em>
<em>有關 <code>config.ini</code> 詳細說明，請見 <a href="#config">設定說明</a>。</em></p>
<hr />
<h2>在本機運行 LLM 的設定</h2>
<p><strong>硬體需求：</strong></p>
<p>若要本地運行 LLM，需具備足夠硬體。最低需能運行 Magistral、Qwen 或 Deepseek 14B 的 GPU。詳細模型/效能建議請參見 FAQ。</p>
<p><strong>設定本地供應者</strong></p>
<p>啟動您的本地供應者，例如用 ollama：</p>
<pre><code class="language-sh">ollama serve
</code></pre>
<p>下方列出所有受支援的本地供應者。</p>
<p><strong>更新 config.ini</strong></p>
<p>修改 config.ini 檔案，將 provider_name 設為受支援的供應者，provider_model 設為該供應者支援的 LLM。我們推薦如 <em>Magistral</em> 或 <em>Deepseek</em> 等推理模型。</p>
<p>有關硬體需求請參見本文件結尾的 <strong>FAQ</strong>。</p>
<pre><code class="language-sh">[MAIN]
is_local = True # 無論是本地還是遠端運行
provider_name = ollama # 或 lm-studio、openai 等
provider_model = deepseek-r1:14b # 選擇適合您硬體的模型
provider_server_address = 127.0.0.1:11434
agent_name = Jarvis # 您的 AI 名稱
recover_last_session = True # 是否恢復上次工作階段
save_session = True # 是否記住目前工作階段
speak = False # 文字轉語音
listen = False # 語音轉文字，僅限 CLI，實驗性
jarvis_personality = False # 是否啟用更像 &quot;Jarvis&quot; 的個性（實驗性）
languages = en zh # 支援的語言列表，語音合成將預設第一個語言
[BROWSER]
headless_browser = True # 除非於主機 CLI 運行，否則保持不變
stealth_mode = True # 使用 undetected selenium 降低瀏覽器偵測
</code></pre>
<p><strong>注意：</strong></p>
<ul>
<li><p><code>config.ini</code> 檔案格式不支援註解。
請勿直接複製貼上範例設定，註解將導致錯誤。請手動編輯 <code>config.ini</code>，移除所有註解後再保存。</p>
</li>
<li><p>若使用 LM-studio 運行 LLM，請<em>勿</em>將 provider_name 設為 <code>openai</code>，而要設為 <code>lm-studio</code>。</p>
</li>
<li><p>某些供應者（如 lm-studio）要求 IP 前需加上 <code>http://</code>，例如：<code>http://127.0.0.1:1234</code></p>
</li>
</ul>
<p><strong>本地供應者列表</strong></p>
<p>| 供應者    | 本地？ | 說明                                                         |
|-----------|--------|-------------------------------------------------------------|
| ollama    | 是     | 使用 ollama 作為 LLM 供應者，本地輕鬆運行 LLM                |
| lm-studio | 是     | 使用 LM studio 本地運行 LLM（<code>provider_name</code> 設為 <code>lm-studio</code>）|
| openai    | 是     | 使用 openai 相容 API（如 llama.cpp server）                   |</p>
<p>下一步：<a href="#Start-services-and-Run">啟動服務並運行 AgenticSeek</a></p>
<p><em>若有問題，請參閱 <a href="#troubleshooting">疑難排解</a> 小節。</em>
<em>若您的硬體無法本地運行 LLM，請參閱 <a href="#setup-to-run-with-an-api">API 運行設定</a>。</em>
<em>有關 <code>config.ini</code> 詳細說明，請見 <a href="#config">設定說明</a>。</em></p>
<h2>使用 API 運行的設定</h2>
<p>此方式採用外部雲端 LLM 供應者。您需從所選服務取得 API 金鑰。</p>
<p><strong>1. 選擇 API 供應者並取得 API 金鑰：</strong></p>
<p>請參閱下方 <a href="#list-of-api-providers">API 供應者列表</a>。造訪相關網站註冊並取得 API 金鑰。</p>
<p><strong>2. 將 API 金鑰設為環境變數：</strong></p>
<ul>
<li><strong>Linux/macOS：</strong>
開啟終端機，使用 <code>export</code> 指令。建議將其加入 shell 的設定檔（如 <code>~/.bashrc</code>、<code>~/.zshrc</code>），以便永久生效。
<pre><code class="language-sh">export PROVIDER_API_KEY=&quot;your_api_key_here&quot; 
# 請將 PROVIDER_API_KEY 替換為具體變數名稱，如 OPENAI_API_KEY、GOOGLE_API_KEY
</code></pre>
TogetherAI 範例：
<pre><code class="language-sh">export TOGETHER_API_KEY=&quot;xxxxxxxxxxxxxxxxxxxxxx&quot;
</code></pre>
</li>
<li><strong>Windows：</strong></li>
<li><strong>命令提示字元（僅限目前工作階段暫時設定）：</strong>
<pre><code class="language-cmd">set PROVIDER_API_KEY=your_api_key_here
</code></pre>
</li>
<li><strong>PowerShell（僅限目前工作階段暫時設定）：</strong>
<pre><code class="language-powershell">$env:PROVIDER_API_KEY=&quot;your_api_key_here&quot;
</code></pre>
</li>
<li><strong>永久設定：</strong> 在 Windows 搜尋列輸入「環境變數」，點擊「編輯系統環境變數」，再點選「環境變數...」按鈕。新增一個使用者變數，名稱（例如 <code>OPENAI_API_KEY</code>）和你的金鑰作為值。</li>
</ul>
<p><em>（詳見常見問題：<a href="#how-do-i-set-api-keys">如何設定 API 金鑰？</a>）</em></p>
<p><strong>3. 更新 <code>config.ini</code>:</strong></p>
<pre><code class="language-ini">[MAIN]
is_local = False
provider_name = openai # 或 google、deepseek、togetherAI、huggingface
provider_model = gpt-3.5-turbo # 或 gemini-1.5-flash、deepseek-chat、mistralai/Mixtral-8x7B-Instruct-v0.1 等
provider_server_address = # 當 is_local = False 時，通常可忽略或留白，適用於大多數 API
# ... 其他設定 ...
</code></pre>
<p><em>警告：</em> 請確保 <code>config.ini</code> 的值末尾沒有空格。</p>
<p><strong>API 提供商列表</strong></p>
<p>| 提供商        | <code>provider_name</code>   | 本地？ | 說明                                               | API 金鑰連結（範例）                                |
|--------------|-------------------|--------|----------------------------------------------------|------------------------------------------------------|
| OpenAI       | <code>openai</code>          | 否     | 透過 OpenAI API 使用 ChatGPT 模型。                 | <a href="https://platform.openai.com/signup">platform.openai.com/signup</a> |
| Google Gemini| <code>google</code>          | 否     | 透過 Google AI Studio 使用 Google Gemini 模型。     | <a href="https://aistudio.google.com/keys">aistudio.google.com/keys</a>     |
| Deepseek     | <code>deepseek</code>        | 否     | 透過他們的 API 使用 Deepseek 模型。                 | <a href="https://platform.deepseek.com">platform.deepseek.com</a>           |
| Hugging Face | <code>huggingface</code>     | 否     | 透過 Hugging Face Inference API 使用模型。          | <a href="https://huggingface.co/settings/tokens">huggingface.co/settings/tokens</a> |
| TogetherAI   | <code>togetherAI</code>      | 否     | 透過 TogetherAI API 使用多種開源模型。              | <a href="https://api.together.ai/settings/api-keys">api.together.ai/settings/api-keys</a> |</p>
<p><em>注意：</em></p>
<ul>
<li>建議不要在複雜的網頁瀏覽和任務規劃中使用 <code>gpt-4o</code> 或其他 OpenAI 模型，目前提示詞最佳化主要針對 Deepseek 等模型。</li>
<li>使用 Gemini 進行程式碼/bash 任務可能會遇到問題，因為其格式化回應不一定嚴格遵循針對 Deepseek 最佳化的提示。</li>
<li>當 <code>is_local = False</code> 時，<code>config.ini</code> 的 <code>provider_server_address</code> 一般不需要設定，API 端點通常已在各自的提供商函式庫中硬編碼。</li>
</ul>
<p>下一步：<a href="#Start-services-and-Run">啟動服務並運行 AgenticSeek</a></p>
<p><em>如果遇到問題，請參閱 <strong>已知問題</strong> 章節</em></p>
<p><em>完整的設定檔說明，請參閱 <strong>Config</strong> 章節。</em></p>
<hr />
<h2>啟動服務並運行</h2>
<p>預設情況下，AgenticSeek 完全在 docker 中運行。</p>
<p>啟動所需服務。這會從 docker-compose.yml 啟動所有服務，包括：
- searxng
- redis（searxng 所需）
- frontend
- backend（若使用 <code>full</code>）</p>
<pre><code class="language-sh">./start_services.sh full # MacOS
start ./start_services.cmd full # Window
</code></pre>
<p><strong>警告：</strong> 此步驟將下載並載入所有 Docker 映像檔，可能需要高達 30 分鐘。啟動服務後，請等到 backend 服務完全運行（你應該會在日誌中看到 <strong>backend: &quot;GET /health HTTP/1.1&quot; 200 OK</strong>）再發送任何訊息。backend 服務初次啟動可能需要 5 分鐘。</p>
<p>打開 <code>http://localhost:3000/</code>，你應該會看到網頁介面。</p>
<p><em>服務啟動故障排除：</em> 如果這些腳本執行失敗，請確保 Docker Engine 已啟動，且 Docker Compose（V2，<code>docker compose</code>）已正確安裝。請檢查終端機輸出以獲取錯誤訊息。詳見 <a href="#faq-troubleshooting">常見問題：執行 AgenticSeek 或其腳本時出錯怎麼辦？</a></p>
<p><strong>可選：</strong> 在主機運行（CLI 模式）：</p>
<p>若要使用 CLI 介面，必須在主機安裝套件：</p>
<pre><code class="language-sh">./install.sh
./install.bat # windows
</code></pre>
<p>啟動服務：</p>
<pre><code class="language-sh">./start_services.sh # MacOS
start ./start_services.cmd # Window
</code></pre>
<p>使用 CLI：<code>python3 cli.py</code></p>
<hr />
<h2>使用方式</h2>
<p>請確保服務已經使用 <code>./start_services.sh full</code> 啟動，並前往 <code>localhost:3000</code> 使用網頁介面。</p>
<p>你也可以在設定檔中將 <code>listen = True</code> 來啟用語音轉文字（僅 CLI 模式）。</p>
<p>要離開，只需說/輸入 <code>goodbye</code>。</p>
<p>以下是一些使用範例：</p>
<blockquote>
<p><em>用 python 做一個貪食蛇遊戲！</em></p>
</blockquote>
<blockquote>
<p><em>搜尋網路上法國雷恩（Rennes）最棒的咖啡館，並將三家含地址保存於 rennes_cafes.txt。</em></p>
</blockquote>
<blockquote>
<p><em>寫一個 Go 程式來計算一個數的階乘，並儲存為 factorial.go 於你的工作目錄</em></p>
</blockquote>
<blockquote>
<p><em>搜尋我的 summer_pictures 資料夾內所有 JPG 檔案，將它們以今天日期重新命名，並將重新命名的檔案列表儲存於 photos_list.txt</em></p>
</blockquote>
<blockquote>
<p><em>線上搜尋 2024 年熱門科幻電影，挑三部今晚要看。將片單儲存於 movie_night.txt。</em></p>
</blockquote>
<blockquote>
<p><em>搜尋 2025 年最新 AI 新聞文章，選三篇，寫一個 Python 程式抓取其標題與摘要。將程式碼保存為 news_scraper.py，摘要存於 /home/projects 的 ai_news.txt</em></p>
</blockquote>
<blockquote>
<p><em>週五，搜尋網路免費股票價格 API，使用 supersuper7434567@gmail.com 註冊，再寫一支 Python 腳本每天用 API 取得特斯拉股價，結果存於 stock_prices.csv</em></p>
</blockquote>
<p><em>請注意，表單自動填寫功能仍屬實驗性，可能會失敗。</em></p>
<p>當你輸入查詢後，AgenticSeek 會分配最佳代理來執行該任務。</p>
<p>由於這是早期原型，代理分流系統根據查詢分配的代理可能不是最合適的。</p>
<p>因此，請儘量明確說明你要做什麼，以及 AI 應該如何操作。例如，如果你想讓它進行網路搜尋，請不要這樣說：</p>
<p><code>你知道哪些國家適合單獨旅行嗎？</code></p>
<p>而要這樣問：</p>
<p><code>請搜尋網路並找出最適合單獨旅行的國家</code></p>
<hr />
<h2><strong>設定在自己的伺服器上運行 LLM</strong></h2>
<p>如果你有一台強大的電腦或伺服器想要運行模型，但又想從筆電遠端使用，你可以透過自訂的 llm server 在遠端伺服器運行 LLM。</p>
<p>在將要運行 AI 模型的「伺服器」上，獲取 IP 位址</p>
<pre><code class="language-sh">ip a | grep &quot;inet &quot; | grep -v 127.0.0.1 | awk '{print $2}' | cut -d/ -f1 # 本機 ip
curl https://ipinfo.io/ip # 公網 ip
</code></pre>
<p>注意：Windows 或 macOS 請分別使用 ipconfig 或 ifconfig 查詢 IP 位址。</p>
<p>複製專案並進入 <code>server/</code> 資料夾。</p>
<pre><code class="language-sh">git clone --depth 1 https://github.com/Fosowl/agenticSeek.git
cd agenticSeek/llm_server/
</code></pre>
<p>安裝伺服器專用套件：</p>
<pre><code class="language-sh">pip3 install -r requirements.txt
</code></pre>
<p>執行伺服器腳本。</p>
<pre><code class="language-sh">python3 app.py --provider ollama --port 3333
</code></pre>
<p>你可以選擇使用 <code>ollama</code> 或 <code>llamacpp</code> 作為 LLM 服務。</p>
<p>現在在你的個人電腦上：</p>
<p>修改 <code>config.ini</code> 檔案，將 <code>provider_name</code> 設為 <code>server</code>，<code>provider_model</code> 設為 <code>deepseek-r1:xxb</code>。
把 <code>provider_server_address</code> 設成運行模型機器的 IP 位址。</p>
<pre><code class="language-sh">[MAIN]
is_local = False
provider_name = server
provider_model = deepseek-r1:70b
provider_server_address = x.x.x.x:3333
</code></pre>
<p>下一步：<a href="#Start-services-and-Run">啟動服務並運行 AgenticSeek</a></p>
<hr />
<h2>語音轉文字</h2>
<p>警告：目前語音轉文字僅支援 CLI 模式。</p>
<p>請注意，目前語音轉文字僅支援英文。</p>
<p>語音轉文字功能預設為關閉。若要啟用，請在 config.ini 檔案中將 listen 選項設為 True：</p>
<pre><code>listen = True
</code></pre>
<p>啟用後，語音轉文字會在你說出觸發關鍵字（即代理名稱）後開始接收輸入。你可以在 <em>config.ini</em> 檔案中修改 <code>agent_name</code> 來自訂代理名稱：</p>
<pre><code>agent_name = Friday
</code></pre>
<p>為了最佳辨識效果，我們建議使用常見的英文名字作為 agent 名稱，例如 &quot;John&quot; 或 &quot;Emma&quot;</p>
<p>當你看到逐字稿開始出現時，請大聲說出 agent 的名字來喚醒它（例如：&quot;Friday&quot;）。</p>
<p>清楚地說出你的查詢內容。</p>
<p>請在請求結尾使用確認語句，讓系統知道可以繼續執行。確認語句的範例包括：</p>
<pre><code>&quot;do it&quot;, &quot;go ahead&quot;, &quot;execute&quot;, &quot;run&quot;, &quot;start&quot;, &quot;thanks&quot;, &quot;would ya&quot;, &quot;please&quot;, &quot;okay?&quot;, &quot;proceed&quot;, &quot;continue&quot;, &quot;go on&quot;, &quot;do that&quot;, &quot;go it&quot;, &quot;do you understand?&quot;
</code></pre>
<h2>設定檔 Config</h2>
<p>設定範例：</p>
<pre><code>[MAIN]
is_local = True
provider_name = ollama
provider_model = deepseek-r1:32b
provider_server_address = http://127.0.0.1:11434 # Ollama 範例；LM-Studio 請用 http://127.0.0.1:1234
agent_name = Friday
recover_last_session = False
save_session = False
speak = False
listen = False

jarvis_personality = False
languages = en zh # TTS 及路由語言清單
[BROWSER]
headless_browser = False
stealth_mode = False
</code></pre>
<p><strong><code>config.ini</code> 設定說明</strong>：</p>
<ul>
<li><strong><code>[MAIN]</code> 區段:</strong>
<ul>
<li><code>is_local</code>：如果使用本地 LLM 供應商（Ollama、LM-Studio、本地 OpenAI 相容伺服器）或自架伺服器，請設為 <code>True</code>。若使用雲端 API（OpenAI、Google 等）請設為 <code>False</code>。</li>
<li><code>provider_name</code>：指定 LLM 供應商名稱。
<ul>
<li>本地選項：<code>ollama</code>、<code>lm-studio</code>、<code>openai</code>（本地 OpenAI 相容伺服器）、<code>server</code>（自架伺服器）。</li>
<li>API 選項：<code>openai</code>、<code>google</code>、<code>deepseek</code>、<code>huggingface</code>、<code>togetherAI</code>。</li>
</ul>
</li>
<li><code>provider_model</code>：所選供應商的具體模型名稱或 ID（如 Ollama 的 <code>deepseekcoder:6.7b</code>，OpenAI API 的 <code>gpt-3.5-turbo</code>，TogetherAI 的 <code>mistralai/Mixtral-8x7B-Instruct-v0.1</code>）。</li>
<li><code>provider_server_address</code>：LLM 供應商伺服器位址。
<ul>
<li>本地供應商範例：Ollama 請用 <code>http://127.0.0.1:11434</code>，LM-Studio 請用 <code>http://127.0.0.1:1234</code>。</li>
<li><code>server</code> 類型：填寫自架 LLM 伺服器地址（如 <code>http://your_server_ip:3333</code>）。</li>
<li>雲端 API（<code>is_local = False</code>）：此欄多半可忽略，API 端點通常由客戶端處理。</li>
</ul>
</li>
<li><code>agent_name</code>：AI 助手名稱（如 Friday）。啟用語音辨識時用作觸發詞。</li>
<li><code>recover_last_session</code>：設為 <code>True</code> 則嘗試回復前次狀態，<code>False</code> 則重新開始。</li>
<li><code>save_session</code>：設為 <code>True</code> 則儲存目前會話以便回復，否則為 <code>False</code>。</li>
<li><code>speak</code>：設為 <code>True</code> 開啟文字轉語音輸出，否則關閉。</li>
<li><code>listen</code>：設為 <code>True</code> 開啟語音辨識輸入（僅限 CLI 模式），否則關閉。</li>
<li><code>work_dir</code>：<strong>重要：</strong> AgenticSeek 讀寫檔案的目錄。<strong>請確保此路徑在你的系統上有效且可存取。</strong></li>
<li><code>jarvis_personality</code>：<code>True</code> 使用更像 Jarvis 的提示詞（實驗性），<code>False</code> 則為標準提示。</li>
<li><code>languages</code>：逗號分隔的語言清單（如 <code>en, zh, fr</code>）。TTS 語音選擇（預設第一個），也可協助 LLM 路由。路由效率建議避免太多或太相似語言。</li>
</ul>
</li>
<li><strong><code>[BROWSER]</code> 區段:</strong>
<ul>
<li><code>headless_browser</code>：設為 <code>True</code> 則無視窗運行自動化瀏覽器（推薦於網頁介面或非互動用途）。<code>False</code> 則顯示瀏覽器視窗（適用於 CLI 模式或除錯）。</li>
<li><code>stealth_mode</code>：<code>True</code> 啟用反偵測瀏覽器自動化，可能需手動安裝如 anticaptcha 等瀏覽器擴充套件。</li>
</ul>
</li>
</ul>
<p>本段落總結支援的 LLM 供應商類型。請於 <code>config.ini</code> 設定。</p>
<p><strong>本地供應商（在你自己的硬體執行）：</strong></p>
<p>| <code>config.ini</code> 供應商名稱       | <code>is_local</code> | 說明                                                                   | 相關設定章節                                                                    |
|-------------------------------|------------|------------------------------------------------------------------------|--------------------------------------------------------------------------------|
| <code>ollama</code>                      | <code>True</code>     | 使用 Ollama 服務本地 LLM。                                             | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-for-running-llm-locally-on-your-machine">本地執行 LLM 設定</a> |
| <code>lm-studio</code>                   | <code>True</code>     | 使用 LM-Studio 服務本地 LLM。                                          | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-for-running-llm-locally-on-your-machine">本地執行 LLM 設定</a> |
| <code>openai</code>（本地伺服器）        | <code>True</code>     | 連接本地 OpenAI 相容 API 伺服器（如 llama.cpp）。                      | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-for-running-llm-locally-on-your-machine">本地執行 LLM 設定</a> |
| <code>server</code>                      | <code>False</code>    | 連接運行於其他主機的 AgenticSeek 自架 LLM 伺服器。                     | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-the-llm-on-your-own-server">自架伺服器 LLM 設定</a> |</p>
<p><strong>API 供應商（雲端）：</strong></p>
<p>| <code>config.ini</code> 供應商名稱       | <code>is_local</code> | 說明                                            | 相關設定章節                                                                |
|-------------------------------|------------|-------------------------------------------------|----------------------------------------------------------------------------|
| <code>openai</code>                      | <code>False</code>    | 使用 OpenAI 官方 API（如 GPT-3.5、GPT-4）。      | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api">API 運行設定</a> |
| <code>google</code>                      | <code>False</code>    | 使用 Google 的 Gemini 模型 API。                | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api">API 運行設定</a> |
| <code>deepseek</code>                    | <code>False</code>    | 使用 Deepseek 官方 API。                        | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api">API 運行設定</a> |
| <code>huggingface</code>                 | <code>False</code>    | 使用 Hugging Face 推論 API。                    | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api">API 運行設定</a> |
| <code>togetherAI</code>                  | <code>False</code>    | 使用 TogetherAI API 支援多種開放模型。           | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api">API 運行設定</a> |</p>
<hr />
<h2>疑難排解</h2>
<p>如遇問題請參考本節說明。</p>
<h1>已知問題</h1>
<h2>ChromeDriver 問題</h2>
<p><strong>錯誤範例：</strong> <code>SessionNotCreatedException: Message: session not created: This version of ChromeDriver only supports Chrome version XXX</code></p>
<ul>
<li><strong>原因：</strong> 你安裝的 ChromeDriver 版本與 Google Chrome 瀏覽器版本不相容。</li>
<li><strong>解決方式：</strong>
<ol>
<li><strong>檢查 Chrome 版本：</strong> 開啟 Google Chrome，至 <code>設定 &gt; 關於 Chrome</code> 查詢版本（如 &quot;版本 120.0.6099.110&quot;）。</li>
<li><strong>下載對應的 ChromeDriver：</strong>
<ul>
<li>Chrome 115 版以上：至 <a href="https://googlechromelabs.github.io/chrome-for-testing/">Chrome for Testing (CfT) JSON Endpoints</a> 查詢 &quot;stable&quot; 頻道，下載對應你作業系統與 Chrome 主版本的 ChromeDriver。</li>
<li>舊版（較少見）：可至 <a href="https://chromedriver.chromium.org/downloads">ChromeDriver - WebDriver for Chrome</a> 尋找。</li>
<li>下圖為 CfT 頁面範例：
<img src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/chromedriver_readme.png" alt="從 Chrome for Testing 頁面下載指定版本 Chromedriver" /></li>
</ul>
</li>
<li><strong>安裝 ChromeDriver：</strong>
<ul>
<li>請將下載的 <code>chromedriver</code>（Windows 為 <code>chromedriver.exe</code>）放到系統 PATH 目錄（如 Linux/macOS 的 <code>/usr/local/bin</code>，或 Windows 的自訂腳本資料夾）。</li>
<li>或直接放在 <code>agenticSeek</code> 專案根目錄。</li>
<li>確保驅動程式具有執行權限（如 Linux/macOS 執行 <code>chmod +x chromedriver</code>）。</li>
</ul>
</li>
<li>詳細請參考主安裝指南內 <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#chromedriver-installation">ChromeDriver 安裝說明</a>。</li>
</ol>
</li>
</ul>
<p>若本節說明不足或遇到其他 ChromeDriver 問題，請搜尋 <a href="https://github.com/Fosowl/agenticSeek/issues">GitHub Issues</a> 或提出新問題。</p>
<p><code>Exception: Failed to initialize browser: Message: session not created: This version of ChromeDriver only supports Chrome version 113 Current browser version is 134.0.6998.89 with binary path</code></p>
<p>當你的瀏覽器與 chromedriver 版本不符時會發生此錯誤。</p>
<p>你需要前往下載最新版本：</p>
<p>https://developer.chrome.com/docs/chromedriver/downloads</p>
<p>若你使用 Chrome 115 以上，請前往：</p>
<p>https://googlechromelabs.github.io/chrome-for-testing/</p>
<p>下載與你作業系統相符的 chromedriver 版本。</p>
<p><img src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/chromedriver_readme.png" alt="alt text" /></p>
<p>如本節說明不足請提出 issue。</p>
<h2>connection adapters 問題</h2>
<pre><code>Exception: Provider lm-studio failed: HTTP request failed: No connection adapters were found for '127.0.0.1:1234/v1/chat/completions'` (注意：port 可能不同)
</code></pre>
<ul>
<li><strong>原因：</strong> <code>config.ini</code> 內 <code>lm-studio</code>（或其他本地 OpenAI 相容伺服器）的 <code>provider_server_address</code> 缺少 <code>http://</code> 前綴或連到錯誤的埠號。</li>
<li><strong>解決方式：</strong>
<ul>
<li>請確保地址包含 <code>http://</code>。LM-Studio 預設為 <code>http://127.0.0.1:1234</code>。</li>
<li>正確設定 <code>config.ini</code>：<code>provider_server_address = http://127.0.0.1:1234</code>（或你的實際伺服器埠號）。</li>
</ul>
</li>
</ul>
<h2>未提供 SearxNG Base URL</h2>
<pre><code>raise ValueError(&quot;SearxNG base URL must be provided either as an argument or via the SEARXNG_BASE_URL environment variable.&quot;)
ValueError: SearxNG base URL must be provided either as an argument or via the SEARXNG_BASE_URL environment variable.`
</code></pre>
<h2>常見問題 FAQ</h2>
<p><strong>Q: 我需要什麼硬體？</strong></p>
<p>| 模型大小   | GPU          | 說明                                               |
|-----------|--------------|----------------------------------------------------|
| 7B        | 8GB Vram     | ⚠️ 不建議。效能不佳，易產生幻覺，規劃型 agent 可能失敗。|
| 14B       | 12GB Vram (如 RTX 3060) | ✅ 簡單任務可用。瀏覽網頁與規劃可能吃力。          |
| 32B       | 24GB 以上 Vram (如 RTX 4090) | 🚀 大多數任務可成功，規劃型任務仍有挑戰。       |
| 70B+      | 48GB 以上 Vram | 💪 極佳。推薦進階使用情境。                         |</p>
<p><strong>Q: 出現錯誤怎麼辦？</strong></p>
<p>請確認本地服務（<code>ollama serve</code>）正常，<code>config.ini</code> 與供應商相符，且相關依賴已安裝。如皆無效歡迎提出 issue。</p>
<p><strong>Q: 能否 100% 本地執行？</strong></p>
<p>可以，使用 Ollama、lm-studio 或 server 供應商時，語音辨識、LLM、文字轉語音皆於本地運行。非本地（OpenAI 等 API）選項為可選。</p>
<p><strong>Q: 已有 Manus，為什麼還要用 AgenticSeek？</strong></p>
<p>AgenticSeek 強調對外部系統的獨立性，讓你有更多控制權、隱私保障且避免 API 成本。</p>
<p><strong>Q: 專案是由誰維護？</strong></p>
<p>專案由我本人與兩位在 GitHub 開源社群活躍的朋友共同維護。我們只是熱愛開發的個人，並非新創公司或組織成員。</p>
<p>除了我的個人帳號（https://x.com/Martin993886460）以外，任何 AgenticSeek 在 X 上的帳戶皆為冒名。</p>
<h2>貢獻</h2>
<p>我們歡迎開發者參與改進 AgenticSeek！請參考 open issues 或討論區。</p>
<p><a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/docs/CONTRIBUTING.md">貢獻指南</a></p>
<p><a href="https://www.star-history.com/#Fosowl/agenticSeek&amp;Date"><img src="https://api.star-history.com/svg?repos=Fosowl/agenticSeek&amp;type=Date" alt="Star History Chart" /></a></p>
<h2>維護者：</h2>
<blockquote>
<p><a href="https://github.com/Fosowl">Fosowl</a> | 巴黎時間</p>
</blockquote>
<blockquote>
<p><a href="https://github.com/antoineVIVIES">antoineVIVIES</a> | 台北時間</p>
</blockquote>
<blockquote>
<p><a href="https://github.com/steveh8758">steveh8758</a> | 台北時間</p>
</blockquote>
<h2>特別感謝：</h2>
<blockquote>
<p><a href="https://github.com/tcsenpai">tcsenpai</a> 和 <a href="https://github.com/plitc">plitc</a> 協助後端 Docker 化</p>
</blockquote>
<h2>贊助者：</h2>
<p>每月贊助 5 美元或以上會顯示於此：</p>
<ul>
<li><strong>tatra-labs</strong></li>
</ul>
<p>Sorry, but I need the content of Part 4 of 4 in order to translate it. Please provide the text you want translated.</p>
<hr />
<p>Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx">Open Ai Tx</a> | Last indexed: 2025-06-16</p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
</body>
</html>