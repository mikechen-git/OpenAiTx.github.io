<!DOCTYPE html><html lang="en"><head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AgenticSeek: Private, Local Manus Alternative. - Fosowl/agenticSeek</title>

    <!-- Primary Meta Tags -->
    <meta name="title" content="AgenticSeek: Private, Local Manus Alternative. - Fosowl/agenticSeek">
    <meta name="description" content="Fosowl/agenticSeek - GitHub repository en documentation and information">
    <meta name="keywords" content="Fosowl, agenticSeek, GitHub, repository, en documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">

    <!-- Open Graph -->
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/Fosowl/agenticSeek/README-en.html">
    <meta property="og:title" content="AgenticSeek: Private, Local Manus Alternative. - Fosowl/agenticSeek">
    <meta property="og:description" content="Fosowl/agenticSeek - GitHub repository en documentation and information">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">

    <!-- Favicon -->
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">

    <!-- Marked.js for Markdown rendering -->
    <script type="text/javascript" async="" src="https://www.statcounter.com/counter/recorder.js"></script><script src="/js/marked.min.js?v=20250613"></script>
    <!-- Highlight.js for code syntax highlighting -->
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <!-- Custom CSS -->
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        /* Layout */
        body {
            display: flex;
            flex-direction: column;
            min-height: 100vh;
        }

        .main-container {
            margin: 0 auto;
            width: 100%;
            max-width: 980px;
            padding: 0 20px;
        }

        @media (max-width: 768px) {
            .main-container {
                padding: 0 15px;
            }
        }

        /* Image size restrictions */
        .markdown-body img {
            max-width: 100%;
            height: auto;
        }

        /* Existing styles */
        .header {
            text-align: center;
            margin-bottom: 30px;
            padding: 20px;
            background-color: #f6f8fa;
            border-bottom: 1px solid #e1e4e8;
            position: relative;
        }

        .back-button {
            position: absolute;
            left: 20px;
            top: 50%;
            transform: translateY(-50%);
            color: #0366d6;
            text-decoration: none;
            display: flex;
            align-items: center;
            font-size: 14px;
            padding: 5px 10px;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            background-color: #fff;
        }

        .back-button:hover {
            background-color: #f6f8fa;
            border-color: #0366d6;
        }

        .back-button::before {
            content: "←";
            margin-right: 5px;
            font-size: 16px;
        }

        .header .links {
            margin-top: 10px;
            font-size: 16px;
        }

        .header .links a {
            color: #0366d6;
            text-decoration: none;
            margin-left: 5px;
        }

        .header .links a:hover {
            text-decoration: underline;
        }
        
        /* Language badges styles */
        .language-badges {
            margin-top: 15px;
            text-align: center;
        }
        .language-badges a {
            display: inline-block;
            margin: 2px;
            text-decoration: none;
        }
        .language-badges img {
            height: 20px;
            border-radius: 3px;
        }
        .language-badges a:hover img {
            opacity: 0.8;
        }
    </style>
</head>

<body>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/Fosowl/agenticSeek" id="githubRepoLink" target="_blank">Fosowl/agenticSeek</a>
        </div>
        <div class="language-badges" id="languageBadges"><a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=en"><img src="https://img.shields.io/badge/EN-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=zh-CN"><img src="https://img.shields.io/badge/简中-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=zh-TW"><img src="https://img.shields.io/badge/繁中-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=ja"><img src="https://img.shields.io/badge/日本語-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=ko"><img src="https://img.shields.io/badge/한국어-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=th"><img src="https://img.shields.io/badge/ไทย-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=fr"><img src="https://img.shields.io/badge/Français-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=de"><img src="https://img.shields.io/badge/Deutsch-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=es"><img src="https://img.shields.io/badge/Español-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=it"><img src="https://img.shields.io/badge/Italiano-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=ru"><img src="https://img.shields.io/badge/Русский-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=pt"><img src="https://img.shields.io/badge/Português-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=nl"><img src="https://img.shields.io/badge/Nederlands-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=pl"><img src="https://img.shields.io/badge/Polski-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=ar"><img src="https://img.shields.io/badge/العربية-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=tr"><img src="https://img.shields.io/badge/Türkçe-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=vi"><img src="https://img.shields.io/badge/Tiếng Việt-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=hi"><img src="https://img.shields.io/badge/हिंदी-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=fa"><img src="https://img.shields.io/badge/فارسی-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=id"><img src="https://img.shields.io/badge/Bahasa Indonesia-white" alt="version"></a></div>
    </div>

    <div class="main-container">
        <div class="markdown-body" id="content"><h1>AgenticSeek: Private, Local Manus Alternative.</h1>
<p align="center">
<img align="center" src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/agentic_seek_logo.png" width="300" height="300" alt="Agentic Seek Logo">
</p><p>

</p><p>  English | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_CHS.md">中文</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_CHT.md">繁體中文</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_FR.md">Français</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_JP.md">日本語</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_PTBR.md">Português (Brasil)</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_ES.md">Español</a></p>
<p><em>A <strong>100% local alternative to Manus AI</strong>, this voice-enabled AI assistant autonomously browses the web, writes code, and plans tasks while keeping all data on your device. Tailored for local reasoning models, it runs entirely on your hardware, ensuring complete privacy and zero cloud dependency.</em></p>
<p><a href="https://fosowl.github.io/agenticSeek.html"><img src="https://img.shields.io/static/v1?label=Website&amp;message=AgenticSeek&amp;color=blue&amp;style=flat-square" alt="Visit AgenticSeek"></a> <img src="https://img.shields.io/badge/license-GPL--3.0-green" alt="License"> <a href="https://discord.gg/8hGDaME3TC"><img src="https://img.shields.io/badge/Discord-Join%20Us-7289DA?logo=discord&amp;logoColor=white" alt="Discord"></a> <a href="https://x.com/Martin993886460"><img src="https://img.shields.io/twitter/url/https/twitter.com/fosowl.svg?style=social&amp;label=Update%20%40Fosowl" alt="Twitter"></a> <a href="https://github.com/Fosowl/agenticSeek/stargazers"><img src="https://img.shields.io/github/stars/Fosowl/agenticSeek?style=social" alt="GitHub stars"></a></p>
<h3>Why AgenticSeek?</h3>
<ul>
<li><p>🔒 Fully Local &amp; Private - Everything runs on your machine — no cloud, no data sharing. Your files, conversations, and searches stay private.</p>
</li>
<li><p>🌐 Smart Web Browsing - AgenticSeek can browse the internet by itself — search, read, extract info, fill web form — all hands-free.</p>
</li>
<li><p>💻 Autonomous Coding Assistant - Need code? It can write, debug, and run programs in Python, C, Go, Java, and more — all without supervision.</p>
</li>
<li><p>🧠 Smart Agent Selection - You ask, it figures out the best agent for the job automatically. Like having a team of experts ready to help.</p>
</li>
<li><p>📋 Plans &amp; Executes Complex Tasks - From trip planning to complex projects — it can split big tasks into steps and get things done using multiple AI agents.</p>
</li>
<li><p>🎙️ Voice-Enabled - Clean, fast, futuristic voice and speech to text allowing you to talk to it like it's your personal AI from a sci-fi movie. (In progress)</p>
</li>
</ul>
<h3><strong>Demo</strong></h3>
<blockquote>
<p><em>Can you search for the agenticSeek project, learn what skills are required, then open the CV_candidates.zip and then tell me which match best the project</em></p>
</blockquote>
<p><a href="https://github.com/user-attachments/assets/b8ca60e9-7b3b-4533-840e-08f9ac426316">https://github.com/user-attachments/assets/b8ca60e9-7b3b-4533-840e-08f9ac426316</a></p>
<p>Disclaimer: This demo, including all the files that appear (e.g: CV_candidates.zip), are entirely fictional. We are not a corporation, we seek open-source contributors not candidates.</p>
<blockquote>
<p>🛠⚠️️ <strong>Active Work in Progress</strong></p>
</blockquote>
<blockquote>
<p>🙏 This project started as a side-project and has zero roadmap and zero funding. It's grown way beyond what I expected by ending in GitHub Trending. Contributions, feedback, and patience are deeply appreciated.</p>
</blockquote>
<h2>Prerequisites</h2>
<p>Before you begin, ensure you have the following software installed:</p>
<ul>
<li><strong>Git:</strong> For cloning the repository. <a href="https://git-scm.com/downloads">Download Git</a></li>
<li><strong>Python 3.10.x:</strong> We strongly recommend using Python version 3.10.x. Using other versions might lead to dependency errors. <a href="https://www.python.org/downloads/release/python-3100/">Download Python 3.10</a> (pick a 3.10.x version).</li>
<li><strong>Docker Engine &amp; Docker Compose:</strong> For running bundled services like SearxNG.<ul>
<li>Install Docker Desktop (which includes Docker Compose V2): <a href="https://docs.docker.com/desktop/install/windows-install/">Windows</a> | <a href="https://docs.docker.com/desktop/install/mac-install/">Mac</a> | <a href="https://docs.docker.com/desktop/install/linux-install/">Linux</a></li>
<li>Alternatively, install Docker Engine and Docker Compose separately on Linux: <a href="https://docs.docker.com/engine/install/">Docker Engine</a> | <a href="https://docs.docker.com/compose/install/">Docker Compose</a> (ensure you install Compose V2, e.g., <code>sudo apt-get install docker-compose-plugin</code>).</li>
</ul>
</li>
</ul>
<h3>1. <strong>Clone the repository and setup</strong></h3>
<pre><code class="language-sh hljs language-bash">git <span class="hljs-built_in">clone</span> https://github.com/Fosowl/agenticSeek.git
<span class="hljs-built_in">cd</span> agenticSeek
<span class="hljs-built_in">mv</span> .env.example .<span class="hljs-built_in">env</span>
</code></pre>
<h3>2. Change the .env file content</h3>
<pre><code class="language-sh hljs language-bash">SEARXNG_BASE_URL=<span class="hljs-string">"http://127.0.0.1:8080"</span>
REDIS_BASE_URL=<span class="hljs-string">"redis://redis:6379/0"</span>
WORK_DIR=<span class="hljs-string">"/Users/mlg/Documents/workspace_for_ai"</span>
OLLAMA_PORT=<span class="hljs-string">"11434"</span>
LM_STUDIO_PORT=<span class="hljs-string">"1234"</span>
CUSTOM_ADDITIONAL_LLM_PORT=<span class="hljs-string">"11435"</span>
OPENAI_API_KEY=<span class="hljs-string">'optional'</span>
DEEPSEEK_API_KEY=<span class="hljs-string">'optional'</span>
OPENROUTER_API_KEY=<span class="hljs-string">'optional'</span>
TOGETHER_API_KEY=<span class="hljs-string">'optional'</span>
GOOGLE_API_KEY=<span class="hljs-string">'optional'</span>
ANTHROPIC_API_KEY=<span class="hljs-string">'optional'</span>
</code></pre>
<p>Update the <code>.env</code> file with your own values as needed:</p>
<ul>
<li><strong>SEARXNG_BASE_URL</strong>: Leave unchanged </li>
<li><strong>REDIS_BASE_URL</strong>: Leave unchanged </li>
<li><strong>WORK_DIR</strong>: Path to your working directory on your local machine. AgenticSeek will be able to read and interact with these files.</li>
<li><strong>OLLAMA_PORT</strong>: Port number for the Ollama service.</li>
<li><strong>LM_STUDIO_PORT</strong>: Port number for the LM Studio service.</li>
<li><strong>CUSTOM_ADDITIONAL_LLM_PORT</strong>: Port for any additional custom LLM service.</li>
</ul>
<p><strong>API Key are totally optional for user who choose to run LLM locally. Which is the primary purpose of this project. Leave empty if you have sufficient hardware</strong></p>
<h3>3. <strong>Start Docker</strong></h3>
<p>Make sure Docker is installed and running on your system. You can start Docker using the following commands:</p>
<ul>
<li><p><strong>On Linux/macOS:</strong><br>  Open a terminal and run:</p>
<pre><code class="language-sh hljs language-bash">sudo systemctl start docker
</code></pre>
<p>  Or launch Docker Desktop from your applications menu if installed.</p>
</li>
<li><p><strong>On Windows:</strong><br>  Start Docker Desktop from the Start menu.</p>
</li>
</ul>
<p>You can verify Docker is running by executing:</p>
<pre><code class="language-sh hljs language-bash">docker info
</code></pre>
<p>If you see information about your Docker installation, it is running correctly.</p>
<p>See the table of <a href="#list-of-local-providers">Local Providers</a> below for a summary.</p>
<p>Next step: <a href="#start-services-and-run">Run AgenticSeek locally</a></p>
<p><em>See the <a href="#troubleshooting">Troubleshooting</a> section if you are having issues.</em><br><em>If your hardware can't run LLMs locally, see <a href="#setup-to-run-with-an-api">Setup to run with an API</a>.</em><br><em>For detailed <code>config.ini</code> explanations, see <a href="#config">Config Section</a>.</em></p>
<hr>
<h2>Setup for running LLM locally on your machine</h2>
<p><strong>Hardware Requirements:</strong></p>
<p>To run LLMs locally, you'll need sufficient hardware. At a minimum, a GPU capable of running Magistral, Qwen or Deepseek 14B is required. See the FAQ for detailed model/performance recommendations.</p>
<p><strong>Setup your local provider</strong>  </p>
<p>Start your local provider, for example with ollama:</p>
<pre><code class="language-sh hljs language-bash">ollama serve
</code></pre>
<p>See below for a list of local supported provider.</p>
<p><strong>Update the config.ini</strong></p>
<p>Change the config.ini file to set the provider_name to a supported provider and provider_model to a LLM supported by your provider. We recommend reasoning model such as <em>Magistral</em> or <em>Deepseek</em>.</p>
<p>See the <strong>FAQ</strong> at the end of the README for required hardware.</p>
<pre><code class="language-sh hljs language-bash">[MAIN]
is_local = True <span class="hljs-comment"># Whenever you are running locally or with remote provider.</span>
provider_name = ollama <span class="hljs-comment"># or lm-studio, openai, etc..</span>
provider_model = deepseek-r1:14b <span class="hljs-comment"># choose a model that fit your hardware</span>
provider_server_address = 127.0.0.1:11434
agent_name = Jarvis <span class="hljs-comment"># name of your AI</span>
recover_last_session = True <span class="hljs-comment"># whenever to recover the previous session</span>
save_session = True <span class="hljs-comment"># whenever to remember the current session</span>
speak = False <span class="hljs-comment"># text to speech</span>
listen = False <span class="hljs-comment"># Speech to text, only for CLI, experimental</span>
jarvis_personality = False <span class="hljs-comment"># Whenever to use a more "Jarvis" like personality (experimental)</span>
languages = en zh <span class="hljs-comment"># The list of languages, Text to speech will default to the first language on the list</span>
[BROWSER]
headless_browser = True <span class="hljs-comment"># leave unchanged unless using CLI on host.</span>
stealth_mode = True <span class="hljs-comment"># Use undetected selenium to reduce browser detection</span>
</code></pre>
<p><strong>Warning</strong>:</p>
<ul>
<li><p>The <code>config.ini</code> file format does not support comments.<br>Do not copy and paste the example configuration directly, as comments will cause errors.  Instead, manually modify the <code>config.ini</code> file with your desired settings, excluding any comments.</p>
</li>
<li><p>Do <em>NOT</em> set provider_name to <code>openai</code> if using LM-studio for running LLMs. Set it to <code>lm-studio</code>.</p>
</li>
<li><p>Some provider (eg: lm-studio) require you to have <code>http://</code> in front of the IP. For example <code>http://127.0.0.1:1234</code></p>
</li>
</ul>
<p><strong>List of local providers</strong></p>
<table>
<thead>
<tr>
<th>Provider</th>
<th>Local?</th>
<th>Description</th>
</tr>
</thead>
<tbody><tr>
<td>ollama</td>
<td>Yes</td>
<td>Run LLMs locally with ease using ollama as a LLM provider</td>
</tr>
<tr>
<td>lm-studio</td>
<td>Yes</td>
<td>Run LLM locally with LM studio (set <code>provider_name</code> to <code>lm-studio</code>)</td>
</tr>
<tr>
<td>openai</td>
<td>Yes</td>
<td>Use openai compatible API (eg: llama.cpp server)</td>
</tr>
</tbody></table>
<p>Next step: <a href="#Start-services-and-Run">Start services and run AgenticSeek</a>  </p>
<p><em>See the <a href="#troubleshooting">Troubleshooting</a> section if you are having issues.</em><br><em>If your hardware can't run LLMs locally, see <a href="#setup-to-run-with-an-api">Setup to run with an API</a>.</em><br><em>For detailed <code>config.ini</code> explanations, see <a href="#config">Config Section</a>.</em></p>
<h2>Setup to run with an API</h2>
<p>This setup uses external, cloud-based LLM providers. You'll need an API key from your chosen service.</p>
<p><strong>1. Choose an API Provider and Get an API Key:</strong></p>
<p>Refer to the <a href="#list-of-api-providers">List of API Providers</a> below. Visit their websites to sign up and obtain an API key.</p>
<p><strong>2. Set Your API Key as an Environment Variable:</strong></p>
<ul>
<li><strong>Linux/macOS:</strong><br>Open your terminal and use the <code>export</code> command. It's best to add this to your shell's profile file (e.g., <code>~/.bashrc</code>, <code>~/.zshrc</code>) for persistence.<pre><code class="language-sh hljs language-bash"><span class="hljs-built_in">export</span> PROVIDER_API_KEY=<span class="hljs-string">"your_api_key_here"</span> 
<span class="hljs-comment"># Replace PROVIDER_API_KEY with the specific variable name, e.g., OPENAI_API_KEY, GOOGLE_API_KEY</span>
</code></pre>
Example for TogetherAI:<pre><code class="language-sh hljs language-bash"><span class="hljs-built_in">export</span> TOGETHER_API_KEY=<span class="hljs-string">"xxxxxxxxxxxxxxxxxxxxxx"</span>
</code></pre>
</li>
<li><strong>Windows:</strong></li>
<li><strong>Command Prompt (Temporary for current session):</strong><pre><code class="language-cmd">set PROVIDER_API_KEY=your_api_key_here
</code></pre>
</li>
<li><strong>PowerShell (Temporary for current session):</strong><pre><code class="language-powershell">$env:PROVIDER_API_KEY="your_api_key_here"
</code></pre>
</li>
<li><strong>Permanently:</strong> Search for "environment variables" in the Windows search bar, click "Edit the system environment variables," then click the "Environment Variables..." button. Add a new User variable with the appropriate name (e.g., <code>OPENAI_API_KEY</code>) and your key as the value.</li>
</ul>
<p><em>(See FAQ: <a href="#how-do-i-set-api-keys">How do I set API keys?</a> for more details).</em></p>
<p><strong>3. Update <code>config.ini</code>:</strong></p>
<pre><code class="language-ini hljs"><span class="hljs-section">[MAIN]</span>
<span class="hljs-attr">is_local</span> = <span class="hljs-literal">False</span>
<span class="hljs-attr">provider_name</span> = openai <span class="hljs-comment"># Or google, deepseek, togetherAI, huggingface</span>
<span class="hljs-attr">provider_model</span> = gpt-<span class="hljs-number">3.5</span>-turbo <span class="hljs-comment"># Or gemini-1.5-flash, deepseek-chat, mistralai/Mixtral-8x7B-Instruct-v0.1 etc.</span>
provider_server_address = <span class="hljs-comment"># Typically ignored or can be left blank when is_local = False for most APIs</span>
<span class="hljs-comment"># ... other settings ...</span>
</code></pre>
<p><em>Warning:</em> Make sure there are no trailing spaces in the <code>config.ini</code> values.</p>
<p><strong>List of API Providers</strong></p>
<table>
<thead>
<tr>
<th>Provider</th>
<th><code>provider_name</code></th>
<th>Local?</th>
<th>Description</th>
<th>API Key Link (Examples)</th>
</tr>
</thead>
<tbody><tr>
<td>OpenAI</td>
<td><code>openai</code></td>
<td>No</td>
<td>Use ChatGPT models via OpenAI's API.</td>
<td><a href="https://platform.openai.com/signup">platform.openai.com/signup</a></td>
</tr>
<tr>
<td>Google Gemini</td>
<td><code>google</code></td>
<td>No</td>
<td>Use Google Gemini models via Google AI Studio.</td>
<td><a href="https://aistudio.google.com/keys">aistudio.google.com/keys</a></td>
</tr>
<tr>
<td>Deepseek</td>
<td><code>deepseek</code></td>
<td>No</td>
<td>Use Deepseek models via their API.</td>
<td><a href="https://platform.deepseek.com">platform.deepseek.com</a></td>
</tr>
<tr>
<td>Hugging Face</td>
<td><code>huggingface</code></td>
<td>No</td>
<td>Use models from Hugging Face Inference API.</td>
<td><a href="https://huggingface.co/settings/tokens">huggingface.co/settings/tokens</a></td>
</tr>
<tr>
<td>TogetherAI</td>
<td><code>togetherAI</code></td>
<td>No</td>
<td>Use various open-source models via TogetherAI API.</td>
<td><a href="https://api.together.ai/settings/api-keys">api.together.ai/settings/api-keys</a></td>
</tr>
</tbody></table>
<p><em>Note:</em></p>
<ul>
<li>We advise against using <code>gpt-4o</code> or other OpenAI models for complex web browsing and task planning as current prompt optimizations are geared towards models like Deepseek.</li>
<li>Coding/bash tasks might encounter issues with Gemini, as it may not strictly follow formatting prompts optimized for Deepseek.</li>
<li>The <code>provider_server_address</code> in <code>config.ini</code> is generally not used when <code>is_local = False</code> as the API endpoint is usually hardcoded in the respective provider's library.</li>
</ul>
<p>Next step: <a href="#Start-services-and-Run">Start services and run AgenticSeek</a></p>
<p><em>See the <strong>Known issues</strong> section if you are having issues</em></p>
<p><em>See the <strong>Config</strong> section for detailed config file explanation.</em></p>
<hr>
<h2>Start services and Run</h2>
<p>By default AgenticSeek is run fully in docker.</p>
<p>Start required services. This will start all services from the docker-compose.yml, including:<br>    - searxng<br>    - redis (required by searxng)<br>    - frontend<br>    - backend (if using <code>full</code>)</p>
<pre><code class="language-sh hljs language-bash">./start_services.sh full <span class="hljs-comment"># MacOS</span>
start ./start_services.cmd full <span class="hljs-comment"># Window</span>
</code></pre>
<p><strong>Warning:</strong> This step will download and load all Docker images, which may take up to 30 minutes. After starting the services, please wait until the backend service is fully running (you should see <strong>backend: "GET /health HTTP/1.1" 200 OK</strong> in the log) before sending any messages. The backend services might take 5 minute to start on first run.</p>
<p>Go to <code>http://localhost:3000/</code> and you should see the web interface.</p>
<p><em>Troubleshooting service start:</em> If these scripts fail, ensure Docker Engine is running and Docker Compose (V2, <code>docker compose</code>) is correctly installed. Check the output in the terminal for error messages. See <a href="#faq-troubleshooting">FAQ: Help! I get an error when running AgenticSeek or its scripts.</a></p>
<p><strong>Optional:</strong> Run on host (CLI mode):</p>
<p>To run with CLI interface you would have to install package on host:</p>
<pre><code class="language-sh hljs language-bash">./install.sh
./install.bat <span class="hljs-comment"># windows</span>
</code></pre>
<p>Start services:</p>
<pre><code class="language-sh hljs language-bash">./start_services.sh <span class="hljs-comment"># MacOS</span>
start ./start_services.cmd <span class="hljs-comment"># Window</span>
</code></pre>
<p>Use the CLI: <code>python3 cli.py</code></p>
<hr>
<h2>Usage</h2>
<p>Make sure the services are up and running with <code>./start_services.sh full</code> and go to <code>localhost:3000</code> for web interface.</p>
<p>You can also use speech to text by setting <code>listen = True</code> in the config. Only for CLI mode.</p>
<p>To exit, simply say/type <code>goodbye</code>.</p>
<p>Here are some example usage:</p>
<blockquote>
<p><em>Make a snake game in python!</em></p>
</blockquote>
<blockquote>
<p><em>Search the web for top cafes in Rennes, France, and save a list of three with their addresses in rennes_cafes.txt.</em></p>
</blockquote>
<blockquote>
<p><em>Write a Go program to calculate the factorial of a number, save it as factorial.go in your workspace</em></p>
</blockquote>
<blockquote>
<p><em>Search my summer_pictures folder for all JPG files, rename them with today’s date, and save a list of renamed files in photos_list.txt</em></p>
</blockquote>
<blockquote>
<p><em>Search online for popular sci-fi movies from 2024 and pick three to watch tonight. Save the list in movie_night.txt.</em></p>
</blockquote>
<blockquote>
<p><em>Search the web for the latest AI news articles from 2025, select three, and write a Python script to scrape their titles and summaries. Save the script as news_scraper.py and the summaries in ai_news.txt in /home/projects</em></p>
</blockquote>
<blockquote>
<p><em>Friday, search the web for a free stock price API, register with <a href="mailto:supersuper7434567@gmail.com">supersuper7434567@gmail.com</a> then write a Python script to fetch using the API daily prices for Tesla, and save the results in stock_prices.csv</em></p>
</blockquote>
<p><em>Note that form filling capabilities are still experimental and might fail.</em></p>
<p>After you type your query, AgenticSeek will allocate the best agent for the task.</p>
<p>Because this is an early prototype, the agent routing system might not always allocate the right agent based on your query.</p>
<p>Therefore, you should be very explicit in what you want and how the AI might proceed for example if you want it to conduct a web search, do not say:</p>
<p><code>Do you know some good countries for solo-travel?</code></p>
<p>Instead, ask:</p>
<p><code>Do a web search and find out which are the best country for solo-travel</code></p>
<hr>
<h2><strong>Setup to run the LLM on your own server</strong></h2>
<p>If you have a powerful computer or a server that you can use, but you want to use it from your laptop you have the options to run the LLM on a remote server using our custom llm server. </p>
<p>On your "server" that will run the AI model, get the ip address</p>
<pre><code class="language-sh hljs language-bash">ip a | grep <span class="hljs-string">"inet "</span> | grep -v 127.0.0.1 | awk <span class="hljs-string">'{print $2}'</span> | <span class="hljs-built_in">cut</span> -d/ -f1 <span class="hljs-comment"># local ip</span>
curl https://ipinfo.io/ip <span class="hljs-comment"># public ip</span>
</code></pre>
<p>Note: For Windows or macOS, use ipconfig or ifconfig respectively to find the IP address.</p>
<p>Clone the repository and enter the <code>server/</code>folder.</p>
<pre><code class="language-sh hljs language-bash">git <span class="hljs-built_in">clone</span> --depth 1 https://github.com/Fosowl/agenticSeek.git
<span class="hljs-built_in">cd</span> agenticSeek/llm_server/
</code></pre>
<p>Install server specific requirements:</p>
<pre><code class="language-sh hljs language-bash">pip3 install -r requirements.txt
</code></pre>
<p>Run the server script.</p>
<pre><code class="language-sh hljs language-bash">python3 app.py --provider ollama --port 3333
</code></pre>
<p>You have the choice between using <code>ollama</code> and <code>llamacpp</code> as a LLM service.</p>
<p>Now on your personal computer:</p>
<p>Change the <code>config.ini</code> file to set the <code>provider_name</code> to <code>server</code> and <code>provider_model</code> to <code>deepseek-r1:xxb</code>.<br>Set the <code>provider_server_address</code> to the ip address of the machine that will run the model.</p>
<pre><code class="language-sh hljs language-bash">[MAIN]
is_local = False
provider_name = server
provider_model = deepseek-r1:70b
provider_server_address = x.x.x.x:3333
</code></pre>
<p>Next step: <a href="#Start-services-and-Run">Start services and run AgenticSeek</a>  </p>
<hr>
<h2>Speech to Text</h2>
<p>Warning: speech to text only work in CLI mode at the moment.</p>
<p>Please note that currently speech to text only work in english.</p>
<p>The speech-to-text functionality is disabled by default. To enable it, set the listen option to True in the config.ini file:</p>
<pre><code class="hljs language-ini"><span class="hljs-attr">listen</span> = <span class="hljs-literal">True</span>
</code></pre>
<p>When enabled, the speech-to-text feature listens for a trigger keyword, which is the agent's name, before it begins processing your input. You can customize the agent's name by updating the <code>agent_name</code> value in the <em>config.ini</em> file:</p>
<pre><code class="hljs language-ini"><span class="hljs-attr">agent_name</span> = Friday
</code></pre>
<p>For optimal recognition, we recommend using a common English name like "John" or "Emma" as the agent name</p>
<p>Once you see the transcript start to appear, say the agent's name aloud to wake it up (e.g., "Friday").</p>
<p>Speak your query clearly.</p>
<p>End your request with a confirmation phrase to signal the system to proceed. Examples of confirmation phrases include:</p>
<pre><code class="hljs language-bash"><span class="hljs-string">"do it"</span>, <span class="hljs-string">"go ahead"</span>, <span class="hljs-string">"execute"</span>, <span class="hljs-string">"run"</span>, <span class="hljs-string">"start"</span>, <span class="hljs-string">"thanks"</span>, <span class="hljs-string">"would ya"</span>, <span class="hljs-string">"please"</span>, <span class="hljs-string">"okay?"</span>, <span class="hljs-string">"proceed"</span>, <span class="hljs-string">"continue"</span>, <span class="hljs-string">"go on"</span>, <span class="hljs-string">"do that"</span>, <span class="hljs-string">"go it"</span>, <span class="hljs-string">"do you understand?"</span>
</code></pre>
<h2>Config</h2>
<p>Example config:</p>
<pre><code class="hljs language-ini"><span class="hljs-section">[MAIN]</span>
<span class="hljs-attr">is_local</span> = <span class="hljs-literal">True</span>
<span class="hljs-attr">provider_name</span> = ollama
<span class="hljs-attr">provider_model</span> = deepseek-r1:<span class="hljs-number">32</span>b
<span class="hljs-attr">provider_server_address</span> = http://<span class="hljs-number">127.0</span>.<span class="hljs-number">0.1</span>:<span class="hljs-number">11434</span> <span class="hljs-comment"># Example for Ollama; use http://127.0.0.1:1234 for LM-Studio</span>
<span class="hljs-attr">agent_name</span> = Friday
<span class="hljs-attr">recover_last_session</span> = <span class="hljs-literal">False</span>
<span class="hljs-attr">save_session</span> = <span class="hljs-literal">False</span>
<span class="hljs-attr">speak</span> = <span class="hljs-literal">False</span>
<span class="hljs-attr">listen</span> = <span class="hljs-literal">False</span>

<span class="hljs-attr">jarvis_personality</span> = <span class="hljs-literal">False</span>
<span class="hljs-attr">languages</span> = en zh <span class="hljs-comment"># List of languages for TTS and potentially routing.</span>
<span class="hljs-section">[BROWSER]</span>
<span class="hljs-attr">headless_browser</span> = <span class="hljs-literal">False</span>
<span class="hljs-attr">stealth_mode</span> = <span class="hljs-literal">False</span>
</code></pre>
<p><strong>Explanation of <code>config.ini</code> Settings</strong>:</p>
<ul>
<li><strong><code>[MAIN]</code> Section:</strong><ul>
<li><code>is_local</code>: <code>True</code> if using a local LLM provider (Ollama, LM-Studio, local OpenAI-compatible server) or the self-hosted server option. <code>False</code> if using a cloud-based API (OpenAI, Google, etc.).</li>
<li><code>provider_name</code>: Specifies the LLM provider.<ul>
<li>Local options: <code>ollama</code>, <code>lm-studio</code>, <code>openai</code> (for local OpenAI-compatible servers), <code>server</code> (for the self-hosted server setup).</li>
<li>API options: <code>openai</code>, <code>google</code>, <code>deepseek</code>, <code>huggingface</code>, <code>togetherAI</code>.</li>
</ul>
</li>
<li><code>provider_model</code>: The specific model name or ID for the chosen provider (e.g., <code>deepseekcoder:6.7b</code> for Ollama, <code>gpt-3.5-turbo</code> for OpenAI API, <code>mistralai/Mixtral-8x7B-Instruct-v0.1</code> for TogetherAI).</li>
<li><code>provider_server_address</code>: The address of your LLM provider.<ul>
<li>For local providers: e.g., <code>http://127.0.0.1:11434</code> for Ollama, <code>http://127.0.0.1:1234</code> for LM-Studio.</li>
<li>For the <code>server</code> provider type: The address of your self-hosted LLM server (e.g., <code>http://your_server_ip:3333</code>).</li>
<li>For cloud APIs (<code>is_local = False</code>): This is often ignored or can be left blank, as the API endpoint is usually handled by the client library.</li>
</ul>
</li>
<li><code>agent_name</code>: Name of the AI assistant (e.g., Friday). Used as a trigger word for speech-to-text if enabled.</li>
<li><code>recover_last_session</code>: <code>True</code> to attempt to restore the previous session's state, <code>False</code> to start fresh.</li>
<li><code>save_session</code>: <code>True</code> to save the current session's state for potential recovery, <code>False</code> otherwise.</li>
<li><code>speak</code>: <code>True</code> to enable text-to-speech voice output, <code>False</code> to disable.</li>
<li><code>listen</code>: <code>True</code> to enable speech-to-text voice input (CLI mode only), <code>False</code> to disable.</li>
<li><code>work_dir</code>: <strong>Crucial:</strong> The directory where AgenticSeek will read/write files. <strong>Ensure this path is valid and accessible on your system.</strong></li>
<li><code>jarvis_personality</code>: <code>True</code> to use a more "Jarvis-like" system prompt (experimental), <code>False</code> for the standard prompt.</li>
<li><code>languages</code>: A comma-separated list of languages (e.g., <code>en, zh, fr</code>). Used for TTS voice selection (defaults to the first) and can assist the LLM router. Avoid too many or very similar languages for router efficiency.</li>
</ul>
</li>
<li><strong><code>[BROWSER]</code> Section:</strong><ul>
<li><code>headless_browser</code>: <code>True</code> to run the automated browser without a visible window (recommended for web interface or non-interactive use). <code>False</code> to show the browser window (useful for CLI mode or debugging).</li>
<li><code>stealth_mode</code>: <code>True</code> to enable measures to make browser automation harder to detect. May require manual installation of browser extensions like anticaptcha.</li>
</ul>
</li>
</ul>
<p>This section summarizes the supported LLM provider types. Configure them in <code>config.ini</code>.</p>
<p><strong>Local Providers (Run on Your Own Hardware):</strong></p>
<table>
<thead>
<tr>
<th>Provider Name in <code>config.ini</code></th>
<th><code>is_local</code></th>
<th>Description</th>
<th>Setup Section</th>
</tr>
</thead>
<tbody><tr>
<td><code>ollama</code></td>
<td><code>True</code></td>
<td>Use Ollama to serve local LLMs.</td>
<td><a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-for-running-llm-locally-on-your-machine">Setup for running LLM locally</a></td>
</tr>
<tr>
<td><code>lm-studio</code></td>
<td><code>True</code></td>
<td>Use LM-Studio to serve local LLMs.</td>
<td><a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-for-running-llm-locally-on-your-machine">Setup for running LLM locally</a></td>
</tr>
<tr>
<td><code>openai</code> (for local server)</td>
<td><code>True</code></td>
<td>Connect to a local server that exposes an OpenAI-compatible API (e.g., llama.cpp).</td>
<td><a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-for-running-llm-locally-on-your-machine">Setup for running LLM locally</a></td>
</tr>
<tr>
<td><code>server</code></td>
<td><code>False</code></td>
<td>Connect to the AgenticSeek self-hosted LLM server running on another machine.</td>
<td><a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-the-llm-on-your-own-server">Setup to run the LLM on your own server</a></td>
</tr>
</tbody></table>
<p><strong>API Providers (Cloud-Based):</strong></p>
<table>
<thead>
<tr>
<th>Provider Name in <code>config.ini</code></th>
<th><code>is_local</code></th>
<th>Description</th>
<th>Setup Section</th>
</tr>
</thead>
<tbody><tr>
<td><code>openai</code></td>
<td><code>False</code></td>
<td>Use OpenAI's official API (e.g., GPT-3.5, GPT-4).</td>
<td><a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api">Setup to run with an API</a></td>
</tr>
<tr>
<td><code>google</code></td>
<td><code>False</code></td>
<td>Use Google's Gemini models via API.</td>
<td><a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api">Setup to run with an API</a></td>
</tr>
<tr>
<td><code>deepseek</code></td>
<td><code>False</code></td>
<td>Use Deepseek's official API.</td>
<td><a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api">Setup to run with an API</a></td>
</tr>
<tr>
<td><code>huggingface</code></td>
<td><code>False</code></td>
<td>Use Hugging Face Inference API.</td>
<td><a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api">Setup to run with an API</a></td>
</tr>
<tr>
<td><code>togetherAI</code></td>
<td><code>False</code></td>
<td>Use TogetherAI's API for various open models.</td>
<td><a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api">Setup to run with an API</a></td>
</tr>
</tbody></table>
<hr>
<h2>Troubleshooting</h2>
<p>If you encounter issues, this section provides guidance.</p>
<h1>Known Issues</h1>
<h2>ChromeDriver Issues</h2>
<p><strong>Error Example:</strong> <code>SessionNotCreatedException: Message: session not created: This version of ChromeDriver only supports Chrome version XXX</code></p>
<ul>
<li><strong>Cause:</strong> Your installed ChromeDriver version is incompatible with your Google Chrome browser version.</li>
<li><strong>Solution:</strong><ol>
<li><strong>Check Chrome Version:</strong> Open Google Chrome, go to <code>Settings &gt; About Chrome</code> to find your version (e.g., "Version 120.0.6099.110").</li>
<li><strong>Download Matching ChromeDriver:</strong><ul>
<li>For Chrome versions 115 and newer: Go to the <a href="https://googlechromelabs.github.io/chrome-for-testing/">Chrome for Testing (CfT) JSON Endpoints</a>. Find the "stable" channel and download the ChromeDriver for your OS that matches your Chrome's major version.</li>
<li>For older versions (less common): You might find them on the <a href="https://chromedriver.chromium.org/downloads">ChromeDriver - WebDriver for Chrome</a> page.</li>
<li>The image below shows an example from the CfT page:<br><img src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/chromedriver_readme.png" alt="Download Chromedriver specific version from Chrome for Testing page"></li>
</ul>
</li>
<li><strong>Install ChromeDriver:</strong><ul>
<li>Ensure the downloaded <code>chromedriver</code> (or <code>chromedriver.exe</code> on Windows) is placed in a directory listed in your system's PATH environment variable (e.g., <code>/usr/local/bin</code> on Linux/macOS, or a custom scripts folder added to PATH on Windows).</li>
<li>Alternatively, place it in the root directory of the <code>agenticSeek</code> project.</li>
<li>Make sure the driver is executable (e.g., <code>chmod +x chromedriver</code> on Linux/macOS).</li>
</ul>
</li>
<li>Refer to the <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#chromedriver-installation">ChromeDriver Installation</a> section in the main Installation guide for more details.</li>
</ol>
</li>
</ul>
<p>If this section is incomplete or you encounter other ChromeDriver issues, please consider searching existing <a href="https://github.com/Fosowl/agenticSeek/issues">GitHub Issues</a> or raising a new one.</p>
<p><code>Exception: Failed to initialize browser: Message: session not created: This version of ChromeDriver only supports Chrome version 113 Current browser version is 134.0.6998.89 with binary path</code></p>
<p>This happen if there is a mismatch between your browser and chromedriver version.</p>
<p>You need to navigate to download the latest version:</p>
<p><a href="https://developer.chrome.com/docs/chromedriver/downloads">https://developer.chrome.com/docs/chromedriver/downloads</a></p>
<p>If you're using Chrome version 115 or newer go to:</p>
<p><a href="https://googlechromelabs.github.io/chrome-for-testing/">https://googlechromelabs.github.io/chrome-for-testing/</a></p>
<p>And download the chromedriver version matching your OS.</p>
<p><img src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/chromedriver_readme.png" alt="alt text"></p>
<p>If this section is incomplete please raise an issue.</p>
<h2>connection adapters Issues</h2>
<pre><code class="hljs language-php"><span class="hljs-built_in">Exception</span>: Provider lm-studio failed: HTTP request failed: No connection adapters were found <span class="hljs-keyword">for</span> <span class="hljs-string">'127.0.0.1:1234/v1/chat/completions'</span>` (Note: port may vary)
</code></pre>
<ul>
<li><strong>Cause:</strong> The <code>provider_server_address</code> in <code>config.ini</code> for <code>lm-studio</code> (or other similar local OpenAI-compatible servers) is missing the <code>http://</code> prefix or is pointing to the wrong port.</li>
<li><strong>Solution:</strong><ul>
<li>Ensure the address includes <code>http://</code>. LM-Studio typically defaults to <code>http://127.0.0.1:1234</code>.</li>
<li>Correct <code>config.ini</code>: <code>provider_server_address = http://127.0.0.1:1234</code> (or your actual LM-Studio server port).</li>
</ul>
</li>
</ul>
<h2>SearxNG Base URL Not Provided</h2>
<pre><code class="hljs language-csharp"><span class="hljs-function">raise <span class="hljs-title">ValueError</span>(<span class="hljs-params"><span class="hljs-string">"SearxNG base URL must be provided either as an argument or via the SEARXNG_BASE_URL environment variable."</span></span>)
ValueError: SearxNG <span class="hljs-keyword">base</span> URL must be provided either <span class="hljs-keyword">as</span> an argument <span class="hljs-keyword">or</span> via the SEARXNG_BASE_URL environment variable.`
</span></code></pre>
<h2>FAQ</h2>
<p><strong>Q: What hardware do I need?</strong>  </p>
<table>
<thead>
<tr>
<th>Model Size</th>
<th>GPU</th>
<th>Comment</th>
</tr>
</thead>
<tbody><tr>
<td>7B</td>
<td>8GB Vram</td>
<td>⚠️ Not recommended. Performance is poor, frequent hallucinations, and planner agents will likely fail.</td>
</tr>
<tr>
<td>14B</td>
<td>12 GB VRAM (e.g. RTX 3060)</td>
<td>✅ Usable for simple tasks. May struggle with web browsing and planning tasks.</td>
</tr>
<tr>
<td>32B</td>
<td>24+ GB VRAM (e.g. RTX 4090)</td>
<td>🚀 Success with most tasks, might still struggle with task planning</td>
</tr>
<tr>
<td>70B+</td>
<td>48+ GB Vram</td>
<td>💪 Excellent. Recommended for advanced use cases.</td>
</tr>
</tbody></table>
<p><strong>Q: I get an error what do I do?</strong>  </p>
<p>Ensure local is running (<code>ollama serve</code>), your <code>config.ini</code> matches your provider, and dependencies are installed. If none work feel free to raise an issue.</p>
<p><strong>Q: Can it really run 100% locally?</strong>  </p>
<p>Yes with Ollama, lm-studio or server providers, all speech to text, LLM and text to speech model run locally. Non-local options (OpenAI or others API) are optional.</p>
<p><strong>Q: Why should I use AgenticSeek when I have Manus?</strong></p>
<p>Unlike Manus, AgenticSeek prioritizes independence from external systems, giving you more control, privacy and avoid api cost.</p>
<p><strong>Q: Who is behind the project ?</strong></p>
<p>The project was created by me, along with two friends who serve as maintainers and contributors from the open-source community on GitHub. We’re just a group of passionate individuals, not a startup or affiliated with any organization.</p>
<p>Any AgenticSeek account on X other than my personal account (<a href="https://x.com/Martin993886460">https://x.com/Martin993886460</a>) is an impersonation.</p>
<h2>Contribute</h2>
<p>We’re looking for developers to improve AgenticSeek! Check out open issues or discussion.</p>
<p><a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/docs/CONTRIBUTING.md">Contribution guide</a></p>
<p><a href="https://www.star-history.com/#Fosowl/agenticSeek&amp;Date"><img src="https://api.star-history.com/svg?repos=Fosowl/agenticSeek&amp;type=Date" alt="Star History Chart"></a></p>
<h2>Maintainers:</h2>
<blockquote>
<p><a href="https://github.com/Fosowl">Fosowl</a> | Paris Time </p>
</blockquote>
<blockquote>
<p><a href="https://github.com/antoineVIVIES">antoineVIVIES</a> | Taipei Time </p>
</blockquote>
<blockquote>
<p><a href="https://github.com/steveh8758">steveh8758</a> | Taipei Time </p>
</blockquote>
<h2>Special Thanks:</h2>
<blockquote>
<p><a href="https://github.com/tcsenpai">tcsenpai</a> and <a href="https://github.com/plitc">plitc</a> For helping with backend dockerization</p>
</blockquote>
<h2>Sponsors:</h2>
<p>5$ or more Monthly sponsor appear here:</p>
<ul>
<li><strong>tatra-labs</strong></li>
</ul>
<p>Sorry, but I didn't receive the content you want translated. Please provide the technical document (Part 4 of 4) so I can translate it for you.</p>
<hr>
<p>Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx">Open Ai Tx</a> | Last indexed: 2025-06-16</p>
<hr>
</div>
    </div>

    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async=""></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
    


</body></html>