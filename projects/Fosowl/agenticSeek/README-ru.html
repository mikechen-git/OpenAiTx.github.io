<!DOCTYPE html><html lang="en"><head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AgenticSeek: Приватная локальная альтернатива Manus. - Fosowl/agenticSeek</title>

    <!-- Primary Meta Tags -->
    <meta name="title" content="AgenticSeek: Приватная локальная альтернатива Manus. - Fosowl/agenticSeek">
    <meta name="description" content="Fosowl/agenticSeek - GitHub repository ru documentation and information">
    <meta name="keywords" content="Fosowl, agenticSeek, GitHub, repository, ru documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">

    <!-- Open Graph -->
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/Fosowl/agenticSeek/README-ru.html">
    <meta property="og:title" content="AgenticSeek: Приватная локальная альтернатива Manus. - Fosowl/agenticSeek">
    <meta property="og:description" content="Fosowl/agenticSeek - GitHub repository ru documentation and information">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">

    <!-- Favicon -->
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">

    <!-- Marked.js for Markdown rendering -->
    <script type="text/javascript" async="" src="https://www.statcounter.com/counter/recorder.js"></script><script src="/js/marked.min.js?v=20250613"></script>
    <!-- Highlight.js for code syntax highlighting -->
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <!-- Custom CSS -->
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        /* Layout */
        body {
            display: flex;
            flex-direction: column;
            min-height: 100vh;
        }

        .main-container {
            margin: 0 auto;
            width: 100%;
            max-width: 980px;
            padding: 0 20px;
        }

        @media (max-width: 768px) {
            .main-container {
                padding: 0 15px;
            }
        }

        /* Image size restrictions */
        .markdown-body img {
            max-width: 100%;
            height: auto;
        }

        /* Existing styles */
        .header {
            text-align: center;
            margin-bottom: 30px;
            padding: 20px;
            background-color: #f6f8fa;
            border-bottom: 1px solid #e1e4e8;
            position: relative;
        }

        .back-button {
            position: absolute;
            left: 20px;
            top: 50%;
            transform: translateY(-50%);
            color: #0366d6;
            text-decoration: none;
            display: flex;
            align-items: center;
            font-size: 14px;
            padding: 5px 10px;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            background-color: #fff;
        }

        .back-button:hover {
            background-color: #f6f8fa;
            border-color: #0366d6;
        }

        .back-button::before {
            content: "←";
            margin-right: 5px;
            font-size: 16px;
        }

        .header .links {
            margin-top: 10px;
            font-size: 16px;
        }

        .header .links a {
            color: #0366d6;
            text-decoration: none;
            margin-left: 5px;
        }

        .header .links a:hover {
            text-decoration: underline;
        }
        
        /* Language badges styles */
        .language-badges {
            margin-top: 15px;
            text-align: center;
        }
        .language-badges a {
            display: inline-block;
            margin: 2px;
            text-decoration: none;
        }
        .language-badges img {
            height: 20px;
            border-radius: 3px;
        }
        .language-badges a:hover img {
            opacity: 0.8;
        }
    </style>
</head>

<body>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/Fosowl/agenticSeek" id="githubRepoLink" target="_blank">Fosowl/agenticSeek</a>
        </div>
        <div class="language-badges" id="languageBadges"><a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=en"><img src="https://img.shields.io/badge/EN-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=zh-CN"><img src="https://img.shields.io/badge/简中-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=zh-TW"><img src="https://img.shields.io/badge/繁中-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=ja"><img src="https://img.shields.io/badge/日本語-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=ko"><img src="https://img.shields.io/badge/한국어-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=th"><img src="https://img.shields.io/badge/ไทย-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=fr"><img src="https://img.shields.io/badge/Français-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=de"><img src="https://img.shields.io/badge/Deutsch-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=es"><img src="https://img.shields.io/badge/Español-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=it"><img src="https://img.shields.io/badge/Italiano-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=ru"><img src="https://img.shields.io/badge/Русский-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=pt"><img src="https://img.shields.io/badge/Português-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=nl"><img src="https://img.shields.io/badge/Nederlands-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=pl"><img src="https://img.shields.io/badge/Polski-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=ar"><img src="https://img.shields.io/badge/العربية-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=tr"><img src="https://img.shields.io/badge/Türkçe-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=vi"><img src="https://img.shields.io/badge/Tiếng Việt-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=hi"><img src="https://img.shields.io/badge/हिंदी-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=fa"><img src="https://img.shields.io/badge/فارسی-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=id"><img src="https://img.shields.io/badge/Bahasa Indonesia-white" alt="version"></a></div>
    </div>

    <div class="main-container">
        <div class="markdown-body" id="content"><h1>AgenticSeek: Приватная локальная альтернатива Manus.</h1>
<p align="center">
<img align="center" src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/agentic_seek_logo.png" width="300" height="300" alt="Agentic Seek Logo">
</p><p>

</p><p>  English | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_CHS.md">中文</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_CHT.md">繁體中文</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_FR.md">Français</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_JP.md">日本語</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_PTBR.md">Português (Brasil)</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_ES.md">Español</a></p>
<p><em>Полностью локальная альтернатива Manus AI</em>: этот голосовой AI-ассистент автономно просматривает веб, пишет код и планирует задачи, сохраняя все данные только на вашем устройстве. Оптимизирован для локальных моделей рассуждения, полностью работает на вашем оборудовании, обеспечивая полную приватность и отсутствие облачной зависимости.</p>
<p><a href="https://fosowl.github.io/agenticSeek.html"><img src="https://img.shields.io/static/v1?label=Website&amp;message=AgenticSeek&amp;color=blue&amp;style=flat-square" alt="Visit AgenticSeek"></a> <img src="https://img.shields.io/badge/license-GPL--3.0-green" alt="License"> <a href="https://discord.gg/8hGDaME3TC"><img src="https://img.shields.io/badge/Discord-Join%20Us-7289DA?logo=discord&amp;logoColor=white" alt="Discord"></a> <a href="https://x.com/Martin993886460"><img src="https://img.shields.io/twitter/url/https/twitter.com/fosowl.svg?style=social&amp;label=Update%20%40Fosowl" alt="Twitter"></a> <a href="https://github.com/Fosowl/agenticSeek/stargazers"><img src="https://img.shields.io/github/stars/Fosowl/agenticSeek?style=social" alt="GitHub stars"></a></p>
<h3>Почему AgenticSeek?</h3>
<ul>
<li><p>🔒 Полностью локальный и приватный — Всё работает на вашем компьютере: никаких облаков, никакой передачи данных. Ваши файлы, диалоги и поисковые запросы остаются приватными.</p>
</li>
<li><p>🌐 Умный веб-браузер — AgenticSeek может самостоятельно просматривать интернет: искать, читать, извлекать информацию, заполнять веб-формы — полностью без рук.</p>
</li>
<li><p>💻 Автономный помощник по программированию — Нужен код? Он может писать, отлаживать и запускать программы на Python, C, Go, Java и других языках — полностью автономно.</p>
</li>
<li><p>🧠 Умный выбор агента — Вы задаёте вопрос, и он автоматически выбирает лучшего агента для задачи. Как команда экспертов, готовых помочь.</p>
</li>
<li><p>📋 Планирование и выполнение сложных задач — От планирования путешествий до реализации сложных проектов — может разбивать большие задачи на этапы и выполнять их с помощью нескольких AI-агентов.</p>
</li>
<li><p>🎙️ Голосовое управление — Современное, быстрое, футуристичное распознавание речи и синтез позволяет общаться с ним голосом, как с личным AI из фантастики. (В разработке)</p>
</li>
</ul>
<h3><strong>Демонстрация</strong></h3>
<blockquote>
<p><em>Можешь найти проект agenticSeek, узнать какие навыки требуются, затем открыть CV_candidates.zip и сказать, кто из кандидатов лучше всего подходит для проекта?</em></p>
</blockquote>
<p><a href="https://github.com/user-attachments/assets/b8ca60e9-7b3b-4533-840e-08f9ac426316">https://github.com/user-attachments/assets/b8ca60e9-7b3b-4533-840e-08f9ac426316</a></p>
<p>Дисклеймер: Эта демонстрация, включая все показанные файлы (например, CV_candidates.zip), полностью вымышлена. Мы не корпорация, мы ищем open-source контрибьюторов, а не кандидатов.</p>
<blockquote>
<p>🛠⚠️️ <strong>Активная разработка</strong></p>
</blockquote>
<blockquote>
<p>🙏 Этот проект начался как хобби и не имеет ни дорожной карты, ни финансирования. Он превзошёл все ожидания, попав в GitHub Trending. Вклад, обратная связь и терпение очень ценятся.</p>
</blockquote>
<h2>Необходимое ПО</h2>
<p>Перед началом убедитесь, что у вас установлено следующее ПО:</p>
<ul>
<li><strong>Git:</strong> Для клонирования репозитория. <a href="https://git-scm.com/downloads">Скачать Git</a></li>
<li><strong>Python 3.10.x:</strong> Настоятельно рекомендуется использовать Python версии 3.10.x. Использование других версий может привести к ошибкам зависимостей. <a href="https://www.python.org/downloads/release/python-3100/">Скачать Python 3.10</a> (выберите версию 3.10.x).</li>
<li><strong>Docker Engine &amp; Docker Compose:</strong> Для запуска встроенных сервисов, таких как SearxNG.<ul>
<li>Установите Docker Desktop (включает Docker Compose V2): <a href="https://docs.docker.com/desktop/install/windows-install/">Windows</a> | <a href="https://docs.docker.com/desktop/install/mac-install/">Mac</a> | <a href="https://docs.docker.com/desktop/install/linux-install/">Linux</a></li>
<li>Либо установите Docker Engine и Docker Compose отдельно для Linux: <a href="https://docs.docker.com/engine/install/">Docker Engine</a> | <a href="https://docs.docker.com/compose/install/">Docker Compose</a> (убедитесь, что установили Compose V2, например, <code>sudo apt-get install docker-compose-plugin</code>).</li>
</ul>
</li>
</ul>
<h3>1. <strong>Клонируйте репозиторий и настройте</strong></h3>
<pre><code class="language-sh hljs language-bash">git <span class="hljs-built_in">clone</span> https://github.com/Fosowl/agenticSeek.git
<span class="hljs-built_in">cd</span> agenticSeek
<span class="hljs-built_in">mv</span> .env.example .<span class="hljs-built_in">env</span>
</code></pre>
<h3>2. Измените содержимое файла .env</h3>
<pre><code class="language-sh hljs language-bash">SEARXNG_BASE_URL=<span class="hljs-string">"http://127.0.0.1:8080"</span>
REDIS_BASE_URL=<span class="hljs-string">"redis://redis:6379/0"</span>
WORK_DIR=<span class="hljs-string">"/Users/mlg/Documents/workspace_for_ai"</span>
OLLAMA_PORT=<span class="hljs-string">"11434"</span>
LM_STUDIO_PORT=<span class="hljs-string">"1234"</span>
CUSTOM_ADDITIONAL_LLM_PORT=<span class="hljs-string">"11435"</span>
OPENAI_API_KEY=<span class="hljs-string">'optional'</span>
DEEPSEEK_API_KEY=<span class="hljs-string">'optional'</span>
OPENROUTER_API_KEY=<span class="hljs-string">'optional'</span>
TOGETHER_API_KEY=<span class="hljs-string">'optional'</span>
GOOGLE_API_KEY=<span class="hljs-string">'optional'</span>
ANTHROPIC_API_KEY=<span class="hljs-string">'optional'</span>
</code></pre>
<p>Обновите файл <code>.env</code> своими значениями по мере необходимости:</p>
<ul>
<li><strong>SEARXNG_BASE_URL</strong>: Оставьте без изменений </li>
<li><strong>REDIS_BASE_URL</strong>: Оставьте без изменений </li>
<li><strong>WORK_DIR</strong>: Путь к вашей рабочей директории на локальном устройстве. AgenticSeek сможет читать и взаимодействовать с этими файлами.</li>
<li><strong>OLLAMA_PORT</strong>: Порт для сервиса Ollama.</li>
<li><strong>LM_STUDIO_PORT</strong>: Порт для сервиса LM Studio.</li>
<li><strong>CUSTOM_ADDITIONAL_LLM_PORT</strong>: Порт для дополнительного собственного LLM-сервиса.</li>
</ul>
<p><strong>API-ключи полностью опциональны для пользователей, которые запускают LLM локально. Это основное назначение проекта. Оставьте пустыми, если у вас достаточно ресурсов.</strong></p>
<h3>3. <strong>Запустите Docker</strong></h3>
<p>Убедитесь, что Docker установлен и запущен на вашей системе. Запустить Docker можно следующими командами:</p>
<ul>
<li><p><strong>Linux/macOS:</strong><br>  Откройте терминал и выполните:</p>
<pre><code class="language-sh hljs language-bash">sudo systemctl start docker
</code></pre>
<p>  Или запустите Docker Desktop из меню приложений, если он установлен.</p>
</li>
<li><p><strong>Windows:</strong><br>  Запустите Docker Desktop из меню "Пуск".</p>
</li>
</ul>
<p>Проверьте, что Docker работает, выполнив:</p>
<pre><code class="language-sh hljs language-bash">docker info
</code></pre>
<p>Если вы видите информацию о вашей установке Docker, значит всё работает корректно.</p>
<p>См. таблицу <a href="#list-of-local-providers">Локальных провайдеров</a> ниже для сводки.</p>
<p>Следующий шаг: <a href="#start-services-and-run">Запуск AgenticSeek локально</a></p>
<p><em>Обратитесь к разделу <a href="#troubleshooting">Устранение неполадок</a>, если возникнут проблемы.</em><br><em>Если ваше оборудование не поддерживает локальный запуск LLM, смотрите <a href="#setup-to-run-with-an-api">Настройка для работы с API</a>.</em><br><em>За подробным описанием <code>config.ini</code> смотрите <a href="#config">Раздел Конфигурации</a>.</em></p>
<hr>
<h2>Настройка для запуска LLM локально на вашем устройстве</h2>
<p><strong>Требования к оборудованию:</strong></p>
<p>Для локального запуска LLM необходимы соответствующие ресурсы. Минимум — GPU, способный запускать Magistral, Qwen или Deepseek 14B. См. раздел FAQ для рекомендаций по моделям и производительности.</p>
<p><strong>Настройте локального провайдера</strong>  </p>
<p>Запустите локального провайдера, например с помощью ollama:</p>
<pre><code class="language-sh hljs language-bash">ollama serve
</code></pre>
<p>См. ниже список поддерживаемых локальных провайдеров.</p>
<p><strong>Обновите config.ini</strong></p>
<p>Измените файл config.ini, установив provider_name на поддерживаемого провайдера и provider_model на LLM, поддерживаемую вашим провайдером. Рекомендуем использовать модели рассуждения, такие как <em>Magistral</em> или <em>Deepseek</em>.</p>
<p>См. <strong>FAQ</strong> в конце README для требований к оборудованию.</p>
<pre><code class="language-sh hljs language-bash">[MAIN]
is_local = True <span class="hljs-comment"># Локальный запуск или через удалённого провайдера.</span>
provider_name = ollama <span class="hljs-comment"># или lm-studio, openai и т.д.</span>
provider_model = deepseek-r1:14b <span class="hljs-comment"># выберите модель, подходящую вашему оборудованию</span>
provider_server_address = 127.0.0.1:11434
agent_name = Jarvis <span class="hljs-comment"># имя вашего AI</span>
recover_last_session = True <span class="hljs-comment"># восстанавливать предыдущую сессию</span>
save_session = True <span class="hljs-comment"># сохранять текущую сессию</span>
speak = False <span class="hljs-comment"># синтез речи</span>
listen = False <span class="hljs-comment"># распознавание речи, только для CLI, экспериментально</span>
jarvis_personality = False <span class="hljs-comment"># использовать стиль личности "Jarvis" (экспериментально)</span>
languages = en zh <span class="hljs-comment"># список языков, синтез речи по умолчанию на первом в списке</span>
[BROWSER]
headless_browser = True <span class="hljs-comment"># не меняйте, если не используете CLI на хосте</span>
stealth_mode = True <span class="hljs-comment"># использовать undetected selenium для уменьшения обнаружения браузера</span>
</code></pre>
<p><strong>Внимание</strong>:</p>
<ul>
<li><p>Формат файла <code>config.ini</code> не поддерживает комментарии.<br>Не копируйте и не вставляйте пример конфигурации напрямую: комментарии вызовут ошибки. Вместо этого вручную измените файл <code>config.ini</code>, исключив все комментарии.</p>
</li>
<li><p>Не указывайте provider_name как <code>openai</code>, если используете LM-studio для запуска LLM. Установите <code>lm-studio</code>.</p>
</li>
<li><p>Некоторые провайдеры (например, lm-studio) требуют наличие <code>http://</code> перед IP. Например, <code>http://127.0.0.1:1234</code></p>
</li>
</ul>
<p><strong>Список локальных провайдеров</strong></p>
<table>
<thead>
<tr>
<th>Провайдер</th>
<th>Локальный?</th>
<th>Описание</th>
</tr>
</thead>
<tbody><tr>
<td>ollama</td>
<td>Да</td>
<td>Запуск LLM локально с помощью ollama как LLM-провайдера</td>
</tr>
<tr>
<td>lm-studio</td>
<td>Да</td>
<td>Запуск LLM локально с помощью LM studio (установите <code>provider_name</code> как <code>lm-studio</code>)</td>
</tr>
<tr>
<td>openai</td>
<td>Да</td>
<td>Использование совместимого с openai API (например, сервер llama.cpp)</td>
</tr>
</tbody></table>
<p>Следующий шаг: <a href="#Start-services-and-Run">Запуск сервисов и AgenticSeek</a>  </p>
<p><em>Смотрите раздел <a href="#troubleshooting">Устранение неполадок</a>, если возникли проблемы.</em><br><em>Если ваше оборудование не поддерживает локальный запуск LLM, смотрите <a href="#setup-to-run-with-an-api">Настройка для работы с API</a>.</em><br><em>Для подробных объяснений <code>config.ini</code> смотрите <a href="#config">Раздел Конфигурации</a>.</em></p>
<h2>Настройка для работы с API</h2>
<p>В этом режиме используются внешние облачные провайдеры LLM. Вам понадобится API-ключ от выбранного сервиса.</p>
<p><strong>1. Выберите API-провайдера и получите API-ключ:</strong></p>
<p>Смотрите <a href="#list-of-api-providers">Список API-провайдеров</a> ниже. Посетите их сайты, зарегистрируйтесь и получите API-ключ.</p>
<p><strong>2. Установите свой API-ключ как переменную окружения:</strong></p>
<ul>
<li><strong>Linux/macOS:</strong><br>Откройте терминал и используйте команду <code>export</code>. Лучше добавить эту команду в профиль оболочки (например, <code>~/.bashrc</code>, <code>~/.zshrc</code>) для постоянства.<pre><code class="language-sh hljs language-bash"><span class="hljs-built_in">export</span> PROVIDER_API_KEY=<span class="hljs-string">"your_api_key_here"</span> 
<span class="hljs-comment"># Замените PROVIDER_API_KEY на конкретное имя переменной, например, OPENAI_API_KEY, GOOGLE_API_KEY</span>
</code></pre>
Пример для TogetherAI:<pre><code class="language-sh hljs language-bash"><span class="hljs-built_in">export</span> TOGETHER_API_KEY=<span class="hljs-string">"xxxxxxxxxxxxxxxxxxxxxx"</span>
</code></pre>
</li>
<li><strong>Windows:</strong></li>
<li><strong>Командная строка (Временно для текущей сессии):</strong><pre><code class="language-cmd">set PROVIDER_API_KEY=your_api_key_here
</code></pre>
</li>
<li><strong>PowerShell (Временно для текущей сессии):</strong><pre><code class="language-powershell">$env:PROVIDER_API_KEY="your_api_key_here"
</code></pre>
</li>
<li><strong>Постоянно:</strong> Найдите "переменные среды" в поисковой строке Windows, нажмите "Изменить системные переменные среды", затем нажмите кнопку "Переменные среды...". Добавьте новую пользовательскую переменную с соответствующим именем (например, <code>OPENAI_API_KEY</code>) и вашим ключом в качестве значения.</li>
</ul>
<p><em>(См. FAQ: <a href="#how-do-i-set-api-keys">Как установить API ключи?</a> для получения подробностей).</em></p>
<p><strong>3. Обновите <code>config.ini</code>:</strong></p>
<pre><code class="language-ini hljs"><span class="hljs-section">[MAIN]</span>
<span class="hljs-attr">is_local</span> = <span class="hljs-literal">False</span>
<span class="hljs-attr">provider_name</span> = openai <span class="hljs-comment"># Или google, deepseek, togetherAI, huggingface</span>
<span class="hljs-attr">provider_model</span> = gpt-<span class="hljs-number">3.5</span>-turbo <span class="hljs-comment"># Или gemini-1.5-flash, deepseek-chat, mistralai/Mixtral-8x7B-Instruct-v0.1 и т.д.</span>
provider_server_address = <span class="hljs-comment"># Обычно игнорируется или может быть оставлен пустым, когда is_local = False для большинства API</span>
<span class="hljs-comment"># ... другие настройки ...</span>
</code></pre>
<p><em>Внимание:</em> Убедитесь, что в значениях <code>config.ini</code> нет пробелов в конце строк.</p>
<p><strong>Список API провайдеров</strong></p>
<table>
<thead>
<tr>
<th>Провайдер</th>
<th><code>provider_name</code></th>
<th>Локальный?</th>
<th>Описание</th>
<th>Ссылка для получения API ключа</th>
</tr>
</thead>
<tbody><tr>
<td>OpenAI</td>
<td><code>openai</code></td>
<td>Нет</td>
<td>Использовать модели ChatGPT через API OpenAI.</td>
<td><a href="https://platform.openai.com/signup">platform.openai.com/signup</a></td>
</tr>
<tr>
<td>Google Gemini</td>
<td><code>google</code></td>
<td>Нет</td>
<td>Использовать модели Google Gemini через Google AI Studio.</td>
<td><a href="https://aistudio.google.com/keys">aistudio.google.com/keys</a></td>
</tr>
<tr>
<td>Deepseek</td>
<td><code>deepseek</code></td>
<td>Нет</td>
<td>Использовать модели Deepseek через их API.</td>
<td><a href="https://platform.deepseek.com">platform.deepseek.com</a></td>
</tr>
<tr>
<td>Hugging Face</td>
<td><code>huggingface</code></td>
<td>Нет</td>
<td>Использовать модели через Hugging Face Inference API.</td>
<td><a href="https://huggingface.co/settings/tokens">huggingface.co/settings/tokens</a></td>
</tr>
<tr>
<td>TogetherAI</td>
<td><code>togetherAI</code></td>
<td>Нет</td>
<td>Использовать различные open-source модели через TogetherAI API.</td>
<td><a href="https://api.together.ai/settings/api-keys">api.together.ai/settings/api-keys</a></td>
</tr>
</tbody></table>
<p><em>Примечание:</em></p>
<ul>
<li>Мы не рекомендуем использовать <code>gpt-4o</code> или другие модели OpenAI для сложного веб-сёрфинга и планирования задач, так как текущие оптимизации подсказок ориентированы на модели вроде Deepseek.</li>
<li>Задания на программирование/bash могут сталкиваться с ошибками при использовании Gemini, поскольку он может не строго следовать форматированию подсказок, оптимизированных для Deepseek.</li>
<li>Параметр <code>provider_server_address</code> в <code>config.ini</code> обычно не используется, когда <code>is_local = False</code>, так как конечная точка API обычно зашита в соответствующей библиотеке провайдера.</li>
</ul>
<p>Следующий шаг: <a href="#Start-services-and-Run">Запустите сервисы и AgenticSeek</a></p>
<p><em>См. раздел <strong>Известные проблемы</strong>, если у вас возникают сложности.</em></p>
<p><em>См. раздел <strong>Config</strong> для подробного объяснения файла конфигурации.</em></p>
<hr>
<h2>Запуск сервисов и работа</h2>
<p>По умолчанию AgenticSeek полностью запускается в docker.</p>
<p>Запустите необходимые сервисы. Это запустит все сервисы из docker-compose.yml, включая:<br>    - searxng<br>    - redis (требуется для searxng)<br>    - frontend<br>    - backend (если используется <code>full</code>)</p>
<pre><code class="language-sh hljs language-bash">./start_services.sh full <span class="hljs-comment"># MacOS</span>
start ./start_services.cmd full <span class="hljs-comment"># Window</span>
</code></pre>
<p><strong>Внимание:</strong> На этом этапе будут загружены и распакованы все образы Docker, что может занять до 30 минут. После запуска сервисов дождитесь полной загрузки backend-сервиса (вы должны увидеть <strong>backend: "GET /health HTTP/1.1" 200 OK</strong> в логе) перед отправкой каких-либо сообщений. При первом запуске backend-сервис может запускаться до 5 минут.</p>
<p>Перейдите на <code>http://localhost:3000/</code> — вы должны увидеть веб-интерфейс.</p>
<p><em>Устранение проблем с запуском сервисов:</em> Если эти скрипты не срабатывают, убедитесь, что Docker Engine запущен и Docker Compose (V2, <code>docker compose</code>) корректно установлен. Проверьте сообщения об ошибках в терминале. См. <a href="#faq-troubleshooting">FAQ: Помогите! Я получаю ошибку при запуске AgenticSeek или его скриптов.</a></p>
<p><strong>Необязательно:</strong> Запуск на хосте (CLI-режим):</p>
<p>Чтобы использовать CLI-интерфейс, необходимо установить пакет на хосте:</p>
<pre><code class="language-sh hljs language-bash">./install.sh
./install.bat <span class="hljs-comment"># windows</span>
</code></pre>
<p>Запустите сервисы:</p>
<pre><code class="language-sh hljs language-bash">./start_services.sh <span class="hljs-comment"># MacOS</span>
start ./start_services.cmd <span class="hljs-comment"># Window</span>
</code></pre>
<p>Используйте CLI: <code>python3 cli.py</code></p>
<hr>
<h2>Использование</h2>
<p>Убедитесь, что сервисы запущены командой <code>./start_services.sh full</code>, и перейдите на <code>localhost:3000</code> для доступа к веб-интерфейсу.</p>
<p>Вы также можете использовать преобразование речи в текст, установив <code>listen = True</code> в конфиге. Только для CLI-режима.</p>
<p>Для выхода просто скажите/напишите <code>goodbye</code>.</p>
<p>Вот несколько примеров использования:</p>
<blockquote>
<p><em>Сделай игру "змейка" на python!</em></p>
</blockquote>
<blockquote>
<p><em>Найди лучшие кафе в Ренне (Франция) через интернет и сохрани список из трёх с их адресами в rennes_cafes.txt.</em></p>
</blockquote>
<blockquote>
<p><em>Напиши программу на Go для вычисления факториала числа, сохрани как factorial.go в свою рабочую папку</em></p>
</blockquote>
<blockquote>
<p><em>Найди в папке summer_pictures все файлы JPG, переименуй их с сегодняшней датой и сохрани список переименованных файлов в photos_list.txt</em></p>
</blockquote>
<blockquote>
<p><em>Ищи онлайн популярные научно-фантастические фильмы 2024 года и выбери три для просмотра сегодня вечером. Сохрани список в movie_night.txt.</em></p>
</blockquote>
<blockquote>
<p><em>Найди последние новости об ИИ за 2025 год, выбери три статьи и напиши скрипт на Python для парсинга их заголовков и кратких описаний. Сохрани скрипт как news_scraper.py, а описания в ai_news.txt в /home/projects</em></p>
</blockquote>
<blockquote>
<p><em>В пятницу найди бесплатный API для котировок акций, зарегистрируйся с <a href="mailto:supersuper7434567@gmail.com">supersuper7434567@gmail.com</a>, затем напиши скрипт на Python для ежедневного получения цен Tesla по этому API и сохрани результаты в stock_prices.csv</em></p>
</blockquote>
<p><em>Обратите внимание, что заполнение форм пока экспериментальное и может не работать.</em></p>
<p>После ввода вашего запроса AgenticSeek выделит для задачи подходящего агента.</p>
<p>Поскольку это ранний прототип, система маршрутизации агентов может не всегда выбирать правильного агента по вашему запросу.</p>
<p>Поэтому старайтесь максимально чётко формулировать, что вы хотите и как AI должен действовать. Например, если вы хотите, чтобы он провёл веб-поиск, не говорите:</p>
<p><code>Ты знаешь хорошие страны для одиночных путешествий?</code></p>
<p>Вместо этого спросите:</p>
<p><code>Сделай веб-поиск и выясни, какие страны лучше всего подходят для одиночных путешествий</code></p>
<hr>
<h2><strong>Настройка для запуска LLM на вашем сервере</strong></h2>
<p>Если у вас есть мощный компьютер или сервер, который вы хотите использовать удалённо со своего ноутбука, вы можете запустить LLM на удалённом сервере с помощью нашего собственного llm-сервера.</p>
<p>На вашем "сервере", где будет запущена AI-модель, получите IP-адрес</p>
<pre><code class="language-sh hljs language-bash">ip a | grep <span class="hljs-string">"inet "</span> | grep -v 127.0.0.1 | awk <span class="hljs-string">'{print $2}'</span> | <span class="hljs-built_in">cut</span> -d/ -f1 <span class="hljs-comment"># локальный ip</span>
curl https://ipinfo.io/ip <span class="hljs-comment"># публичный ip</span>
</code></pre>
<p>Примечание: для Windows или macOS используйте соответственно ipconfig или ifconfig для определения IP-адреса.</p>
<p>Клонируйте репозиторий и перейдите в папку <code>server/</code>.</p>
<pre><code class="language-sh hljs language-bash">git <span class="hljs-built_in">clone</span> --depth 1 https://github.com/Fosowl/agenticSeek.git
<span class="hljs-built_in">cd</span> agenticSeek/llm_server/
</code></pre>
<p>Установите специфические для сервера зависимости:</p>
<pre><code class="language-sh hljs language-bash">pip3 install -r requirements.txt
</code></pre>
<p>Запустите серверный скрипт.</p>
<pre><code class="language-sh hljs language-bash">python3 app.py --provider ollama --port 3333
</code></pre>
<p>Вы можете выбрать между использованием <code>ollama</code> и <code>llamacpp</code> как сервиса LLM.</p>
<p>Теперь на вашем персональном компьютере:</p>
<p>Измените файл <code>config.ini</code>, чтобы установить <code>provider_name</code> в <code>server</code> и <code>provider_model</code> в <code>deepseek-r1:xxb</code>.<br>Установите <code>provider_server_address</code> на IP-адрес машины, где будет запускаться модель.</p>
<pre><code class="language-sh hljs language-bash">[MAIN]
is_local = False
provider_name = server
provider_model = deepseek-r1:70b
provider_server_address = x.x.x.x:3333
</code></pre>
<p>Следующий шаг: <a href="#Start-services-and-Run">Запустите сервисы и AgenticSeek</a>  </p>
<hr>
<h2>Преобразование речи в текст</h2>
<p>Внимание: функция распознавания речи работает только в CLI-режиме на данный момент.</p>
<p>Обратите внимание, что сейчас речь в текст работает только на английском языке.</p>
<p>Функция распознавания речи по умолчанию отключена. Чтобы включить её, установите опцию listen в True в файле config.ini:</p>
<pre><code class="hljs language-ini"><span class="hljs-attr">listen</span> = <span class="hljs-literal">True</span>
</code></pre>
<p>Когда функция включена, перед началом обработки вашего ввода она будет слушать ключевое слово-триггер, которым является имя агента. Вы можете изменить имя агента, изменив значение <code>agent_name</code> в файле <em>config.ini</em>:</p>
<pre><code class="hljs language-ini"><span class="hljs-attr">agent_name</span> = Friday
</code></pre>
<p>Для оптимального распознавания рекомендуется использовать распространённое английское имя, например "John" или "Emma", в качестве имени агента.</p>
<p>Как только вы увидите, что транскрипция начала появляться, произнесите имя агента вслух, чтобы разбудить его (например, "Friday").</p>
<p>Чётко озвучьте свой запрос.</p>
<p>Завершите свой запрос подтверждающей фразой, чтобы система приступила к выполнению. Примеры подтверждающих фраз:</p>
<pre><code class="hljs language-bash"><span class="hljs-string">"do it"</span>, <span class="hljs-string">"go ahead"</span>, <span class="hljs-string">"execute"</span>, <span class="hljs-string">"run"</span>, <span class="hljs-string">"start"</span>, <span class="hljs-string">"thanks"</span>, <span class="hljs-string">"would ya"</span>, <span class="hljs-string">"please"</span>, <span class="hljs-string">"okay?"</span>, <span class="hljs-string">"proceed"</span>, <span class="hljs-string">"continue"</span>, <span class="hljs-string">"go on"</span>, <span class="hljs-string">"do that"</span>, <span class="hljs-string">"go it"</span>, <span class="hljs-string">"do you understand?"</span>
</code></pre>
<h2>Config</h2>
<p>Пример конфигурации:</p>
<pre><code class="hljs language-ini"><span class="hljs-section">[MAIN]</span>
<span class="hljs-attr">is_local</span> = <span class="hljs-literal">True</span>
<span class="hljs-attr">provider_name</span> = ollama
<span class="hljs-attr">provider_model</span> = deepseek-r1:<span class="hljs-number">32</span>b
<span class="hljs-attr">provider_server_address</span> = http://<span class="hljs-number">127.0</span>.<span class="hljs-number">0.1</span>:<span class="hljs-number">11434</span> <span class="hljs-comment"># Пример для Ollama; используйте http://127.0.0.1:1234 для LM-Studio</span>
<span class="hljs-attr">agent_name</span> = Friday
<span class="hljs-attr">recover_last_session</span> = <span class="hljs-literal">False</span>
<span class="hljs-attr">save_session</span> = <span class="hljs-literal">False</span>
<span class="hljs-attr">speak</span> = <span class="hljs-literal">False</span>
<span class="hljs-attr">listen</span> = <span class="hljs-literal">False</span>

<span class="hljs-attr">jarvis_personality</span> = <span class="hljs-literal">False</span>
<span class="hljs-attr">languages</span> = en zh <span class="hljs-comment"># Список языков для TTS и, возможно, маршрутизации.</span>
<span class="hljs-section">[BROWSER]</span>
<span class="hljs-attr">headless_browser</span> = <span class="hljs-literal">False</span>
<span class="hljs-attr">stealth_mode</span> = <span class="hljs-literal">False</span>
</code></pre>
<p><strong>Пояснение к настройкам <code>config.ini</code></strong>:</p>
<ul>
<li><strong>Раздел <code>[MAIN]</code>:</strong><ul>
<li><code>is_local</code>: <code>True</code>, если используется локальный LLM-провайдер (Ollama, LM-Studio, локальный сервер совместимый с OpenAI) или опция самостоятельного размещения. <code>False</code>, если используется облачный API (OpenAI, Google и др.).</li>
<li><code>provider_name</code>: Указывает провайдера LLM.<ul>
<li>Локальные варианты: <code>ollama</code>, <code>lm-studio</code>, <code>openai</code> (для локальных серверов, совместимых с OpenAI), <code>server</code> (для самостоятельного размещения).</li>
<li>Варианты API: <code>openai</code>, <code>google</code>, <code>deepseek</code>, <code>huggingface</code>, <code>togetherAI</code>.</li>
</ul>
</li>
<li><code>provider_model</code>: Конкретное название или ID модели для выбранного провайдера (например, <code>deepseekcoder:6.7b</code> для Ollama, <code>gpt-3.5-turbo</code> для OpenAI API, <code>mistralai/Mixtral-8x7B-Instruct-v0.1</code> для TogetherAI).</li>
<li><code>provider_server_address</code>: Адрес вашего LLM-провайдера.<ul>
<li>Для локальных провайдеров: например, <code>http://127.0.0.1:11434</code> для Ollama, <code>http://127.0.0.1:1234</code> для LM-Studio.</li>
<li>Для типа провайдера <code>server</code>: адрес вашего собственного сервера LLM (например, <code>http://your_server_ip:3333</code>).</li>
<li>Для облачных API (<code>is_local = False</code>): часто игнорируется или может быть пустым, так как конечная точка API обычно обрабатывается клиентской библиотекой.</li>
</ul>
</li>
<li><code>agent_name</code>: Имя AI-ассистента (например, Friday). Используется как ключевое слово для активации распознавания речи, если оно включено.</li>
<li><code>recover_last_session</code>: <code>True</code> — попытка восстановить состояние предыдущей сессии, <code>False</code> — начать новую.</li>
<li><code>save_session</code>: <code>True</code> — сохранить состояние текущей сессии для возможного восстановления, иначе <code>False</code>.</li>
<li><code>speak</code>: <code>True</code> — включить голосовой вывод (TTS), <code>False</code> — отключить.</li>
<li><code>listen</code>: <code>True</code> — включить голосовой ввод (распознавание речи, только CLI режим), <code>False</code> — отключить.</li>
<li><code>work_dir</code>: <strong>Важное значение:</strong> Каталог, в котором AgenticSeek будет читать и записывать файлы. <strong>Убедитесь, что этот путь существует и доступен на вашей системе.</strong></li>
<li><code>jarvis_personality</code>: <code>True</code> — использовать более "Jarvis-подобный" системный prompt (экспериментально), <code>False</code> — стандартный prompt.</li>
<li><code>languages</code>: Перечисление языков через запятую (например, <code>en, zh, fr</code>). Используется для выбора голоса TTS (по умолчанию — первый язык) и может помочь маршрутизатору LLM. Не указывайте слишком много или очень похожих языков для эффективности.</li>
</ul>
</li>
<li><strong>Раздел <code>[BROWSER]</code>:</strong><ul>
<li><code>headless_browser</code>: <code>True</code> — запускать автоматизированный браузер без видимого окна (рекомендуется для веб-интерфейса или неинтерактивного использования). <code>False</code> — показать окно браузера (удобно для CLI или отладки).</li>
<li><code>stealth_mode</code>: <code>True</code> — включить меры против обнаружения автоматизации браузера. Может потребовать ручной установки расширений, например, anticaptcha.</li>
</ul>
</li>
</ul>
<p>В этом разделе приводится сводка поддерживаемых типов LLM-провайдеров. Настройте их в <code>config.ini</code>.</p>
<p><strong>Локальные провайдеры (на вашем оборудовании):</strong></p>
<table>
<thead>
<tr>
<th>Имя провайдера в <code>config.ini</code></th>
<th><code>is_local</code></th>
<th>Описание</th>
<th>Раздел настройки</th>
</tr>
</thead>
<tbody><tr>
<td><code>ollama</code></td>
<td><code>True</code></td>
<td>Использовать Ollama для локального запуска LLM.</td>
<td><a href="#setup-for-running-llm-locally-on-your-machine">Настройка локального LLM</a></td>
</tr>
<tr>
<td><code>lm-studio</code></td>
<td><code>True</code></td>
<td>Использовать LM-Studio для локального запуска LLM.</td>
<td><a href="#setup-for-running-llm-locally-on-your-machine">Настройка локального LLM</a></td>
</tr>
<tr>
<td><code>openai</code> (для локального сервера)</td>
<td><code>True</code></td>
<td>Подключение к локальному серверу с OpenAI-совместимым API (например, llama.cpp).</td>
<td><a href="#setup-for-running-llm-locally-on-your-machine">Настройка локального LLM</a></td>
</tr>
<tr>
<td><code>server</code></td>
<td><code>False</code></td>
<td>Подключение к самостоятельному серверу AgenticSeek LLM на другом устройстве.</td>
<td><a href="#setup-to-run-the-llm-on-your-own-server">Настройка собственного сервера LLM</a></td>
</tr>
</tbody></table>
<p><strong>API-провайдеры (облачные):</strong></p>
<table>
<thead>
<tr>
<th>Имя провайдера в <code>config.ini</code></th>
<th><code>is_local</code></th>
<th>Описание</th>
<th>Раздел настройки</th>
</tr>
</thead>
<tbody><tr>
<td><code>openai</code></td>
<td><code>False</code></td>
<td>Использовать официальный API OpenAI (например, GPT-3.5, GPT-4).</td>
<td><a href="#setup-to-run-with-an-api">Настройка с API</a></td>
</tr>
<tr>
<td><code>google</code></td>
<td><code>False</code></td>
<td>Использовать модели Gemini от Google через API.</td>
<td><a href="#setup-to-run-with-an-api">Настройка с API</a></td>
</tr>
<tr>
<td><code>deepseek</code></td>
<td><code>False</code></td>
<td>Использовать официальный API Deepseek.</td>
<td><a href="#setup-to-run-with-an-api">Настройка с API</a></td>
</tr>
<tr>
<td><code>huggingface</code></td>
<td><code>False</code></td>
<td>Использовать API Hugging Face Inference.</td>
<td><a href="#setup-to-run-with-an-api">Настройка с API</a></td>
</tr>
<tr>
<td><code>togetherAI</code></td>
<td><code>False</code></td>
<td>Использовать API TogetherAI для различных open моделей.</td>
<td><a href="#setup-to-run-with-an-api">Настройка с API</a></td>
</tr>
</tbody></table>
<hr>
<h2>Поиск и устранение неисправностей</h2>
<p>Если вы сталкиваетесь с проблемами, этот раздел поможет вам.</p>
<h1>Известные проблемы</h1>
<h2>Проблемы с ChromeDriver</h2>
<p><strong>Пример ошибки:</strong> <code>SessionNotCreatedException: Message: session not created: This version of ChromeDriver only supports Chrome version XXX</code></p>
<ul>
<li><strong>Причина:</strong> Установленная версия ChromeDriver не совместима с вашей версией браузера Google Chrome.</li>
<li><strong>Решение:</strong><ol>
<li><strong>Проверьте версию Chrome:</strong> Откройте Google Chrome, перейдите в <code>Настройки &gt; О Chrome</code>, чтобы узнать версию (например, "Версия 120.0.6099.110").</li>
<li><strong>Скачайте подходящий ChromeDriver:</strong><ul>
<li>Для версий Chrome 115 и новее: Перейдите на страницу <a href="https://googlechromelabs.github.io/chrome-for-testing/">Chrome for Testing (CfT) JSON Endpoints</a>. Найдите канал "stable" и скачайте ChromeDriver для вашей ОС, соответствующий основной версии Chrome.</li>
<li>Для более старых версий (редко): Попробуйте найти их на странице <a href="https://chromedriver.chromium.org/downloads">ChromeDriver - WebDriver for Chrome</a>.</li>
<li>На изображении ниже показан пример CfT страницы:<br><img src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/chromedriver_readme.png" alt="Download Chromedriver specific version from Chrome for Testing page"></li>
</ul>
</li>
<li><strong>Установите ChromeDriver:</strong><ul>
<li>Убедитесь, что скачанный <code>chromedriver</code> (или <code>chromedriver.exe</code> на Windows) находится в каталоге, который прописан в переменной PATH вашей системы (например, <code>/usr/local/bin</code> на Linux/macOS или папка со скриптами, добавленная в PATH на Windows).</li>
<li>Либо поместите его в корневую папку проекта <code>agenticSeek</code>.</li>
<li>Проверьте, что драйвер исполняемый (например, выполните <code>chmod +x chromedriver</code> на Linux/macOS).</li>
</ul>
</li>
<li>Подробнее смотрите в разделе <a href="#chromedriver-installation">ChromeDriver Installation</a> в основном руководстве по установке.</li>
</ol>
</li>
</ul>
<p>Если этот раздел неполный или вы столкнулись с другими проблемами ChromeDriver, попробуйте поискать похожие <a href="https://github.com/Fosowl/agenticSeek/issues">GitHub Issues</a> или создайте новую заявку.</p>
<p><code>Exception: Failed to initialize browser: Message: session not created: This version of ChromeDriver only supports Chrome version 113 Current browser version is 134.0.6998.89 with binary path</code></p>
<p>Это возникает, если версии браузера и chromedriver не совпадают.</p>
<p>Вам нужно скачать последнюю версию по адресу:</p>
<p><a href="https://developer.chrome.com/docs/chromedriver/downloads">https://developer.chrome.com/docs/chromedriver/downloads</a></p>
<p>Если вы используете Chrome версии 115 или новее, перейдите по адресу:</p>
<p><a href="https://googlechromelabs.github.io/chrome-for-testing/">https://googlechromelabs.github.io/chrome-for-testing/</a></p>
<p>И скачайте chromedriver, соответствующий вашей ОС.</p>
<p><img src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/chromedriver_readme.png" alt="alt text"></p>
<p>Если этот раздел неполный, пожалуйста, создайте issue.</p>
<h2>Проблемы connection adapters</h2>
<pre><code class="hljs language-php"><span class="hljs-built_in">Exception</span>: Provider lm-studio failed: HTTP request failed: No connection adapters were found <span class="hljs-keyword">for</span> <span class="hljs-string">'127.0.0.1:1234/v1/chat/completions'</span>` (Примечание: порт может отличаться)
</code></pre>
<ul>
<li><strong>Причина:</strong> В <code>provider_server_address</code> в <code>config.ini</code> для <code>lm-studio</code> (или других локальных серверов, совместимых с OpenAI) отсутствует префикс <code>http://</code> или указан неверный порт.</li>
<li><strong>Решение:</strong><ul>
<li>Убедитесь, что адрес начинается с <code>http://</code>. По умолчанию для LM-Studio: <code>http://127.0.0.1:1234</code>.</li>
<li>Исправьте <code>config.ini</code>: <code>provider_server_address = http://127.0.0.1:1234</code> (или ваш реальный порт LM-Studio).</li>
</ul>
</li>
</ul>
<h2>Не указан базовый URL SearxNG</h2>
<pre><code class="hljs language-csharp"><span class="hljs-function">raise <span class="hljs-title">ValueError</span>(<span class="hljs-params"><span class="hljs-string">"SearxNG base URL must be provided either as an argument or via the SEARXNG_BASE_URL environment variable."</span></span>)
ValueError: SearxNG <span class="hljs-keyword">base</span> URL must be provided either <span class="hljs-keyword">as</span> an argument <span class="hljs-keyword">or</span> via the SEARXNG_BASE_URL environment variable.`
</span></code></pre>
<h2>FAQ</h2>
<p><strong>В: Какое железо мне нужно?</strong>  </p>
<table>
<thead>
<tr>
<th>Размер модели</th>
<th>GPU</th>
<th>Комментарий</th>
</tr>
</thead>
<tbody><tr>
<td>7B</td>
<td>8ГБ VRAM</td>
<td>⚠️ Не рекомендуется. Низкая производительность, частые галлюцинации, агенты-планировщики, скорее всего, не будут работать.</td>
</tr>
<tr>
<td>14B</td>
<td>12ГБ VRAM (например, RTX 3060)</td>
<td>✅ Подходит для простых задач. Может испытывать трудности с веб-браузингом и планированием.</td>
</tr>
<tr>
<td>32B</td>
<td>24+ ГБ VRAM (например, RTX 4090)</td>
<td>🚀 Большинство задач успешно, могут быть сложности с планированием задач.</td>
</tr>
<tr>
<td>70B+</td>
<td>48+ ГБ VRAM</td>
<td>💪 Отлично. Рекомендуется для продвинутых сценариев.</td>
</tr>
</tbody></table>
<p><strong>В: Я получаю ошибку — что делать?</strong>  </p>
<p>Убедитесь, что локальный сервер запущен (<code>ollama serve</code>), ваш <code>config.ini</code> соответствует провайдеру, и все зависимости установлены. Если ничего не помогает — создайте issue.</p>
<p><strong>В: Может ли всё работать полностью локально?</strong>  </p>
<p>Да, с провайдерами Ollama, lm-studio или server, все компоненты — распознавание речи, LLM и синтез речи — работают локально. Не локальные варианты (OpenAI или другие API) — опциональны.</p>
<p><strong>В: Почему стоит использовать AgenticSeek, если есть Manus?</strong></p>
<p>В отличие от Manus, AgenticSeek ориентирован на независимость от внешних систем, что даёт больше контроля, приватности и позволяет избежать затрат на API.</p>
<p><strong>В: Кто стоит за проектом?</strong></p>
<p>Проект создан мной и двумя друзьями, которые также являются мейнтейнерами и контрибьюторами из open-source сообщества на GitHub. Мы — просто группа энтузиастов, не стартап и не связаны с какими-либо организациями.</p>
<p>Любой аккаунт AgenticSeek на X, кроме моего личного (<a href="https://x.com/Martin993886460">https://x.com/Martin993886460</a>), — это подделка.</p>
<h2>Вклад</h2>
<p>Мы ищем разработчиков для улучшения AgenticSeek! Смотрите открытые issue или обсуждения.</p>
<p><a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/docs/CONTRIBUTING.md">Руководство по вкладу</a></p>
<p><a href="https://www.star-history.com/#Fosowl/agenticSeek&amp;Date"><img src="https://api.star-history.com/svg?repos=Fosowl/agenticSeek&amp;type=Date" alt="Star History Chart"></a></p>
<h2>Мейнтейнеры:</h2>
<blockquote>
<p><a href="https://github.com/Fosowl">Fosowl</a> | Парижское время </p>
</blockquote>
<blockquote>
<p><a href="https://github.com/antoineVIVIES">antoineVIVIES</a> | Тайбэйское время </p>
</blockquote>
<blockquote>
<p><a href="https://github.com/steveh8758">steveh8758</a> | Тайбэйское время </p>
</blockquote>
<h2>Особая благодарность:</h2>
<blockquote>
<p><a href="https://github.com/tcsenpai">tcsenpai</a> и <a href="https://github.com/plitc">plitc</a> за помощь с docker-изация backend</p>
</blockquote>
<h2>Спонсоры:</h2>
<p>5$ и более — здесь отображаются ежемесячные спонсоры:</p>
<ul>
<li><strong>tatra-labs</strong></li>
</ul>
<p>Certainly! Please provide the content for Part 4 of 4 that you would like translated.</p>
<hr>
<p>Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx">Open Ai Tx</a> | Last indexed: 2025-06-16</p>
<hr>
</div>
    </div>

    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async=""></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
    


</body></html>