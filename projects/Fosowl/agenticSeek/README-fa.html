<!DOCTYPE html><html lang="en"><head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AgenticSeek: جایگزین خصوصی و محلی Manus - Fosowl/agenticSeek</title>

    <!-- Primary Meta Tags -->
    <meta name="title" content="AgenticSeek: جایگزین خصوصی و محلی Manus - Fosowl/agenticSeek">
    <meta name="description" content="Fosowl/agenticSeek - GitHub repository fa documentation and information">
    <meta name="keywords" content="Fosowl, agenticSeek, GitHub, repository, fa documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">

    <!-- Open Graph -->
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/Fosowl/agenticSeek/README-fa.html">
    <meta property="og:title" content="AgenticSeek: جایگزین خصوصی و محلی Manus - Fosowl/agenticSeek">
    <meta property="og:description" content="Fosowl/agenticSeek - GitHub repository fa documentation and information">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">

    <!-- Favicon -->
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">

    <!-- Marked.js for Markdown rendering -->
    <script type="text/javascript" async="" src="https://www.statcounter.com/counter/recorder.js"></script><script src="/js/marked.min.js?v=20250613"></script>
    <!-- Highlight.js for code syntax highlighting -->
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <!-- Custom CSS -->
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        /* Layout */
        body {
            display: flex;
            flex-direction: column;
            min-height: 100vh;
        }

        .main-container {
            margin: 0 auto;
            width: 100%;
            max-width: 980px;
            padding: 0 20px;
        }

        @media (max-width: 768px) {
            .main-container {
                padding: 0 15px;
            }
        }

        /* Image size restrictions */
        .markdown-body img {
            max-width: 100%;
            height: auto;
        }

        /* Existing styles */
        .header {
            text-align: center;
            margin-bottom: 30px;
            padding: 20px;
            background-color: #f6f8fa;
            border-bottom: 1px solid #e1e4e8;
            position: relative;
        }

        .back-button {
            position: absolute;
            left: 20px;
            top: 50%;
            transform: translateY(-50%);
            color: #0366d6;
            text-decoration: none;
            display: flex;
            align-items: center;
            font-size: 14px;
            padding: 5px 10px;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            background-color: #fff;
        }

        .back-button:hover {
            background-color: #f6f8fa;
            border-color: #0366d6;
        }

        .back-button::before {
            content: "←";
            margin-right: 5px;
            font-size: 16px;
        }

        .header .links {
            margin-top: 10px;
            font-size: 16px;
        }

        .header .links a {
            color: #0366d6;
            text-decoration: none;
            margin-left: 5px;
        }

        .header .links a:hover {
            text-decoration: underline;
        }
        
        /* Language badges styles */
        .language-badges {
            margin-top: 15px;
            text-align: center;
        }
        .language-badges a {
            display: inline-block;
            margin: 2px;
            text-decoration: none;
        }
        .language-badges img {
            height: 20px;
            border-radius: 3px;
        }
        .language-badges a:hover img {
            opacity: 0.8;
        }
    </style>
</head>

<body>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/Fosowl/agenticSeek" id="githubRepoLink" target="_blank">Fosowl/agenticSeek</a>
        </div>
        <div class="language-badges" id="languageBadges"><a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=en"><img src="https://img.shields.io/badge/EN-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=zh-CN"><img src="https://img.shields.io/badge/简中-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=zh-TW"><img src="https://img.shields.io/badge/繁中-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=ja"><img src="https://img.shields.io/badge/日本語-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=ko"><img src="https://img.shields.io/badge/한국어-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=th"><img src="https://img.shields.io/badge/ไทย-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=fr"><img src="https://img.shields.io/badge/Français-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=de"><img src="https://img.shields.io/badge/Deutsch-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=es"><img src="https://img.shields.io/badge/Español-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=it"><img src="https://img.shields.io/badge/Italiano-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=ru"><img src="https://img.shields.io/badge/Русский-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=pt"><img src="https://img.shields.io/badge/Português-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=nl"><img src="https://img.shields.io/badge/Nederlands-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=pl"><img src="https://img.shields.io/badge/Polski-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=ar"><img src="https://img.shields.io/badge/العربية-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=tr"><img src="https://img.shields.io/badge/Türkçe-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=vi"><img src="https://img.shields.io/badge/Tiếng Việt-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=hi"><img src="https://img.shields.io/badge/हिंदी-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=fa"><img src="https://img.shields.io/badge/فارسی-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=id"><img src="https://img.shields.io/badge/Bahasa Indonesia-white" alt="version"></a></div>
    </div>

    <div class="main-container">
        <div class="markdown-body" id="content"><h1>AgenticSeek: جایگزین خصوصی و محلی Manus</h1>
<p align="center">
<img align="center" src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/agentic_seek_logo.png" width="300" height="300" alt="Agentic Seek Logo">
</p><p>

</p><p>انگلیسی | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_CHS.md">中文</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_CHT.md">繁體中文</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_FR.md">Français</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_JP.md">日本語</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_PTBR.md">Português (Brasil)</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_ES.md">Español</a></p>
<p><em>یک <strong>جایگزین ۱۰۰٪ محلی برای Manus AI</strong>، این دستیار هوشمند مبتنی بر صدا، به طور مستقل وب را مرور می‌کند، کد می‌نویسد و وظایف را برنامه‌ریزی می‌کند در حالی که همه داده‌ها را روی دستگاه شما نگه می‌دارد. این ابزار برای مدل‌های استدلال محلی طراحی شده و کاملاً روی سخت‌افزار شما اجرا می‌شود تا حریم خصوصی کامل و وابستگی صفر به فضای ابری را تضمین کند.</em></p>
<p><a href="https://fosowl.github.io/agenticSeek.html"><img src="https://img.shields.io/static/v1?label=Website&amp;message=AgenticSeek&amp;color=blue&amp;style=flat-square" alt="Visit AgenticSeek"></a> <img src="https://img.shields.io/badge/license-GPL--3.0-green" alt="License"> <a href="https://discord.gg/8hGDaME3TC"><img src="https://img.shields.io/badge/Discord-Join%20Us-7289DA?logo=discord&amp;logoColor=white" alt="Discord"></a> <a href="https://x.com/Martin993886460"><img src="https://img.shields.io/twitter/url/https/twitter.com/fosowl.svg?style=social&amp;label=Update%20%40Fosowl" alt="Twitter"></a> <a href="https://github.com/Fosowl/agenticSeek/stargazers"><img src="https://img.shields.io/github/stars/Fosowl/agenticSeek?style=social" alt="GitHub stars"></a></p>
<h3>چرا AgenticSeek ؟</h3>
<ul>
<li><p>🔒 کاملاً محلی و خصوصی - همه چیز روی دستگاه شما اجرا می‌شود — بدون ابر، بدون به‌اشتراک‌گذاری داده. فایل‌ها، گفتگوها و جستجوهای شما خصوصی باقی می‌مانند.</p>
</li>
<li><p>🌐 مرور هوشمند وب - AgenticSeek می‌تواند به طور خودکار اینترنت را مرور کند — جستجو، مطالعه، استخراج اطلاعات، پرکردن فرم‌های وب — همه بدون دخالت دست.</p>
</li>
<li><p>💻 دستیار برنامه‌نویسی خودمختار - به کد نیاز دارید؟ می‌تواند برنامه‌ها را در پایتون، C، Go، جاوا و بیشتر بنویسد، رفع اشکال کند و اجرا نماید — بدون نیاز به نظارت.</p>
</li>
<li><p>🧠 انتخاب هوشمند عامل - شما درخواست می‌کنید، این ابزار بهترین عامل را برای انجام کار به طور خودکار انتخاب می‌کند. مانند داشتن تیمی از متخصصان آماده کمک.</p>
</li>
<li><p>📋 برنامه‌ریزی و اجرای وظایف پیچیده - از برنامه‌ریزی سفر تا پروژه‌های پیچیده — می‌تواند وظایف بزرگ را به مراحل تقسیم کند و با استفاده از چندین عامل هوش مصنوعی کار را انجام دهد.</p>
</li>
<li><p>🎙️ فعال‌سازی صوتی - صدای تمیز، سریع و آینده‌نگر و تبدیل گفتار به متن به شما اجازه می‌دهد مثل یک هوش مصنوعی شخصی علمی-تخیلی با آن صحبت کنید. (در حال توسعه)</p>
</li>
</ul>
<h3><strong>دمو</strong></h3>
<blockquote>
<p><em>آیا می‌توانی پروژه agenticSeek را جستجو کنی، مهارت‌های مورد نیاز را بیاموزی، سپس فایل CV_candidates.zip را باز کنی و بگویی کدام‌یک بهترین تطابق را با پروژه دارد؟</em></p>
</blockquote>
<p><a href="https://github.com/user-attachments/assets/b8ca60e9-7b3b-4533-840e-08f9ac426316">https://github.com/user-attachments/assets/b8ca60e9-7b3b-4533-840e-08f9ac426316</a></p>
<p>توجه: این دمو، شامل تمام فایل‌های ظاهر شده (مثلاً: CV_candidates.zip)، کاملاً ساختگی است. ما یک شرکت نیستیم؛ به دنبال مشارکت‌کنندگان متن‌باز هستیم، نه داوطلبان استخدام.</p>
<blockquote>
<p>🛠⚠️️ <strong>پروژه فعال و در حال توسعه</strong></p>
</blockquote>
<blockquote>
<p>🙏 این پروژه به عنوان یک پروژه جانبی آغاز شد و هیچ نقشه راه یا بودجه‌ای ندارد. فراتر از انتظار من رشد کرده و به GitHub Trending رسیده است. کمک‌ها، بازخوردها و شکیبایی شما بسیار ارزشمند است.</p>
</blockquote>
<h2>پیش‌نیازها</h2>
<p>قبل از شروع، مطمئن شوید نرم‌افزارهای زیر را نصب کرده‌اید:</p>
<ul>
<li><strong>Git:</strong> برای کلون کردن مخزن. <a href="https://git-scm.com/downloads">دانلود Git</a></li>
<li><strong>Python 3.10.x:</strong> اکیداً توصیه می‌شود از نسخه 3.10.x پایتون استفاده کنید. استفاده از نسخه‌های دیگر ممکن است منجر به خطاهای وابستگی شود. <a href="https://www.python.org/downloads/release/python-3100/">دانلود Python 3.10</a> (یک نسخه 3.10.x را انتخاب کنید).</li>
<li><strong>Docker Engine و Docker Compose:</strong> برای اجرای سرویس‌های بسته‌بندی‌شده مانند SearxNG.<ul>
<li>نصب Docker Desktop (که شامل Docker Compose V2 است): <a href="https://docs.docker.com/desktop/install/windows-install/">ویندوز</a> | <a href="https://docs.docker.com/desktop/install/mac-install/">مک</a> | <a href="https://docs.docker.com/desktop/install/linux-install/">لینوکس</a></li>
<li>یا به صورت جداگانه Docker Engine و Docker Compose را روی لینوکس نصب کنید: <a href="https://docs.docker.com/engine/install/">Docker Engine</a> | <a href="https://docs.docker.com/compose/install/">Docker Compose</a> (اطمینان حاصل کنید Compose V2 را نصب می‌کنید، مثلاً: <code>sudo apt-get install docker-compose-plugin</code>).</li>
</ul>
</li>
</ul>
<h3>1. <strong>کلون کردن مخزن و راه‌اندازی</strong></h3>
<pre><code class="language-sh hljs language-bash">git <span class="hljs-built_in">clone</span> https://github.com/Fosowl/agenticSeek.git
<span class="hljs-built_in">cd</span> agenticSeek
<span class="hljs-built_in">mv</span> .env.example .<span class="hljs-built_in">env</span>
</code></pre>
<h3>2. تغییر محتوای فایل .env</h3>
<pre><code class="language-sh hljs language-bash">SEARXNG_BASE_URL=<span class="hljs-string">"http://127.0.0.1:8080"</span>
REDIS_BASE_URL=<span class="hljs-string">"redis://redis:6379/0"</span>
WORK_DIR=<span class="hljs-string">"/Users/mlg/Documents/workspace_for_ai"</span>
OLLAMA_PORT=<span class="hljs-string">"11434"</span>
LM_STUDIO_PORT=<span class="hljs-string">"1234"</span>
CUSTOM_ADDITIONAL_LLM_PORT=<span class="hljs-string">"11435"</span>
OPENAI_API_KEY=<span class="hljs-string">'optional'</span>
DEEPSEEK_API_KEY=<span class="hljs-string">'optional'</span>
OPENROUTER_API_KEY=<span class="hljs-string">'optional'</span>
TOGETHER_API_KEY=<span class="hljs-string">'optional'</span>
GOOGLE_API_KEY=<span class="hljs-string">'optional'</span>
ANTHROPIC_API_KEY=<span class="hljs-string">'optional'</span>
</code></pre>
<p>فایل <code>.env</code> را با مقادیر دلخواه خود به‌روزرسانی کنید:</p>
<ul>
<li><strong>SEARXNG_BASE_URL</strong>: بدون تغییر باقی بماند</li>
<li><strong>REDIS_BASE_URL</strong>: بدون تغییر باقی بماند</li>
<li><strong>WORK_DIR</strong>: مسیر پوشه کاری شما در دستگاه محلی. AgenticSeek می‌تواند به این فایل‌ها دسترسی داشته باشد و با آن‌ها تعامل کند.</li>
<li><strong>OLLAMA_PORT</strong>: شماره پورت سرویس Ollama.</li>
<li><strong>LM_STUDIO_PORT</strong>: شماره پورت سرویس LM Studio.</li>
<li><strong>CUSTOM_ADDITIONAL_LLM_PORT</strong>: پورت سرویس LLM سفارشی اضافی.</li>
</ul>
<p><strong>کلیدهای API کاملاً اختیاری هستند برای کاربرانی که انتخاب می‌کنند LLM را به صورت محلی اجرا کنند. این هدف اصلی این پروژه است. اگر سخت‌افزار کافی دارید، خالی بگذارید</strong></p>
<h3>3. <strong>راه‌اندازی Docker</strong></h3>
<p>اطمینان حاصل کنید Docker روی سیستم شما نصب و در حال اجرا است. می‌توانید Docker را با دستورات زیر اجرا کنید:</p>
<ul>
<li><p><strong>در لینوکس/مک:</strong><br>  ترمینال را باز کنید و اجرا کنید:</p>
<pre><code class="language-sh hljs language-bash">sudo systemctl start docker
</code></pre>
<p>  یا Docker Desktop را از منوی برنامه‌ها اجرا کنید (اگر نصب شده است).</p>
</li>
<li><p><strong>در ویندوز:</strong><br>  Docker Desktop را از منوی Start اجرا کنید.</p>
</li>
</ul>
<p>برای اطمینان از اجرای Docker، دستور زیر را وارد کنید:</p>
<pre><code class="language-sh hljs language-bash">docker info
</code></pre>
<p>اگر اطلاعاتی درباره نصب Docker مشاهده کردید، یعنی به درستی اجرا می‌شود.</p>
<p>جدول <a href="#list-of-local-providers">ارائه‌دهندگان محلی</a> را در پایین برای خلاصه مشاهده کنید.</p>
<p>گام بعدی: <a href="#start-services-and-run">اجرای AgenticSeek به صورت محلی</a></p>
<p><em>در صورت بروز مشکل به بخش <a href="#troubleshooting">عیب‌یابی</a> مراجعه کنید.</em><br><em>اگر سخت‌افزار شما قادر به اجرای LLM به صورت محلی نیست، به <a href="#setup-to-run-with-an-api">راه‌اندازی برای اجرا با API</a> مراجعه کنید.</em><br><em>برای توضیحات دقیق‌تر فایل <code>config.ini</code> به بخش <a href="#config">پیکربندی</a> مراجعه کنید.</em></p>
<hr>
<h2>راه‌اندازی برای اجرای LLM به صورت محلی روی دستگاه شما</h2>
<p><strong>نیازمندی‌های سخت‌افزاری:</strong></p>
<p>برای اجرای LLMها به صورت محلی، به سخت‌افزار کافی نیاز دارید. حداقل، یک GPU که قادر به اجرای Magistral، Qwen یا Deepseek 14B باشد لازم است. برای توصیه‌های دقیق مدل/کارایی به بخش FAQ مراجعه کنید.</p>
<p><strong>راه‌اندازی ارائه‌دهنده محلی</strong>  </p>
<p>ارائه‌دهنده محلی خود را راه‌اندازی کنید، مثلاً با ollama:</p>
<pre><code class="language-sh hljs language-bash">ollama serve
</code></pre>
<p>در ادامه فهرست ارائه‌دهندگان محلی پشتیبانی‌شده آمده است.</p>
<p><strong>به‌روزرسانی config.ini</strong></p>
<p>فایل config.ini را تغییر دهید تا provider_name را به یک ارائه‌دهنده پشتیبانی‌شده و provider_model را به یک LLM سازگار با ارائه‌دهنده خود تنظیم کنید. مدل‌های استدلال مانند <em>Magistral</em> یا <em>Deepseek</em> توصیه می‌شود.</p>
<p>در FAQ انتهای README نیازمندی‌های سخت‌افزاری آورده شده است.</p>
<pre><code class="language-sh hljs language-bash">[MAIN]
is_local = True <span class="hljs-comment"># اگر به صورت محلی یا با ارائه‌دهنده راه دور اجرا می‌کنید.</span>
provider_name = ollama <span class="hljs-comment"># یا lm-studio، openai، و غیره.</span>
provider_model = deepseek-r1:14b <span class="hljs-comment"># مدلی که مناسب سخت‌افزار شماست را انتخاب کنید</span>
provider_server_address = 127.0.0.1:11434
agent_name = Jarvis <span class="hljs-comment"># نام هوش مصنوعی شما</span>
recover_last_session = True <span class="hljs-comment"># بازیابی جلسه قبلی</span>
save_session = True <span class="hljs-comment"># ذخیره جلسه فعلی</span>
speak = False <span class="hljs-comment"># تبدیل متن به گفتار</span>
listen = False <span class="hljs-comment"># تبدیل گفتار به متن، فقط CLI، آزمایشی</span>
jarvis_personality = False <span class="hljs-comment"># استفاده از شخصیت مشابه "Jarvis" (آزمایشی)</span>
languages = en zh <span class="hljs-comment"># لیست زبان‌ها، تبدیل متن به گفتار به اولین زبان لیست پیش‌فرض می‌شود</span>
[BROWSER]
headless_browser = True <span class="hljs-comment"># بدون تغییر بگذارید مگر اینکه از CLI روی میزبان استفاده می‌کنید.</span>
stealth_mode = True <span class="hljs-comment"># استفاده از selenium مخفی برای کاهش تشخیص مرورگر</span>
</code></pre>
<p><strong>هشدار</strong>:</p>
<ul>
<li><p>فرمت فایل <code>config.ini</code> از کامنت پشتیبانی نمی‌کند.<br>هرگز پیکربندی نمونه را مستقیماً کپی و جایگذاری نکنید، زیرا وجود کامنت باعث خطا می‌شود. به جای آن، فایل config.ini را به صورت دستی با تنظیمات دلخواه و بدون کامنت ویرایش کنید.</p>
</li>
<li><p>اگر از LM-studio برای اجرای LLM استفاده می‌کنید، provider_name را روی <code>openai</code> قرار ندهید. باید روی <code>lm-studio</code> باشد.</p>
</li>
<li><p>برخی ارائه‌دهندگان (مثلاً lm-studio) نیاز دارند که <code>http://</code> قبل از IP باشد. مثلاً <code>http://127.0.0.1:1234</code></p>
</li>
</ul>
<p><strong>فهرست ارائه‌دهندگان محلی</strong></p>
<table>
<thead>
<tr>
<th>ارائه‌دهنده</th>
<th>محلی؟</th>
<th>توضیحات</th>
</tr>
</thead>
<tbody><tr>
<td>ollama</td>
<td>بله</td>
<td>اجرای LLMها به راحتی با ollama به عنوان ارائه‌دهنده LLM</td>
</tr>
<tr>
<td>lm-studio</td>
<td>بله</td>
<td>اجرای LLM به صورت محلی با LM studio (provider_name را روی <code>lm-studio</code> قرار دهید)</td>
</tr>
<tr>
<td>openai</td>
<td>بله</td>
<td>استفاده از API سازگار با openai (مثلاً: llama.cpp server)</td>
</tr>
</tbody></table>
<p>گام بعدی: <a href="#Start-services-and-Run">راه‌اندازی سرویس‌ها و اجرای AgenticSeek</a>  </p>
<p><em>در صورت بروز مشکل به بخش <a href="#troubleshooting">عیب‌یابی</a> مراجعه کنید.</em><br><em>اگر سخت‌افزار شما قادر به اجرای LLM به صورت محلی نیست، به <a href="#setup-to-run-with-an-api">راه‌اندازی برای اجرا با API</a> مراجعه کنید.</em><br><em>برای توضیحات دقیق‌تر فایل <code>config.ini</code> به بخش <a href="#config">پیکربندی</a> مراجعه کنید.</em></p>
<h2>راه‌اندازی برای اجرا با API</h2>
<p>این روش از ارائه‌دهندگان LLM مبتنی بر ابر خارجی استفاده می‌کند. به کلید API از سرویس انتخابی خود نیاز دارید.</p>
<p><strong>۱. انتخاب یک ارائه‌دهنده API و دریافت کلید API:</strong></p>
<p>به <a href="#list-of-api-providers">فهرست ارائه‌دهندگان API</a> مراجعه کنید. به وب‌سایت آن‌ها بروید، ثبت‌نام کنید و کلید API دریافت نمایید.</p>
<p><strong>۲. تنظیم کلید API به عنوان متغیر محیطی:</strong></p>
<ul>
<li><strong>لینوکس/مک:</strong><br>ترمینال خود را باز کنید و از دستور <code>export</code> استفاده کنید. بهتر است این دستور را به فایل پروفایل شل خود (مثلاً <code>~/.bashrc</code>، <code>~/.zshrc</code>) برای پایداری اضافه کنید.<pre><code class="language-sh hljs language-bash"><span class="hljs-built_in">export</span> PROVIDER_API_KEY=<span class="hljs-string">"your_api_key_here"</span> 
<span class="hljs-comment"># PROVIDER_API_KEY را با نام متغیر خاص جایگزین کنید، مثلاً OPENAI_API_KEY، GOOGLE_API_KEY</span>
</code></pre>
نمونه برای TogetherAI:<pre><code class="language-sh hljs language-bash"><span class="hljs-built_in">export</span> TOGETHER_API_KEY=<span class="hljs-string">"xxxxxxxxxxxxxxxxxxxxxx"</span>
</code></pre>
</li>
<li><strong>ویندوز:</strong></li>
<li><strong>Command Prompt (موقت برای جلسه فعلی):</strong><pre><code class="language-cmd">set PROVIDER_API_KEY=your_api_key_here
</code></pre>
</li>
<li><strong>PowerShell (موقت برای جلسه فعلی):</strong><pre><code class="language-powershell">$env:PROVIDER_API_KEY="your_api_key_here"
</code></pre>
</li>
<li><strong>دائمی:</strong> در نوار جستجوی ویندوز عبارت "environment variables" را جستجو کنید، روی "Edit the system environment variables" کلیک کنید، سپس دکمه "Environment Variables..." را بزنید. یک متغیر کاربری جدید با نام مناسب (مثلاً <code>OPENAI_API_KEY</code>) و مقدار کلید خود اضافه کنید.</li>
</ul>
<p><em>(برای جزئیات بیشتر به پرسش متداول: <a href="#how-do-i-set-api-keys">چگونه کلید API را تنظیم کنم؟</a> مراجعه کنید).</em></p>
<p><strong>3. به‌روزرسانی <code>config.ini</code>:</strong></p>
<pre><code class="language-ini hljs"><span class="hljs-section">[MAIN]</span>
<span class="hljs-attr">is_local</span> = <span class="hljs-literal">False</span>
<span class="hljs-attr">provider_name</span> = openai <span class="hljs-comment"># یا google، deepseek، togetherAI، huggingface</span>
<span class="hljs-attr">provider_model</span> = gpt-<span class="hljs-number">3.5</span>-turbo <span class="hljs-comment"># یا gemini-1.5-flash، deepseek-chat، mistralai/Mixtral-8x7B-Instruct-v0.1 و غیره</span>
provider_server_address = <span class="hljs-comment"># معمولاً زمانی که is_local = False باشد برای اکثر APIها نادیده گرفته می‌شود یا می‌توانید خالی بگذارید</span>
<span class="hljs-comment"># ... سایر تنظیمات ...</span>
</code></pre>
<p><em>هشدار:</em> اطمینان حاصل کنید که مقادیر <code>config.ini</code> فاقد فاصله اضافی در انتها باشند.</p>
<p><strong>لیست ارائه‌دهندگان API</strong></p>
<table>
<thead>
<tr>
<th>ارائه‌دهنده</th>
<th><code>provider_name</code></th>
<th>محلی؟</th>
<th>توضیحات</th>
<th>لینک کلید API (مثال)</th>
</tr>
</thead>
<tbody><tr>
<td>OpenAI</td>
<td><code>openai</code></td>
<td>خیر</td>
<td>استفاده از مدل‌های ChatGPT از طریق API اوپن‌اِی‌آی.</td>
<td><a href="https://platform.openai.com/signup">platform.openai.com/signup</a></td>
</tr>
<tr>
<td>Google Gemini</td>
<td><code>google</code></td>
<td>خیر</td>
<td>استفاده از مدل‌های Gemini گوگل از طریق Google AI Studio.</td>
<td><a href="https://aistudio.google.com/keys">aistudio.google.com/keys</a></td>
</tr>
<tr>
<td>Deepseek</td>
<td><code>deepseek</code></td>
<td>خیر</td>
<td>استفاده از مدل‌های Deepseek از طریق API آن‌ها.</td>
<td><a href="https://platform.deepseek.com">platform.deepseek.com</a></td>
</tr>
<tr>
<td>Hugging Face</td>
<td><code>huggingface</code></td>
<td>خیر</td>
<td>استفاده از مدل‌های Hugging Face Inference API.</td>
<td><a href="https://huggingface.co/settings/tokens">huggingface.co/settings/tokens</a></td>
</tr>
<tr>
<td>TogetherAI</td>
<td><code>togetherAI</code></td>
<td>خیر</td>
<td>استفاده از مدل‌های متن‌باز مختلف از طریق TogetherAI API.</td>
<td><a href="https://api.together.ai/settings/api-keys">api.together.ai/settings/api-keys</a></td>
</tr>
</tbody></table>
<p><em>توجه:</em></p>
<ul>
<li>توصیه می‌شود برای مرور وب پیچیده و برنامه‌ریزی وظایف از مدل‌هایی مانند Deepseek به جای <code>gpt-4o</code> یا سایر مدل‌های OpenAI استفاده کنید، چراکه بهینه‌سازی‌های فعلی prompt برای این مدل‌ها انجام شده است.</li>
<li>وظایف کدنویسی/bash ممکن است با Gemini به مشکل بخورند، زیرا ممکن است فرمت‌بندی prompt که برای Deepseek بهینه شده را دقیق رعایت نکند.</li>
<li>معمولاً زمانی که <code>is_local = False</code> باشد، مقدار <code>provider_server_address</code> در <code>config.ini</code> استفاده نمی‌شود زیرا endpoint مربوطه در کتابخانه ارائه‌دهنده API به صورت hardcode شده است.</li>
</ul>
<p>گام بعدی: <a href="#Start-services-and-Run">شروع سرویس‌ها و اجرای AgenticSeek</a></p>
<p><em>در صورت بروز مشکل به بخش <strong>Known issues</strong> مراجعه کنید.</em></p>
<p><em>برای توضیح کامل فایل تنظیمات به بخش <strong>Config</strong> مراجعه کنید.</em></p>
<hr>
<h2>شروع سرویس‌ها و اجرا</h2>
<p>به طور پیش‌فرض AgenticSeek به طور کامل در داکر اجرا می‌شود.</p>
<p>سرویس‌های مورد نیاز را اجرا کنید. این کار تمام سرویس‌های موجود در docker-compose.yml را راه‌اندازی می‌کند، از جمله:<br>    - searxng<br>    - redis (مورد نیاز توسط searxng)<br>    - frontend<br>    - backend (در صورت استفاده از <code>full</code>)</p>
<pre><code class="language-sh hljs language-bash">./start_services.sh full <span class="hljs-comment"># مک‌اواس</span>
start ./start_services.cmd full <span class="hljs-comment"># ویندوز</span>
</code></pre>
<p><strong>هشدار:</strong> این مرحله تمام ایمیج‌های داکر را دانلود و بارگذاری می‌کند که ممکن است تا ۳۰ دقیقه طول بکشد. پس از راه‌اندازی سرویس‌ها، لطفاً تا اجرای کامل سرویس backend (باید در لاگ عبارت <strong>backend: "GET /health HTTP/1.1" 200 OK</strong> را مشاهده کنید) منتظر بمانید و سپس پیام ارسال کنید. اجرای اولیه سرویس‌های backend ممکن است تا ۵ دقیقه طول بکشد.</p>
<p>به آدرس <code>http://localhost:3000/</code> بروید و باید رابط وب را مشاهده کنید.</p>
<p><em>عیب‌یابی شروع سرویس:</em> اگر این اسکریپت‌ها با خطا مواجه شدند، مطمئن شوید Docker Engine اجرا می‌شود و Docker Compose (نسخه ۲، <code>docker compose</code>) به درستی نصب شده است. خروجی ترمینال را برای پیام‌های خطا بررسی کنید. به <a href="#faq-troubleshooting">پرسش متداول: در اجرای AgenticSeek یا اسکریپت‌های آن خطا دریافت می‌کنم.</a> مراجعه کنید.</p>
<p><strong>اختیاری:</strong> اجرا بر روی میزبان (حالت CLI):</p>
<p>برای اجرا با رابط خط فرمان باید پکیج را روی میزبان نصب کنید:</p>
<pre><code class="language-sh hljs language-bash">./install.sh
./install.bat <span class="hljs-comment"># ویندوز</span>
</code></pre>
<p>سرویس‌ها را راه‌اندازی کنید:</p>
<pre><code class="language-sh hljs language-bash">./start_services.sh <span class="hljs-comment"># مک‌اواس</span>
start ./start_services.cmd <span class="hljs-comment"># ویندوز</span>
</code></pre>
<p>استفاده از CLI: <code>python3 cli.py</code></p>
<hr>
<h2>استفاده</h2>
<p>مطمئن شوید که سرویس‌ها با اجرای <code>./start_services.sh full</code> فعال هستند و برای رابط وب به <code>localhost:3000</code> بروید.</p>
<p>همچنین می‌توانید با تنظیم <code>listen = True</code> در فایل config از قابلیت تبدیل گفتار به متن استفاده کنید (فقط در حالت CLI).</p>
<p>برای خروج، کافیست بگویید/بنویسید <code>goodbye</code>.</p>
<p>در اینجا چند نمونه استفاده آورده شده است:</p>
<blockquote>
<p><em>یک بازی مار با پایتون بساز!</em></p>
</blockquote>
<blockquote>
<p><em>در وب به دنبال بهترین کافه‌ها در رن، فرانسه بگرد و لیستی از سه مورد با آدرس‌شان را در rennes_cafes.txt ذخیره کن.</em></p>
</blockquote>
<blockquote>
<p><em>یک برنامه Go بنویس که فاکتوریل یک عدد را محاسبه کند، آن را به نام factorial.go در workspace خود ذخیره کن</em></p>
</blockquote>
<blockquote>
<p><em>در پوشه summer_pictures خود تمام فایل‌های JPG را پیدا کن، آن‌ها را با تاریخ امروز تغییر نام بده و لیست فایل‌های تغییر نام یافته را در photos_list.txt ذخیره کن</em></p>
</blockquote>
<blockquote>
<p><em>در اینترنت به دنبال فیلم‌های علمی‌تخیلی محبوب سال ۲۰۲۴ بگرد و سه تای آن‌ها را برای تماشای امشب انتخاب کن. لیست را در movie_night.txt ذخیره کن.</em></p>
</blockquote>
<blockquote>
<p><em>در وب به دنبال آخرین اخبار هوش مصنوعی سال ۲۰۲۵ بگرد، سه مورد را انتخاب کن و یک اسکریپت پایتون برای جمع‌آوری عنوان و خلاصه‌شان بنویس. اسکریپت را به نام news_scraper.py و خلاصه‌ها را در ai_news.txt در /home/projects ذخیره کن</em></p>
</blockquote>
<blockquote>
<p><em>جمعه، در وب به دنبال یک API رایگان قیمت سهام بگرد، با ایمیل <a href="mailto:supersuper7434567@gmail.com">supersuper7434567@gmail.com</a> ثبت‌نام کن، سپس یک اسکریپت پایتون برای دریافت قیمت روزانه تسلا با استفاده از API بنویس و نتایج را در stock_prices.csv ذخیره کن</em></p>
</blockquote>
<p><em>توجه داشته باشید که قابلیت پرکردن فرم هنوز آزمایشی است و ممکن است با خطا مواجه شود.</em></p>
<p>پس از وارد کردن پرسش، AgenticSeek بهترین عامل را برای انجام وظیفه اختصاص می‌دهد.</p>
<p>از آنجا که این نسخه یک نمونه اولیه است، سیستم مسیریابی عامل ممکن است همیشه عامل مناسب را با توجه به پرسش شما انتخاب نکند.</p>
<p>بنابراین باید کاملاً صریح بیان کنید که چه می‌خواهید و AI چگونه باید پیش برود؛ مثلاً اگر می‌خواهید جستجوی وب انجام شود، نگویید:</p>
<p><code>Do you know some good countries for solo-travel?</code></p>
<p>بلکه بپرسید:</p>
<p><code>Do a web search and find out which are the best country for solo-travel</code></p>
<hr>
<h2><strong>راه‌اندازی اجرای LLM روی سرور شخصی</strong></h2>
<p>اگر یک کامپیوتر قوی یا سروری در اختیار دارید اما می‌خواهید از لپ‌تاپ خود به آن دسترسی داشته باشید، می‌توانید LLM را روی یک سرور راه دور با استفاده از llm server سفارشی ما اجرا کنید.</p>
<p>روی "سرور" خود که قرار است مدل هوش مصنوعی روی آن اجرا شود، آدرس IP را به دست آورید</p>
<pre><code class="language-sh hljs language-bash">ip a | grep <span class="hljs-string">"inet "</span> | grep -v 127.0.0.1 | awk <span class="hljs-string">'{print $2}'</span> | <span class="hljs-built_in">cut</span> -d/ -f1 <span class="hljs-comment"># آی‌پی محلی</span>
curl https://ipinfo.io/ip <span class="hljs-comment"># آی‌پی عمومی</span>
</code></pre>
<p>توجه: در ویندوز یا macOS از ipconfig یا ifconfig برای پیدا کردن آدرس IP استفاده کنید.</p>
<p>مخزن را کلون کرده و وارد پوشه <code>server/</code> شوید.</p>
<pre><code class="language-sh hljs language-bash">git <span class="hljs-built_in">clone</span> --depth 1 https://github.com/Fosowl/agenticSeek.git
<span class="hljs-built_in">cd</span> agenticSeek/llm_server/
</code></pre>
<p>پیش‌نیازهای سرور را نصب کنید:</p>
<pre><code class="language-sh hljs language-bash">pip3 install -r requirements.txt
</code></pre>
<p>اسکریپت سرور را اجرا کنید.</p>
<pre><code class="language-sh hljs language-bash">python3 app.py --provider ollama --port 3333
</code></pre>
<p>می‌توانید از بین <code>ollama</code> و <code>llamacpp</code> به عنوان سرویس LLM انتخاب کنید.</p>
<p>حالا روی کامپیوتر شخصی خود:</p>
<p>فایل <code>config.ini</code> را ویرایش کرده و مقدار <code>provider_name</code> را روی <code>server</code> و <code>provider_model</code> را روی <code>deepseek-r1:xxb</code> تنظیم کنید.<br>مقدار <code>provider_server_address</code> را به آدرس آی‌پی دستگاهی که مدل روی آن اجرا می‌شود قرار دهید.</p>
<pre><code class="language-sh hljs language-bash">[MAIN]
is_local = False
provider_name = server
provider_model = deepseek-r1:70b
provider_server_address = x.x.x.x:3333
</code></pre>
<p>گام بعدی: <a href="#Start-services-and-Run">شروع سرویس‌ها و اجرای AgenticSeek</a>  </p>
<hr>
<h2>تبدیل گفتار به متن</h2>
<p>هشدار: تبدیل گفتار به متن در حال حاضر فقط در حالت CLI فعال است.</p>
<p>لطفاً توجه داشته باشید که فعلاً تبدیل گفتار به متن تنها به زبان انگلیسی کار می‌کند.</p>
<p>قابلیت تبدیل گفتار به متن به طور پیش‌فرض غیرفعال است. برای فعال‌سازی، گزینه listen را در فایل config.ini به True تغییر دهید:</p>
<pre><code class="hljs language-ini"><span class="hljs-attr">listen</span> = <span class="hljs-literal">True</span>
</code></pre>
<p>پس از فعال‌سازی، ویژگی تبدیل گفتار به متن منتظر یک کلمه کلیدی (نام عامل) می‌ماند تا پیش از پردازش ورودی شما شروع به کار کند. می‌توانید نام عامل را با به‌روزرسانی مقدار <code>agent_name</code> در فایل <em>config.ini</em> شخصی‌سازی کنید:</p>
<pre><code class="hljs language-ini"><span class="hljs-attr">agent_name</span> = Friday
</code></pre>
<p>برای شناسایی بهینه، توصیه می‌کنیم از یک نام رایج انگلیسی مانند "John" یا "Emma" به عنوان نام ایجنت استفاده کنید.</p>
<p>پس از اینکه رونوشت شروع به ظاهر شدن کرد، نام ایجنت را با صدای بلند بگویید تا بیدار شود (مثلاً "Friday").</p>
<p>سؤال خود را واضح بیان کنید.</p>
<p>در پایان درخواست خود، یک عبارت تأییدی بگویید تا سیستم اقدام کند. نمونه‌هایی از عبارات تأییدی:</p>
<pre><code class="hljs language-bash"><span class="hljs-string">"انجام بده"</span>، <span class="hljs-string">"ادامه بده"</span>، <span class="hljs-string">"اجرا کن"</span>، <span class="hljs-string">"شروع کن"</span>، <span class="hljs-string">"ممنون"</span>، <span class="hljs-string">"لطفاً"</span>، <span class="hljs-string">"باشه؟"</span>، <span class="hljs-string">"ادامه"</span>، <span class="hljs-string">"برو"</span>، <span class="hljs-string">"این کار رو انجام بده"</span>، <span class="hljs-string">"متوجه شدی؟"</span>
</code></pre>
<h2>تنظیمات (Config)</h2>
<p>نمونه تنظیمات:</p>
<pre><code class="hljs language-ini"><span class="hljs-section">[MAIN]</span>
<span class="hljs-attr">is_local</span> = <span class="hljs-literal">True</span>
<span class="hljs-attr">provider_name</span> = ollama
<span class="hljs-attr">provider_model</span> = deepseek-r1:<span class="hljs-number">32</span>b
<span class="hljs-attr">provider_server_address</span> = http://<span class="hljs-number">127.0</span>.<span class="hljs-number">0.1</span>:<span class="hljs-number">11434</span> <span class="hljs-comment"># نمونه برای Ollama؛ برای LM-Studio از http://127.0.0.1:1234 استفاده کنید</span>
<span class="hljs-attr">agent_name</span> = Friday
<span class="hljs-attr">recover_last_session</span> = <span class="hljs-literal">False</span>
<span class="hljs-attr">save_session</span> = <span class="hljs-literal">False</span>
<span class="hljs-attr">speak</span> = <span class="hljs-literal">False</span>
<span class="hljs-attr">listen</span> = <span class="hljs-literal">False</span>

<span class="hljs-attr">jarvis_personality</span> = <span class="hljs-literal">False</span>
<span class="hljs-attr">languages</span> = en zh <span class="hljs-comment"># لیست زبان‌ها برای تبدیل متن به گفتار و مسیریابی احتمالی.</span>
<span class="hljs-section">[BROWSER]</span>
<span class="hljs-attr">headless_browser</span> = <span class="hljs-literal">False</span>
<span class="hljs-attr">stealth_mode</span> = <span class="hljs-literal">False</span>
</code></pre>
<p><strong>توضیح تنظیمات <code>config.ini</code>:</strong></p>
<ul>
<li><strong>بخش <code>[MAIN]</code>:</strong><ul>
<li><code>is_local</code>: اگر از ارائه‌دهنده LLM محلی (Ollama، LM-Studio، سرور OpenAI سازگار محلی) یا گزینه سرور خودمیزبان استفاده می‌کنید مقدار <code>True</code> باشد. اگر از API مبتنی بر ابر (OpenAI، گوگل و غیره) استفاده می‌کنید مقدار <code>False</code> باشد.</li>
<li><code>provider_name</code>: مشخص‌کننده ارائه‌دهنده LLM.<ul>
<li>گزینه‌های محلی: <code>ollama</code>، <code>lm-studio</code>، <code>openai</code> (برای سرور OpenAI سازگار محلی)، <code>server</code> (برای سرور خودمیزبان).</li>
<li>گزینه‌های API: <code>openai</code>، <code>google</code>، <code>deepseek</code>، <code>huggingface</code>، <code>togetherAI</code>.</li>
</ul>
</li>
<li><code>provider_model</code>: نام یا شناسه مدل موردنظر برای ارائه‌دهنده انتخابی (مثلاً <code>deepseekcoder:6.7b</code> برای Ollama، <code>gpt-3.5-turbo</code> برای OpenAI API، <code>mistralai/Mixtral-8x7B-Instruct-v0.1</code> برای TogetherAI).</li>
<li><code>provider_server_address</code>: آدرس ارائه‌دهنده LLM شما.<ul>
<li>برای ارائه‌دهندگان محلی: مثلاً <code>http://127.0.0.1:11434</code> برای Ollama، <code>http://127.0.0.1:1234</code> برای LM-Studio.</li>
<li>برای نوع ارائه‌دهنده <code>server</code>: آدرس سرور LLM خودمیزبان شما (مثلاً <code>http://your_server_ip:3333</code>).</li>
<li>برای APIهای ابری (<code>is_local = False</code>): اغلب نادیده گرفته می‌شود یا می‌تواند خالی باشد، زیرا نقطه پایانی API معمولاً توسط کتابخانه کلاینت مدیریت می‌شود.</li>
</ul>
</li>
<li><code>agent_name</code>: نام دستیار هوشمند (مثلاً Friday). به‌عنوان کلمه کلیدی فعال‌سازی برای تبدیل گفتار به متن در صورت فعال بودن استفاده می‌شود.</li>
<li><code>recover_last_session</code>: اگر مقدار <code>True</code> باشد سعی در بازیابی وضعیت جلسه قبلی دارد؛ اگر <code>False</code> باشد یک جلسه جدید آغاز می‌کند.</li>
<li><code>save_session</code>: اگر مقدار <code>True</code> باشد وضعیت جلسه فعلی برای بازیابی احتمالی ذخیره می‌شود؛ در غیر اینصورت <code>False</code>.</li>
<li><code>speak</code>: اگر مقدار <code>True</code> باشد خروجی صوتی تبدیل متن به گفتار فعال می‌شود؛ در غیر اینصورت غیرفعال است.</li>
<li><code>listen</code>: اگر مقدار <code>True</code> باشد ورودی صوتی تبدیل گفتار به متن (فقط حالت CLI) فعال می‌شود؛ در غیر اینصورت غیرفعال.</li>
<li><code>work_dir</code>: <strong>مهم:</strong> مسیری که AgenticSeek فایل‌ها را از آن می‌خواند/می‌نویسد. <strong>اطمینان حاصل کنید که این مسیر معتبر و در دسترس باشد.</strong></li>
<li><code>jarvis_personality</code>: اگر مقدار <code>True</code> باشد از پرامپت سیستمی مشابه "Jarvis" استفاده می‌کند (آزمایشی)، اگر <code>False</code> باشد از پرامپت استاندارد بهره می‌گیرد.</li>
<li><code>languages</code>: لیست زبان‌ها به صورت جداشده با ویرگول (مثلاً <code>en, zh, fr</code>). برای انتخاب صدای TTS (پیش‌فرض اولین زبان) و کمک به مسیریاب LLM استفاده می‌شود. برای بازدهی بهتر مسیریاب، از انتخاب زبان‌های بسیار مشابه یا تعداد زیاد خودداری کنید.</li>
</ul>
</li>
<li><strong>بخش <code>[BROWSER]</code>:</strong><ul>
<li><code>headless_browser</code>: اگر مقدار <code>True</code> باشد مرورگر خودکار بدون نمایش پنجره اجرا می‌شود (برای رابط وب یا استفاده غیرتعاملی توصیه می‌شود). مقدار <code>False</code> باعث نمایش پنجره مرورگر می‌شود (برای حالت CLI یا اشکال‌زدایی مفید است).</li>
<li><code>stealth_mode</code>: اگر مقدار <code>True</code> باشد اقدامات لازم برای سخت‌تر شدن تشخیص اتوماسیون مرورگر فعال می‌شود. ممکن است نیاز به نصب دستی افزونه‌هایی مانند anticaptcha داشته باشد.</li>
</ul>
</li>
</ul>
<p>این بخش انواع ارائه‌دهندگان LLM پشتیبانی‌شده را خلاصه می‌کند. آن‌ها را در <code>config.ini</code> پیکربندی کنید.</p>
<p><strong>ارائه‌دهندگان محلی (اجرا روی سخت‌افزار خودتان):</strong></p>
<table>
<thead>
<tr>
<th>نام ارائه‌دهنده در <code>config.ini</code></th>
<th><code>is_local</code></th>
<th>توضیحات</th>
<th>بخش راه‌اندازی</th>
</tr>
</thead>
<tbody><tr>
<td><code>ollama</code></td>
<td><code>True</code></td>
<td>استفاده از Ollama برای سرویس‌دهی LLMهای محلی.</td>
<td><a href="#setup-for-running-llm-locally-on-your-machine">راه‌اندازی اجرای LLM به صورت محلی</a></td>
</tr>
<tr>
<td><code>lm-studio</code></td>
<td><code>True</code></td>
<td>استفاده از LM-Studio برای سرویس‌دهی LLMهای محلی.</td>
<td><a href="#setup-for-running-llm-locally-on-your-machine">راه‌اندازی اجرای LLM به صورت محلی</a></td>
</tr>
<tr>
<td><code>openai</code> (برای سرور محلی)</td>
<td><code>True</code></td>
<td>اتصال به سروری که API سازگار با OpenAI را ارائه می‌دهد (مثلاً llama.cpp).</td>
<td><a href="#setup-for-running-llm-locally-on-your-machine">راه‌اندازی اجرای LLM به صورت محلی</a></td>
</tr>
<tr>
<td><code>server</code></td>
<td><code>False</code></td>
<td>اتصال به سرور LLM خودمیزبان AgenticSeek که روی دستگاه دیگر اجرا می‌شود.</td>
<td><a href="#setup-to-run-the-llm-on-your-own-server">راه‌اندازی اجرای LLM روی سرور خودتان</a></td>
</tr>
</tbody></table>
<p><strong>ارائه‌دهندگان API (مبتنی بر ابر):</strong></p>
<table>
<thead>
<tr>
<th>نام ارائه‌دهنده در <code>config.ini</code></th>
<th><code>is_local</code></th>
<th>توضیحات</th>
<th>بخش راه‌اندازی</th>
</tr>
</thead>
<tbody><tr>
<td><code>openai</code></td>
<td><code>False</code></td>
<td>استفاده از API رسمی OpenAI (مثلاً GPT-3.5، GPT-4).</td>
<td><a href="#setup-to-run-with-an-api">راه‌اندازی با API</a></td>
</tr>
<tr>
<td><code>google</code></td>
<td><code>False</code></td>
<td>استفاده از مدل‌های Gemini گوگل از طریق API.</td>
<td><a href="#setup-to-run-with-an-api">راه‌اندازی با API</a></td>
</tr>
<tr>
<td><code>deepseek</code></td>
<td><code>False</code></td>
<td>استفاده از API رسمی Deepseek.</td>
<td><a href="#setup-to-run-with-an-api">راه‌اندازی با API</a></td>
</tr>
<tr>
<td><code>huggingface</code></td>
<td><code>False</code></td>
<td>استفاده از API استنتاج Hugging Face.</td>
<td><a href="#setup-to-run-with-an-api">راه‌اندازی با API</a></td>
</tr>
<tr>
<td><code>togetherAI</code></td>
<td><code>False</code></td>
<td>استفاده از API TogetherAI برای مدل‌های باز مختلف.</td>
<td><a href="#setup-to-run-with-an-api">راه‌اندازی با API</a></td>
</tr>
</tbody></table>
<hr>
<h2>عیب‌یابی</h2>
<p>اگر با مشکلی مواجه شدید، این بخش راهنمایی ارائه می‌دهد.</p>
<h1>مشکلات شناخته‌شده</h1>
<h2>مشکلات ChromeDriver</h2>
<p><strong>نمونه خطا:</strong><br><code>SessionNotCreatedException: Message: session not created: This version of ChromeDriver only supports Chrome version XXX</code></p>
<ul>
<li><strong>دلیل:</strong> نسخه نصب‌شده ChromeDriver با نسخه مرورگر Google Chrome شما ناسازگار است.</li>
<li><strong>راه‌حل:</strong><ol>
<li><strong>بررسی نسخه Chrome:</strong> مرورگر Google Chrome را باز کنید و به <code>تنظیمات &gt; درباره Chrome</code> بروید تا نسخه را بیابید (مثلاً "Version 120.0.6099.110").</li>
<li><strong>دانلود ChromeDriver هماهنگ:</strong><ul>
<li>برای نسخه‌های 115 و بالاتر: به <a href="https://googlechromelabs.github.io/chrome-for-testing/">Chrome for Testing (CfT) JSON Endpoints</a> بروید. کانال "stable" را پیدا کنید و ChromeDriver مناسب سیستم عامل و نسخه اصلی مرورگر خود را دانلود کنید.</li>
<li>برای نسخه‌های قدیمی‌تر (کمتر رایج): ممکن است آن‌ها را در صفحه <a href="https://chromedriver.chromium.org/downloads">ChromeDriver - WebDriver for Chrome</a> پیدا کنید.</li>
<li>تصویر زیر نمونه‌ای از صفحه CfT را نشان می‌دهد:<br><img src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/chromedriver_readme.png" alt="دانلود نسخه خاص Chromedriver از صفحه Chrome for Testing"></li>
</ul>
</li>
<li><strong>نصب ChromeDriver:</strong><ul>
<li>اطمینان حاصل کنید که فایل دانلودی <code>chromedriver</code> (یا <code>chromedriver.exe</code> در ویندوز) در مسیری قرار گیرد که در متغیر محیطی PATH سیستم شما باشد (مثلاً <code>/usr/local/bin</code> در لینوکس/مک، یا یک پوشه اسکریپت اختصاصی که به PATH ویندوز افزوده شده).</li>
<li>یا آن را در پوشه اصلی پروژه <code>agenticSeek</code> قرار دهید.</li>
<li>مطمئن شوید که فایل اجرایی است (مثلاً <code>chmod +x chromedriver</code> در لینوکس/مک).</li>
</ul>
</li>
<li>به بخش <a href="#chromedriver-installation">نصب ChromeDriver</a> در راهنمای نصب اصلی برای جزئیات بیشتر مراجعه کنید.</li>
</ol>
</li>
</ul>
<p>اگر این بخش کامل نیست یا با مشکل دیگری در ChromeDriver مواجه شدید، لطفاً در <a href="https://github.com/Fosowl/agenticSeek/issues">Issues گیت‌هاب</a> جستجو کنید یا مورد جدیدی ثبت نمایید.</p>
<p><code>Exception: Failed to initialize browser: Message: session not created: This version of ChromeDriver only supports Chrome version 113 Current browser version is 134.0.6998.89 with binary path</code></p>
<p>این خطا هنگامی رخ می‌دهد که نسخه مرورگر و chromedriver شما مطابقت نداشته باشد.</p>
<p>باید به آدرس زیر رفته و آخرین نسخه را دانلود کنید:</p>
<p><a href="https://developer.chrome.com/docs/chromedriver/downloads">https://developer.chrome.com/docs/chromedriver/downloads</a></p>
<p>اگر از Chrome نسخه 115 یا بالاتر استفاده می‌کنید به:</p>
<p><a href="https://googlechromelabs.github.io/chrome-for-testing/">https://googlechromelabs.github.io/chrome-for-testing/</a></p>
<p>رفته و نسخه chromedriver متناسب با سیستم عامل خود را دانلود کنید.</p>
<p><img src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/chromedriver_readme.png" alt="alt text"></p>
<p>اگر این بخش کامل نیست لطفاً یک issue ثبت کنید.</p>
<h2>مشکلات connection adapters</h2>
<pre><code class="hljs language-php"><span class="hljs-built_in">Exception</span>: Provider lm-studio failed: HTTP request failed: No connection adapters were found <span class="hljs-keyword">for</span> <span class="hljs-string">'127.0.0.1:1234/v1/chat/completions'</span>` (توجه: شماره پورت ممکن است متفاوت باشد)
</code></pre>
<ul>
<li><strong>دلیل:</strong> در تنظیمات <code>config.ini</code> برای <code>lm-studio</code> (یا سایر سرورهای مشابه OpenAI محلی) پیشوند <code>http://</code> در آدرس <code>provider_server_address</code> وجود ندارد یا پورت اشتباه است.</li>
<li><strong>راه‌حل:</strong><ul>
<li>مطمئن شوید آدرس شامل <code>http://</code> است. LM-Studio معمولاً به طور پیش‌فرض <code>http://127.0.0.1:1234</code> است.</li>
<li>تنظیم صحیح در <code>config.ini</code>:<br><code>provider_server_address = http://127.0.0.1:1234</code> (یا پورت واقعی سرور LM-Studio شما).</li>
</ul>
</li>
</ul>
<h2>SearxNG Base URL ارائه نشده است</h2>
<pre><code class="hljs language-csharp"><span class="hljs-function">raise <span class="hljs-title">ValueError</span>(<span class="hljs-params"><span class="hljs-string">"SearxNG base URL must be provided either as an argument or via the SEARXNG_BASE_URL environment variable."</span></span>)
ValueError: SearxNG <span class="hljs-keyword">base</span> URL must be provided either <span class="hljs-keyword">as</span> an argument <span class="hljs-keyword">or</span> via the SEARXNG_BASE_URL environment variable.`
</span></code></pre>
<h2>سوالات متداول (FAQ)</h2>
<p><strong>س: چه سخت‌افزاری نیاز دارم؟</strong>  </p>
<table>
<thead>
<tr>
<th>اندازه مدل</th>
<th>GPU</th>
<th>توضیحات</th>
</tr>
</thead>
<tbody><tr>
<td>7B</td>
<td>8GB Vram</td>
<td>⚠️ توصیه نمی‌شود. عملکرد ضعیف، هذیان‌گویی زیاد و احتمال شکست ایجنت‌های برنامه‌ریز.</td>
</tr>
<tr>
<td>14B</td>
<td>12 GB VRAM (مثلاً RTX 3060)</td>
<td>✅ مناسب برای کارهای ساده. ممکن است در وب‌گردی و برنامه‌ریزی مشکل داشته باشد.</td>
</tr>
<tr>
<td>32B</td>
<td>24+ GB VRAM (مثلاً RTX 4090)</td>
<td>🚀 موفقیت در اکثر کارها، شاید هنوز در برنامه‌ریزی وظایف کمی مشکل داشته باشد.</td>
</tr>
<tr>
<td>70B+</td>
<td>48+ GB Vram</td>
<td>💪 عالی. برای موارد پیشرفته توصیه می‌شود.</td>
</tr>
</tbody></table>
<p><strong>س: خطا دریافت می‌کنم، چه کنم؟</strong>  </p>
<p>مطمئن شوید حالت محلی (<code>ollama serve</code>) اجرا می‌شود، <code>config.ini</code> شما با ارائه‌دهنده هماهنگ است و وابستگی‌ها نصب شده‌اند. اگر هیچ‌کدام جواب نداد یک issue ثبت کنید.</p>
<p><strong>س: آیا واقعاً می‌تواند ۱۰۰٪ محلی اجرا شود؟</strong>  </p>
<p>بله، با ارائه‌دهندگان Ollama، lm-studio یا server، تمام تبدیل گفتار به متن، LLM و تبدیل متن به گفتار به طور کامل محلی اجرا می‌شوند. گزینه‌های غیرمحلی (OpenAI یا سایر APIها) اختیاری هستند.</p>
<p><strong>س: چرا باید از AgenticSeek استفاده کنم وقتی Manus را دارم؟</strong></p>
<p>برخلاف Manus، AgenticSeek بر استقلال از سیستم‌های بیرونی تأکید دارد و کنترل، حریم خصوصی بیشتر و عدم هزینه API را به شما می‌دهد.</p>
<p><strong>س: چه کسی پشت پروژه است؟</strong></p>
<p>پروژه توسط من و دو دوست دیگر که نگهدارنده و مشارکت‌کننده از جامعه متن‌باز گیت‌هاب هستند ساخته شده است. ما فقط یک گروه علاقه‌مند هستیم و هیچ استارت‌آپ یا سازمانی پشت آن نیست.</p>
<p>هر حساب AgenticSeek در X به‌جز حساب شخصی من (<a href="https://x.com/Martin993886460">https://x.com/Martin993886460</a>) جعل هویت است.</p>
<h2>مشارکت</h2>
<p>ما به دنبال توسعه‌دهندگانی برای بهبود AgenticSeek هستیم! مسائل باز یا بحث‌ها را بررسی کنید.</p>
<p><a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/docs/CONTRIBUTING.md">راهنمای مشارکت</a></p>
<p><a href="https://www.star-history.com/#Fosowl/agenticSeek&amp;Date"><img src="https://api.star-history.com/svg?repos=Fosowl/agenticSeek&amp;type=Date" alt="Star History Chart"></a></p>
<h2>نگهدارندگان:</h2>
<blockquote>
<p><a href="https://github.com/Fosowl">Fosowl</a> | ساعت پاریس</p>
</blockquote>
<blockquote>
<p><a href="https://github.com/antoineVIVIES">antoineVIVIES</a> | ساعت تایپه</p>
</blockquote>
<blockquote>
<p><a href="https://github.com/steveh8758">steveh8758</a> | ساعت تایپه</p>
</blockquote>
<h2>تشکر ویژه:</h2>
<blockquote>
<p><a href="https://github.com/tcsenpai">tcsenpai</a> و <a href="https://github.com/plitc">plitc</a> برای کمک به داکرایز کردن بک‌اند</p>
</blockquote>
<h2>اسپانسرها:</h2>
<p>اسپانسرهای ماهیانه ۵ دلار یا بیشتر اینجا نمایش داده می‌شوند:</p>
<ul>
<li><strong>tatra-labs</strong><br>Sure! Please provide the content of Part 4 of 4 for translation.</li>
</ul>
<hr>
<p>Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx">Open Ai Tx</a> | Last indexed: 2025-06-16</p>
<hr>
</div>
    </div>

    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async=""></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
    


</body></html>