<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>agenticSeek - Fosowl/agenticSeek ja</title>
    <meta name="title" content="agenticSeek - Fosowl/agenticSeek ja | AgenticSeek: プライベート・ローカル Manus 代替 English | 中文 | 繁體中文 | Français | 日本語 | Português (Brasil) | Español 100%ローカルなManus AIの代替。 この音声対応AIアシスタントは、すべてのデータをデバイス上に保持しながら...">
    <meta name="description" content="Fosowl/agenticSeek - GitHub repository ja documentation and information | AgenticSeek: プライベート・ローカル Manus 代替 English | 中文 | 繁體中文 | Français | 日本語 | Português (Brasil) | Español 100%ローカルなManus AIの代替。 この音声対応AIアシスタントは、すべてのデータをデバイス上に保持しながら...">
    <meta name="keywords" content="Fosowl, agenticSeek, GitHub, repository, ja documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/Fosowl/agenticSeek/README-ja.html">
    <meta property="og:title" content="agenticSeek - Fosowl/agenticSeek ja | AgenticSeek: プライベート・ローカル Manus 代替 English | 中文 | 繁體中文 | Français | 日本語 | Português (Brasil) | Español 100%ローカルなManus AIの代替。 この音声対応AIアシスタントは、すべてのデータをデバイス上に保持しながら...">
    <meta property="og:description" content="Fosowl/agenticSeek - GitHub repository ja documentation and information | AgenticSeek: プライベート・ローカル Manus 代替 English | 中文 | 繁體中文 | Français | 日本語 | Português (Brasil) | Español 100%ローカルなManus AIの代替。 この音声対応AIアシスタントは、すべてのデータをデバイス上に保持しながら...">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div style="position: fixed; top: 2px; left: 2px; z-index: 2000; background: rgba(255,255,255,0.95); border-radius: 6px; box-shadow: 0 2px 8px rgba(0,0,0,0.06); padding: 4px 14px; font-size: 15px; color: #222; font-family: 'Segoe UI', Arial, sans-serif; font-weight: 500; letter-spacing: 0.5px;">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" style="color: #0366d6; text-decoration: none; font-weight: 600;">Open AI Tx</a>
    </div>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/Fosowl/agenticSeek" id="githubRepoLink" target="_blank">Fosowl/agenticSeek</a>
<h1 style="display: none;">AgenticSeek: プライベート・ローカル Manus 代替 English | 中文 | 繁體中文 | Français | 日本語 | Português (Brasil) | Español 100%ローカルなManus AIの代替。 この音声対応AIアシスタントは、すべてのデータをデバイス上に保持しながら...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <h1>AgenticSeek: プライベート・ローカル Manus 代替</h1>
<p align="center">
<img align="center" src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/agentic_seek_logo.png" width="300" height="300" alt="Agentic Seek Logo">
<p>
<p>English | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_CHS.md">中文</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_CHT.md">繁體中文</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_FR.md">Français</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_JP.md">日本語</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_PTBR.md">Português (Brasil)</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_ES.md">Español</a></p>
<ul>
<li><strong>100%ローカルなManus AIの代替。</strong> この音声対応AIアシスタントは、すべてのデータをデバイス上に保持しながら、自律的にウェブを閲覧し、コードを書き、タスクを計画します。ローカル推論モデル向けに最適化されており、完全に自分のハードウェア上で動作し、完全なプライバシーとクラウド依存ゼロを保証します。</li>
</ul>
<p><a href="https://fosowl.github.io/agenticSeek.html"><img src="https://img.shields.io/static/v1?label=Website&amp;message=AgenticSeek&amp;color=blue&amp;style=flat-square" alt="Visit AgenticSeek" /></a> <img src="https://img.shields.io/badge/license-GPL--3.0-green" alt="License" /> <a href="https://discord.gg/8hGDaME3TC"><img src="https://img.shields.io/badge/Discord-Join%20Us-7289DA?logo=discord&amp;logoColor=white" alt="Discord" /></a> <a href="https://x.com/Martin993886460"><img src="https://img.shields.io/twitter/url/https/twitter.com/fosowl.svg?style=social&amp;label=Update%20%40Fosowl" alt="Twitter" /></a> <a href="https://github.com/Fosowl/agenticSeek/stargazers"><img src="https://img.shields.io/github/stars/Fosowl/agenticSeek?style=social" alt="GitHub stars" /></a></p>
<h3>なぜAgenticSeekなのか？</h3>
<ul>
<li><p>🔒 完全ローカル＆プライベート - すべてがあなたのマシン上で動作します。クラウドなし、データ共有なし。ファイル、会話、検索内容はすべてプライベートに保たれます。</p>
</li>
<li><p>🌐 スマートなウェブブラウジング - AgenticSeekは自動でインターネットを閲覧できます。検索、読取、情報抽出、ウェブフォームへの入力もハンズフリーで可能です。</p>
</li>
<li><p>💻 自律型コーディングアシスタント - コードが必要ですか？Python、C、Go、Javaなどのプログラムを自動で作成、デバッグ、実行できます。</p>
</li>
<li><p>🧠 スマートエージェント選択 - あなたが依頼すれば、自動的に最適なエージェントを選択します。まるで専門家チームが常に助けてくれるようです。</p>
</li>
<li><p>📋 複雑なタスクの計画と実行 - 旅行計画から複雑なプロジェクトまで、大きなタスクをステップに分解し、複数のAIエージェントを使って完遂します。</p>
</li>
<li><p>🎙️ 音声対応 - クリアで高速、未来的な音声認識・テキスト変換機能により、まるでSF映画のAIのように会話できます。（開発中）</p>
</li>
</ul>
<h3><strong>デモ</strong></h3>
<blockquote>
<p><em>agenticSeekプロジェクトを検索し、必要なスキルを調べてからCV_candidates.zipを開き、プロジェクトに最も合致する候補者を教えてください</em></p>
</blockquote>
<p>https://github.com/user-attachments/assets/b8ca60e9-7b3b-4533-840e-08f9ac426316</p>
<p>免責事項：このデモに登場する全てのファイル（例：CV_candidates.zip）は完全なフィクションです。私たちは法人ではなく、候補者でなくオープンソースのコントリビューターを募集しています。</p>
<blockquote>
<p>🛠⚠️️ <strong>活発な開発中</strong></p>
</blockquote>
<blockquote>
<p>🙏 このプロジェクトはサイドプロジェクトとして始まり、ロードマップも資金もありません。GitHub Trending入りで想像以上に成長しました。貢献・フィードバック・ご辛抱に深く感謝します。</p>
</blockquote>
<h2>前提条件</h2>
<p>開始する前に、以下のソフトウェアがインストールされていることを確認してください：</p>
<ul>
<li><strong>Git:</strong> リポジトリのクローン用。<a href="https://git-scm.com/downloads">Gitをダウンロード</a></li>
<li><strong>Python 3.10.x:</strong> Python 3.10.xバージョンを強く推奨します。他のバージョンでは依存関係エラーが発生することがあります。<a href="https://www.python.org/downloads/release/python-3100/">Python 3.10をダウンロード</a>（3.10.xバージョンを選択）</li>
<li><strong>Docker Engine &amp; Docker Compose:</strong> SearxNGなどのバンドルサービス用。
<ul>
<li>Docker Desktop（Docker Compose V2を含む）をインストール：<a href="https://docs.docker.com/desktop/install/windows-install/">Windows</a> | <a href="https://docs.docker.com/desktop/install/mac-install/">Mac</a> | <a href="https://docs.docker.com/desktop/install/linux-install/">Linux</a></li>
<li>またはLinuxでDocker EngineとDocker Composeを個別にインストール：<a href="https://docs.docker.com/engine/install/">Docker Engine</a> | <a href="https://docs.docker.com/compose/install/">Docker Compose</a>（必ずCompose V2をインストール、例：<code>sudo apt-get install docker-compose-plugin</code>）</li>
</ul>
</li>
</ul>
<h3>1. <strong>リポジトリのクローンとセットアップ</strong></h3>
<pre><code class="language-sh">git clone https://github.com/Fosowl/agenticSeek.git
cd agenticSeek
mv .env.example .env
</code></pre>
<h3>2. .envファイルの内容を変更</h3>
<pre><code class="language-sh">SEARXNG_BASE_URL=&quot;http://127.0.0.1:8080&quot;
REDIS_BASE_URL=&quot;redis://redis:6379/0&quot;
WORK_DIR=&quot;/Users/mlg/Documents/workspace_for_ai&quot;
OLLAMA_PORT=&quot;11434&quot;
LM_STUDIO_PORT=&quot;1234&quot;
CUSTOM_ADDITIONAL_LLM_PORT=&quot;11435&quot;
OPENAI_API_KEY='optional'
DEEPSEEK_API_KEY='optional'
OPENROUTER_API_KEY='optional'
TOGETHER_API_KEY='optional'
GOOGLE_API_KEY='optional'
ANTHROPIC_API_KEY='optional'
</code></pre>
<p>必要に応じて <code>.env</code> ファイルを自分の値に更新してください：</p>
<ul>
<li><strong>SEARXNG_BASE_URL</strong>: 変更不要</li>
<li><strong>REDIS_BASE_URL</strong>: 変更不要</li>
<li><strong>WORK_DIR</strong>: ローカルマシン上の作業ディレクトリへのパス。AgenticSeekがこれらのファイルを読み書きできます。</li>
<li><strong>OLLAMA_PORT</strong>: Ollamaサービス用のポート番号。</li>
<li><strong>LM_STUDIO_PORT</strong>: LM Studioサービス用のポート番号。</li>
<li><strong>CUSTOM_ADDITIONAL_LLM_PORT</strong>: 追加のカスタムLLMサービス用のポート。</li>
</ul>
<p><strong>APIキーはローカルでLLMを動作させる場合は完全に任意です。本プロジェクトの主目的です。十分なハードウェアがある場合は空欄でOKです。</strong></p>
<h3>3. <strong>Dockerを起動</strong></h3>
<p>Dockerがインストールされ、システムで起動していることを確認してください。以下のコマンドでDockerを起動できます：</p>
<ul>
<li><p><strong>Linux/macOSの場合:</strong><br />
ターミナルを開いて以下を実行：</p>
<pre><code class="language-sh">sudo systemctl start docker
</code></pre>
<p>または、インストール済みの場合はアプリケーションメニューからDocker Desktopを起動。</p>
</li>
<li><p><strong>Windowsの場合:</strong><br />
スタートメニューからDocker Desktopを起動。</p>
</li>
</ul>
<p>Dockerが動作しているかを確認するには、以下を実行：</p>
<pre><code class="language-sh">docker info
</code></pre>
<p>Dockerインストール情報が表示されれば、正常に動作しています。</p>
<p>下記の<a href="#list-of-local-providers">ローカルプロバイダー一覧</a>を参照してください。</p>
<p>次のステップ：<a href="#start-services-and-run">AgenticSeekをローカルで実行</a></p>
<p><em>問題が発生した場合は<a href="#troubleshooting">トラブルシューティング</a>セクションを参照してください。</em>
<em>ハードウェアがローカルLLMに対応していない場合は<a href="#setup-to-run-with-an-api">APIでの実行セットアップ</a>を参照してください。</em>
<em>詳しい<code>config.ini</code>の説明は<a href="#config">Configセクション</a>を参照してください。</em></p>
<hr />
<h2>LLMをローカルマシンで実行するセットアップ</h2>
<p><strong>ハードウェア要件:</strong></p>
<p>LLMをローカルで動作させるには十分なハードウェアが必要です。最低でもMagistral、Qwen、Deepseek 14Bが動作するGPUが必要です。詳しいモデル・パフォーマンスの推奨はFAQを参照してください。</p>
<p><strong>ローカルプロバイダーの起動</strong></p>
<p>例としてollamaを起動する場合：</p>
<pre><code class="language-sh">ollama serve
</code></pre>
<p>対応するローカルプロバイダーの一覧は下記参照。</p>
<p><strong>config.iniの更新</strong></p>
<p>config.iniファイルのprovider_nameを対応プロバイダーに、provider_modelを利用したいLLMモデル名に設定します。推論モデル（<em>Magistral</em>や<em>Deepseek</em>など）を推奨します。</p>
<p>必要ハードウェアはREADME末尾の<strong>FAQ</strong>参照。</p>
<pre><code class="language-sh">[MAIN]
is_local = True # ローカルまたはリモートプロバイダーの使用を選択
provider_name = ollama # lm-studio, openaiなども可
provider_model = deepseek-r1:14b # ハードウェアに合ったモデルを選択
provider_server_address = 127.0.0.1:11434
agent_name = Jarvis # AIの名前
recover_last_session = True # 前回セッションの復元
save_session = True # 現在のセッションを保存
speak = False # テキスト読み上げ
listen = False # 音声認識（CLIのみ、実験的）
jarvis_personality = False # Jarvis風パーソナリティ使用（実験的）
languages = en zh # 言語リスト、TTSはリスト先頭をデフォルト使用
[BROWSER]
headless_browser = True # CLIでの利用を除き変更不要
stealth_mode = True # ブラウザ検出防止のため未検出Seleniumを使用
</code></pre>
<p><strong>注意:</strong></p>
<ul>
<li><p><code>config.ini</code>の書式はコメントをサポートしていません。
例の設定をそのままコピー＆ペーストしないでください。コメントがエラーとなります。必要な設定のみ手動で編集してください。</p>
</li>
<li><p>LM-studioでLLMを起動する場合、<code>provider_name</code>を<code>openai</code>に設定しないでください。<code>lm-studio</code>に設定してください。</p>
</li>
<li><p>一部プロバイダー（例：lm-studio）はIPの前に<code>http://</code>が必要です。例：<code>http://127.0.0.1:1234</code></p>
</li>
</ul>
<p><strong>ローカルプロバイダー一覧</strong></p>
<p>| プロバイダー  | ローカル対応 | 説明                                               |
|-----------|--------|-----------------------------------------------------------|
| ollama    | はい    | ollamaをLLMプロバイダーとして使い、簡単にローカルLLM実行       |
| lm-studio  | はい    | LM StudioでローカルLLM実行（<code>provider_name</code>は<code>lm-studio</code>に設定）|
| openai    | はい     | openai互換API使用（例：llama.cppサーバー）  |</p>
<p>次のステップ：<a href="#Start-services-and-Run">AgenticSeekのサービス開始・実行</a></p>
<p><em>問題が発生した場合は<a href="#troubleshooting">トラブルシューティング</a>セクションを参照してください。</em>
<em>ハードウェアがローカルLLMに対応していない場合は<a href="#setup-to-run-with-an-api">APIでの実行セットアップ</a>を参照してください。</em>
<em>詳しい<code>config.ini</code>の説明は<a href="#config">Configセクション</a>を参照してください。</em></p>
<h2>APIでの実行セットアップ</h2>
<p>このセットアップでは、外部クラウドベースのLLMプロバイダーを利用します。選択したサービスのAPIキーが必要です。</p>
<p><strong>1. APIプロバイダーを選択しAPIキーを取得:</strong></p>
<p><a href="#list-of-api-providers">APIプロバイダー一覧</a>を参照し、各ウェブサイトでサインアップしAPIキーを取得してください。</p>
<p><strong>2. APIキーを環境変数として設定:</strong></p>
<ul>
<li><strong>Linux/macOS:</strong>
ターミナルを開き、<code>export</code>コマンドを利用。永続化にはシェルのプロファイルファイル（例：<code>~/.bashrc</code>, <code>~/.zshrc</code>）に追加するのが最適です。
<pre><code class="language-sh">export PROVIDER_API_KEY=&quot;your_api_key_here&quot; 
# PROVIDER_API_KEYは各サービスの変数名（例：OPENAI_API_KEY, GOOGLE_API_KEY）に置き換えてください
</code></pre>
TogetherAIの例：
<pre><code class="language-sh">export TOGETHER_API_KEY=&quot;xxxxxxxxxxxxxxxxxxxxxx&quot;
</code></pre>
</li>
<li><strong>Windows:</strong></li>
<li><strong>コマンドプロンプト（現在のセッションのみ一時的に設定）:</strong>
<pre><code class="language-cmd">set PROVIDER_API_KEY=your_api_key_here
</code></pre>
</li>
<li><strong>PowerShell（現在のセッションのみ一時的に設定）:</strong>
<pre><code class="language-powershell">$env:PROVIDER_API_KEY=&quot;your_api_key_here&quot;
</code></pre>
</li>
<li><strong>永続的に設定:</strong> Windowsの検索バーで「環境変数」と検索し、「システム環境変数の編集」をクリックして、「環境変数...」ボタンを押します。適切な名前（例: <code>OPENAI_API_KEY</code>）と値（APIキー）で新しいユーザー変数を追加してください。</li>
</ul>
<p><em>（詳細はFAQ: <a href="#how-do-i-set-api-keys">APIキーの設定方法</a> を参照してください）。</em></p>
<p><strong>3. <code>config.ini</code> の更新:</strong></p>
<pre><code class="language-ini">[MAIN]
is_local = False
provider_name = openai # または google, deepseek, togetherAI, huggingface
provider_model = gpt-3.5-turbo # または gemini-1.5-flash, deepseek-chat, mistralai/Mixtral-8x7B-Instruct-v0.1 など
provider_server_address = # 通常、is_local = False の場合はほとんどのAPIで無視されるか空欄でOK
# ... その他の設定 ...
</code></pre>
<p><em>警告:</em> <code>config.ini</code> の値に末尾スペースが無いことを確認してください。</p>
<p><strong>APIプロバイダー一覧</strong></p>
<p>| プロバイダー   | <code>provider_name</code> | ローカル? | 説明                                              | APIキーリンク（例）                        |
|----------------|-----------------|-----------|--------------------------------------------------|---------------------------------------------|
| OpenAI         | <code>openai</code>        | いいえ    | OpenAIのAPI経由でChatGPTモデルを使用              | <a href="https://platform.openai.com/signup">platform.openai.com/signup</a> |
| Google Gemini  | <code>google</code>        | いいえ    | Google AI Studio経由でGoogle Geminiモデルを使用   | <a href="https://aistudio.google.com/keys">aistudio.google.com/keys</a> |
| Deepseek       | <code>deepseek</code>      | いいえ    | DeepseekのAPI経由でDeepseekモデルを使用           | <a href="https://platform.deepseek.com">platform.deepseek.com</a> |
| Hugging Face   | <code>huggingface</code>   | いいえ    | Hugging Face Inference API経由でモデルを使用      | <a href="https://huggingface.co/settings/tokens">huggingface.co/settings/tokens</a> |
| TogetherAI     | <code>togetherAI</code>    | いいえ    | TogetherAI API経由で様々なOSSモデルを利用可能     | <a href="https://api.together.ai/settings/api-keys">api.together.ai/settings/api-keys</a> |</p>
<p><em>注意:</em></p>
<ul>
<li>複雑なウェブブラウジングやタスク計画には、現在のプロンプト最適化はDeepseek向けのため、<code>gpt-4o</code>や他のOpenAIモデルの利用は推奨しません。</li>
<li>コーディングやbashのタスクはGeminiではDeepseek向けの書式に厳密に従わない可能性があり、問題が発生する場合があります。</li>
<li><code>config.ini</code> の <code>provider_server_address</code> は、<code>is_local = False</code> の場合、APIエンドポイントが各プロバイダーのライブラリでハードコーディングされているため通常使用しません。</li>
</ul>
<p>次のステップ: <a href="#Start-services-and-Run">サービスの起動とAgenticSeekの実行</a></p>
<p><em>問題が発生した場合は「<strong>既知の問題</strong>」セクションを参照してください。</em></p>
<p><em>詳細な設定ファイルの説明は「<strong>Config</strong>」セクションを参照してください。</em></p>
<hr />
<h2>サービスの起動と実行</h2>
<p>デフォルトでは、AgenticSeekはすべてDocker内で実行されます。</p>
<p>必要なサービスを起動します。これによりdocker-compose.ymlから以下のすべてのサービスが起動します:
- searxng
- redis（searxngに必須）
- frontend
- backend（<code>full</code>を使用する場合）</p>
<pre><code class="language-sh">./start_services.sh full # MacOS
start ./start_services.cmd full # Window
</code></pre>
<p><strong>警告:</strong> このステップで全てのDockerイメージのダウンロード・ロードが行われ、最大30分かかる場合があります。サービス起動後、バックエンドサービスが完全に起動するまで（ログに <strong>backend: &quot;GET /health HTTP/1.1&quot; 200 OK</strong> と表示されるまで）メッセージの送信はお待ちください。初回起動時はバックエンドサービスの起動に最大5分かかることがあります。</p>
<p><code>http://localhost:3000/</code> にアクセスするとWebインターフェースが表示されます。</p>
<p><em>サービス起動時のトラブルシューティング:</em> これらのスクリプトが失敗する場合は、Docker Engineが起動しており、Docker Compose（V2, <code>docker compose</code>）が正しくインストールされていることを確認してください。エラーメッセージは端末の出力を確認してください。<a href="#faq-troubleshooting">FAQ: AgenticSeekやスクリプト実行時にエラーが出る場合の対処法</a>も参照してください。</p>
<p><strong>オプション:</strong> ホスト（CLIモード）での実行</p>
<p>CLIインターフェースで実行するには、ホストにパッケージをインストールしてください:</p>
<pre><code class="language-sh">./install.sh
./install.bat # windows
</code></pre>
<p>サービスを起動します:</p>
<pre><code class="language-sh">./start_services.sh # MacOS
start ./start_services.cmd # Window
</code></pre>
<p>CLIの利用: <code>python3 cli.py</code></p>
<hr />
<h2>利用方法</h2>
<p><code>./start_services.sh full</code> でサービスが稼働していることを確認し、Webインターフェースは <code>localhost:3000</code> で利用できます。</p>
<p>CLIモードのみ、configで <code>listen = True</code> に設定することで音声認識（speech to text）も利用可能です。</p>
<p>終了するには、単に <code>goodbye</code> と発話または入力してください。</p>
<p>利用例:</p>
<blockquote>
<p><em>pythonでスネークゲームを作って！</em></p>
</blockquote>
<blockquote>
<p><em>フランス・レンヌのトップカフェをWeb検索し、3つを住所付きでrennes_cafes.txtに保存して。</em></p>
</blockquote>
<blockquote>
<p><em>Goで階乗を計算するプログラムを書き、factorial.goとしてワークスペースに保存して</em></p>
</blockquote>
<blockquote>
<p><em>summer_picturesフォルダー内の全JPGファイルを今日の日付でリネームし、リネーム後のファイル一覧をphotos_list.txtに保存</em></p>
</blockquote>
<blockquote>
<p><em>2024年の人気SF映画をネットで調べて、今夜観る3本を選んで。リストをmovie_night.txtに保存。</em></p>
</blockquote>
<blockquote>
<p><em>2025年の最新AIニュース記事をネット検索し、3つ選んで、それらのタイトルと要約をスクレイピングするPythonスクリプトを書いて。スクリプトはnews_scraper.py、要約は/home/projectsのai_news.txtに保存</em></p>
</blockquote>
<blockquote>
<p><em>金曜日、無料の株価APIをWebで探し、supersuper7434567@gmail.comで登録、そのAPIでテスラの日次株価を取得するPythonスクリプトを書いて、結果をstock_prices.csvに保存</em></p>
</blockquote>
<p><em>なお、フォーム入力の自動化は実験的機能のため失敗する場合があります。</em></p>
<p>クエリを入力すると、AgenticSeekがタスクに最適なエージェントを割り当てます。</p>
<p>本プロトタイプは初期段階のため、エージェントルーティングが必ずしも最適なものとは限りません。</p>
<p>そのため、AIにしてほしいことや進め方をできるだけ明確に伝えてください。例えばWeb検索させたい場合は、</p>
<p><code>Do you know some good countries for solo-travel?</code></p>
<p>のように曖昧にせず、</p>
<p><code>Do a web search and find out which are the best country for solo-travel</code></p>
<p>のように具体的に指示しましょう。</p>
<hr />
<h2><strong>LLMを自分のサーバーで動かす設定</strong></h2>
<p>高性能なコンピュータやサーバーがあり、それをノートPCから利用したい場合は、独自のllmサーバーでLLMをリモート実行できます。</p>
<p>AIモデルを動かす「サーバー」でIPアドレスを取得します。</p>
<pre><code class="language-sh">ip a | grep &quot;inet &quot; | grep -v 127.0.0.1 | awk '{print $2}' | cut -d/ -f1 # ローカルIP
curl https://ipinfo.io/ip # グローバルIP
</code></pre>
<p>注: WindowsやmacOSの場合は、それぞれipconfigやifconfigでIPアドレスを確認してください。</p>
<p>リポジトリをクローンし、<code>server/</code>フォルダーに移動します。</p>
<pre><code class="language-sh">git clone --depth 1 https://github.com/Fosowl/agenticSeek.git
cd agenticSeek/llm_server/
</code></pre>
<p>サーバー用の要件をインストール:</p>
<pre><code class="language-sh">pip3 install -r requirements.txt
</code></pre>
<p>サーバースクリプトを実行します。</p>
<pre><code class="language-sh">python3 app.py --provider ollama --port 3333
</code></pre>
<p><code>ollama</code>または<code>llamacpp</code>をLLMサービスとして利用可能です。</p>
<p>次に、個人PC側で:</p>
<p><code>config.ini</code>ファイルの<code>provider_name</code>を<code>server</code>、<code>provider_model</code>を<code>deepseek-r1:xxb</code>に設定します。
<code>provider_server_address</code>にはモデルを動かすマシンのIPアドレスを設定します。</p>
<pre><code class="language-sh">[MAIN]
is_local = False
provider_name = server
provider_model = deepseek-r1:70b
provider_server_address = x.x.x.x:3333
</code></pre>
<p>次のステップ: <a href="#Start-services-and-Run">サービスの起動とAgenticSeekの実行</a></p>
<hr />
<h2>音声認識（Speech to Text）</h2>
<p>注意: 音声認識は現状CLIモードのみ対応です。</p>
<p>現時点では音声認識は英語のみ対応しています。</p>
<p>音声認識はデフォルトで無効です。有効にするには、config.iniのlistenオプションをTrueに設定してください:</p>
<pre><code>listen = True
</code></pre>
<p>有効にすると、音声認識は入力処理の前にトリガーワード（エージェント名）を待ち受けます。エージェント名は<em>config.ini</em>ファイルの <code>agent_name</code> 値を更新してカスタマイズできます:</p>
<pre><code>agent_name = Friday
</code></pre>
<p>最適な認識のため、エージェント名には「John」や「Emma」などの一般的な英語名を使用することを推奨します。</p>
<p>トランスクリプトが表示され始めたら、エージェント名（例：「Friday」）を声に出して呼びかけて起動します。</p>
<p>質問ははっきりと話してください。</p>
<p>リクエストの最後に、システムに処理を進めるよう伝える確認フレーズを付けてください。確認フレーズの例：</p>
<pre><code>&quot;do it&quot;, &quot;go ahead&quot;, &quot;execute&quot;, &quot;run&quot;, &quot;start&quot;, &quot;thanks&quot;, &quot;would ya&quot;, &quot;please&quot;, &quot;okay?&quot;, &quot;proceed&quot;, &quot;continue&quot;, &quot;go on&quot;, &quot;do that&quot;, &quot;go it&quot;, &quot;do you understand?&quot;
</code></pre>
<h2>Config</h2>
<p>設定例：</p>
<pre><code>[MAIN]
is_local = True
provider_name = ollama
provider_model = deepseek-r1:32b
provider_server_address = http://127.0.0.1:11434 # Ollamaの場合の例。LM-Studioの場合は http://127.0.0.1:1234
agent_name = Friday
recover_last_session = False
save_session = False
speak = False
listen = False

jarvis_personality = False
languages = en zh # TTSやルーティングに利用する言語リスト
[BROWSER]
headless_browser = False
stealth_mode = False
</code></pre>
<p><strong><code>config.ini</code> 設定の説明</strong>:</p>
<ul>
<li><strong><code>[MAIN]</code> セクション:</strong>
<ul>
<li><code>is_local</code>: ローカルLLMプロバイダ（Ollama、LM-Studio、OpenAI互換ローカルサーバー、セルフホスト型サーバー）を使用する場合は <code>True</code>。クラウドAPI（OpenAI、Google等）は <code>False</code>。</li>
<li><code>provider_name</code>: LLMプロバイダーを指定します。
<ul>
<li>ローカル: <code>ollama</code>, <code>lm-studio</code>, <code>openai</code>（OpenAI互換ローカルサーバー用）, <code>server</code>（セルフホストサーバー用）</li>
<li>API: <code>openai</code>, <code>google</code>, <code>deepseek</code>, <code>huggingface</code>, <code>togetherAI</code></li>
</ul>
</li>
<li><code>provider_model</code>: 選択したプロバイダー用のモデル名またはID（例：Ollamaなら <code>deepseekcoder:6.7b</code>、OpenAI APIなら <code>gpt-3.5-turbo</code>、TogetherAIなら <code>mistralai/Mixtral-8x7B-Instruct-v0.1</code>）</li>
<li><code>provider_server_address</code>: LLMプロバイダーのアドレス
<ul>
<li>ローカル: 例 <code>http://127.0.0.1:11434</code>（Ollama）、<code>http://127.0.0.1:1234</code>（LM-Studio）</li>
<li><code>server</code> プロバイダーの場合: セルフホストLLMサーバーのアドレス（例：<code>http://your_server_ip:3333</code>）</li>
<li>クラウドAPI（<code>is_local = False</code>）の場合：多くは無視されるか空欄でOK。APIエンドポイントはクライアントライブラリが管理します。</li>
</ul>
</li>
<li><code>agent_name</code>: AIアシスタントの名前（例：Friday）。音声認識トリガーワードとして使用。</li>
<li><code>recover_last_session</code>: 前回セッションの状態を復元する場合は <code>True</code>、新規開始は <code>False</code></li>
<li><code>save_session</code>: 現在のセッション状態を保存する場合は <code>True</code></li>
<li><code>speak</code>: テキスト読み上げ音声出力を有効にする場合は <code>True</code></li>
<li><code>listen</code>: 音声入力（CLIモードのみ）を有効にする場合は <code>True</code></li>
<li><code>work_dir</code>: <strong>重要:</strong> AgenticSeekがファイルの読み書きを行うディレクトリ。<strong>このパスが有効かつアクセス可能であることを確認してください。</strong></li>
<li><code>jarvis_personality</code>: &quot;Jarvis風&quot; のシステムプロンプトを使う場合は <code>True</code>（実験的）、標準プロンプトは <code>False</code></li>
<li><code>languages</code>: カンマ区切りの言語リスト（例：<code>en, zh, fr</code>）。TTS音声選択（最初がデフォルト）やLLMルーターに利用。効率化のため、似すぎた言語や多すぎる言語は避けてください。</li>
</ul>
</li>
<li><strong><code>[BROWSER]</code> セクション:</strong>
<ul>
<li><code>headless_browser</code>: ウィンドウを表示せず自動化ブラウザを実行する場合は <code>True</code>（ウェブインターフェースや非対話用途推奨）。ウィンドウを表示する場合は <code>False</code>（CLIモードやデバッグ用）。</li>
<li><code>stealth_mode</code>: ブラウザ自動化の検出を難しくする機能を有効化する場合は <code>True</code>。anticaptcha等の拡張機能の手動インストールが必要な場合があります。</li>
</ul>
</li>
</ul>
<p>このセクションではサポートされているLLMプロバイダータイプをまとめています。<code>config.ini</code> で設定してください。</p>
<p><strong>ローカルプロバイダー（自身のハードウェア上で実行）:</strong></p>
<p>| <code>config.ini</code>内のプロバイダー名 | <code>is_local</code> | 説明                                                                         | セットアップセクション                                                   |
|-------------------------------|------------|------------------------------------------------------------------------------|--------------------------------------------------------------------------|
| <code>ollama</code>                      | <code>True</code>     | OllamaでローカルLLMを提供                                                    | <a href="#setup-for-running-llm-locally-on-your-machine">ローカル実行のセットアップ</a> |
| <code>lm-studio</code>                   | <code>True</code>     | LM-StudioでローカルLLMを提供                                                 | <a href="#setup-for-running-llm-locally-on-your-machine">ローカル実行のセットアップ</a> |
| <code>openai</code>（ローカルサーバー用）| <code>True</code>     | OpenAI互換APIを公開するローカルサーバーへ接続（例：llama.cpp）               | <a href="#setup-for-running-llm-locally-on-your-machine">ローカル実行のセットアップ</a> |
| <code>server</code>                      | <code>False</code>    | 他のマシンで動作するAgenticSeekセルフホストLLMサーバーへ接続                 | <a href="#setup-to-run-the-llm-on-your-own-server">独自サーバーでのセットアップ</a>      |</p>
<p><strong>APIプロバイダー（クラウドベース）:</strong></p>
<p>| <code>config.ini</code>内のプロバイダー名 | <code>is_local</code> | 説明                                             | セットアップセクション                     |
|-------------------------------|------------|--------------------------------------------------|--------------------------------------------|
| <code>openai</code>                      | <code>False</code>    | OpenAI公式API（例：GPT-3.5, GPT-4）利用         | <a href="#setup-to-run-with-an-api">API利用セットアップ</a> |
| <code>google</code>                      | <code>False</code>    | Google GeminiモデルをAPI経由で利用               | <a href="#setup-to-run-with-an-api">API利用セットアップ</a> |
| <code>deepseek</code>                    | <code>False</code>    | Deepseek公式API利用                             | <a href="#setup-to-run-with-an-api">API利用セットアップ</a> |
| <code>huggingface</code>                 | <code>False</code>    | Hugging Face Inference API利用                   | <a href="#setup-to-run-with-an-api">API利用セットアップ</a> |
| <code>togetherAI</code>                  | <code>False</code>    | TogetherAIのAPIで様々なオープンモデルを利用      | <a href="#setup-to-run-with-an-api">API利用セットアップ</a> |</p>
<hr />
<h2>トラブルシューティング</h2>
<p>問題が発生した場合、このセクションがガイドとなります。</p>
<h1>既知の問題</h1>
<h2>ChromeDriverの問題</h2>
<p><strong>エラー例:</strong> <code>SessionNotCreatedException: Message: session not created: This version of ChromeDriver only supports Chrome version XXX</code></p>
<ul>
<li><strong>原因:</strong> インストール済みのChromeDriverのバージョンがGoogle Chromeブラウザのバージョンと互換性がありません。</li>
<li><strong>解決策:</strong>
<ol>
<li><strong>Chromeバージョンの確認:</strong> Google Chromeを開き、<code>設定 &gt; Chromeについて</code> でバージョン（例：&quot;Version 120.0.6099.110&quot;）を確認。</li>
<li><strong>対応するChromeDriverをダウンロード:</strong>
<ul>
<li>Chrome 115以降の場合: <a href="https://googlechromelabs.github.io/chrome-for-testing/">Chrome for Testing (CfT) JSON Endpoints</a>で「stable」チャンネルを探し、ご自身のOSに合ったChromeのメジャーバージョンに一致するChromeDriverをダウンロード。</li>
<li>旧バージョン（稀）: <a href="https://chromedriver.chromium.org/downloads">ChromeDriver - WebDriver for Chrome</a>ページを参照。</li>
<li>下記画像はCfTページの例です:
<img src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/chromedriver_readme.png" alt="Download Chromedriver specific version from Chrome for Testing page" /></li>
</ul>
</li>
<li><strong>ChromeDriverのインストール:</strong>
<ul>
<li>ダウンロードした <code>chromedriver</code>（Windowsの場合は <code>chromedriver.exe</code>）を、システムのPATH環境変数に含まれるディレクトリ（例：Linux/macOSは <code>/usr/local/bin</code>、WindowsはPATHに追加したカスタムスクリプトフォルダ等）に配置。</li>
<li>もしくは、<code>agenticSeek</code> プロジェクトのルートディレクトリに配置。</li>
<li>実行権限を付与（例：Linux/macOSは <code>chmod +x chromedriver</code>）。</li>
</ul>
</li>
<li>詳細はインストールガイド内 <a href="#chromedriver-installation">ChromeDriver Installation</a> セクションを参照。</li>
</ol>
</li>
</ul>
<p>このセクションが不完全な場合や他のChromeDriver問題が発生した場合、<a href="https://github.com/Fosowl/agenticSeek/issues">GitHub Issues</a> で既存の内容を検索、または新規Issueを作成してください。</p>
<p><code>Exception: Failed to initialize browser: Message: session not created: This version of ChromeDriver only supports Chrome version 113 Current browser version is 134.0.6998.89 with binary path</code></p>
<p>このエラーはブラウザとchromedriverのバージョンが一致していない場合に発生します。</p>
<p>以下から最新バージョンをダウンロードしてください：</p>
<p>https://developer.chrome.com/docs/chromedriver/downloads</p>
<p>Chrome バージョン115以降の場合はこちら：</p>
<p>https://googlechromelabs.github.io/chrome-for-testing/</p>
<p>ご自身のOSに合ったchromedriverバージョンをダウンロードしてください。</p>
<p><img src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/chromedriver_readme.png" alt="alt text" /></p>
<p>このセクションが不完全な場合はIssueを作成してください。</p>
<h2>connection adapters の問題</h2>
<pre><code>Exception: Provider lm-studio failed: HTTP request failed: No connection adapters were found for '127.0.0.1:1234/v1/chat/completions'` (Note: port may vary)
</code></pre>
<ul>
<li><strong>原因:</strong> <code>lm-studio</code>（または同様のOpenAI互換ローカルサーバー）用に <code>config.ini</code> の <code>provider_server_address</code> に <code>http://</code> プレフィックスがない、またはポートが誤っています。</li>
<li><strong>解決策:</strong>
<ul>
<li>アドレスが <code>http://</code> を含んでいることを確認。LM-Studioは通常 <code>http://127.0.0.1:1234</code> がデフォルトです。</li>
<li><code>config.ini</code>の修正例：<code>provider_server_address = http://127.0.0.1:1234</code>（ご利用のLM-Studioサーバーのポートに合わせて修正）</li>
</ul>
</li>
</ul>
<h2>SearxNG Base URL未指定</h2>
<pre><code>raise ValueError(&quot;SearxNG base URL must be provided either as an argument or via the SEARXNG_BASE_URL environment variable.&quot;)
ValueError: SearxNG base URL must be provided either as an argument or via the SEARXNG_BASE_URL environment variable.`
</code></pre>
<h2>FAQ</h2>
<p><strong>Q: 必要なハードウェアは？</strong></p>
<p>| モデルサイズ  | GPU  | コメント                                               |
|--------------|--------|-----------------------------------------------------------|
| 7B           | 8GB Vram | ⚠️ 推奨しません。パフォーマンスが悪く、幻覚も多く、プランナーエージェントはほぼ失敗します。 |
| 14B          | 12GB VRAM (例：RTX 3060) | ✅ 簡単なタスクには使用可能。ウェブブラウジングや計画タスクにはやや力不足。 |
| 32B          | 24GB以上VRAM (例：RTX 4090) | 🚀 ほとんどのタスクで成功。ただしタスクプランニングはやや苦手な場合あり。|
| 70B以上       | 48GB以上VRAM | 💪 優秀。高度な用途に推奨。|</p>
<p><strong>Q: エラーが出た場合は？</strong></p>
<p>ローカルが起動中（<code>ollama serve</code>）、<code>config.ini</code>がプロバイダーに一致、依存関係がインストール済みであることを確認。それでも解決しない場合はIssueを作成してください。</p>
<p><strong>Q: 本当に100％ローカル実行できる？</strong></p>
<p>Ollama、lm-studioまたはserverプロバイダー利用時は、音声認識・LLM・TTSモデルすべてローカル動作します。非ローカル（OpenAI等API）はオプションです。</p>
<p><strong>Q: ManusがあるのにAgenticSeekを使う理由は？</strong></p>
<p>Manusと異なり、AgenticSeekは外部システム依存を最小化し、より多くのコントロールやプライバシー、APIコスト回避を重視しています。</p>
<p><strong>Q: プロジェクトの運営者は？</strong></p>
<p>このプロジェクトは私と、オープンソースコミュニティの2人の友人（メンテナー兼コントリビューター）で開発しています。私たちはスタートアップや組織所属ではなく、情熱を持った個人の集まりです。</p>
<p>私の個人アカウント（https://x.com/Martin993886460）以外のAgenticSeek名義のXアカウントはなりすましです。</p>
<h2>貢献について</h2>
<p>AgenticSeekの開発にご協力いただける開発者を募集中です！オープンなIssueやディスカッションをご覧ください。</p>
<p><a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/docs/CONTRIBUTING.md">貢献ガイド</a></p>
<p><a href="https://www.star-history.com/#Fosowl/agenticSeek&amp;Date"><img src="https://api.star-history.com/svg?repos=Fosowl/agenticSeek&amp;type=Date" alt="Star History Chart" /></a></p>
<h2>メンテナー:</h2>
<blockquote>
<p><a href="https://github.com/Fosowl">Fosowl</a> | パリ時間</p>
</blockquote>
<blockquote>
<p><a href="https://github.com/antoineVIVIES">antoineVIVIES</a> | 台北時間</p>
</blockquote>
<blockquote>
<p><a href="https://github.com/steveh8758">steveh8758</a> | 台北時間</p>
</blockquote>
<h2>スペシャルサンクス:</h2>
<blockquote>
<p><a href="https://github.com/tcsenpai">tcsenpai</a> および <a href="https://github.com/plitc">plitc</a> バックエンドのDocker化にご協力いただきました</p>
</blockquote>
<h2>スポンサー:</h2>
<p>月額5ドル以上のスポンサー様（順不同）:</p>
<ul>
<li><strong>tatra-labs</strong></li>
</ul>
<p>It appears that you have not provided the content of Part 4 of 4 for translation. Please paste the text you would like translated, and I will proceed as instructed.</p>
<hr />
<p>Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx">Open Ai Tx</a> | Last indexed: 2025-06-16</p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
</body>
</html>