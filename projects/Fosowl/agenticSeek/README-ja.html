<!DOCTYPE html><html lang="en"><head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AgenticSeek: プライベート・ローカル Manus 代替 - Fosowl/agenticSeek</title>

    <!-- Primary Meta Tags -->
    <meta name="title" content="AgenticSeek: プライベート・ローカル Manus 代替 - Fosowl/agenticSeek">
    <meta name="description" content="Fosowl/agenticSeek - GitHub repository ja documentation and information">
    <meta name="keywords" content="Fosowl, agenticSeek, GitHub, repository, ja documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">

    <!-- Open Graph -->
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/Fosowl/agenticSeek/README-ja.html">
    <meta property="og:title" content="AgenticSeek: プライベート・ローカル Manus 代替 - Fosowl/agenticSeek">
    <meta property="og:description" content="Fosowl/agenticSeek - GitHub repository ja documentation and information">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">

    <!-- Favicon -->
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">

    <!-- Marked.js for Markdown rendering -->
    <script type="text/javascript" async="" src="https://www.statcounter.com/counter/recorder.js"></script><script src="/js/marked.min.js?v=20250613"></script>
    <!-- Highlight.js for code syntax highlighting -->
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <!-- Custom CSS -->
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        /* Layout */
        body {
            display: flex;
            flex-direction: column;
            min-height: 100vh;
        }

        .main-container {
            margin: 0 auto;
            width: 100%;
            max-width: 980px;
            padding: 0 20px;
        }

        @media (max-width: 768px) {
            .main-container {
                padding: 0 15px;
            }
        }

        /* Image size restrictions */
        .markdown-body img {
            max-width: 100%;
            height: auto;
        }

        /* Existing styles */
        .header {
            text-align: center;
            margin-bottom: 30px;
            padding: 20px;
            background-color: #f6f8fa;
            border-bottom: 1px solid #e1e4e8;
            position: relative;
        }

        .back-button {
            position: absolute;
            left: 20px;
            top: 50%;
            transform: translateY(-50%);
            color: #0366d6;
            text-decoration: none;
            display: flex;
            align-items: center;
            font-size: 14px;
            padding: 5px 10px;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            background-color: #fff;
        }

        .back-button:hover {
            background-color: #f6f8fa;
            border-color: #0366d6;
        }

        .back-button::before {
            content: "←";
            margin-right: 5px;
            font-size: 16px;
        }

        .header .links {
            margin-top: 10px;
            font-size: 16px;
        }

        .header .links a {
            color: #0366d6;
            text-decoration: none;
            margin-left: 5px;
        }

        .header .links a:hover {
            text-decoration: underline;
        }
        
        /* Language badges styles */
        .language-badges {
            margin-top: 15px;
            text-align: center;
        }
        .language-badges a {
            display: inline-block;
            margin: 2px;
            text-decoration: none;
        }
        .language-badges img {
            height: 20px;
            border-radius: 3px;
        }
        .language-badges a:hover img {
            opacity: 0.8;
        }
    </style>
</head>

<body>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/Fosowl/agenticSeek" id="githubRepoLink" target="_blank">Fosowl/agenticSeek</a>
        </div>
        <div class="language-badges" id="languageBadges"><a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=en"><img src="https://img.shields.io/badge/EN-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=zh-CN"><img src="https://img.shields.io/badge/简中-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=zh-TW"><img src="https://img.shields.io/badge/繁中-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=ja"><img src="https://img.shields.io/badge/日本語-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=ko"><img src="https://img.shields.io/badge/한국어-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=th"><img src="https://img.shields.io/badge/ไทย-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=fr"><img src="https://img.shields.io/badge/Français-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=de"><img src="https://img.shields.io/badge/Deutsch-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=es"><img src="https://img.shields.io/badge/Español-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=it"><img src="https://img.shields.io/badge/Italiano-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=ru"><img src="https://img.shields.io/badge/Русский-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=pt"><img src="https://img.shields.io/badge/Português-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=nl"><img src="https://img.shields.io/badge/Nederlands-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=pl"><img src="https://img.shields.io/badge/Polski-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=ar"><img src="https://img.shields.io/badge/العربية-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=tr"><img src="https://img.shields.io/badge/Türkçe-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=vi"><img src="https://img.shields.io/badge/Tiếng Việt-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=hi"><img src="https://img.shields.io/badge/हिंदी-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=fa"><img src="https://img.shields.io/badge/فارسی-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Fosowl&amp;project=agenticSeek&amp;lang=id"><img src="https://img.shields.io/badge/Bahasa Indonesia-white" alt="version"></a></div>
    </div>

    <div class="main-container">
        <div class="markdown-body" id="content"><h1>AgenticSeek: プライベート・ローカル Manus 代替</h1>
<p align="center">
<img align="center" src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/agentic_seek_logo.png" width="300" height="300" alt="Agentic Seek Logo">
</p><p>

</p><p>  English | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_CHS.md">中文</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_CHT.md">繁體中文</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_FR.md">Français</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_JP.md">日本語</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_PTBR.md">Português (Brasil)</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_ES.md">Español</a></p>
<ul>
<li><strong>100%ローカルなManus AIの代替。</strong> この音声対応AIアシスタントは、すべてのデータをデバイス上に保持しながら、自律的にウェブを閲覧し、コードを書き、タスクを計画します。ローカル推論モデル向けに最適化されており、完全に自分のハードウェア上で動作し、完全なプライバシーとクラウド依存ゼロを保証します。</li>
</ul>
<p><a href="https://fosowl.github.io/agenticSeek.html"><img src="https://img.shields.io/static/v1?label=Website&amp;message=AgenticSeek&amp;color=blue&amp;style=flat-square" alt="Visit AgenticSeek"></a> <img src="https://img.shields.io/badge/license-GPL--3.0-green" alt="License"> <a href="https://discord.gg/8hGDaME3TC"><img src="https://img.shields.io/badge/Discord-Join%20Us-7289DA?logo=discord&amp;logoColor=white" alt="Discord"></a> <a href="https://x.com/Martin993886460"><img src="https://img.shields.io/twitter/url/https/twitter.com/fosowl.svg?style=social&amp;label=Update%20%40Fosowl" alt="Twitter"></a> <a href="https://github.com/Fosowl/agenticSeek/stargazers"><img src="https://img.shields.io/github/stars/Fosowl/agenticSeek?style=social" alt="GitHub stars"></a></p>
<h3>なぜAgenticSeekなのか？</h3>
<ul>
<li><p>🔒 完全ローカル＆プライベート - すべてがあなたのマシン上で動作します。クラウドなし、データ共有なし。ファイル、会話、検索内容はすべてプライベートに保たれます。</p>
</li>
<li><p>🌐 スマートなウェブブラウジング - AgenticSeekは自動でインターネットを閲覧できます。検索、読取、情報抽出、ウェブフォームへの入力もハンズフリーで可能です。</p>
</li>
<li><p>💻 自律型コーディングアシスタント - コードが必要ですか？Python、C、Go、Javaなどのプログラムを自動で作成、デバッグ、実行できます。</p>
</li>
<li><p>🧠 スマートエージェント選択 - あなたが依頼すれば、自動的に最適なエージェントを選択します。まるで専門家チームが常に助けてくれるようです。</p>
</li>
<li><p>📋 複雑なタスクの計画と実行 - 旅行計画から複雑なプロジェクトまで、大きなタスクをステップに分解し、複数のAIエージェントを使って完遂します。</p>
</li>
<li><p>🎙️ 音声対応 - クリアで高速、未来的な音声認識・テキスト変換機能により、まるでSF映画のAIのように会話できます。（開発中）</p>
</li>
</ul>
<h3><strong>デモ</strong></h3>
<blockquote>
<p><em>agenticSeekプロジェクトを検索し、必要なスキルを調べてからCV_candidates.zipを開き、プロジェクトに最も合致する候補者を教えてください</em></p>
</blockquote>
<p><a href="https://github.com/user-attachments/assets/b8ca60e9-7b3b-4533-840e-08f9ac426316">https://github.com/user-attachments/assets/b8ca60e9-7b3b-4533-840e-08f9ac426316</a></p>
<p>免責事項：このデモに登場する全てのファイル（例：CV_candidates.zip）は完全なフィクションです。私たちは法人ではなく、候補者でなくオープンソースのコントリビューターを募集しています。</p>
<blockquote>
<p>🛠⚠️️ <strong>活発な開発中</strong></p>
</blockquote>
<blockquote>
<p>🙏 このプロジェクトはサイドプロジェクトとして始まり、ロードマップも資金もありません。GitHub Trending入りで想像以上に成長しました。貢献・フィードバック・ご辛抱に深く感謝します。</p>
</blockquote>
<h2>前提条件</h2>
<p>開始する前に、以下のソフトウェアがインストールされていることを確認してください：</p>
<ul>
<li><strong>Git:</strong> リポジトリのクローン用。<a href="https://git-scm.com/downloads">Gitをダウンロード</a></li>
<li><strong>Python 3.10.x:</strong> Python 3.10.xバージョンを強く推奨します。他のバージョンでは依存関係エラーが発生することがあります。<a href="https://www.python.org/downloads/release/python-3100/">Python 3.10をダウンロード</a>（3.10.xバージョンを選択）</li>
<li><strong>Docker Engine &amp; Docker Compose:</strong> SearxNGなどのバンドルサービス用。<ul>
<li>Docker Desktop（Docker Compose V2を含む）をインストール：<a href="https://docs.docker.com/desktop/install/windows-install/">Windows</a> | <a href="https://docs.docker.com/desktop/install/mac-install/">Mac</a> | <a href="https://docs.docker.com/desktop/install/linux-install/">Linux</a></li>
<li>またはLinuxでDocker EngineとDocker Composeを個別にインストール：<a href="https://docs.docker.com/engine/install/">Docker Engine</a> | <a href="https://docs.docker.com/compose/install/">Docker Compose</a>（必ずCompose V2をインストール、例：<code>sudo apt-get install docker-compose-plugin</code>）</li>
</ul>
</li>
</ul>
<h3>1. <strong>リポジトリのクローンとセットアップ</strong></h3>
<pre><code class="language-sh hljs language-bash">git <span class="hljs-built_in">clone</span> https://github.com/Fosowl/agenticSeek.git
<span class="hljs-built_in">cd</span> agenticSeek
<span class="hljs-built_in">mv</span> .env.example .<span class="hljs-built_in">env</span>
</code></pre>
<h3>2. .envファイルの内容を変更</h3>
<pre><code class="language-sh hljs language-bash">SEARXNG_BASE_URL=<span class="hljs-string">"http://127.0.0.1:8080"</span>
REDIS_BASE_URL=<span class="hljs-string">"redis://redis:6379/0"</span>
WORK_DIR=<span class="hljs-string">"/Users/mlg/Documents/workspace_for_ai"</span>
OLLAMA_PORT=<span class="hljs-string">"11434"</span>
LM_STUDIO_PORT=<span class="hljs-string">"1234"</span>
CUSTOM_ADDITIONAL_LLM_PORT=<span class="hljs-string">"11435"</span>
OPENAI_API_KEY=<span class="hljs-string">'optional'</span>
DEEPSEEK_API_KEY=<span class="hljs-string">'optional'</span>
OPENROUTER_API_KEY=<span class="hljs-string">'optional'</span>
TOGETHER_API_KEY=<span class="hljs-string">'optional'</span>
GOOGLE_API_KEY=<span class="hljs-string">'optional'</span>
ANTHROPIC_API_KEY=<span class="hljs-string">'optional'</span>
</code></pre>
<p>必要に応じて <code>.env</code> ファイルを自分の値に更新してください：</p>
<ul>
<li><strong>SEARXNG_BASE_URL</strong>: 変更不要 </li>
<li><strong>REDIS_BASE_URL</strong>: 変更不要 </li>
<li><strong>WORK_DIR</strong>: ローカルマシン上の作業ディレクトリへのパス。AgenticSeekがこれらのファイルを読み書きできます。</li>
<li><strong>OLLAMA_PORT</strong>: Ollamaサービス用のポート番号。</li>
<li><strong>LM_STUDIO_PORT</strong>: LM Studioサービス用のポート番号。</li>
<li><strong>CUSTOM_ADDITIONAL_LLM_PORT</strong>: 追加のカスタムLLMサービス用のポート。</li>
</ul>
<p><strong>APIキーはローカルでLLMを動作させる場合は完全に任意です。本プロジェクトの主目的です。十分なハードウェアがある場合は空欄でOKです。</strong></p>
<h3>3. <strong>Dockerを起動</strong></h3>
<p>Dockerがインストールされ、システムで起動していることを確認してください。以下のコマンドでDockerを起動できます：</p>
<ul>
<li><p><strong>Linux/macOSの場合:</strong><br>  ターミナルを開いて以下を実行：</p>
<pre><code class="language-sh hljs language-bash">sudo systemctl start docker
</code></pre>
<p>  または、インストール済みの場合はアプリケーションメニューからDocker Desktopを起動。</p>
</li>
<li><p><strong>Windowsの場合:</strong><br>  スタートメニューからDocker Desktopを起動。</p>
</li>
</ul>
<p>Dockerが動作しているかを確認するには、以下を実行：</p>
<pre><code class="language-sh hljs language-bash">docker info
</code></pre>
<p>Dockerインストール情報が表示されれば、正常に動作しています。</p>
<p>下記の<a href="#list-of-local-providers">ローカルプロバイダー一覧</a>を参照してください。</p>
<p>次のステップ：<a href="#start-services-and-run">AgenticSeekをローカルで実行</a></p>
<p><em>問題が発生した場合は<a href="#troubleshooting">トラブルシューティング</a>セクションを参照してください。</em><br><em>ハードウェアがローカルLLMに対応していない場合は<a href="#setup-to-run-with-an-api">APIでの実行セットアップ</a>を参照してください。</em><br><em>詳しい<code>config.ini</code>の説明は<a href="#config">Configセクション</a>を参照してください。</em></p>
<hr>
<h2>LLMをローカルマシンで実行するセットアップ</h2>
<p><strong>ハードウェア要件:</strong></p>
<p>LLMをローカルで動作させるには十分なハードウェアが必要です。最低でもMagistral、Qwen、Deepseek 14Bが動作するGPUが必要です。詳しいモデル・パフォーマンスの推奨はFAQを参照してください。</p>
<p><strong>ローカルプロバイダーの起動</strong></p>
<p>例としてollamaを起動する場合：</p>
<pre><code class="language-sh hljs language-bash">ollama serve
</code></pre>
<p>対応するローカルプロバイダーの一覧は下記参照。</p>
<p><strong>config.iniの更新</strong></p>
<p>config.iniファイルのprovider_nameを対応プロバイダーに、provider_modelを利用したいLLMモデル名に設定します。推論モデル（<em>Magistral</em>や<em>Deepseek</em>など）を推奨します。</p>
<p>必要ハードウェアはREADME末尾の<strong>FAQ</strong>参照。</p>
<pre><code class="language-sh hljs language-bash">[MAIN]
is_local = True <span class="hljs-comment"># ローカルまたはリモートプロバイダーの使用を選択</span>
provider_name = ollama <span class="hljs-comment"># lm-studio, openaiなども可</span>
provider_model = deepseek-r1:14b <span class="hljs-comment"># ハードウェアに合ったモデルを選択</span>
provider_server_address = 127.0.0.1:11434
agent_name = Jarvis <span class="hljs-comment"># AIの名前</span>
recover_last_session = True <span class="hljs-comment"># 前回セッションの復元</span>
save_session = True <span class="hljs-comment"># 現在のセッションを保存</span>
speak = False <span class="hljs-comment"># テキスト読み上げ</span>
listen = False <span class="hljs-comment"># 音声認識（CLIのみ、実験的）</span>
jarvis_personality = False <span class="hljs-comment"># Jarvis風パーソナリティ使用（実験的）</span>
languages = en zh <span class="hljs-comment"># 言語リスト、TTSはリスト先頭をデフォルト使用</span>
[BROWSER]
headless_browser = True <span class="hljs-comment"># CLIでの利用を除き変更不要</span>
stealth_mode = True <span class="hljs-comment"># ブラウザ検出防止のため未検出Seleniumを使用</span>
</code></pre>
<p><strong>注意:</strong></p>
<ul>
<li><p><code>config.ini</code>の書式はコメントをサポートしていません。<br>例の設定をそのままコピー＆ペーストしないでください。コメントがエラーとなります。必要な設定のみ手動で編集してください。</p>
</li>
<li><p>LM-studioでLLMを起動する場合、<code>provider_name</code>を<code>openai</code>に設定しないでください。<code>lm-studio</code>に設定してください。</p>
</li>
<li><p>一部プロバイダー（例：lm-studio）はIPの前に<code>http://</code>が必要です。例：<code>http://127.0.0.1:1234</code></p>
</li>
</ul>
<p><strong>ローカルプロバイダー一覧</strong></p>
<table>
<thead>
<tr>
<th>プロバイダー</th>
<th>ローカル対応</th>
<th>説明</th>
</tr>
</thead>
<tbody><tr>
<td>ollama</td>
<td>はい</td>
<td>ollamaをLLMプロバイダーとして使い、簡単にローカルLLM実行</td>
</tr>
<tr>
<td>lm-studio</td>
<td>はい</td>
<td>LM StudioでローカルLLM実行（<code>provider_name</code>は<code>lm-studio</code>に設定）</td>
</tr>
<tr>
<td>openai</td>
<td>はい</td>
<td>openai互換API使用（例：llama.cppサーバー）</td>
</tr>
</tbody></table>
<p>次のステップ：<a href="#Start-services-and-Run">AgenticSeekのサービス開始・実行</a>  </p>
<p><em>問題が発生した場合は<a href="#troubleshooting">トラブルシューティング</a>セクションを参照してください。</em><br><em>ハードウェアがローカルLLMに対応していない場合は<a href="#setup-to-run-with-an-api">APIでの実行セットアップ</a>を参照してください。</em><br><em>詳しい<code>config.ini</code>の説明は<a href="#config">Configセクション</a>を参照してください。</em></p>
<h2>APIでの実行セットアップ</h2>
<p>このセットアップでは、外部クラウドベースのLLMプロバイダーを利用します。選択したサービスのAPIキーが必要です。</p>
<p><strong>1. APIプロバイダーを選択しAPIキーを取得:</strong></p>
<p><a href="#list-of-api-providers">APIプロバイダー一覧</a>を参照し、各ウェブサイトでサインアップしAPIキーを取得してください。</p>
<p><strong>2. APIキーを環境変数として設定:</strong></p>
<ul>
<li><strong>Linux/macOS:</strong><br>ターミナルを開き、<code>export</code>コマンドを利用。永続化にはシェルのプロファイルファイル（例：<code>~/.bashrc</code>, <code>~/.zshrc</code>）に追加するのが最適です。<pre><code class="language-sh hljs language-bash"><span class="hljs-built_in">export</span> PROVIDER_API_KEY=<span class="hljs-string">"your_api_key_here"</span> 
<span class="hljs-comment"># PROVIDER_API_KEYは各サービスの変数名（例：OPENAI_API_KEY, GOOGLE_API_KEY）に置き換えてください</span>
</code></pre>
TogetherAIの例：<pre><code class="language-sh hljs language-bash"><span class="hljs-built_in">export</span> TOGETHER_API_KEY=<span class="hljs-string">"xxxxxxxxxxxxxxxxxxxxxx"</span>
</code></pre>
</li>
<li><strong>Windows:</strong></li>
<li><strong>コマンドプロンプト（現在のセッションのみ一時的に設定）:</strong><pre><code class="language-cmd">set PROVIDER_API_KEY=your_api_key_here
</code></pre>
</li>
<li><strong>PowerShell（現在のセッションのみ一時的に設定）:</strong><pre><code class="language-powershell">$env:PROVIDER_API_KEY="your_api_key_here"
</code></pre>
</li>
<li><strong>永続的に設定:</strong> Windowsの検索バーで「環境変数」と検索し、「システム環境変数の編集」をクリックして、「環境変数...」ボタンを押します。適切な名前（例: <code>OPENAI_API_KEY</code>）と値（APIキー）で新しいユーザー変数を追加してください。</li>
</ul>
<p><em>（詳細はFAQ: <a href="#how-do-i-set-api-keys">APIキーの設定方法</a> を参照してください）。</em></p>
<p><strong>3. <code>config.ini</code> の更新:</strong></p>
<pre><code class="language-ini hljs"><span class="hljs-section">[MAIN]</span>
<span class="hljs-attr">is_local</span> = <span class="hljs-literal">False</span>
<span class="hljs-attr">provider_name</span> = openai <span class="hljs-comment"># または google, deepseek, togetherAI, huggingface</span>
<span class="hljs-attr">provider_model</span> = gpt-<span class="hljs-number">3.5</span>-turbo <span class="hljs-comment"># または gemini-1.5-flash, deepseek-chat, mistralai/Mixtral-8x7B-Instruct-v0.1 など</span>
provider_server_address = <span class="hljs-comment"># 通常、is_local = False の場合はほとんどのAPIで無視されるか空欄でOK</span>
<span class="hljs-comment"># ... その他の設定 ...</span>
</code></pre>
<p><em>警告:</em> <code>config.ini</code> の値に末尾スペースが無いことを確認してください。</p>
<p><strong>APIプロバイダー一覧</strong></p>
<table>
<thead>
<tr>
<th>プロバイダー</th>
<th><code>provider_name</code></th>
<th>ローカル?</th>
<th>説明</th>
<th>APIキーリンク（例）</th>
</tr>
</thead>
<tbody><tr>
<td>OpenAI</td>
<td><code>openai</code></td>
<td>いいえ</td>
<td>OpenAIのAPI経由でChatGPTモデルを使用</td>
<td><a href="https://platform.openai.com/signup">platform.openai.com/signup</a></td>
</tr>
<tr>
<td>Google Gemini</td>
<td><code>google</code></td>
<td>いいえ</td>
<td>Google AI Studio経由でGoogle Geminiモデルを使用</td>
<td><a href="https://aistudio.google.com/keys">aistudio.google.com/keys</a></td>
</tr>
<tr>
<td>Deepseek</td>
<td><code>deepseek</code></td>
<td>いいえ</td>
<td>DeepseekのAPI経由でDeepseekモデルを使用</td>
<td><a href="https://platform.deepseek.com">platform.deepseek.com</a></td>
</tr>
<tr>
<td>Hugging Face</td>
<td><code>huggingface</code></td>
<td>いいえ</td>
<td>Hugging Face Inference API経由でモデルを使用</td>
<td><a href="https://huggingface.co/settings/tokens">huggingface.co/settings/tokens</a></td>
</tr>
<tr>
<td>TogetherAI</td>
<td><code>togetherAI</code></td>
<td>いいえ</td>
<td>TogetherAI API経由で様々なOSSモデルを利用可能</td>
<td><a href="https://api.together.ai/settings/api-keys">api.together.ai/settings/api-keys</a></td>
</tr>
</tbody></table>
<p><em>注意:</em></p>
<ul>
<li>複雑なウェブブラウジングやタスク計画には、現在のプロンプト最適化はDeepseek向けのため、<code>gpt-4o</code>や他のOpenAIモデルの利用は推奨しません。</li>
<li>コーディングやbashのタスクはGeminiではDeepseek向けの書式に厳密に従わない可能性があり、問題が発生する場合があります。</li>
<li><code>config.ini</code> の <code>provider_server_address</code> は、<code>is_local = False</code> の場合、APIエンドポイントが各プロバイダーのライブラリでハードコーディングされているため通常使用しません。</li>
</ul>
<p>次のステップ: <a href="#Start-services-and-Run">サービスの起動とAgenticSeekの実行</a></p>
<p><em>問題が発生した場合は「<strong>既知の問題</strong>」セクションを参照してください。</em></p>
<p><em>詳細な設定ファイルの説明は「<strong>Config</strong>」セクションを参照してください。</em></p>
<hr>
<h2>サービスの起動と実行</h2>
<p>デフォルトでは、AgenticSeekはすべてDocker内で実行されます。</p>
<p>必要なサービスを起動します。これによりdocker-compose.ymlから以下のすべてのサービスが起動します:<br>    - searxng<br>    - redis（searxngに必須）<br>    - frontend<br>    - backend（<code>full</code>を使用する場合）</p>
<pre><code class="language-sh hljs language-bash">./start_services.sh full <span class="hljs-comment"># MacOS</span>
start ./start_services.cmd full <span class="hljs-comment"># Window</span>
</code></pre>
<p><strong>警告:</strong> このステップで全てのDockerイメージのダウンロード・ロードが行われ、最大30分かかる場合があります。サービス起動後、バックエンドサービスが完全に起動するまで（ログに <strong>backend: "GET /health HTTP/1.1" 200 OK</strong> と表示されるまで）メッセージの送信はお待ちください。初回起動時はバックエンドサービスの起動に最大5分かかることがあります。</p>
<p><code>http://localhost:3000/</code> にアクセスするとWebインターフェースが表示されます。</p>
<p><em>サービス起動時のトラブルシューティング:</em> これらのスクリプトが失敗する場合は、Docker Engineが起動しており、Docker Compose（V2, <code>docker compose</code>）が正しくインストールされていることを確認してください。エラーメッセージは端末の出力を確認してください。<a href="#faq-troubleshooting">FAQ: AgenticSeekやスクリプト実行時にエラーが出る場合の対処法</a>も参照してください。</p>
<p><strong>オプション:</strong> ホスト（CLIモード）での実行</p>
<p>CLIインターフェースで実行するには、ホストにパッケージをインストールしてください:</p>
<pre><code class="language-sh hljs language-bash">./install.sh
./install.bat <span class="hljs-comment"># windows</span>
</code></pre>
<p>サービスを起動します:</p>
<pre><code class="language-sh hljs language-bash">./start_services.sh <span class="hljs-comment"># MacOS</span>
start ./start_services.cmd <span class="hljs-comment"># Window</span>
</code></pre>
<p>CLIの利用: <code>python3 cli.py</code></p>
<hr>
<h2>利用方法</h2>
<p><code>./start_services.sh full</code> でサービスが稼働していることを確認し、Webインターフェースは <code>localhost:3000</code> で利用できます。</p>
<p>CLIモードのみ、configで <code>listen = True</code> に設定することで音声認識（speech to text）も利用可能です。</p>
<p>終了するには、単に <code>goodbye</code> と発話または入力してください。</p>
<p>利用例:</p>
<blockquote>
<p><em>pythonでスネークゲームを作って！</em></p>
</blockquote>
<blockquote>
<p><em>フランス・レンヌのトップカフェをWeb検索し、3つを住所付きでrennes_cafes.txtに保存して。</em></p>
</blockquote>
<blockquote>
<p><em>Goで階乗を計算するプログラムを書き、factorial.goとしてワークスペースに保存して</em></p>
</blockquote>
<blockquote>
<p><em>summer_picturesフォルダー内の全JPGファイルを今日の日付でリネームし、リネーム後のファイル一覧をphotos_list.txtに保存</em></p>
</blockquote>
<blockquote>
<p><em>2024年の人気SF映画をネットで調べて、今夜観る3本を選んで。リストをmovie_night.txtに保存。</em></p>
</blockquote>
<blockquote>
<p><em>2025年の最新AIニュース記事をネット検索し、3つ選んで、それらのタイトルと要約をスクレイピングするPythonスクリプトを書いて。スクリプトはnews_scraper.py、要約は/home/projectsのai_news.txtに保存</em></p>
</blockquote>
<blockquote>
<p><em>金曜日、無料の株価APIをWebで探し、<a href="mailto:supersuper7434567@gmail.com">supersuper7434567@gmail.com</a>で登録、そのAPIでテスラの日次株価を取得するPythonスクリプトを書いて、結果をstock_prices.csvに保存</em></p>
</blockquote>
<p><em>なお、フォーム入力の自動化は実験的機能のため失敗する場合があります。</em></p>
<p>クエリを入力すると、AgenticSeekがタスクに最適なエージェントを割り当てます。</p>
<p>本プロトタイプは初期段階のため、エージェントルーティングが必ずしも最適なものとは限りません。</p>
<p>そのため、AIにしてほしいことや進め方をできるだけ明確に伝えてください。例えばWeb検索させたい場合は、</p>
<p><code>Do you know some good countries for solo-travel?</code></p>
<p>のように曖昧にせず、</p>
<p><code>Do a web search and find out which are the best country for solo-travel</code></p>
<p>のように具体的に指示しましょう。</p>
<hr>
<h2><strong>LLMを自分のサーバーで動かす設定</strong></h2>
<p>高性能なコンピュータやサーバーがあり、それをノートPCから利用したい場合は、独自のllmサーバーでLLMをリモート実行できます。</p>
<p>AIモデルを動かす「サーバー」でIPアドレスを取得します。</p>
<pre><code class="language-sh hljs language-bash">ip a | grep <span class="hljs-string">"inet "</span> | grep -v 127.0.0.1 | awk <span class="hljs-string">'{print $2}'</span> | <span class="hljs-built_in">cut</span> -d/ -f1 <span class="hljs-comment"># ローカルIP</span>
curl https://ipinfo.io/ip <span class="hljs-comment"># グローバルIP</span>
</code></pre>
<p>注: WindowsやmacOSの場合は、それぞれipconfigやifconfigでIPアドレスを確認してください。</p>
<p>リポジトリをクローンし、<code>server/</code>フォルダーに移動します。</p>
<pre><code class="language-sh hljs language-bash">git <span class="hljs-built_in">clone</span> --depth 1 https://github.com/Fosowl/agenticSeek.git
<span class="hljs-built_in">cd</span> agenticSeek/llm_server/
</code></pre>
<p>サーバー用の要件をインストール:</p>
<pre><code class="language-sh hljs language-bash">pip3 install -r requirements.txt
</code></pre>
<p>サーバースクリプトを実行します。</p>
<pre><code class="language-sh hljs language-bash">python3 app.py --provider ollama --port 3333
</code></pre>
<p><code>ollama</code>または<code>llamacpp</code>をLLMサービスとして利用可能です。</p>
<p>次に、個人PC側で:</p>
<p><code>config.ini</code>ファイルの<code>provider_name</code>を<code>server</code>、<code>provider_model</code>を<code>deepseek-r1:xxb</code>に設定します。<br><code>provider_server_address</code>にはモデルを動かすマシンのIPアドレスを設定します。</p>
<pre><code class="language-sh hljs language-bash">[MAIN]
is_local = False
provider_name = server
provider_model = deepseek-r1:70b
provider_server_address = x.x.x.x:3333
</code></pre>
<p>次のステップ: <a href="#Start-services-and-Run">サービスの起動とAgenticSeekの実行</a>  </p>
<hr>
<h2>音声認識（Speech to Text）</h2>
<p>注意: 音声認識は現状CLIモードのみ対応です。</p>
<p>現時点では音声認識は英語のみ対応しています。</p>
<p>音声認識はデフォルトで無効です。有効にするには、config.iniのlistenオプションをTrueに設定してください:</p>
<pre><code class="hljs language-ini"><span class="hljs-attr">listen</span> = <span class="hljs-literal">True</span>
</code></pre>
<p>有効にすると、音声認識は入力処理の前にトリガーワード（エージェント名）を待ち受けます。エージェント名は<em>config.ini</em>ファイルの <code>agent_name</code> 値を更新してカスタマイズできます:</p>
<pre><code class="hljs language-ini"><span class="hljs-attr">agent_name</span> = Friday
</code></pre>
<p>最適な認識のため、エージェント名には「John」や「Emma」などの一般的な英語名を使用することを推奨します。</p>
<p>トランスクリプトが表示され始めたら、エージェント名（例：「Friday」）を声に出して呼びかけて起動します。</p>
<p>質問ははっきりと話してください。</p>
<p>リクエストの最後に、システムに処理を進めるよう伝える確認フレーズを付けてください。確認フレーズの例：</p>
<pre><code class="hljs language-bash"><span class="hljs-string">"do it"</span>, <span class="hljs-string">"go ahead"</span>, <span class="hljs-string">"execute"</span>, <span class="hljs-string">"run"</span>, <span class="hljs-string">"start"</span>, <span class="hljs-string">"thanks"</span>, <span class="hljs-string">"would ya"</span>, <span class="hljs-string">"please"</span>, <span class="hljs-string">"okay?"</span>, <span class="hljs-string">"proceed"</span>, <span class="hljs-string">"continue"</span>, <span class="hljs-string">"go on"</span>, <span class="hljs-string">"do that"</span>, <span class="hljs-string">"go it"</span>, <span class="hljs-string">"do you understand?"</span>
</code></pre>
<h2>Config</h2>
<p>設定例：</p>
<pre><code class="hljs language-ini"><span class="hljs-section">[MAIN]</span>
<span class="hljs-attr">is_local</span> = <span class="hljs-literal">True</span>
<span class="hljs-attr">provider_name</span> = ollama
<span class="hljs-attr">provider_model</span> = deepseek-r1:<span class="hljs-number">32</span>b
<span class="hljs-attr">provider_server_address</span> = http://<span class="hljs-number">127.0</span>.<span class="hljs-number">0.1</span>:<span class="hljs-number">11434</span> <span class="hljs-comment"># Ollamaの場合の例。LM-Studioの場合は http://127.0.0.1:1234</span>
<span class="hljs-attr">agent_name</span> = Friday
<span class="hljs-attr">recover_last_session</span> = <span class="hljs-literal">False</span>
<span class="hljs-attr">save_session</span> = <span class="hljs-literal">False</span>
<span class="hljs-attr">speak</span> = <span class="hljs-literal">False</span>
<span class="hljs-attr">listen</span> = <span class="hljs-literal">False</span>

<span class="hljs-attr">jarvis_personality</span> = <span class="hljs-literal">False</span>
<span class="hljs-attr">languages</span> = en zh <span class="hljs-comment"># TTSやルーティングに利用する言語リスト</span>
<span class="hljs-section">[BROWSER]</span>
<span class="hljs-attr">headless_browser</span> = <span class="hljs-literal">False</span>
<span class="hljs-attr">stealth_mode</span> = <span class="hljs-literal">False</span>
</code></pre>
<p><strong><code>config.ini</code> 設定の説明</strong>:</p>
<ul>
<li><strong><code>[MAIN]</code> セクション:</strong><ul>
<li><code>is_local</code>: ローカルLLMプロバイダ（Ollama、LM-Studio、OpenAI互換ローカルサーバー、セルフホスト型サーバー）を使用する場合は <code>True</code>。クラウドAPI（OpenAI、Google等）は <code>False</code>。</li>
<li><code>provider_name</code>: LLMプロバイダーを指定します。<ul>
<li>ローカル: <code>ollama</code>, <code>lm-studio</code>, <code>openai</code>（OpenAI互換ローカルサーバー用）, <code>server</code>（セルフホストサーバー用）</li>
<li>API: <code>openai</code>, <code>google</code>, <code>deepseek</code>, <code>huggingface</code>, <code>togetherAI</code></li>
</ul>
</li>
<li><code>provider_model</code>: 選択したプロバイダー用のモデル名またはID（例：Ollamaなら <code>deepseekcoder:6.7b</code>、OpenAI APIなら <code>gpt-3.5-turbo</code>、TogetherAIなら <code>mistralai/Mixtral-8x7B-Instruct-v0.1</code>）</li>
<li><code>provider_server_address</code>: LLMプロバイダーのアドレス<ul>
<li>ローカル: 例 <code>http://127.0.0.1:11434</code>（Ollama）、<code>http://127.0.0.1:1234</code>（LM-Studio）</li>
<li><code>server</code> プロバイダーの場合: セルフホストLLMサーバーのアドレス（例：<code>http://your_server_ip:3333</code>）</li>
<li>クラウドAPI（<code>is_local = False</code>）の場合：多くは無視されるか空欄でOK。APIエンドポイントはクライアントライブラリが管理します。</li>
</ul>
</li>
<li><code>agent_name</code>: AIアシスタントの名前（例：Friday）。音声認識トリガーワードとして使用。</li>
<li><code>recover_last_session</code>: 前回セッションの状態を復元する場合は <code>True</code>、新規開始は <code>False</code></li>
<li><code>save_session</code>: 現在のセッション状態を保存する場合は <code>True</code></li>
<li><code>speak</code>: テキスト読み上げ音声出力を有効にする場合は <code>True</code></li>
<li><code>listen</code>: 音声入力（CLIモードのみ）を有効にする場合は <code>True</code></li>
<li><code>work_dir</code>: <strong>重要:</strong> AgenticSeekがファイルの読み書きを行うディレクトリ。<strong>このパスが有効かつアクセス可能であることを確認してください。</strong></li>
<li><code>jarvis_personality</code>: "Jarvis風" のシステムプロンプトを使う場合は <code>True</code>（実験的）、標準プロンプトは <code>False</code></li>
<li><code>languages</code>: カンマ区切りの言語リスト（例：<code>en, zh, fr</code>）。TTS音声選択（最初がデフォルト）やLLMルーターに利用。効率化のため、似すぎた言語や多すぎる言語は避けてください。</li>
</ul>
</li>
<li><strong><code>[BROWSER]</code> セクション:</strong><ul>
<li><code>headless_browser</code>: ウィンドウを表示せず自動化ブラウザを実行する場合は <code>True</code>（ウェブインターフェースや非対話用途推奨）。ウィンドウを表示する場合は <code>False</code>（CLIモードやデバッグ用）。</li>
<li><code>stealth_mode</code>: ブラウザ自動化の検出を難しくする機能を有効化する場合は <code>True</code>。anticaptcha等の拡張機能の手動インストールが必要な場合があります。</li>
</ul>
</li>
</ul>
<p>このセクションではサポートされているLLMプロバイダータイプをまとめています。<code>config.ini</code> で設定してください。</p>
<p><strong>ローカルプロバイダー（自身のハードウェア上で実行）:</strong></p>
<table>
<thead>
<tr>
<th><code>config.ini</code>内のプロバイダー名</th>
<th><code>is_local</code></th>
<th>説明</th>
<th>セットアップセクション</th>
</tr>
</thead>
<tbody><tr>
<td><code>ollama</code></td>
<td><code>True</code></td>
<td>OllamaでローカルLLMを提供</td>
<td><a href="#setup-for-running-llm-locally-on-your-machine">ローカル実行のセットアップ</a></td>
</tr>
<tr>
<td><code>lm-studio</code></td>
<td><code>True</code></td>
<td>LM-StudioでローカルLLMを提供</td>
<td><a href="#setup-for-running-llm-locally-on-your-machine">ローカル実行のセットアップ</a></td>
</tr>
<tr>
<td><code>openai</code>（ローカルサーバー用）</td>
<td><code>True</code></td>
<td>OpenAI互換APIを公開するローカルサーバーへ接続（例：llama.cpp）</td>
<td><a href="#setup-for-running-llm-locally-on-your-machine">ローカル実行のセットアップ</a></td>
</tr>
<tr>
<td><code>server</code></td>
<td><code>False</code></td>
<td>他のマシンで動作するAgenticSeekセルフホストLLMサーバーへ接続</td>
<td><a href="#setup-to-run-the-llm-on-your-own-server">独自サーバーでのセットアップ</a></td>
</tr>
</tbody></table>
<p><strong>APIプロバイダー（クラウドベース）:</strong></p>
<table>
<thead>
<tr>
<th><code>config.ini</code>内のプロバイダー名</th>
<th><code>is_local</code></th>
<th>説明</th>
<th>セットアップセクション</th>
</tr>
</thead>
<tbody><tr>
<td><code>openai</code></td>
<td><code>False</code></td>
<td>OpenAI公式API（例：GPT-3.5, GPT-4）利用</td>
<td><a href="#setup-to-run-with-an-api">API利用セットアップ</a></td>
</tr>
<tr>
<td><code>google</code></td>
<td><code>False</code></td>
<td>Google GeminiモデルをAPI経由で利用</td>
<td><a href="#setup-to-run-with-an-api">API利用セットアップ</a></td>
</tr>
<tr>
<td><code>deepseek</code></td>
<td><code>False</code></td>
<td>Deepseek公式API利用</td>
<td><a href="#setup-to-run-with-an-api">API利用セットアップ</a></td>
</tr>
<tr>
<td><code>huggingface</code></td>
<td><code>False</code></td>
<td>Hugging Face Inference API利用</td>
<td><a href="#setup-to-run-with-an-api">API利用セットアップ</a></td>
</tr>
<tr>
<td><code>togetherAI</code></td>
<td><code>False</code></td>
<td>TogetherAIのAPIで様々なオープンモデルを利用</td>
<td><a href="#setup-to-run-with-an-api">API利用セットアップ</a></td>
</tr>
</tbody></table>
<hr>
<h2>トラブルシューティング</h2>
<p>問題が発生した場合、このセクションがガイドとなります。</p>
<h1>既知の問題</h1>
<h2>ChromeDriverの問題</h2>
<p><strong>エラー例:</strong> <code>SessionNotCreatedException: Message: session not created: This version of ChromeDriver only supports Chrome version XXX</code></p>
<ul>
<li><strong>原因:</strong> インストール済みのChromeDriverのバージョンがGoogle Chromeブラウザのバージョンと互換性がありません。</li>
<li><strong>解決策:</strong><ol>
<li><strong>Chromeバージョンの確認:</strong> Google Chromeを開き、<code>設定 &gt; Chromeについて</code> でバージョン（例："Version 120.0.6099.110"）を確認。</li>
<li><strong>対応するChromeDriverをダウンロード:</strong><ul>
<li>Chrome 115以降の場合: <a href="https://googlechromelabs.github.io/chrome-for-testing/">Chrome for Testing (CfT) JSON Endpoints</a>で「stable」チャンネルを探し、ご自身のOSに合ったChromeのメジャーバージョンに一致するChromeDriverをダウンロード。</li>
<li>旧バージョン（稀）: <a href="https://chromedriver.chromium.org/downloads">ChromeDriver - WebDriver for Chrome</a>ページを参照。</li>
<li>下記画像はCfTページの例です:<br><img src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/chromedriver_readme.png" alt="Download Chromedriver specific version from Chrome for Testing page"></li>
</ul>
</li>
<li><strong>ChromeDriverのインストール:</strong><ul>
<li>ダウンロードした <code>chromedriver</code>（Windowsの場合は <code>chromedriver.exe</code>）を、システムのPATH環境変数に含まれるディレクトリ（例：Linux/macOSは <code>/usr/local/bin</code>、WindowsはPATHに追加したカスタムスクリプトフォルダ等）に配置。</li>
<li>もしくは、<code>agenticSeek</code> プロジェクトのルートディレクトリに配置。</li>
<li>実行権限を付与（例：Linux/macOSは <code>chmod +x chromedriver</code>）。</li>
</ul>
</li>
<li>詳細はインストールガイド内 <a href="#chromedriver-installation">ChromeDriver Installation</a> セクションを参照。</li>
</ol>
</li>
</ul>
<p>このセクションが不完全な場合や他のChromeDriver問題が発生した場合、<a href="https://github.com/Fosowl/agenticSeek/issues">GitHub Issues</a> で既存の内容を検索、または新規Issueを作成してください。</p>
<p><code>Exception: Failed to initialize browser: Message: session not created: This version of ChromeDriver only supports Chrome version 113 Current browser version is 134.0.6998.89 with binary path</code></p>
<p>このエラーはブラウザとchromedriverのバージョンが一致していない場合に発生します。</p>
<p>以下から最新バージョンをダウンロードしてください：</p>
<p><a href="https://developer.chrome.com/docs/chromedriver/downloads">https://developer.chrome.com/docs/chromedriver/downloads</a></p>
<p>Chrome バージョン115以降の場合はこちら：</p>
<p><a href="https://googlechromelabs.github.io/chrome-for-testing/">https://googlechromelabs.github.io/chrome-for-testing/</a></p>
<p>ご自身のOSに合ったchromedriverバージョンをダウンロードしてください。</p>
<p><img src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/chromedriver_readme.png" alt="alt text"></p>
<p>このセクションが不完全な場合はIssueを作成してください。</p>
<h2>connection adapters の問題</h2>
<pre><code class="hljs language-php"><span class="hljs-built_in">Exception</span>: Provider lm-studio failed: HTTP request failed: No connection adapters were found <span class="hljs-keyword">for</span> <span class="hljs-string">'127.0.0.1:1234/v1/chat/completions'</span>` (Note: port may vary)
</code></pre>
<ul>
<li><strong>原因:</strong> <code>lm-studio</code>（または同様のOpenAI互換ローカルサーバー）用に <code>config.ini</code> の <code>provider_server_address</code> に <code>http://</code> プレフィックスがない、またはポートが誤っています。</li>
<li><strong>解決策:</strong><ul>
<li>アドレスが <code>http://</code> を含んでいることを確認。LM-Studioは通常 <code>http://127.0.0.1:1234</code> がデフォルトです。</li>
<li><code>config.ini</code>の修正例：<code>provider_server_address = http://127.0.0.1:1234</code>（ご利用のLM-Studioサーバーのポートに合わせて修正）</li>
</ul>
</li>
</ul>
<h2>SearxNG Base URL未指定</h2>
<pre><code class="hljs language-csharp"><span class="hljs-function">raise <span class="hljs-title">ValueError</span>(<span class="hljs-params"><span class="hljs-string">"SearxNG base URL must be provided either as an argument or via the SEARXNG_BASE_URL environment variable."</span></span>)
ValueError: SearxNG <span class="hljs-keyword">base</span> URL must be provided either <span class="hljs-keyword">as</span> an argument <span class="hljs-keyword">or</span> via the SEARXNG_BASE_URL environment variable.`
</span></code></pre>
<h2>FAQ</h2>
<p><strong>Q: 必要なハードウェアは？</strong>  </p>
<table>
<thead>
<tr>
<th>モデルサイズ</th>
<th>GPU</th>
<th>コメント</th>
</tr>
</thead>
<tbody><tr>
<td>7B</td>
<td>8GB Vram</td>
<td>⚠️ 推奨しません。パフォーマンスが悪く、幻覚も多く、プランナーエージェントはほぼ失敗します。</td>
</tr>
<tr>
<td>14B</td>
<td>12GB VRAM (例：RTX 3060)</td>
<td>✅ 簡単なタスクには使用可能。ウェブブラウジングや計画タスクにはやや力不足。</td>
</tr>
<tr>
<td>32B</td>
<td>24GB以上VRAM (例：RTX 4090)</td>
<td>🚀 ほとんどのタスクで成功。ただしタスクプランニングはやや苦手な場合あり。</td>
</tr>
<tr>
<td>70B以上</td>
<td>48GB以上VRAM</td>
<td>💪 優秀。高度な用途に推奨。</td>
</tr>
</tbody></table>
<p><strong>Q: エラーが出た場合は？</strong>  </p>
<p>ローカルが起動中（<code>ollama serve</code>）、<code>config.ini</code>がプロバイダーに一致、依存関係がインストール済みであることを確認。それでも解決しない場合はIssueを作成してください。</p>
<p><strong>Q: 本当に100％ローカル実行できる？</strong>  </p>
<p>Ollama、lm-studioまたはserverプロバイダー利用時は、音声認識・LLM・TTSモデルすべてローカル動作します。非ローカル（OpenAI等API）はオプションです。</p>
<p><strong>Q: ManusがあるのにAgenticSeekを使う理由は？</strong></p>
<p>Manusと異なり、AgenticSeekは外部システム依存を最小化し、より多くのコントロールやプライバシー、APIコスト回避を重視しています。</p>
<p><strong>Q: プロジェクトの運営者は？</strong></p>
<p>このプロジェクトは私と、オープンソースコミュニティの2人の友人（メンテナー兼コントリビューター）で開発しています。私たちはスタートアップや組織所属ではなく、情熱を持った個人の集まりです。</p>
<p>私の個人アカウント（<a href="https://x.com/Martin993886460%EF%BC%89%E4%BB%A5%E5%A4%96%E3%81%AEAgenticSeek%E5%90%8D%E7%BE%A9%E3%81%AEX%E3%82%A2%E3%82%AB%E3%82%A6%E3%83%B3%E3%83%88%E3%81%AF%E3%81%AA%E3%82%8A%E3%81%99%E3%81%BE%E3%81%97%E3%81%A7%E3%81%99%E3%80%82">https://x.com/Martin993886460）以外のAgenticSeek名義のXアカウントはなりすましです。</a></p>
<h2>貢献について</h2>
<p>AgenticSeekの開発にご協力いただける開発者を募集中です！オープンなIssueやディスカッションをご覧ください。</p>
<p><a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/docs/CONTRIBUTING.md">貢献ガイド</a></p>
<p><a href="https://www.star-history.com/#Fosowl/agenticSeek&amp;Date"><img src="https://api.star-history.com/svg?repos=Fosowl/agenticSeek&amp;type=Date" alt="Star History Chart"></a></p>
<h2>メンテナー:</h2>
<blockquote>
<p><a href="https://github.com/Fosowl">Fosowl</a> | パリ時間</p>
</blockquote>
<blockquote>
<p><a href="https://github.com/antoineVIVIES">antoineVIVIES</a> | 台北時間</p>
</blockquote>
<blockquote>
<p><a href="https://github.com/steveh8758">steveh8758</a> | 台北時間</p>
</blockquote>
<h2>スペシャルサンクス:</h2>
<blockquote>
<p><a href="https://github.com/tcsenpai">tcsenpai</a> および <a href="https://github.com/plitc">plitc</a> バックエンドのDocker化にご協力いただきました</p>
</blockquote>
<h2>スポンサー:</h2>
<p>月額5ドル以上のスポンサー様（順不同）:</p>
<ul>
<li><strong>tatra-labs</strong></li>
</ul>
<p>It appears that you have not provided the content of Part 4 of 4 for translation. Please paste the text you would like translated, and I will proceed as instructed.</p>
<hr>
<p>Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx">Open Ai Tx</a> | Last indexed: 2025-06-16</p>
<hr>
</div>
    </div>

    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async=""></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
    


</body></html>