<!DOCTYPE html>
<html lang="vi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>agenticSeek - Fosowl/agenticSeek</title>
    <meta name="title" content="agenticSeek - Fosowl/agenticSeek">
    <meta name="description" content="Fosowl/agenticSeek - GitHub repository vi documentation and informationAgenticSeek: Giải pháp thay thế Manus riêng tư, cục bộ. English | 中文 | 繁體中文 | Français | 日本語 | Português (Brasil) | Español Một giải pháp thay thế Manus AI 100%...">
    <meta name="keywords" content="Fosowl, agenticSeek, GitHub, repository, vi documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/Fosowl/agenticSeek/README-vi.html">
    <meta property="og:title" content="agenticSeek - Fosowl/agenticSeek">
    <meta property="og:description" content="Fosowl/agenticSeek - GitHub repository vi documentation and information">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/Fosowl/agenticSeek" id="githubRepoLink" target="_blank">Fosowl/agenticSeek</a>
<h1 style="display: none;">AgenticSeek: Giải pháp thay thế Manus riêng tư, cục bộ. English | 中文 | 繁體中文 | Français | 日本語 | Português (Brasil) | Español Một giải pháp thay thế Manus AI 100%...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <h1>AgenticSeek: Giải pháp thay thế Manus riêng tư, cục bộ.</h1>
<p align="center">
<img align="center" src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/agentic_seek_logo.png" width="300" height="300" alt="Agentic Seek Logo">
<p>
<p>English | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_CHS.md">中文</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_CHT.md">繁體中文</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_FR.md">Français</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_JP.md">日本語</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_PTBR.md">Português (Brasil)</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_ES.md">Español</a></p>
<p><em>Một <strong>giải pháp thay thế Manus AI 100% cục bộ</strong>, trợ lý AI kích hoạt giọng nói này tự động duyệt web, viết mã, và lập kế hoạch công việc, đồng thời giữ tất cả dữ liệu trên thiết bị của bạn. Tối ưu cho các mô hình suy luận cục bộ, chương trình chạy hoàn toàn trên phần cứng của bạn, đảm bảo quyền riêng tư tuyệt đối và không phụ thuộc vào đám mây.</em></p>
<p><a href="https://fosowl.github.io/agenticSeek.html"><img src="https://img.shields.io/static/v1?label=Website&amp;message=AgenticSeek&amp;color=blue&amp;style=flat-square" alt="Truy cập AgenticSeek" /></a> <img src="https://img.shields.io/badge/license-GPL--3.0-green" alt="License" /> <a href="https://discord.gg/8hGDaME3TC"><img src="https://img.shields.io/badge/Discord-Join%20Us-7289DA?logo=discord&amp;logoColor=white" alt="Discord" /></a> <a href="https://x.com/Martin993886460"><img src="https://img.shields.io/twitter/url/https/twitter.com/fosowl.svg?style=social&amp;label=Update%20%40Fosowl" alt="Twitter" /></a> <a href="https://github.com/Fosowl/agenticSeek/stargazers"><img src="https://img.shields.io/github/stars/Fosowl/agenticSeek?style=social" alt="GitHub stars" /></a></p>
<h3>Vì sao chọn AgenticSeek?</h3>
<ul>
<li><p>🔒 Hoàn toàn cục bộ &amp; riêng tư - Mọi thứ đều chạy trên máy của bạn — không đám mây, không chia sẻ dữ liệu. Tệp tin, cuộc trò chuyện, và tìm kiếm của bạn luôn được bảo mật.</p>
</li>
<li><p>🌐 Duyệt web thông minh - AgenticSeek có thể tự động duyệt web — tìm kiếm, đọc, trích xuất thông tin, điền biểu mẫu — hoàn toàn rảnh tay.</p>
</li>
<li><p>💻 Trợ lý lập trình tự động - Cần mã nguồn? Nó có thể viết, gỡ lỗi, và chạy chương trình Python, C, Go, Java và nhiều hơn nữa — hoàn toàn tự động.</p>
</li>
<li><p>🧠 Chọn tác vụ thông minh - Bạn hỏi, nó tự động chọn tác nhân phù hợp nhất. Như có một đội ngũ chuyên gia luôn sẵn sàng hỗ trợ.</p>
</li>
<li><p>📋 Lập kế hoạch &amp; thực thi tác vụ phức tạp - Từ lên kế hoạch du lịch đến dự án lớn — nó có thể chia nhỏ công việc và hoàn thành bằng nhiều tác nhân AI.</p>
</li>
<li><p>🎙️ Kích hoạt bằng giọng nói - Giọng nói sạch, nhanh, hiện đại và chuyển đổi giọng nói thành văn bản, cho phép bạn trò chuyện với nó như AI cá nhân trong phim khoa học viễn tưởng. (Đang phát triển)</p>
</li>
</ul>
<h3><strong>Demo</strong></h3>
<blockquote>
<p><em>Bạn có thể tìm kiếm dự án agenticSeek, tìm hiểu các kỹ năng cần thiết, sau đó mở CV_candidates.zip và cho tôi biết ai phù hợp nhất với dự án không?</em></p>
</blockquote>
<p>https://github.com/user-attachments/assets/b8ca60e9-7b3b-4533-840e-08f9ac426316</p>
<p>Lưu ý: Demo này, bao gồm mọi tệp xuất hiện (vd: CV_candidates.zip), đều là hư cấu. Chúng tôi không phải công ty, chúng tôi tìm kiếm cộng tác viên mã nguồn mở chứ không phải ứng viên.</p>
<blockquote>
<p>🛠⚠️️ <strong>Đang phát triển tích cực</strong></p>
</blockquote>
<blockquote>
<p>🙏 Dự án này bắt đầu như một dự án phụ, không có lộ trình và không có tài trợ. Nó phát triển ngoài mong đợi khi xuất hiện trên GitHub Trending. Rất cảm ơn sự đóng góp, phản hồi và kiên nhẫn của bạn.</p>
</blockquote>
<h2>Yêu cầu trước khi cài đặt</h2>
<p>Trước khi bắt đầu, hãy đảm bảo bạn đã cài đặt các phần mềm sau:</p>
<ul>
<li><strong>Git:</strong> Để nhân bản kho mã. <a href="https://git-scm.com/downloads">Tải Git</a></li>
<li><strong>Python 3.10.x:</strong> Chúng tôi khuyến nghị sử dụng Python phiên bản 3.10.x. Sử dụng phiên bản khác có thể gây lỗi phụ thuộc. <a href="https://www.python.org/downloads/release/python-3100/">Tải Python 3.10</a> (chọn phiên bản 3.10.x).</li>
<li><strong>Docker Engine &amp; Docker Compose:</strong> Để chạy các dịch vụ đi kèm như SearxNG.
<ul>
<li>Cài đặt Docker Desktop (bao gồm Docker Compose V2): <a href="https://docs.docker.com/desktop/install/windows-install/">Windows</a> | <a href="https://docs.docker.com/desktop/install/mac-install/">Mac</a> | <a href="https://docs.docker.com/desktop/install/linux-install/">Linux</a></li>
<li>Hoặc, cài đặt Docker Engine và Docker Compose riêng trên Linux: <a href="https://docs.docker.com/engine/install/">Docker Engine</a> | <a href="https://docs.docker.com/compose/install/">Docker Compose</a> (đảm bảo cài đặt Compose V2, ví dụ: <code>sudo apt-get install docker-compose-plugin</code>).</li>
</ul>
</li>
</ul>
<h3>1. <strong>Nhân bản kho mã và thiết lập</strong></h3>
<pre><code class="language-sh">git clone https://github.com/Fosowl/agenticSeek.git
cd agenticSeek
mv .env.example .env
</code></pre>
<h3>2. Thay đổi nội dung tệp .env</h3>
<pre><code class="language-sh">SEARXNG_BASE_URL=&quot;http://127.0.0.1:8080&quot;
REDIS_BASE_URL=&quot;redis://redis:6379/0&quot;
WORK_DIR=&quot;/Users/mlg/Documents/workspace_for_ai&quot;
OLLAMA_PORT=&quot;11434&quot;
LM_STUDIO_PORT=&quot;1234&quot;
CUSTOM_ADDITIONAL_LLM_PORT=&quot;11435&quot;
OPENAI_API_KEY='optional'
DEEPSEEK_API_KEY='optional'
OPENROUTER_API_KEY='optional'
TOGETHER_API_KEY='optional'
GOOGLE_API_KEY='optional'
ANTHROPIC_API_KEY='optional'
</code></pre>
<p>Cập nhật tệp <code>.env</code> với giá trị của bạn nếu cần:</p>
<ul>
<li><strong>SEARXNG_BASE_URL</strong>: Giữ nguyên</li>
<li><strong>REDIS_BASE_URL</strong>: Giữ nguyên</li>
<li><strong>WORK_DIR</strong>: Đường dẫn tới thư mục làm việc trên máy của bạn. AgenticSeek sẽ có thể đọc và tương tác với các tệp này.</li>
<li><strong>OLLAMA_PORT</strong>: Số cổng cho dịch vụ Ollama.</li>
<li><strong>LM_STUDIO_PORT</strong>: Số cổng cho dịch vụ LM Studio.</li>
<li><strong>CUSTOM_ADDITIONAL_LLM_PORT</strong>: Cổng cho dịch vụ LLM tùy chỉnh bổ sung.</li>
</ul>
<p><strong>API Key hoàn toàn tùy chọn cho người dùng chọn chạy LLM cục bộ. Đây là mục đích chính của dự án này. Để trống nếu phần cứng của bạn đủ mạnh</strong></p>
<h3>3. <strong>Khởi động Docker</strong></h3>
<p>Đảm bảo Docker đã được cài đặt và chạy trên hệ thống. Bạn có thể khởi động Docker bằng các lệnh sau:</p>
<ul>
<li><p><strong>Trên Linux/macOS:</strong><br />
Mở terminal và chạy:</p>
<pre><code class="language-sh">sudo systemctl start docker
</code></pre>
<p>Hoặc khởi động Docker Desktop từ menu ứng dụng nếu đã cài đặt.</p>
</li>
<li><p><strong>Trên Windows:</strong><br />
Mở Docker Desktop từ menu Start.</p>
</li>
</ul>
<p>Bạn có thể kiểm tra Docker đang chạy bằng cách thực hiện:</p>
<pre><code class="language-sh">docker info
</code></pre>
<p>Nếu bạn thấy thông tin về cài đặt Docker, Docker đã chạy đúng.</p>
<p>Xem bảng <a href="#list-of-local-providers">Các nhà cung cấp cục bộ</a> bên dưới để tóm tắt.</p>
<p>Bước tiếp theo: <a href="#start-services-and-run">Chạy AgenticSeek cục bộ</a></p>
<p><em>Xem mục <a href="#troubleshooting">Khắc phục sự cố</a> nếu bạn gặp vấn đề.</em>
<em>Nếu phần cứng của bạn không thể chạy LLM cục bộ, xem <a href="#setup-to-run-with-an-api">Thiết lập chạy bằng API</a>.</em>
<em>Để giải thích chi tiết <code>config.ini</code>, xem <a href="#config">Phần Cấu hình</a>.</em></p>
<hr />
<h2>Thiết lập để chạy LLM cục bộ trên máy của bạn</h2>
<p><strong>Yêu cầu phần cứng:</strong></p>
<p>Để chạy LLM cục bộ, bạn cần phần cứng đủ mạnh. Tối thiểu, cần GPU đủ để chạy Magistral, Qwen hoặc Deepseek 14B. Xem FAQ để biết khuyến nghị về mô hình/hiệu suất chi tiết.</p>
<p><strong>Thiết lập nhà cung cấp cục bộ của bạn</strong></p>
<p>Khởi động nhà cung cấp cục bộ, ví dụ với ollama:</p>
<pre><code class="language-sh">ollama serve
</code></pre>
<p>Xem bên dưới danh sách các nhà cung cấp cục bộ được hỗ trợ.</p>
<p><strong>Cập nhật config.ini</strong></p>
<p>Thay đổi tệp config.ini để thiết lập provider_name thành nhà cung cấp hỗ trợ và provider_model thành LLM được nhà cung cấp hỗ trợ. Chúng tôi khuyến nghị các mô hình suy luận như <em>Magistral</em> hoặc <em>Deepseek</em>.</p>
<p>Xem <strong>FAQ</strong> cuối README để biết phần cứng cần thiết.</p>
<pre><code class="language-sh">[MAIN]
is_local = True # Khi bạn chạy cục bộ hoặc bằng nhà cung cấp từ xa.
provider_name = ollama # hoặc lm-studio, openai, v.v..
provider_model = deepseek-r1:14b # chọn mô hình phù hợp phần cứng của bạn
provider_server_address = 127.0.0.1:11434
agent_name = Jarvis # tên AI của bạn
recover_last_session = True # có khôi phục phiên trước không
save_session = True # có lưu phiên hiện tại không
speak = False # chuyển văn bản thành giọng nói
listen = False # chuyển giọng nói thành văn bản, chỉ cho CLI, thử nghiệm
jarvis_personality = False # Có dùng tính cách &quot;Jarvis&quot; hơn không (thử nghiệm)
languages = en zh # Danh sách ngôn ngữ, chuyển văn bản thành giọng nói mặc định lấy ngôn ngữ đầu tiên
[BROWSER]
headless_browser = True # giữ nguyên nếu dùng CLI trên host.
stealth_mode = True # Dùng selenium không bị phát hiện để giảm nhận diện trình duyệt
</code></pre>
<p><strong>Cảnh báo</strong>:</p>
<ul>
<li><p>Định dạng tệp <code>config.ini</code> không hỗ trợ chú thích.
Không sao chép và dán cấu hình mẫu trực tiếp, vì chú thích sẽ gây lỗi. Hãy chỉnh sửa thủ công tệp <code>config.ini</code> với thiết lập mong muốn, không bao gồm chú thích.</p>
</li>
<li><p><em>KHÔNG</em> đặt provider_name thành <code>openai</code> nếu dùng LM-studio để chạy LLM. Hãy đặt thành <code>lm-studio</code>.</p>
</li>
<li><p>Một số nhà cung cấp (vd: lm-studio) yêu cầu bạn phải có <code>http://</code> trước địa chỉ IP. Ví dụ: <code>http://127.0.0.1:1234</code></p>
</li>
</ul>
<p><strong>Danh sách các nhà cung cấp cục bộ</strong></p>
<p>| Nhà cung cấp | Cục bộ? | Mô tả                                                         |
|--------------|--------|----------------------------------------------------------------|
| ollama       | Có     | Chạy LLM cục bộ dễ dàng bằng ollama làm nhà cung cấp LLM       |
| lm-studio    | Có     | Chạy LLM cục bộ bằng LM studio (đặt <code>provider_name</code> là <code>lm-studio</code>)|
| openai       | Có     | Dùng API tương thích openai (vd: llama.cpp server)             |</p>
<p>Bước tiếp theo: <a href="#Start-services-and-Run">Khởi động dịch vụ và chạy AgenticSeek</a></p>
<p><em>Xem mục <a href="#troubleshooting">Khắc phục sự cố</a> nếu bạn gặp vấn đề.</em>
<em>Nếu phần cứng của bạn không thể chạy LLM cục bộ, xem <a href="#setup-to-run-with-an-api">Thiết lập chạy bằng API</a>.</em>
<em>Để giải thích chi tiết <code>config.ini</code>, xem <a href="#config">Phần Cấu hình</a>.</em></p>
<h2>Thiết lập chạy bằng API</h2>
<p>Cách này dùng các nhà cung cấp LLM bên ngoài, dựa trên đám mây. Bạn cần API key từ dịch vụ bạn chọn.</p>
<p><strong>1. Chọn nhà cung cấp API và lấy API Key:</strong></p>
<p>Tham khảo <a href="#list-of-api-providers">Danh sách nhà cung cấp API</a> bên dưới. Truy cập trang web của họ để đăng ký và nhận API key.</p>
<p><strong>2. Thiết lập API Key dưới dạng biến môi trường:</strong></p>
<ul>
<li><strong>Linux/macOS:</strong>
Mở terminal và dùng lệnh <code>export</code>. Nên thêm vào tệp cấu hình shell của bạn (vd: <code>~/.bashrc</code>, <code>~/.zshrc</code>) để duy trì lâu dài.
<pre><code class="language-sh">export PROVIDER_API_KEY=&quot;your_api_key_here&quot; 
# Thay PROVIDER_API_KEY bằng tên biến cụ thể, vd: OPENAI_API_KEY, GOOGLE_API_KEY
</code></pre>
Ví dụ cho TogetherAI:
<pre><code class="language-sh">export TOGETHER_API_KEY=&quot;xxxxxxxxxxxxxxxxxxxxxx&quot;
</code></pre>
</li>
<li><strong>Windows:</strong></li>
<li><strong>Command Prompt (Tạm thời cho phiên làm việc hiện tại):</strong>
<pre><code class="language-cmd">set PROVIDER_API_KEY=your_api_key_here
</code></pre>
</li>
<li><strong>PowerShell (Tạm thời cho phiên làm việc hiện tại):</strong>
<pre><code class="language-powershell">$env:PROVIDER_API_KEY=&quot;your_api_key_here&quot;
</code></pre>
</li>
<li><strong>Thiết lập vĩnh viễn:</strong> Tìm kiếm &quot;environment variables&quot; trên thanh tìm kiếm của Windows, nhấn &quot;Edit the system environment variables,&quot; sau đó nhấn nút &quot;Environment Variables...&quot;. Thêm một biến người dùng mới với tên phù hợp (ví dụ: <code>OPENAI_API_KEY</code>) và giá trị là khóa API của bạn.</li>
</ul>
<p><em>(Xem mục FAQ: <a href="#how-do-i-set-api-keys">Làm thế nào để thiết lập API keys?</a> để biết thêm chi tiết).</em></p>
<p><strong>3. Cập nhật <code>config.ini</code>:</strong></p>
<pre><code class="language-ini">[MAIN]
is_local = False
provider_name = openai # Hoặc google, deepseek, togetherAI, huggingface
provider_model = gpt-3.5-turbo # Hoặc gemini-1.5-flash, deepseek-chat, mistralai/Mixtral-8x7B-Instruct-v0.1 v.v.
provider_server_address = # Thường bị bỏ qua hoặc để trống khi is_local = False đối với hầu hết API
# ... các thiết lập khác ...
</code></pre>
<p><em>Cảnh báo:</em> Đảm bảo không có dấu cách thừa ở cuối các giá trị trong <code>config.ini</code>.</p>
<p><strong>Danh sách các nhà cung cấp API</strong></p>
<p>| Nhà cung cấp  | <code>provider_name</code> | Local? | Mô tả                                               | Liên kết lấy API Key (Ví dụ)                |
|---------------|-----------------|--------|-----------------------------------------------------|---------------------------------------------|
| OpenAI        | <code>openai</code>        | Không  | Sử dụng mô hình ChatGPT qua API của OpenAI.         | <a href="https://platform.openai.com/signup">platform.openai.com/signup</a> |
| Google Gemini | <code>google</code>        | Không  | Sử dụng mô hình Google Gemini qua Google AI Studio. | <a href="https://aistudio.google.com/keys">aistudio.google.com/keys</a> |
| Deepseek      | <code>deepseek</code>      | Không  | Sử dụng mô hình Deepseek qua API của họ.            | <a href="https://platform.deepseek.com">platform.deepseek.com</a> |
| Hugging Face  | <code>huggingface</code>   | Không  | Sử dụng mô hình từ Hugging Face Inference API.      | <a href="https://huggingface.co/settings/tokens">huggingface.co/settings/tokens</a> |
| TogetherAI    | <code>togetherAI</code>    | Không  | Sử dụng nhiều mô hình mã nguồn mở qua TogetherAI API.| <a href="https://api.together.ai/settings/api-keys">api.together.ai/settings/api-keys</a> |</p>
<p><em>Lưu ý:</em></p>
<ul>
<li>Chúng tôi khuyến cáo không nên sử dụng <code>gpt-4o</code> hoặc các mô hình OpenAI khác cho các tác vụ duyệt web phức tạp và lập kế hoạch nhiệm vụ vì tối ưu prompt hiện tại phù hợp hơn với các mô hình như Deepseek.</li>
<li>Các tác vụ coding/bash có thể gặp vấn đề với Gemini, do nó có thể không tuân thủ chặt chẽ định dạng prompt đã tối ưu cho Deepseek.</li>
<li>Trường <code>provider_server_address</code> trong <code>config.ini</code> thường không được sử dụng khi <code>is_local = False</code> vì endpoint API thường đã được cố định trong thư viện của từng nhà cung cấp.</li>
</ul>
<p>Bước tiếp theo: <a href="#Start-services-and-Run">Khởi động dịch vụ và chạy AgenticSeek</a></p>
<p><em>Xem mục <strong>Vấn đề đã biết</strong> nếu bạn gặp vấn đề</em></p>
<p><em>Xem mục <strong>Config</strong> để giải thích chi tiết về file cấu hình.</em></p>
<hr />
<h2>Khởi động dịch vụ và chạy</h2>
<p>Theo mặc định, AgenticSeek được chạy hoàn toàn trong docker.</p>
<p>Khởi động các dịch vụ cần thiết. Lệnh này sẽ khởi động tất cả dịch vụ từ docker-compose.yml, bao gồm:
- searxng
- redis (bắt buộc bởi searxng)
- frontend
- backend (nếu dùng <code>full</code>)</p>
<pre><code class="language-sh">./start_services.sh full # MacOS
start ./start_services.cmd full # Window
</code></pre>
<p><strong>Cảnh báo:</strong> Bước này sẽ tải về và load tất cả Docker image, có thể mất tới 30 phút. Sau khi khởi động các dịch vụ, vui lòng chờ cho đến khi dịch vụ backend chạy hoàn toàn (bạn sẽ thấy <strong>backend: &quot;GET /health HTTP/1.1&quot; 200 OK</strong> trong log) trước khi gửi bất kỳ tin nhắn nào. Dịch vụ backend có thể mất 5 phút để khởi động lần đầu.</p>
<p>Truy cập <code>http://localhost:3000/</code> và bạn sẽ thấy giao diện web.</p>
<p><em>Khắc phục sự cố khi khởi động dịch vụ:</em> Nếu các script này bị lỗi, hãy đảm bảo Docker Engine đang chạy và Docker Compose (V2, <code>docker compose</code>) đã được cài đặt đúng. Kiểm tra thông báo lỗi trên terminal. Xem <a href="#faq-troubleshooting">FAQ: Help! Tôi gặp lỗi khi chạy AgenticSeek hoặc các script của nó.</a></p>
<p><strong>Tùy chọn:</strong> Chạy trên máy chủ (chế độ CLI):</p>
<p>Để chạy với giao diện CLI, bạn cần cài đặt package trên máy chủ:</p>
<pre><code class="language-sh">./install.sh
./install.bat # windows
</code></pre>
<p>Khởi động dịch vụ:</p>
<pre><code class="language-sh">./start_services.sh # MacOS
start ./start_services.cmd # Window
</code></pre>
<p>Sử dụng CLI: <code>python3 cli.py</code></p>
<hr />
<h2>Sử dụng</h2>
<p>Đảm bảo các dịch vụ đã được khởi động với <code>./start_services.sh full</code> và truy cập <code>localhost:3000</code> cho giao diện web.</p>
<p>Bạn cũng có thể sử dụng chức năng chuyển giọng nói thành văn bản bằng cách đặt <code>listen = True</code> trong file config. Chức năng này chỉ hỗ trợ ở chế độ CLI.</p>
<p>Để thoát, chỉ cần nói/gõ <code>goodbye</code>.</p>
<p>Dưới đây là một số ví dụ sử dụng:</p>
<blockquote>
<p><em>Hãy tạo một trò chơi rắn săn mồi bằng python!</em></p>
</blockquote>
<blockquote>
<p><em>Tìm kiếm trên web các quán cà phê hàng đầu ở Rennes, Pháp, và lưu danh sách ba quán cùng địa chỉ vào rennes_cafes.txt.</em></p>
</blockquote>
<blockquote>
<p><em>Viết một chương trình Go để tính giai thừa của một số, lưu lại với tên factorial.go trong thư mục làm việc của bạn</em></p>
</blockquote>
<blockquote>
<p><em>Tìm kiếm trong thư mục summer_pictures của tôi tất cả các file JPG, đổi tên chúng với ngày hôm nay, và lưu danh sách các file đã đổi tên vào photos_list.txt</em></p>
</blockquote>
<blockquote>
<p><em>Tìm kiếm trực tuyến các phim khoa học viễn tưởng nổi tiếng năm 2024 và chọn ba phim để xem tối nay. Lưu danh sách vào movie_night.txt.</em></p>
</blockquote>
<blockquote>
<p><em>Tìm kiếm trên web các bài báo AI mới nhất năm 2025, chọn ba bài, và viết một script Python để lấy tiêu đề và tóm tắt của chúng. Lưu script thành news_scraper.py và các bản tóm tắt vào ai_news.txt trong /home/projects</em></p>
</blockquote>
<blockquote>
<p><em>Thứ Sáu, tìm kiếm trên web một API giá cổ phiếu miễn phí, đăng ký với supersuper7434567@gmail.com rồi viết một script Python để lấy giá Tesla hàng ngày bằng API này và lưu kết quả vào stock_prices.csv</em></p>
</blockquote>
<p><em>Lưu ý rằng khả năng điền form vẫn đang thử nghiệm và có thể bị lỗi.</em></p>
<p>Sau khi bạn nhập truy vấn, AgenticSeek sẽ phân bổ agent phù hợp nhất cho tác vụ.</p>
<p>Vì đây là bản prototype sớm, hệ thống định tuyến agent có thể không luôn phân bổ đúng agent dựa trên truy vấn của bạn.</p>
<p>Do đó, bạn nên diễn đạt thật rõ ràng điều bạn muốn và AI nên thực hiện như thế nào. Ví dụ, nếu bạn muốn nó tìm kiếm web, đừng nói:</p>
<p><code>Bạn có biết những quốc gia nào tốt cho du lịch một mình không?</code></p>
<p>Thay vào đó, hãy hỏi:</p>
<p><code>Tìm kiếm trên web và cho biết quốc gia nào tốt nhất cho du lịch một mình</code></p>
<hr />
<h2><strong>Thiết lập để chạy LLM trên máy chủ riêng của bạn</strong></h2>
<p>Nếu bạn có một máy tính mạnh hoặc một máy chủ có thể sử dụng, nhưng muốn dùng nó từ laptop, bạn có thể chạy LLM trên máy chủ từ xa thông qua llm server tùy chỉnh của chúng tôi.</p>
<p>Trên &quot;máy chủ&quot; sẽ chạy mô hình AI, lấy địa chỉ ip:</p>
<pre><code class="language-sh">ip a | grep &quot;inet &quot; | grep -v 127.0.0.1 | awk '{print $2}' | cut -d/ -f1 # ip cục bộ
curl https://ipinfo.io/ip # ip công cộng
</code></pre>
<p>Lưu ý: Với Windows hoặc macOS, dùng ipconfig hoặc ifconfig tương ứng để tìm địa chỉ IP.</p>
<p>Clone repository và vào thư mục <code>server/</code>.</p>
<pre><code class="language-sh">git clone --depth 1 https://github.com/Fosowl/agenticSeek.git
cd agenticSeek/llm_server/
</code></pre>
<p>Cài đặt các yêu cầu riêng cho server:</p>
<pre><code class="language-sh">pip3 install -r requirements.txt
</code></pre>
<p>Chạy script server.</p>
<pre><code class="language-sh">python3 app.py --provider ollama --port 3333
</code></pre>
<p>Bạn có thể lựa chọn giữa việc sử dụng <code>ollama</code> và <code>llamacpp</code> làm dịch vụ LLM.</p>
<p>Bây giờ trên máy cá nhân của bạn:</p>
<p>Thay đổi file <code>config.ini</code> để đặt <code>provider_name</code> thành <code>server</code> và <code>provider_model</code> thành <code>deepseek-r1:xxb</code>.
Đặt <code>provider_server_address</code> là địa chỉ ip của máy sẽ chạy mô hình.</p>
<pre><code class="language-sh">[MAIN]
is_local = False
provider_name = server
provider_model = deepseek-r1:70b
provider_server_address = x.x.x.x:3333
</code></pre>
<p>Bước tiếp theo: <a href="#Start-services-and-Run">Khởi động dịch vụ và chạy AgenticSeek</a></p>
<hr />
<h2>Chuyển giọng nói thành văn bản</h2>
<p>Cảnh báo: chức năng chuyển giọng nói thành văn bản chỉ hoạt động ở chế độ CLI hiện tại.</p>
<p>Lưu ý rằng hiện tại chức năng này chỉ hỗ trợ tiếng Anh.</p>
<p>Chức năng chuyển giọng nói thành văn bản bị tắt theo mặc định. Để bật, hãy đặt tùy chọn listen thành True trong file config.ini:</p>
<pre><code>listen = True
</code></pre>
<p>Khi được bật, chức năng này sẽ lắng nghe từ khóa kích hoạt, chính là tên agent, trước khi bắt đầu xử lý đầu vào của bạn. Bạn có thể tùy chỉnh tên agent bằng cách cập nhật giá trị <code>agent_name</code> trong file <em>config.ini</em>:</p>
<pre><code>agent_name = Friday
</code></pre>
<p>Để nhận diện tốt nhất, chúng tôi khuyến nghị sử dụng tên tiếng Anh phổ biến như &quot;John&quot; hoặc &quot;Emma&quot; làm tên agent</p>
<p>Khi bạn thấy bản ghi bắt đầu xuất hiện, hãy nói to tên agent để đánh thức nó (ví dụ: &quot;Friday&quot;).</p>
<p>Phát biểu truy vấn của bạn một cách rõ ràng.</p>
<p>Kết thúc yêu cầu của bạn bằng một cụm xác nhận để báo hiệu hệ thống tiến hành. Ví dụ về cụm xác nhận bao gồm:</p>
<pre><code>&quot;do it&quot;, &quot;go ahead&quot;, &quot;execute&quot;, &quot;run&quot;, &quot;start&quot;, &quot;thanks&quot;, &quot;would ya&quot;, &quot;please&quot;, &quot;okay?&quot;, &quot;proceed&quot;, &quot;continue&quot;, &quot;go on&quot;, &quot;do that&quot;, &quot;go it&quot;, &quot;do you understand?&quot;
</code></pre>
<h2>Config</h2>
<p>Ví dụ cấu hình:</p>
<pre><code>[MAIN]
is_local = True
provider_name = ollama
provider_model = deepseek-r1:32b
provider_server_address = http://127.0.0.1:11434 # Ví dụ cho Ollama; dùng http://127.0.0.1:1234 cho LM-Studio
agent_name = Friday
recover_last_session = False
save_session = False
speak = False
listen = False

jarvis_personality = False
languages = en zh # Danh sách ngôn ngữ cho TTS và có thể dùng cho định tuyến.
[BROWSER]
headless_browser = False
stealth_mode = False
</code></pre>
<p><strong>Giải thích các thiết lập trong <code>config.ini</code></strong>:</p>
<ul>
<li><strong>Phần <code>[MAIN]</code>:</strong>
<ul>
<li><code>is_local</code>: <code>True</code> nếu sử dụng nhà cung cấp LLM nội bộ (Ollama, LM-Studio, máy chủ tương thích OpenAI cục bộ) hoặc tùy chọn máy chủ tự host. <code>False</code> nếu sử dụng API đám mây (OpenAI, Google, v.v.).</li>
<li><code>provider_name</code>: Chỉ định nhà cung cấp LLM.
<ul>
<li>Tùy chọn nội bộ: <code>ollama</code>, <code>lm-studio</code>, <code>openai</code> (cho máy chủ tương thích OpenAI cục bộ), <code>server</code> (cho thiết lập máy chủ tự host).</li>
<li>Tùy chọn API: <code>openai</code>, <code>google</code>, <code>deepseek</code>, <code>huggingface</code>, <code>togetherAI</code>.</li>
</ul>
</li>
<li><code>provider_model</code>: Tên hoặc ID model cụ thể cho nhà cung cấp đã chọn (vd: <code>deepseekcoder:6.7b</code> cho Ollama, <code>gpt-3.5-turbo</code> cho OpenAI API, <code>mistralai/Mixtral-8x7B-Instruct-v0.1</code> cho TogetherAI).</li>
<li><code>provider_server_address</code>: Địa chỉ của nhà cung cấp LLM.
<ul>
<li>Với nhà cung cấp nội bộ: vd <code>http://127.0.0.1:11434</code> cho Ollama, <code>http://127.0.0.1:1234</code> cho LM-Studio.</li>
<li>Với loại <code>server</code>: Địa chỉ máy chủ LLM tự host (vd: <code>http://your_server_ip:3333</code>).</li>
<li>Với API đám mây (<code>is_local = False</code>): Thường bị bỏ qua hoặc để trống, vì endpoint API thường được thư viện client xử lý.</li>
</ul>
</li>
<li><code>agent_name</code>: Tên trợ lý AI (vd: Friday). Dùng như từ kích hoạt cho chuyển giọng nói thành văn bản nếu bật.</li>
<li><code>recover_last_session</code>: <code>True</code> để thử khôi phục trạng thái phiên trước, <code>False</code> để bắt đầu mới.</li>
<li><code>save_session</code>: <code>True</code> để lưu trạng thái phiên hiện tại cho khả năng khôi phục sau này, <code>False</code> nếu không.</li>
<li><code>speak</code>: <code>True</code> để bật đầu ra giọng nói chuyển văn bản thành giọng nói, <code>False</code> để tắt.</li>
<li><code>listen</code>: <code>True</code> để bật đầu vào giọng nói chuyển giọng nói thành văn bản (chỉ chế độ CLI), <code>False</code> để tắt.</li>
<li><code>work_dir</code>: <strong>Quan trọng:</strong> Thư mục nơi AgenticSeek sẽ đọc/ghi file. <strong>Đảm bảo đường dẫn này hợp lệ và có thể truy cập trên hệ thống của bạn.</strong></li>
<li><code>jarvis_personality</code>: <code>True</code> để sử dụng prompt hệ thống giống &quot;Jarvis&quot; hơn (thử nghiệm), <code>False</code> cho prompt chuẩn.</li>
<li><code>languages</code>: Danh sách các ngôn ngữ cách nhau bởi dấu phẩy (vd: <code>en, zh, fr</code>). Dùng để chọn giọng TTS (mặc định là ngôn ngữ đầu tiên) và có thể hỗ trợ router LLM. Tránh quá nhiều hoặc các ngôn ngữ quá giống nhau để router hiệu quả hơn.</li>
</ul>
</li>
<li><strong>Phần <code>[BROWSER]</code>:</strong>
<ul>
<li><code>headless_browser</code>: <code>True</code> để chạy trình duyệt tự động mà không hiện cửa sổ (khuyến nghị cho giao diện web hoặc sử dụng không tương tác). <code>False</code> để hiển thị cửa sổ trình duyệt (hữu ích cho chế độ CLI hoặc debug).</li>
<li><code>stealth_mode</code>: <code>True</code> để bật các biện pháp giúp trình duyệt tự động khó bị phát hiện hơn. Có thể yêu cầu cài đặt thủ công extension trình duyệt như anticaptcha.</li>
</ul>
</li>
</ul>
<p>Phần này tóm tắt các loại nhà cung cấp LLM được hỗ trợ. Hãy cấu hình trong <code>config.ini</code>.</p>
<p><strong>Nhà cung cấp nội bộ (chạy trên phần cứng của bạn):</strong></p>
<p>| Tên nhà cung cấp trong <code>config.ini</code> | <code>is_local</code> | Mô tả                                                                  | Phần hướng dẫn cài đặt                                              |
|-------------------------------------|------------|------------------------------------------------------------------------|---------------------------------------------------------------------|
| <code>ollama</code>                            | <code>True</code>     | Dùng Ollama để phục vụ LLM cục bộ.                                     | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-for-running-llm-locally-on-your-machine">Hướng dẫn chạy LLM nội bộ</a> |
| <code>lm-studio</code>                         | <code>True</code>     | Dùng LM-Studio để phục vụ LLM cục bộ.                                  | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-for-running-llm-locally-on-your-machine">Hướng dẫn chạy LLM nội bộ</a> |
| <code>openai</code> (cho máy chủ nội bộ)       | <code>True</code>     | Kết nối đến máy chủ cục bộ cung cấp API tương thích OpenAI (vd: llama.cpp). | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-for-running-llm-locally-on-your-machine">Hướng dẫn chạy LLM nội bộ</a> |
| <code>server</code>                            | <code>False</code>    | Kết nối đến máy chủ LLM tự host AgenticSeek chạy trên máy khác.        | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-the-llm-on-your-own-server">Hướng dẫn chạy LLM trên máy chủ riêng</a> |</p>
<p><strong>Nhà cung cấp API (dựa trên đám mây):</strong></p>
<p>| Tên nhà cung cấp trong <code>config.ini</code> | <code>is_local</code> | Mô tả                                       | Phần hướng dẫn cài đặt                                            |
|-------------------------------------|------------|----------------------------------------------|-------------------------------------------------------------------|
| <code>openai</code>                            | <code>False</code>    | Dùng API chính thức của OpenAI (vd: GPT-3.5, GPT-4). | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api">Hướng dẫn chạy với API</a> |
| <code>google</code>                            | <code>False</code>    | Dùng mô hình Gemini của Google qua API.      | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api">Hướng dẫn chạy với API</a> |
| <code>deepseek</code>                          | <code>False</code>    | Dùng API chính thức của Deepseek.            | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api">Hướng dẫn chạy với API</a> |
| <code>huggingface</code>                       | <code>False</code>    | Dùng Hugging Face Inference API.             | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api">Hướng dẫn chạy với API</a> |
| <code>togetherAI</code>                        | <code>False</code>    | Dùng TogetherAI API cho nhiều mô hình open.  | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api">Hướng dẫn chạy với API</a> |</p>
<hr />
<h2>Xử lý sự cố</h2>
<p>Nếu bạn gặp sự cố, phần này cung cấp hướng dẫn.</p>
<h1>Lỗi đã biết</h1>
<h2>Lỗi ChromeDriver</h2>
<p><strong>Ví dụ lỗi:</strong> <code>SessionNotCreatedException: Message: session not created: This version of ChromeDriver only supports Chrome version XXX</code></p>
<ul>
<li><strong>Nguyên nhân:</strong> Phiên bản ChromeDriver bạn cài đặt không tương thích với phiên bản trình duyệt Google Chrome.</li>
<li><strong>Cách khắc phục:</strong>
<ol>
<li><strong>Kiểm tra phiên bản Chrome:</strong> Mở Google Chrome, vào <code>Cài đặt &gt; Giới thiệu về Chrome</code> để xem phiên bản (vd: &quot;Phiên bản 120.0.6099.110&quot;).</li>
<li><strong>Tải ChromeDriver phù hợp:</strong>
<ul>
<li>Với Chrome phiên bản 115 trở lên: Truy cập <a href="https://googlechromelabs.github.io/chrome-for-testing/">Chrome for Testing (CfT) JSON Endpoints</a>. Tìm kênh &quot;stable&quot; và tải ChromeDriver cho hệ điều hành của bạn phù hợp với major version của Chrome.</li>
<li>Với các phiên bản cũ hơn (ít gặp): Có thể tìm tại <a href="https://chromedriver.chromium.org/downloads">ChromeDriver - WebDriver for Chrome</a>.</li>
<li>Hình ảnh dưới đây là ví dụ từ trang CfT:
<img src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/chromedriver_readme.png" alt="Tải đúng phiên bản Chromedriver từ trang Chrome for Testing" /></li>
</ul>
</li>
<li><strong>Cài đặt ChromeDriver:</strong>
<ul>
<li>Đảm bảo file <code>chromedriver</code> (hoặc <code>chromedriver.exe</code> trên Windows) được đặt vào thư mục nằm trong biến môi trường PATH của hệ thống (vd: <code>/usr/local/bin</code> trên Linux/macOS, hoặc thư mục scripts tùy chỉnh đã thêm vào PATH trên Windows).</li>
<li>Hoặc đặt nó vào thư mục gốc của dự án <code>agenticSeek</code>.</li>
<li>Đảm bảo driver có quyền thực thi (vd: <code>chmod +x chromedriver</code> trên Linux/macOS).</li>
</ul>
</li>
<li>Tham khảo phần <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#chromedriver-installation">Cài đặt ChromeDriver</a> trong hướng dẫn cài đặt chính để biết thêm chi tiết.</li>
</ol>
</li>
</ul>
<p>Nếu phần này chưa đầy đủ hoặc bạn gặp các vấn đề khác liên quan đến ChromeDriver, vui lòng tìm kiếm các <a href="https://github.com/Fosowl/agenticSeek/issues">Issue trên GitHub</a> hoặc tạo issue mới.</p>
<p><code>Exception: Failed to initialize browser: Message: session not created: This version of ChromeDriver only supports Chrome version 113 Current browser version is 134.0.6998.89 with binary path</code></p>
<p>Điều này xảy ra khi phiên bản trình duyệt và chromedriver không khớp nhau.</p>
<p>Bạn cần truy cập để tải phiên bản mới nhất:</p>
<p>https://developer.chrome.com/docs/chromedriver/downloads</p>
<p>Nếu bạn dùng Chrome phiên bản 115 trở lên hãy truy cập:</p>
<p>https://googlechromelabs.github.io/chrome-for-testing/</p>
<p>Và tải chromedriver phiên bản phù hợp với hệ điều hành của bạn.</p>
<p><img src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/chromedriver_readme.png" alt="alt text" /></p>
<p>Nếu phần này chưa đầy đủ vui lòng tạo issue mới.</p>
<h2>Lỗi connection adapters</h2>
<pre><code>Exception: Provider lm-studio failed: HTTP request failed: No connection adapters were found for '127.0.0.1:1234/v1/chat/completions'` (Lưu ý: port có thể khác)
</code></pre>
<ul>
<li><strong>Nguyên nhân:</strong> Trường <code>provider_server_address</code> trong <code>config.ini</code> cho <code>lm-studio</code> (hoặc các server OpenAI-compatible cục bộ khác) thiếu tiền tố <code>http://</code> hoặc trỏ sai cổng.</li>
<li><strong>Cách khắc phục:</strong>
<ul>
<li>Đảm bảo địa chỉ có tiền tố <code>http://</code>. LM-Studio mặc định là <code>http://127.0.0.1:1234</code>.</li>
<li>Sửa trong <code>config.ini</code>: <code>provider_server_address = http://127.0.0.1:1234</code> (hoặc đúng port server của bạn).</li>
</ul>
</li>
</ul>
<h2>Không cung cấp SearxNG Base URL</h2>
<pre><code>raise ValueError(&quot;SearxNG base URL must be provided either as an argument or via the SEARXNG_BASE_URL environment variable.&quot;)
ValueError: SearxNG base URL must be provided either as an argument or via the SEARXNG_BASE_URL environment variable.`
</code></pre>
<h2>Câu hỏi thường gặp (FAQ)</h2>
<p><strong>Hỏi: Tôi cần phần cứng gì?</strong></p>
<p>| Kích cỡ Model | GPU         | Ghi chú                                                                                   |
|---------------|-------------|------------------------------------------------------------------------------------------|
| 7B            | 8GB Vram    | ⚠️ Không khuyến nghị. Hiệu năng yếu, dễ sinh ảo giác, agent lập kế hoạch có thể thất bại. |
| 14B           | 12GB Vram (vd RTX 3060) | ✅ Dùng cho tác vụ đơn giản. Có thể gặp khó với duyệt web và lập kế hoạch.           |
| 32B           | 24+GB Vram (vd RTX 4090) | 🚀 Thành công với hầu hết tác vụ, vẫn có thể khó với lập kế hoạch phức tạp.         |
| 70B+          | 48+GB Vram  | 💪 Xuất sắc. Khuyến nghị cho các trường hợp nâng cao.                                     |</p>
<p><strong>Hỏi: Tôi bị lỗi thì làm gì?</strong></p>
<p>Đảm bảo dịch vụ cục bộ đang chạy (<code>ollama serve</code>), <code>config.ini</code> trùng khớp với nhà cung cấp, và đã cài đủ phụ thuộc. Nếu vẫn không được hãy tạo issue mới.</p>
<p><strong>Hỏi: Có thực sự chạy 100% cục bộ được không?</strong></p>
<p>Có, với Ollama, lm-studio hoặc server, toàn bộ chuyển giọng nói thành văn bản, LLM và chuyển văn bản thành giọng nói đều chạy cục bộ. Các tùy chọn không cục bộ (OpenAI hay API khác) chỉ là tùy chọn.</p>
<p><strong>Hỏi: Tại sao nên dùng AgenticSeek khi tôi đã có Manus?</strong></p>
<p>Khác với Manus, AgenticSeek ưu tiên sự độc lập khỏi hệ thống bên ngoài, cho bạn nhiều quyền kiểm soát, bảo mật và tránh phí API.</p>
<p><strong>Hỏi: Ai đứng sau dự án này?</strong></p>
<p>Dự án được tạo bởi tôi cùng hai người bạn là các maintainer và contributor đến từ cộng đồng mã nguồn mở trên GitHub. Chúng tôi chỉ là nhóm cá nhân đam mê, không phải startup hay liên kết tổ chức nào.</p>
<p>Bất kỳ tài khoản AgenticSeek nào trên X ngoài tài khoản cá nhân của tôi (https://x.com/Martin993886460) đều là mạo danh.</p>
<h2>Đóng góp</h2>
<p>Chúng tôi luôn tìm kiếm developer giúp cải thiện AgenticSeek! Hãy xem các issue hoặc thảo luận đang mở.</p>
<p><a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/docs/CONTRIBUTING.md">Hướng dẫn đóng góp</a></p>
<p><a href="https://www.star-history.com/#Fosowl/agenticSeek&amp;Date"><img src="https://api.star-history.com/svg?repos=Fosowl/agenticSeek&amp;type=Date" alt="Star History Chart" /></a></p>
<h2>Maintainers:</h2>
<blockquote>
<p><a href="https://github.com/Fosowl">Fosowl</a> | Múi giờ Paris</p>
</blockquote>
<blockquote>
<p><a href="https://github.com/antoineVIVIES">antoineVIVIES</a> | Múi giờ Taipei</p>
</blockquote>
<blockquote>
<p><a href="https://github.com/steveh8758">steveh8758</a> | Múi giờ Taipei</p>
</blockquote>
<h2>Đặc biệt cảm ơn:</h2>
<blockquote>
<p><a href="https://github.com/tcsenpai">tcsenpai</a> và <a href="https://github.com/plitc">plitc</a> Đã hỗ trợ docker hóa backend</p>
</blockquote>
<h2>Nhà tài trợ:</h2>
<p>Nhà tài trợ hàng tháng từ 5$ trở lên sẽ xuất hiện tại đây:</p>
<ul>
<li><strong>tatra-labs</strong>
Certainly! Please provide the content for Part 4 of 4 that you would like to have translated.</li>
</ul>
<hr />
<p>Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx">Open Ai Tx</a> | Last indexed: 2025-06-16</p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Statcounter and other scripts can be added here -->
</body>
</html>