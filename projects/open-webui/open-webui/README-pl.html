<!DOCTYPE html>
<html lang="pl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>open-webui - open-webui/open-webui pl</title>
    <meta name="title" content="open-webui - open-webui/open-webui pl | Open WebUI 👋 Open WebUI to rozszerzalna, bogata w funkcje i przyjazna dla użytkownika, samodzielnie hostowana platforma AI zaprojektowana do pracy całkowicie o...">
    <meta name="description" content="open-webui/open-webui - GitHub repository pl documentation and information | Open WebUI 👋 Open WebUI to rozszerzalna, bogata w funkcje i przyjazna dla użytkownika, samodzielnie hostowana platforma AI zaprojektowana do pracy całkowicie o...">
    <meta name="keywords" content="open-webui, open-webui, GitHub, repository, pl documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/open-webui/open-webui/README-pl.html">
    <meta property="og:title" content="open-webui - open-webui/open-webui pl | Open WebUI 👋 Open WebUI to rozszerzalna, bogata w funkcje i przyjazna dla użytkownika, samodzielnie hostowana platforma AI zaprojektowana do pracy całkowicie o...">
    <meta property="og:description" content="open-webui/open-webui - GitHub repository pl documentation and information | Open WebUI 👋 Open WebUI to rozszerzalna, bogata w funkcje i przyjazna dla użytkownika, samodzielnie hostowana platforma AI zaprojektowana do pracy całkowicie o...">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div style="position: fixed; top: 2px; left: 2px; z-index: 2000; background: rgba(255,255,255,0.95); border-radius: 6px; box-shadow: 0 2px 8px rgba(0,0,0,0.06); padding: 4px 14px; font-size: 15px; color: #222; font-family: 'Segoe UI', Arial, sans-serif; font-weight: 500; letter-spacing: 0.5px;">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" style="color: #0366d6; text-decoration: none; font-weight: 600;">Open AI Tx</a>
    </div>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/open-webui/open-webui" id="githubRepoLink" target="_blank">open-webui/open-webui</a>
<h1 style="display: none;">Open WebUI 👋 Open WebUI to rozszerzalna, bogata w funkcje i przyjazna dla użytkownika, samodzielnie hostowana platforma AI zaprojektowana do pracy całkowicie o...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <h1>Open WebUI 👋</h1>
<p><img src="https://img.shields.io/github/stars/open-webui/open-webui?style=social" alt="GitHub stars" />
<img src="https://img.shields.io/github/forks/open-webui/open-webui?style=social" alt="GitHub forks" />
<img src="https://img.shields.io/github/watchers/open-webui/open-webui?style=social" alt="GitHub watchers" />
<img src="https://img.shields.io/github/repo-size/open-webui/open-webui" alt="GitHub repo size" />
<img src="https://img.shields.io/github/languages/count/open-webui/open-webui" alt="GitHub language count" />
<img src="https://img.shields.io/github/languages/top/open-webui/open-webui" alt="GitHub top language" />
<img src="https://img.shields.io/github/last-commit/open-webui/open-webui?color=red" alt="GitHub last commit" />
<a href="https://discord.gg/5rJgQTnV4s"><img src="https://img.shields.io/badge/Discord-Open_WebUI-blue?logo=discord&amp;logoColor=white" alt="Discord" /></a>
<a href="https://github.com/sponsors/tjbck"><img src="https://img.shields.io/static/v1?label=Sponsor&amp;message=%E2%9D%A4&amp;logo=GitHub&amp;color=%23fe8e86" alt="" /></a></p>
<p><strong>Open WebUI to <a href="https://docs.openwebui.com/features/plugin/">rozszerzalna</a>, bogata w funkcje i przyjazna dla użytkownika, samodzielnie hostowana platforma AI zaprojektowana do pracy całkowicie offline.</strong> Obsługuje różne silniki LLM, takie jak <strong>Ollama</strong> i <strong>API zgodne z OpenAI</strong>, z <strong>wbudowanym silnikiem inferencyjnym</strong> do RAG, czyniąc ją <strong>potężnym rozwiązaniem do wdrażania AI</strong>.</p>
<p><img src="./demo.gif" alt="Open WebUI Demo" /></p>
<blockquote>
<p>[!TIP]<br />
<strong>Szukasz <a href="https://docs.openwebui.com/enterprise">Planu dla Firm</a>?</strong> – <strong><a href="mailto:sales@openwebui.com">Porozmawiaj z naszym zespołem sprzedaży już dziś!</a></strong></p>
<p>Uzyskaj <strong>rozszerzone możliwości</strong>, w tym <strong>dostosowywanie motywów i brandingu</strong>, <strong>wsparcie SLA</strong>, <strong>wersje LTS</strong> i <strong>więcej!</strong></p>
</blockquote>
<p>Więcej informacji znajdziesz w naszej <a href="https://docs.openwebui.com/">Dokumentacji Open WebUI</a>.</p>
<h2>Kluczowe funkcje Open WebUI ⭐</h2>
<ul>
<li><p>🚀 <strong>Bezproblemowa instalacja</strong>: Łatwa instalacja z użyciem Dockera lub Kubernetesa (kubectl, kustomize lub helm) dla bezproblemowego doświadczenia z obsługą obrazów z tagami <code>:ollama</code> i <code>:cuda</code>.</p>
</li>
<li><p>🤝 <strong>Integracja API Ollama/OpenAI</strong>: Bezproblemowa integracja API zgodnych z OpenAI dla wszechstronnych rozmów obok modeli Ollama. Dostosuj URL API OpenAI, aby połączyć się z <strong>LMStudio, GroqCloud, Mistral, OpenRouter i innymi</strong>.</p>
</li>
<li><p>🛡️ <strong>Granularne uprawnienia i grupy użytkowników</strong>: Administratorzy mogą tworzyć szczegółowe role i uprawnienia użytkowników, zapewniając bezpieczne środowisko. Ta szczegółowość zwiększa bezpieczeństwo i pozwala na personalizację doświadczeń użytkowników, budując poczucie odpowiedzialności.</p>
</li>
<li><p>📱 <strong>Responsywny design</strong>: Ciesz się płynną obsługą na komputerach, laptopach i urządzeniach mobilnych.</p>
</li>
<li><p>📱 <strong>Progresywna aplikacja webowa (PWA) na urządzenia mobilne</strong>: Doświadcz wrażeń podobnych do natywnej aplikacji dzięki PWA, zapewniającej dostęp offline na localhost i intuicyjny interfejs.</p>
</li>
<li><p>✒️🔢 <strong>Pełna obsługa Markdown i LaTeX</strong>: Wznieś swoje doświadczenia z LLM dzięki obszernej obsłudze Markdown i LaTeX dla bogatszej interakcji.</p>
</li>
<li><p>🎤📹 <strong>Rozmowy głosowe/wideo bez użycia rąk</strong>: Prowadź rozmowy zintegrowane z funkcjami głosowymi i wideo, dla bardziej dynamicznego i interaktywnego środowiska czatu.</p>
</li>
<li><p>🛠️ <strong>Kreator modeli</strong>: Łatwo twórz modele Ollama przez Web UI. Twórz i dodawaj własne postacie/agentów, dostosowuj elementy czatu i importuj modele dzięki integracji ze <a href="https://openwebui.com/">Społecznością Open WebUI</a>.</p>
</li>
<li><p>🐍 <strong>Natywne narzędzie wywołań funkcji Pythona</strong>: Wzbogacaj LLM o wbudowany edytor kodu w przestrzeni narzędzi. Dodaj własne funkcje Pythona (BYOF), umożliwiając łatwą integrację z LLM.</p>
</li>
<li><p>📚 <strong>Lokalna integracja RAG</strong>: Przyszłość czatów dzięki przełomowemu wsparciu Retrieval Augmented Generation (RAG). Funkcja ta płynnie integruje interakcje z dokumentami w czacie. Możesz ładować dokumenty bezpośrednio do czatu lub dodawać pliki do biblioteki i korzystać z nich przez komendę <code>#</code> przed zapytaniem.</p>
</li>
<li><p>🔍 <strong>Wyszukiwanie w sieci dla RAG</strong>: Przeprowadzaj wyszukiwania w sieci korzystając z dostawców takich jak <code>SearXNG</code>, <code>Google PSE</code>, <code>Brave Search</code>, <code>serpstack</code>, <code>serper</code>, <code>Serply</code>, <code>DuckDuckGo</code>, <code>TavilySearch</code>, <code>SearchApi</code> i <code>Bing</code> i wstawiaj wyniki bezpośrednio do czatu.</p>
</li>
<li><p>🌐 <strong>Możliwość przeglądania stron www</strong>: Integruj strony internetowe w czacie za pomocą komendy <code>#</code> i adresu URL. Ta funkcja pozwala włączać treści internetowe bezpośrednio do rozmów.</p>
</li>
<li><p>🎨 <strong>Integracja generowania obrazów</strong>: Bezproblemowo korzystaj z generowania obrazów przy użyciu takich opcji jak AUTOMATIC1111 API, ComfyUI (lokalnie) oraz DALL-E od OpenAI (zewnętrznie), wzbogacając czat o dynamiczne treści wizualne.</p>
</li>
<li><p>⚙️ <strong>Rozmowy z wieloma modelami</strong>: Korzystaj jednocześnie z różnych modeli, wykorzystując ich mocne strony dla optymalnych odpowiedzi. Zwiększ efektywność dzięki pracy kilku modeli równolegle.</p>
</li>
<li><p>🔐 <strong>Kontrola dostępu oparta na rolach (RBAC)</strong>: Zapewnij bezpieczny dostęp z ograniczonymi uprawnieniami; tylko upoważnione osoby mają dostęp do Ollama, a prawa do tworzenia/pobierania modeli są zarezerwowane dla administratorów.</p>
</li>
<li><p>🌐🌍 <strong>Obsługa wielu języków</strong>: Korzystaj z Open WebUI w wybranym języku dzięki wsparciu i18n. Pomóż nam rozszerzać liczbę obsługiwanych języków! Aktywnie szukamy współtwórców!</p>
</li>
<li><p>🧩 <strong>Pipelines, wsparcie wtyczek Open WebUI</strong>: Integruj własną logikę i biblioteki Pythona w Open WebUI przez <a href="https://github.com/open-webui/pipelines">Pipelines Plugin Framework</a>. Uruchom swoją instancję Pipelines, ustaw URL OpenAI na URL Pipelines i odkrywaj nieograniczone możliwości. <a href="https://github.com/open-webui/pipelines/tree/main/examples">Przykłady</a> to <strong>Wywoływanie funkcji</strong>, <strong>Ograniczanie liczby użytkowników</strong>, <strong>Monitorowanie użycia</strong> narzędziami jak Langfuse, <strong>Tłumaczenie na żywo z LibreTranslate</strong>, <strong>Filtrowanie toksycznych wiadomości</strong> i wiele więcej.</p>
</li>
<li><p>🌟 <strong>Ciągłe aktualizacje</strong>: Regularnie ulepszamy Open WebUI, wdrażając nowe funkcje i poprawki.</p>
</li>
</ul>
<p>Chcesz dowiedzieć się więcej o funkcjach Open WebUI? Zobacz nasze <a href="https://docs.openwebui.com/features">dokumentacje funkcji Open WebUI</a> dla pełnego przeglądu!</p>
<h2>Sponsorzy 🙌</h2>
<h4>Szmaragd</h4>
<table>
  <tr>
    <td>
      <a href="https://n8n.io/" target="_blank">
        <img src="https://docs.openwebui.com/sponsors/logos/n8n.png" alt="n8n" style="width: 8rem; height: 8rem; border-radius: .75rem;" />
      </a>
    </td>
    <td>
      N8N • Czy twoja aplikacja ma już backend?<br>Wypróbuj <a href="https://n8n.io/">n8n</a>
    </td>
  </tr>
  <tr>
    <td>
      <a href="https://warp.dev/open-webui" target="_blank">
        <img src="https://docs.openwebui.com/sponsors/logos/warp.png" alt="n8n" style="width: 8rem; height: 8rem; border-radius: .75rem;" />
      </a>
    </td>
    <td>
      <a href="https://warp.dev/open-webui">Warp</a> • Inteligentny terminal dla deweloperów
    </td>
  </tr>
</table>
<hr />
<p>Jesteśmy ogromnie wdzięczni naszym sponsorom za ich wsparcie. Ich wkład pomaga nam utrzymywać i rozwijać projekt, byśmy mogli nadal dostarczać wysoką jakość społeczności. Dziękujemy!</p>
<h2>Jak zainstalować 🚀</h2>
<h3>Instalacja przez Python pip 🐍</h3>
<p>Open WebUI można zainstalować za pomocą pip, instalatora pakietów Pythona. Przed rozpoczęciem upewnij się, że używasz <strong>Pythona 3.11</strong>, aby uniknąć problemów ze zgodnością.</p>
<ol>
<li><p><strong>Instalacja Open WebUI</strong>:
Otwórz terminal i uruchom poniższe polecenie, aby zainstalować Open WebUI:</p>
<pre><code class="language-bash">pip install open-webui
</code></pre>
</li>
<li><p><strong>Uruchamianie Open WebUI</strong>:
Po instalacji uruchom Open WebUI poleceniem:</p>
<pre><code class="language-bash">open-webui serve
</code></pre>
</li>
</ol>
<p>To uruchomi serwer Open WebUI, dostępny pod adresem <a href="http://localhost:8080">http://localhost:8080</a></p>
<h3>Szybki start z Dockerem 🐳</h3>
<blockquote>
<p>[!NOTE]<br />
W niektórych środowiskach Docker może być wymagane dodatkowe skonfigurowanie. W przypadku problemów z połączeniem zapoznaj się z naszym przewodnikiem w <a href="https://docs.openwebui.com/">Dokumentacji Open WebUI</a>.</p>
</blockquote>
<blockquote>
<p>[!WARNING]
Instalując Open WebUI przez Dockera, pamiętaj o dodaniu <code>-v open-webui:/app/backend/data</code> do polecenia Docker. To kluczowe, by baza danych została poprawnie zamontowana i nie doszło do utraty danych.</p>
</blockquote>
<blockquote>
<p>[!TIP]<br />
Jeśli chcesz korzystać z Open WebUI z dołączonym Ollama lub akceleracją CUDA, zalecamy użycie oficjalnych obrazów z tagiem <code>:cuda</code> lub <code>:ollama</code>. Aby uruchomić CUDA, zainstaluj <a href="https://docs.nvidia.com/dgx/nvidia-container-runtime-upgrade/">Nvidia CUDA container toolkit</a> na swoim systemie Linux/WSL.</p>
</blockquote>
<h3>Instalacja z domyślną konfiguracją</h3>
<ul>
<li><p><strong>Jeśli Ollama jest na twoim komputerze</strong>, użyj tego polecenia:</p>
<pre><code class="language-bash">docker run -d -p 3000:8080 --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main
</code></pre>
</li>
<li><p><strong>Jeśli Ollama jest na innym serwerze</strong>, użyj tego polecenia:</p>
<p>Aby połączyć się z Ollama na innym serwerze, zmień <code>OLLAMA_BASE_URL</code> na URL tego serwera:</p>
<pre><code class="language-bash">docker run -d -p 3000:8080 -e OLLAMA_BASE_URL=https://example.com -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main
</code></pre>
</li>
<li><p><strong>Aby uruchomić Open WebUI z obsługą GPU Nvidia</strong>, użyj tego polecenia:</p>
<pre><code class="language-bash">docker run -d -p 3000:8080 --gpus all --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:cuda
</code></pre>
</li>
</ul>
<h3>Instalacja tylko do użytku z API OpenAI</h3>
<ul>
<li><p><strong>Jeśli korzystasz wyłącznie z API OpenAI</strong>, użyj tego polecenia:</p>
<pre><code class="language-bash">docker run -d -p 3000:8080 -e OPENAI_API_KEY=your_secret_key -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main
</code></pre>
</li>
</ul>
<h3>Instalacja Open WebUI z dołączonym wsparciem Ollama</h3>
<p>Ta metoda instalacji wykorzystuje pojedynczy obraz kontenera, który zawiera Open WebUI wraz z Ollama, umożliwiając szybkie uruchomienie jednym poleceniem. Wybierz odpowiednie polecenie w zależności od sprzętu:</p>
<ul>
<li><p><strong>Z obsługą GPU</strong>:
Wykorzystaj zasoby GPU, uruchamiając poniższe polecenie:</p>
<pre><code class="language-bash">docker run -d -p 3000:8080 --gpus=all -v ollama:/root/.ollama -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:ollama
</code></pre>
</li>
<li><p><strong>Tylko CPU</strong>:
Jeśli nie używasz GPU, użyj tego polecenia:</p>
<pre><code class="language-bash">docker run -d -p 3000:8080 -v ollama:/root/.ollama -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:ollama
</code></pre>
</li>
</ul>
<p>Oba polecenia umożliwiają bezproblemową instalację zarówno Open WebUI, jak i Ollama, zapewniając szybkie uruchomienie.</p>
<p>Po instalacji uzyskasz dostęp do Open WebUI pod adresem <a href="http://localhost:3000">http://localhost:3000</a>. Miłego korzystania! 😄</p>
<h3>Inne metody instalacji</h3>
<p>Oferujemy różne alternatywy instalacyjne, w tym natywną instalację bez Dockera, Docker Compose, Kustomize oraz Helm. Odwiedź naszą <a href="https://docs.openwebui.com/getting-started/">Dokumentację Open WebUI</a> lub dołącz do naszej <a href="https://discord.gg/5rJgQTnV4s">społeczności Discord</a> po szczegółowe wskazówki.</p>
<h3>Rozwiązywanie problemów</h3>
<p>Masz problemy z połączeniem? Sprawdź naszą <a href="https://docs.openwebui.com/troubleshooting/">Dokumentację Open WebUI</a>. Po dalszą pomoc i by dołączyć do naszej społeczności, odwiedź <a href="https://discord.gg/5rJgQTnV4s">Open WebUI Discord</a>.</p>
<h4>Open WebUI: Błąd połączenia z serwerem</h4>
<p>Jeśli masz problemy z połączeniem, często wynika to z tego, że kontener WebUI nie może połączyć się z serwerem Ollama na 127.0.0.1:11434 (host.docker.internal:11434) wewnątrz kontenera. Użyj flagi <code>--network=host</code> w poleceniu docker, aby to rozwiązać. Zauważ, że port zmienia się z 3000 na 8080, więc adres to: <code>http://localhost:8080</code>.</p>
<p><strong>Przykładowe polecenie Docker</strong>:</p>
<pre><code class="language-bash">docker run -d --network=host -v open-webui:/app/backend/data -e OLLAMA_BASE_URL=http://127.0.0.1:11434 --name open-webui --restart always ghcr.io/open-webui/open-webui:main
</code></pre>
<h3>Aktualizacja Dockera do najnowszej wersji</h3>
<p>Aby zaktualizować lokalną instalację Dockera do najnowszej wersji, możesz użyć <a href="https://containrrr.dev/watchtower/">Watchtower</a>:</p>
<pre><code class="language-bash">docker run --rm --volume /var/run/docker.sock:/var/run/docker.sock containrrr/watchtower --run-once open-webui
</code></pre>
<p>W ostatniej części polecenia zamień <code>open-webui</code> na nazwę swojego kontenera, jeśli jest inna.</p>
<p>Sprawdź nasz przewodnik aktualizacji w <a href="https://docs.openwebui.com/getting-started/updating">Dokumentacji Open WebUI</a>.</p>
<h3>Używanie gałęzi deweloperskiej 🌙</h3>
<blockquote>
<p>[!WARNING]
Gałąź <code>:dev</code> zawiera najnowsze, niestabilne funkcje i zmiany. Używasz jej na własne ryzyko – mogą wystąpić błędy lub niepełne funkcje.</p>
</blockquote>
<p>Aby wypróbować najnowsze funkcje i nie przeszkadza ci niestabilność, użyj tagu <code>:dev</code>:</p>
<pre><code class="language-bash">docker run -d -p 3000:8080 -v open-webui:/app/backend/data --name open-webui --add-host=host.docker.internal:host-gateway --restart always ghcr.io/open-webui/open-webui:dev
</code></pre>
<h3>Tryb offline</h3>
<p>Jeśli uruchamiasz Open WebUI w środowisku offline, ustaw zmienną środowiskową <code>HF_HUB_OFFLINE</code> na <code>1</code>, aby zapobiec próbom pobierania modeli z Internetu.</p>
<pre><code class="language-bash">export HF_HUB_OFFLINE=1
</code></pre>
<h2>Co dalej? 🌟</h2>
<p>Odkryj nadchodzące funkcje na naszej mapie drogowej w <a href="https://docs.openwebui.com/roadmap/">Dokumentacji Open WebUI</a>.</p>
<h2>Licencja 📜</h2>
<p>Ten projekt jest licencjonowany na <a href="LICENSE">Licencji Open WebUI</a>, zmodyfikowanej licencji BSD-3-Clause. Otrzymujesz wszystkie prawa klasycznej licencji BSD-3: możesz używać, modyfikować i dystrybuować oprogramowanie, także w produktach komercyjnych i zamkniętych, z minimalnymi ograniczeniami. Jedynym dodatkowym wymogiem jest zachowanie brandingu &quot;Open WebUI&quot;, zgodnie z plikiem LICENSE. Pełne warunki znajdziesz w <a href="LICENSE">dokumencie LICENSE</a>. 📄</p>
<h2>Wsparcie 💬</h2>
<p>Masz pytania, sugestie lub potrzebujesz pomocy? Otwórz zgłoszenie lub dołącz do naszej
<a href="https://discord.gg/5rJgQTnV4s">społeczności Discord Open WebUI</a>, aby się z nami skontaktować! 🤝</p>
<h2>Historia gwiazdek</h2>
<a href="https://star-history.com/#open-webui/open-webui&Date">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=open-webui/open-webui&type=Date&theme=dark" />
    <source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=open-webui/open-webui&type=Date" />
    <img alt="Star History Chart" src="https://api.star-history.com/svg?repos=open-webui/open-webui&type=Date" />
  </picture>
</a>
<hr />
<p>Utworzone przez <a href="https://github.com/tjbck">Timothy Jaeryang Baek</a> – sprawmy, by Open WebUI było jeszcze lepsze, razem! 💪</p>
<hr />
<p><a href="https://github.com/OpenAiTx/OpenAiTx">Powered By OpenAiTx</a></p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
</body>
</html>