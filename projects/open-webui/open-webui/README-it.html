<!DOCTYPE html>
<html lang="it">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>open-webui - open-webui/open-webui it</title>
    <meta name="title" content="open-webui - open-webui/open-webui it | Open WebUI 👋 Open WebUI è una piattaforma AI self-hosted estendibile, ricca di funzionalità e facile da usare, progettata per funzionare completamente offline....">
    <meta name="description" content="open-webui/open-webui - GitHub repository it documentation and information | Open WebUI 👋 Open WebUI è una piattaforma AI self-hosted estendibile, ricca di funzionalità e facile da usare, progettata per funzionare completamente offline....">
    <meta name="keywords" content="open-webui, open-webui, GitHub, repository, it documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/open-webui/open-webui/README-it.html">
    <meta property="og:title" content="open-webui - open-webui/open-webui it | Open WebUI 👋 Open WebUI è una piattaforma AI self-hosted estendibile, ricca di funzionalità e facile da usare, progettata per funzionare completamente offline....">
    <meta property="og:description" content="open-webui/open-webui - GitHub repository it documentation and information | Open WebUI 👋 Open WebUI è una piattaforma AI self-hosted estendibile, ricca di funzionalità e facile da usare, progettata per funzionare completamente offline....">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/open-webui/open-webui" id="githubRepoLink" target="_blank">open-webui/open-webui</a>
<h1 style="display: none;">Open WebUI 👋 Open WebUI è una piattaforma AI self-hosted estendibile, ricca di funzionalità e facile da usare, progettata per funzionare completamente offline....</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <h1>Open WebUI 👋</h1>
<p><img src="https://img.shields.io/github/stars/open-webui/open-webui?style=social" alt="GitHub stars" />
<img src="https://img.shields.io/github/forks/open-webui/open-webui?style=social" alt="GitHub forks" />
<img src="https://img.shields.io/github/watchers/open-webui/open-webui?style=social" alt="GitHub watchers" />
<img src="https://img.shields.io/github/repo-size/open-webui/open-webui" alt="GitHub repo size" />
<img src="https://img.shields.io/github/languages/count/open-webui/open-webui" alt="GitHub language count" />
<img src="https://img.shields.io/github/languages/top/open-webui/open-webui" alt="GitHub top language" />
<img src="https://img.shields.io/github/last-commit/open-webui/open-webui?color=red" alt="GitHub last commit" />
<a href="https://discord.gg/5rJgQTnV4s"><img src="https://img.shields.io/badge/Discord-Open_WebUI-blue?logo=discord&amp;logoColor=white" alt="Discord" /></a>
<a href="https://github.com/sponsors/tjbck"><img src="https://img.shields.io/static/v1?label=Sponsor&amp;message=%E2%9D%A4&amp;logo=GitHub&amp;color=%23fe8e86" alt="" /></a></p>
<p><strong>Open WebUI è una piattaforma AI self-hosted <a href="https://docs.openwebui.com/features/plugin/">estendibile</a>, ricca di funzionalità e facile da usare, progettata per funzionare completamente offline.</strong> Supporta diversi motori LLM come <strong>Ollama</strong> e <strong>API compatibili con OpenAI</strong>, con un <strong>motore di inferenza integrato</strong> per RAG, rendendolo una <strong>soluzione potente per il deployment di AI</strong>.</p>
<p><img src="./demo.gif" alt="Open WebUI Demo" /></p>
<blockquote>
<p>[!TIP]<br />
<strong>Cerchi un <a href="https://docs.openwebui.com/enterprise">Enterprise Plan</a>?</strong> – <strong><a href="mailto:sales@openwebui.com">Parla con il nostro team commerciale oggi stesso!</a></strong></p>
<p>Ottieni <strong>funzionalità avanzate</strong>, inclusi <strong>personalizzazione del tema e del branding</strong>, supporto <strong>SLA (Service Level Agreement)</strong>, versioni <strong>LTS (Long-Term Support)</strong> e <strong>molto altro!</strong></p>
</blockquote>
<p>Per ulteriori informazioni, consulta la nostra <a href="https://docs.openwebui.com/">Documentazione di Open WebUI</a>.</p>
<h2>Caratteristiche principali di Open WebUI ⭐</h2>
<ul>
<li><p>🚀 <strong>Installazione Semplice</strong>: Installa facilmente tramite Docker o Kubernetes (kubectl, kustomize o helm) per un'esperienza senza problemi, con supporto sia per immagini con tag <code>:ollama</code> che <code>:cuda</code>.</p>
</li>
<li><p>🤝 <strong>Integrazione API Ollama/OpenAI</strong>: Integra senza sforzo API compatibili con OpenAI per conversazioni versatili insieme ai modelli Ollama. Personalizza l’URL API OpenAI per collegarti a <strong>LMStudio, GroqCloud, Mistral, OpenRouter e altri</strong>.</p>
</li>
<li><p>🛡️ <strong>Permessi Granulari e Gruppi Utenti</strong>: Consentendo agli amministratori di creare ruoli e permessi utente dettagliati, garantiamo un ambiente sicuro. Questa granularità non solo aumenta la sicurezza ma consente anche esperienze utente personalizzate, promuovendo senso di proprietà e responsabilità tra gli utenti.</p>
</li>
<li><p>📱 <strong>Design Responsivo</strong>: Godi di un'esperienza senza interruzioni su PC Desktop, Laptop e dispositivi mobili.</p>
</li>
<li><p>📱 <strong>Progressive Web App (PWA) per Mobile</strong>: Vivi un’esperienza simile ad un’app nativa sul tuo dispositivo mobile con la nostra PWA, che offre accesso offline in locale e un'interfaccia utente fluida.</p>
</li>
<li><p>✒️🔢 <strong>Supporto Completo a Markdown e LaTeX</strong>: Migliora la tua esperienza LLM con capacità complete di Markdown e LaTeX per interazioni arricchite.</p>
</li>
<li><p>🎤📹 <strong>Chiamata Vocale/Video Senza Mani</strong>: Sperimenta comunicazioni fluide con funzioni integrate di chiamata vocale e video senza mani, per un ambiente chat più dinamico e interattivo.</p>
</li>
<li><p>🛠️ <strong>Model Builder</strong>: Crea facilmente modelli Ollama tramite la Web UI. Crea e aggiungi personaggi/agent personalizzati, personalizza elementi della chat e importa modelli senza sforzo tramite l’integrazione con la <a href="https://openwebui.com/">Community Open WebUI</a>.</p>
</li>
<li><p>🐍 <strong>Strumento Nativo per Chiamata Funzioni Python</strong>: Potenzia i tuoi LLM con supporto per editor di codice integrato nell’area strumenti. Porta le tue funzioni Python (BYOF) aggiungendo semplicemente le tue funzioni pure, per un'integrazione fluida con i LLM.</p>
</li>
<li><p>📚 <strong>Integrazione RAG Locale</strong>: Entra nel futuro delle interazioni in chat con il supporto innovativo a Retrieval Augmented Generation (RAG). Questa funzione integra senza soluzione di continuità l’interazione con i documenti nella chat. Puoi caricare documenti direttamente nella chat o aggiungere file alla tua libreria documenti, accedendovi facilmente tramite il comando <code>#</code> prima di una query.</p>
</li>
<li><p>🔍 <strong>Ricerca Web per RAG</strong>: Esegui ricerche web usando provider come <code>SearXNG</code>, <code>Google PSE</code>, <code>Brave Search</code>, <code>serpstack</code>, <code>serper</code>, <code>Serply</code>, <code>DuckDuckGo</code>, <code>TavilySearch</code>, <code>SearchApi</code> e <code>Bing</code> e inserisci i risultati direttamente nella tua chat.</p>
</li>
<li><p>🌐 <strong>Funzionalità di Navigazione Web</strong>: Integra facilmente siti web nella chat utilizzando il comando <code>#</code> seguito da un URL. Questa funzione consente di incorporare contenuti web direttamente nelle conversazioni, arricchendo la profondità delle interazioni.</p>
</li>
<li><p>🎨 <strong>Integrazione Generazione Immagini</strong>: Integra senza difficoltà la generazione di immagini usando opzioni come AUTOMATIC1111 API o ComfyUI (locale), e DALL-E di OpenAI (esterno), arricchendo le chat con contenuti visivi dinamici.</p>
</li>
<li><p>⚙️ <strong>Conversazioni Multi-Modello</strong>: Interagisci con vari modelli simultaneamente, sfruttando le loro peculiarità per risposte ottimali. Migliora l’esperienza utilizzando diversi modelli in parallelo.</p>
</li>
<li><p>🔐 <strong>Controllo Accessi Basato sui Ruoli (RBAC)</strong>: Garantisce accesso sicuro con permessi restrittivi; solo persone autorizzate possono accedere a Ollama, e la creazione/estrazione dei modelli è riservata agli amministratori.</p>
</li>
<li><p>🌐🌍 <strong>Supporto Multilingua</strong>: Vivi Open WebUI nella tua lingua preferita grazie al supporto internazionale (i18n). Aiutaci ad ampliare le lingue supportate! Cerchiamo attivamente contributori!</p>
</li>
<li><p>🧩 <strong>Pipelines, Supporto Plugin Open WebUI</strong>: Integra facilmente logica personalizzata e librerie Python in Open WebUI usando il <a href="https://github.com/open-webui/pipelines">Pipelines Plugin Framework</a>. Avvia la tua istanza Pipelines, imposta l’URL OpenAI su quello delle Pipelines ed esplora infinite possibilità. Gli <a href="https://github.com/open-webui/pipelines/tree/main/examples">esempi</a> includono <strong>Function Calling</strong>, <strong>Rate Limiting</strong> per controllare l’accesso, <strong>Monitoraggio Utilizzo</strong> con strumenti come Langfuse, <strong>Traduzione Live con LibreTranslate</strong> per supporto multilingua, <strong>Filtro Messaggi Tossici</strong> e altro ancora.</p>
</li>
<li><p>🌟 <strong>Aggiornamenti Continui</strong>: Siamo impegnati a migliorare Open WebUI con aggiornamenti regolari, correzioni e nuove funzionalità.</p>
</li>
</ul>
<p>Vuoi saperne di più sulle funzionalità di Open WebUI? Consulta la nostra <a href="https://docs.openwebui.com/features">documentazione di Open WebUI</a> per una panoramica completa!</p>
<h2>Sponsor 🙌</h2>
<h4>Smeraldo</h4>
<table>
  <tr>
    <td>
      <a href="https://n8n.io/" target="_blank">
        <img src="https://docs.openwebui.com/sponsors/logos/n8n.png" alt="n8n" style="width: 8rem; height: 8rem; border-radius: .75rem;" />
      </a>
    </td>
    <td>
      N8N • La tua interfaccia ha già un backend?<br>Prova <a href="https://n8n.io/">n8n</a>
    </td>
  </tr>
  <tr>
    <td>
      <a href="https://warp.dev/open-webui" target="_blank">
        <img src="https://docs.openwebui.com/sponsors/logos/warp.png" alt="n8n" style="width: 8rem; height: 8rem; border-radius: .75rem;" />
      </a>
    </td>
    <td>
      <a href="https://warp.dev/open-webui">Warp</a> • Il terminale intelligente per sviluppatori
    </td>
  </tr>
</table>
<hr />
<p>Siamo estremamente grati per il generoso supporto dei nostri sponsor. I loro contributi ci aiutano a mantenere e migliorare il progetto, garantendo che possiamo continuare a offrire lavoro di qualità alla nostra community. Grazie!</p>
<h2>Come installare 🚀</h2>
<h3>Installazione tramite Python pip 🐍</h3>
<p>Open WebUI può essere installato utilizzando pip, il gestore pacchetti di Python. Prima di procedere, assicurati di utilizzare <strong>Python 3.11</strong> per evitare problemi di compatibilità.</p>
<ol>
<li><p><strong>Installa Open WebUI</strong>:
Apri il terminale ed esegui il seguente comando per installare Open WebUI:</p>
<pre><code class="language-bash">pip install open-webui
</code></pre>
</li>
<li><p><strong>Esecuzione di Open WebUI</strong>:
Dopo l’installazione, puoi avviare Open WebUI eseguendo:</p>
<pre><code class="language-bash">open-webui serve
</code></pre>
</li>
</ol>
<p>Questo avvierà il server Open WebUI, accessibile all’indirizzo <a href="http://localhost:8080">http://localhost:8080</a></p>
<h3>Avvio rapido con Docker 🐳</h3>
<blockquote>
<p>[!NOTE]<br />
Nota che in alcuni ambienti Docker potrebbero essere necessarie configurazioni aggiuntive. In caso di problemi di connessione, la nostra guida dettagliata sulla <a href="https://docs.openwebui.com/">Documentazione Open WebUI</a> è pronta ad aiutarti.</p>
</blockquote>
<blockquote>
<p>[!WARNING]
Quando usi Docker per installare Open WebUI, assicurati di includere <code>-v open-webui:/app/backend/data</code> nel comando Docker. Questo passaggio è fondamentale per montare correttamente il database ed evitare la perdita di dati.</p>
</blockquote>
<blockquote>
<p>[!TIP]<br />
Se desideri utilizzare Open WebUI con Ollama incluso o accelerazione CUDA, ti consigliamo di usare le immagini ufficiali taggate <code>:cuda</code> o <code>:ollama</code>. Per abilitare CUDA, devi installare il <a href="https://docs.nvidia.com/dgx/nvidia-container-runtime-upgrade/">Nvidia CUDA container toolkit</a> sul tuo sistema Linux/WSL.</p>
</blockquote>
<h3>Installazione con configurazione predefinita</h3>
<ul>
<li><p><strong>Se Ollama è sul tuo computer</strong>, usa questo comando:</p>
<pre><code class="language-bash">docker run -d -p 3000:8080 --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main
</code></pre>
</li>
<li><p><strong>Se Ollama è su un altro server</strong>, usa questo comando:</p>
<p>Per collegarti a Ollama su un altro server, cambia <code>OLLAMA_BASE_URL</code> con l’URL del server:</p>
<pre><code class="language-bash">docker run -d -p 3000:8080 -e OLLAMA_BASE_URL=https://example.com -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main
</code></pre>
</li>
<li><p><strong>Per eseguire Open WebUI con supporto GPU Nvidia</strong>, usa questo comando:</p>
<pre><code class="language-bash">docker run -d -p 3000:8080 --gpus all --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:cuda
</code></pre>
</li>
</ul>
<h3>Installazione solo per uso API OpenAI</h3>
<ul>
<li><p><strong>Se usi solo l’API OpenAI</strong>, usa questo comando:</p>
<pre><code class="language-bash">docker run -d -p 3000:8080 -e OPENAI_API_KEY=your_secret_key -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main
</code></pre>
</li>
</ul>
<h3>Installazione di Open WebUI con supporto Ollama integrato</h3>
<p>Questo metodo utilizza una singola immagine container che include Open WebUI con Ollama, permettendo una configurazione semplificata tramite un solo comando. Scegli il comando appropriato in base all’hardware:</p>
<ul>
<li><p><strong>Con supporto GPU</strong>:
Utilizza le risorse GPU eseguendo il comando:</p>
<pre><code class="language-bash">docker run -d -p 3000:8080 --gpus=all -v ollama:/root/.ollama -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:ollama
</code></pre>
</li>
<li><p><strong>Solo CPU</strong>:
Se non usi una GPU, usa invece questo comando:</p>
<pre><code class="language-bash">docker run -d -p 3000:8080 -v ollama:/root/.ollama -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:ollama
</code></pre>
</li>
</ul>
<p>Entrambi i comandi facilitano un'installazione integrata e senza problemi sia di Open WebUI che di Ollama, garantendo una rapida messa in funzione.</p>
<p>Dopo l’installazione, puoi accedere a Open WebUI all’indirizzo <a href="http://localhost:3000">http://localhost:3000</a>. Buon divertimento! 😄</p>
<h3>Altri metodi di installazione</h3>
<p>Offriamo diverse alternative di installazione, incluse modalità native senza Docker, Docker Compose, Kustomize e Helm. Visita la nostra <a href="https://docs.openwebui.com/getting-started/">Documentazione Open WebUI</a> o unisciti alla nostra <a href="https://discord.gg/5rJgQTnV4s">community Discord</a> per guide complete.</p>
<h3>Risoluzione dei problemi</h3>
<p>Hai problemi di connessione? La nostra <a href="https://docs.openwebui.com/troubleshooting/">Documentazione Open WebUI</a> può aiutarti. Per ulteriore assistenza e per unirti alla nostra community, visita <a href="https://discord.gg/5rJgQTnV4s">Open WebUI Discord</a>.</p>
<h4>Open WebUI: Errore di Connessione al Server</h4>
<p>Se riscontri problemi di connessione, spesso è dovuto al fatto che il container docker WebUI non riesce a raggiungere il server Ollama su 127.0.0.1:11434 (host.docker.internal:11434) dall’interno del container. Usa il flag <code>--network=host</code> nel comando docker per risolvere. Nota che la porta cambia da 3000 a 8080, risultando nel link: <code>http://localhost:8080</code>.</p>
<p><strong>Esempio comando Docker</strong>:</p>
<pre><code class="language-bash">docker run -d --network=host -v open-webui:/app/backend/data -e OLLAMA_BASE_URL=http://127.0.0.1:11434 --name open-webui --restart always ghcr.io/open-webui/open-webui:main
</code></pre>
<h3>Aggiornare la tua installazione Docker</h3>
<p>Se vuoi aggiornare l’installazione Docker locale all’ultima versione, puoi farlo con <a href="https://containrrr.dev/watchtower/">Watchtower</a>:</p>
<pre><code class="language-bash">docker run --rm --volume /var/run/docker.sock:/var/run/docker.sock containrrr/watchtower --run-once open-webui
</code></pre>
<p>Nell’ultima parte del comando, sostituisci <code>open-webui</code> con il nome del tuo container se è diverso.</p>
<p>Consulta la nostra guida all’aggiornamento disponibile nella <a href="https://docs.openwebui.com/getting-started/updating">Documentazione Open WebUI</a>.</p>
<h3>Utilizzo della Dev Branch 🌙</h3>
<blockquote>
<p>[!WARNING]
Il ramo <code>:dev</code> contiene le ultime funzionalità instabili e modifiche. Usalo a tuo rischio poiché potrebbe avere bug o funzionalità incomplete.</p>
</blockquote>
<p>Se vuoi provare le ultime funzionalità all’avanguardia e accetti un po’ di instabilità, puoi usare il tag <code>:dev</code> così:</p>
<pre><code class="language-bash">docker run -d -p 3000:8080 -v open-webui:/app/backend/data --name open-webui --add-host=host.docker.internal:host-gateway --restart always ghcr.io/open-webui/open-webui:dev
</code></pre>
<h3>Modalità Offline</h3>
<p>Se esegui Open WebUI in un ambiente offline, puoi impostare la variabile d’ambiente <code>HF_HUB_OFFLINE</code> a <code>1</code> per impedire tentativi di scaricare modelli da Internet.</p>
<pre><code class="language-bash">export HF_HUB_OFFLINE=1
</code></pre>
<h2>Cosa succede ora? 🌟</h2>
<p>Scopri le funzionalità in arrivo sulla nostra roadmap nella <a href="https://docs.openwebui.com/roadmap/">Documentazione Open WebUI</a>.</p>
<h2>Licenza 📜</h2>
<p>Questo progetto è concesso sotto la <a href="LICENSE">Licenza Open WebUI</a>, una licenza BSD-3-Clause rivista. Hai tutti gli stessi diritti della classica BSD-3: puoi usare, modificare e distribuire il software, anche in prodotti proprietari e commerciali, con restrizioni minime. L’unico requisito aggiuntivo è preservare il branding &quot;Open WebUI&quot;, come dettagliato nel file LICENSE. Per i termini completi, vedi il documento <a href="LICENSE">LICENSE</a>. 📄</p>
<h2>Supporto 💬</h2>
<p>Se hai domande, suggerimenti o hai bisogno di assistenza, apri una issue o unisciti alla nostra
<a href="https://discord.gg/5rJgQTnV4s">community Discord di Open WebUI</a> per entrare in contatto con noi! 🤝</p>
<h2>Storico delle Stelle</h2>
<a href="https://star-history.com/#open-webui/open-webui&Date">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=open-webui/open-webui&type=Date&theme=dark" />
    <source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=open-webui/open-webui&type=Date" />
    <img alt="Star History Chart" src="https://api.star-history.com/svg?repos=open-webui/open-webui&type=Date" />
  </picture>
</a>
<hr />
<p>Creato da <a href="https://github.com/tjbck">Timothy Jaeryang Baek</a> - Rendiamo Open WebUI ancora più straordinario, insieme! 💪</p>
<hr />
<p><a href="https://github.com/OpenAiTx/OpenAiTx">Powered By OpenAiTx</a></p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
</body>
</html>