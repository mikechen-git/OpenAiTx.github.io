<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>open-webui - open-webui/open-webui zh-TW</title>
    <meta name="title" content="open-webui - open-webui/open-webui zh-TW | Open WebUI 👋 Open WebUI 是一個可擴展、功能豐富且用戶友善的自架 AI 平台，設計用於完全離線運作。 它支援多種 LLM 執行器，例如 Ollama 和 相容 OpenAI 的 API，並內建 RAG 推論引擎，使其成為一個強大的 AI 部署解決方案。 [!TIP] 正在尋找企業方案？ – 立即...">
    <meta name="description" content="open-webui/open-webui - GitHub repository zh-TW documentation and information | Open WebUI 👋 Open WebUI 是一個可擴展、功能豐富且用戶友善的自架 AI 平台，設計用於完全離線運作。 它支援多種 LLM 執行器，例如 Ollama 和 相容 OpenAI 的 API，並內建 RAG 推論引擎，使其成為一個強大的 AI 部署解決方案。 [!TIP] 正在尋找企業方案？ – 立即...">
    <meta name="keywords" content="open-webui, open-webui, GitHub, repository, zh-TW documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/open-webui/open-webui/README-zh-TW.html">
    <meta property="og:title" content="open-webui - open-webui/open-webui zh-TW | Open WebUI 👋 Open WebUI 是一個可擴展、功能豐富且用戶友善的自架 AI 平台，設計用於完全離線運作。 它支援多種 LLM 執行器，例如 Ollama 和 相容 OpenAI 的 API，並內建 RAG 推論引擎，使其成為一個強大的 AI 部署解決方案。 [!TIP] 正在尋找企業方案？ – 立即...">
    <meta property="og:description" content="open-webui/open-webui - GitHub repository zh-TW documentation and information | Open WebUI 👋 Open WebUI 是一個可擴展、功能豐富且用戶友善的自架 AI 平台，設計用於完全離線運作。 它支援多種 LLM 執行器，例如 Ollama 和 相容 OpenAI 的 API，並內建 RAG 推論引擎，使其成為一個強大的 AI 部署解決方案。 [!TIP] 正在尋找企業方案？ – 立即...">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div style="position: fixed; top: 2px; left: 2px; z-index: 2000; background: rgba(255,255,255,0.95); border-radius: 6px; box-shadow: 0 2px 8px rgba(0,0,0,0.06); padding: 4px 14px; font-size: 15px; color: #222; font-family: 'Segoe UI', Arial, sans-serif; font-weight: 500; letter-spacing: 0.5px;">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" style="color: #0366d6; text-decoration: none; font-weight: 600;">Open AI Tx</a>
    </div>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/open-webui/open-webui" id="githubRepoLink" target="_blank">open-webui/open-webui</a>
<h1 style="display: none;">Open WebUI 👋 Open WebUI 是一個可擴展、功能豐富且用戶友善的自架 AI 平台，設計用於完全離線運作。 它支援多種 LLM 執行器，例如 Ollama 和 相容 OpenAI 的 API，並內建 RAG 推論引擎，使其成為一個強大的 AI 部署解決方案。 [!TIP] 正在尋找企業方案？ – 立即...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <h1>Open WebUI 👋</h1>
<p><img src="https://img.shields.io/github/stars/open-webui/open-webui?style=social" alt="GitHub stars" />
<img src="https://img.shields.io/github/forks/open-webui/open-webui?style=social" alt="GitHub forks" />
<img src="https://img.shields.io/github/watchers/open-webui/open-webui?style=social" alt="GitHub watchers" />
<img src="https://img.shields.io/github/repo-size/open-webui/open-webui" alt="GitHub repo size" />
<img src="https://img.shields.io/github/languages/count/open-webui/open-webui" alt="GitHub language count" />
<img src="https://img.shields.io/github/languages/top/open-webui/open-webui" alt="GitHub top language" />
<img src="https://img.shields.io/github/last-commit/open-webui/open-webui?color=red" alt="GitHub last commit" />
<a href="https://discord.gg/5rJgQTnV4s"><img src="https://img.shields.io/badge/Discord-Open_WebUI-blue?logo=discord&amp;logoColor=white" alt="Discord" /></a>
<a href="https://github.com/sponsors/tjbck"><img src="https://img.shields.io/static/v1?label=Sponsor&amp;message=%E2%9D%A4&amp;logo=GitHub&amp;color=%23fe8e86" alt="" /></a></p>
<p><strong>Open WebUI 是一個<a href="https://docs.openwebui.com/features/plugin/">可擴展</a>、功能豐富且用戶友善的自架 AI 平台，設計用於完全離線運作。</strong> 它支援多種 LLM 執行器，例如 <strong>Ollama</strong> 和 <strong>相容 OpenAI 的 API</strong>，並內建 RAG 推論引擎，使其成為一個<strong>強大的 AI 部署解決方案</strong>。</p>
<p><img src="./demo.gif" alt="Open WebUI Demo" /></p>
<blockquote>
<p>[!TIP]<br />
<strong>正在尋找<a href="https://docs.openwebui.com/enterprise">企業方案</a>？</strong> – <strong><a href="mailto:sales@openwebui.com">立即聯繫我們的銷售團隊！</a></strong></p>
<p>獲得<strong>增強功能</strong>，包括<strong>自訂主題與品牌</strong>、<strong>服務級協議（SLA）支援</strong>、<strong>長期支援（LTS）版本</strong>等更多功能！</p>
</blockquote>
<p>欲瞭解更多資訊，請務必參閱我們的 <a href="https://docs.openwebui.com/">Open WebUI 文件</a>。</p>
<h2>Open WebUI 主要特點 ⭐</h2>
<ul>
<li><p>🚀 <strong>輕鬆安裝</strong>：使用 Docker 或 Kubernetes（kubectl、kustomize 或 helm）無縫安裝，支援 <code>:ollama</code> 與 <code>:cuda</code> 標記映像，安裝過程無煩惱。</p>
</li>
<li><p>🤝 <strong>Ollama/OpenAI API 整合</strong>：無縫整合相容 OpenAI 的 API，讓 Ollama 模型與多種聊天體驗共存。可自訂 OpenAI API URL，連結至 <strong>LMStudio、GroqCloud、Mistral、OpenRouter 等</strong>。</p>
</li>
<li><p>🛡️ <strong>細緻權限與用戶群組</strong>：管理員可建立詳細的用戶角色與權限，確保安全的用戶環境。這種細緻劃分不僅提升安全性，也能打造客製化的用戶體驗，增強用戶的歸屬感與責任感。</p>
</li>
<li><p>📱 <strong>響應式設計</strong>：在桌上型電腦、筆電與行動裝置上皆有無縫體驗。</p>
</li>
<li><p>📱 <strong>行動裝置專屬 PWA</strong>：透過 PWA，在行動裝置上享有接近原生應用的體驗，於本地主機提供離線存取及流暢介面。</p>
</li>
<li><p>✒️🔢 <strong>完整 Markdown 與 LaTeX 支援</strong>：全方位的 Markdown 與 LaTeX 功能，提升 LLM 的互動體驗。</p>
</li>
<li><p>🎤📹 <strong>免持語音/視訊通話</strong>：內建免持語音與視訊通話，讓聊天更具動態與互動性。</p>
</li>
<li><p>🛠️ <strong>模型建構器</strong>：可直接透過 Web UI 建立 Ollama 模型。新增自訂角色/代理、調整聊天元素，並透過 <a href="https://openwebui.com/">Open WebUI 社群</a> 整合輕鬆匯入模型。</p>
</li>
<li><p>🐍 <strong>原生 Python 函式調用工具</strong>：於工具工作區內支援內建程式碼編輯器，只需新增純 Python 函式即可 BYOF（自帶函式），無縫整合 LLM 與自訂程式碼。</p>
</li>
<li><p>📚 <strong>本地 RAG 整合</strong>：率先支援檢索增強生成（RAG），將文件互動無縫整合進聊天體驗。可將文件直接載入聊天或加入文件庫，使用 <code>#</code> 指令即可存取。</p>
</li>
<li><p>🔍 <strong>RAG 網路搜尋</strong>：支援 <code>SearXNG</code>、<code>Google PSE</code>、<code>Brave Search</code>、<code>serpstack</code>、<code>serper</code>、<code>Serply</code>、<code>DuckDuckGo</code>、<code>TavilySearch</code>、<code>SearchApi</code> 及 <code>Bing</code> 等搜尋引擎，直接將搜尋結果注入聊天。</p>
</li>
<li><p>🌐 <strong>網頁瀏覽功能</strong>：於聊天中使用 <code>#</code> 指令加上網址，將網站內容無縫納入對話，豐富互動層次。</p>
</li>
<li><p>🎨 <strong>圖像生成整合</strong>：可選擇 AUTOMATIC1111 API、ComfyUI（本地）、OpenAI 的 DALL-E（外部）等工具，為聊天體驗增添動態視覺內容。</p>
</li>
<li><p>⚙️ <strong>多模型同時對話</strong>：同時與多個模型互動，發揮各自優勢，獲得最佳回應。可並行運用多組模型提升體驗。</p>
</li>
<li><p>🔐 <strong>基於角色的存取控制（RBAC）</strong>：確保存取安全，僅授權人員能存取 Ollama，只有管理員擁有模型建立/拉取權限。</p>
</li>
<li><p>🌐🌍 <strong>多語言支援</strong>：支援國際化（i18n），可用偏好語言體驗 Open WebUI。歡迎參與翻譯，持續徵求貢獻者！</p>
</li>
<li><p>🧩 <strong>Pipelines、Open WebUI 外掛支援</strong>：利用 <a href="https://github.com/open-webui/pipelines">Pipelines Plugin Framework</a> 整合自訂邏輯與 Python 函式庫。啟動 Pipelines 實例，將 OpenAI URL 設為 Pipelines URL，開啟無限可能。<a href="https://github.com/open-webui/pipelines/tree/main/examples">範例</a> 包含 <strong>函式調用</strong>、用戶 <strong>速率限制</strong>、<strong>使用監控</strong>（如 Langfuse）、<strong>LibreTranslate 實時翻譯</strong>、<strong>有害訊息過濾</strong>等多項功能。</p>
</li>
<li><p>🌟 <strong>持續更新</strong>：我們承諾定期為 Open WebUI 提供更新、修正及新功能。</p>
</li>
</ul>
<p>想更深入了解 Open WebUI 的功能嗎？請參考我們的 <a href="https://docs.openwebui.com/features">Open WebUI 文件</a> 以獲取完整介紹！</p>
<h2>贊助商 🙌</h2>
<h4>綠寶石級</h4>
<table>
  <tr>
    <td>
      <a href="https://n8n.io/" target="_blank">
        <img src="https://docs.openwebui.com/sponsors/logos/n8n.png" alt="n8n" style="width: 8rem; height: 8rem; border-radius: .75rem;" />
      </a>
    </td>
    <td>
      N8N • 你的介面有後端了嗎？<br>試試 <a href="https://n8n.io/">n8n</a>
    </td>
  </tr>
  <tr>
    <td>
      <a href="https://warp.dev/open-webui" target="_blank">
        <img src="https://docs.openwebui.com/sponsors/logos/warp.png" alt="n8n" style="width: 8rem; height: 8rem; border-radius: .75rem;" />
      </a>
    </td>
    <td>
      <a href="https://warp.dev/open-webui">Warp</a> • 開發者的智慧終端機
    </td>
  </tr>
</table>
<hr />
<p>我們非常感謝贊助商的慷慨支持。他們的貢獻幫助我們維護並改進專案，確保能持續為社群提供高品質成果。謝謝！</p>
<h2>安裝方式 🚀</h2>
<h3>透過 Python pip 安裝 🐍</h3>
<p>可使用 Python 套件管理器 pip 安裝 Open WebUI。安裝前請確保使用 <strong>Python 3.11</strong> 以避免相容性問題。</p>
<ol>
<li><p><strong>安裝 Open WebUI</strong>：
開啟終端機並執行以下指令安裝：</p>
<pre><code class="language-bash">pip install open-webui
</code></pre>
</li>
<li><p><strong>啟動 Open WebUI</strong>：
安裝完成後，執行以下指令啟動：</p>
<pre><code class="language-bash">open-webui serve
</code></pre>
</li>
</ol>
<p>這將啟動 Open WebUI 伺服器，您可於 <a href="http://localhost:8080">http://localhost:8080</a> 存取。</p>
<h3>使用 Docker 快速啟動 🐳</h3>
<blockquote>
<p>[!NOTE]<br />
某些 Docker 環境可能需額外設定。若遇連線問題，請參閱我們的 <a href="https://docs.openwebui.com/">Open WebUI 文件</a>。</p>
</blockquote>
<blockquote>
<p>[!WARNING]
使用 Docker 安裝 Open WebUI 時，請務必在指令中加入 <code>-v open-webui:/app/backend/data</code>。此步驟能確保資料庫正確掛載，避免資料遺失。</p>
</blockquote>
<blockquote>
<p>[!TIP]<br />
若需包含 Ollama 或啟用 CUDA 加速，建議使用官方標記為 <code>:cuda</code> 或 <code>:ollama</code> 的映像。啟用 CUDA 前請於 Linux/WSL 系統安裝 <a href="https://docs.nvidia.com/dgx/nvidia-container-runtime-upgrade/">Nvidia CUDA container toolkit</a>。</p>
</blockquote>
<h3>預設設定安裝</h3>
<ul>
<li><p><strong>若 Ollama 在本機</strong>，請使用下列指令：</p>
<pre><code class="language-bash">docker run -d -p 3000:8080 --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main
</code></pre>
</li>
<li><p><strong>若 Ollama 在其他伺服器</strong>，請使用下列指令：</p>
<p>若需連接其他伺服器上的 Ollama，請將 <code>OLLAMA_BASE_URL</code> 改為該伺服器 URL：</p>
<pre><code class="language-bash">docker run -d -p 3000:8080 -e OLLAMA_BASE_URL=https://example.com -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main
</code></pre>
</li>
<li><p><strong>若需 Nvidia GPU 支援</strong>，請使用下列指令：</p>
<pre><code class="language-bash">docker run -d -p 3000:8080 --gpus all --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:cuda
</code></pre>
</li>
</ul>
<h3>僅使用 OpenAI API 的安裝方式</h3>
<ul>
<li><p><strong>若僅使用 OpenAI API</strong>，請使用下列指令：</p>
<pre><code class="language-bash">docker run -d -p 3000:8080 -e OPENAI_API_KEY=your_secret_key -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main
</code></pre>
</li>
</ul>
<h3>安裝包含 Ollama 的 Open WebUI</h3>
<p>此方法使用單一容器映像，將 Open WebUI 與 Ollama 打包，僅需一行指令即可安裝。請依照硬體選擇適合的指令：</p>
<ul>
<li><p><strong>支援 GPU</strong>：
若需運用 GPU 資源，請執行下列指令：</p>
<pre><code class="language-bash">docker run -d -p 3000:8080 --gpus=all -v ollama:/root/.ollama -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:ollama
</code></pre>
</li>
<li><p><strong>僅用 CPU</strong>：
若無 GPU，請改用下列指令：</p>
<pre><code class="language-bash">docker run -d -p 3000:8080 -v ollama:/root/.ollama -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:ollama
</code></pre>
</li>
</ul>
<p>兩種指令皆可一併安裝 Open WebUI 與 Ollama，輕鬆快速完成設定。</p>
<p>安裝完成後，您可於 <a href="http://localhost:3000">http://localhost:3000</a> 存取 Open WebUI。祝您使用愉快！😄</p>
<h3>其他安裝方式</h3>
<p>我們也提供多種安裝選擇，包括非 Docker 原生安裝、Docker Compose、Kustomize 及 Helm。請參閱 <a href="https://docs.openwebui.com/getting-started/">Open WebUI 文件</a> 或加入 <a href="https://discord.gg/5rJgQTnV4s">Discord 社群</a> 取得完整指引。</p>
<h3>疑難排解</h3>
<p>遇到連線問題嗎？請參閱 <a href="https://docs.openwebui.com/troubleshooting/">Open WebUI 文件</a>。如需更多協助及參與熱絡社群，歡迎前往 <a href="https://discord.gg/5rJgQTnV4s">Open WebUI Discord</a>。</p>
<h4>Open WebUI：伺服器連線錯誤</h4>
<p>若遇連線問題，常見原因為 WebUI Docker 容器無法連接至容器內的 Ollama 伺服器（127.0.0.1:11434 或 host.docker.internal:11434）。請於 docker 指令中加入 <code>--network=host</code> 參數解決。需注意此時埠號將由 3000 改為 8080，連結為：<code>http://localhost:8080</code>。</p>
<p><strong>範例 Docker 指令</strong>：</p>
<pre><code class="language-bash">docker run -d --network=host -v open-webui:/app/backend/data -e OLLAMA_BASE_URL=http://127.0.0.1:11434 --name open-webui --restart always ghcr.io/open-webui/open-webui:main
</code></pre>
<h3>保持 Docker 安裝為最新版本</h3>
<p>若欲升級本地 Docker 安裝版本，可使用 <a href="https://containrrr.dev/watchtower/">Watchtower</a>：</p>
<pre><code class="language-bash">docker run --rm --volume /var/run/docker.sock:/var/run/docker.sock containrrr/watchtower --run-once open-webui
</code></pre>
<p>如有更改容器名稱，請將指令最後的 <code>open-webui</code> 替換為您的容器名稱。</p>
<p>請參考我們的升級指南：<a href="https://docs.openwebui.com/getting-started/updating">Open WebUI 文件</a>。</p>
<h3>使用 Dev 開發分支 🌙</h3>
<blockquote>
<p>[!WARNING]
<code>:dev</code> 分支包含最新但尚未穩定的功能及變更，使用時請自行承擔風險，可能會有 bug 或功能不完整。</p>
</blockquote>
<p>若想嘗鮮最新功能且可接受偶爾不穩定，可用 <code>:dev</code> 標記啟動：</p>
<pre><code class="language-bash">docker run -d -p 3000:8080 -v open-webui:/app/backend/data --name open-webui --add-host=host.docker.internal:host-gateway --restart always ghcr.io/open-webui/open-webui:dev
</code></pre>
<h3>離線模式</h3>
<p>若在離線環境運行 Open WebUI，可設定環境變數 <code>HF_HUB_OFFLINE</code> 為 <code>1</code>，避免從網路下載模型。</p>
<pre><code class="language-bash">export HF_HUB_OFFLINE=1
</code></pre>
<h2>接下來？🌟</h2>
<p>探索即將推出的功能，請見 <a href="https://docs.openwebui.com/roadmap/">Open WebUI 路線圖</a>。</p>
<h2>授權 📜</h2>
<p>本專案採用 <a href="LICENSE">Open WebUI License</a>，即 BSD-3-Clause 修正版授權。您將獲得與經典 BSD-3 授權相同的權利：可自由使用、修改、發行（包括專有與商業產品），僅有極少的限制。唯一額外要求是保留「Open WebUI」品牌標示，詳見 LICENSE 檔案。完整條款請參閱 <a href="LICENSE">LICENSE</a> 文件。📄</p>
<h2>支援 💬</h2>
<p>如有任何問題、建議或需協助，請開啟 issue 或加入我們的
<a href="https://discord.gg/5rJgQTnV4s">Open WebUI Discord 社群</a> 與我們聯繫！🤝</p>
<h2>星標歷史</h2>
<a href="https://star-history.com/#open-webui/open-webui&Date">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=open-webui/open-webui&type=Date&theme=dark" />
    <source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=open-webui/open-webui&type=Date" />
    <img alt="Star History Chart" src="https://api.star-history.com/svg?repos=open-webui/open-webui&type=Date" />
  </picture>
</a>
<hr />
<p>由 <a href="https://github.com/tjbck">Timothy Jaeryang Baek</a> 建立——讓我們一起讓 Open WebUI 更加精彩！💪</p>
<hr />
<p><a href="https://github.com/OpenAiTx/OpenAiTx">Powered By OpenAiTx</a></p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
</body>
</html>