<!DOCTYPE html>
<html lang="ar">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>StyTR-2 - diyiiyiii/StyTR-2</title>
    <meta name="title" content="StyTR-2 - diyiiyiii/StyTR-2">
    <meta name="description" content="diyiiyiii/StyTR-2 - GitHub repository ar documentation and informationStyTr^2 : نقل نمط الصورة باستخدام المحولات (CVPR2022) المؤلفون: Yingying Deng، Fan Tang، XingjiaPan، Weiming Dong، Chongyang Ma، Changsheng Xu تم اقتراح هذه الو...">
    <meta name="keywords" content="diyiiyiii, StyTR-2, GitHub, repository, ar documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/diyiiyiii/StyTR-2/README-ar.html">
    <meta property="og:title" content="StyTR-2 - diyiiyiii/StyTR-2">
    <meta property="og:description" content="diyiiyiii/StyTR-2 - GitHub repository ar documentation and information">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/diyiiyiii/StyTR-2" id="githubRepoLink" target="_blank">diyiiyiii/StyTR-2</a>
<h1 style="display: none;">StyTr^2 : نقل نمط الصورة باستخدام المحولات (CVPR2022) المؤلفون: Yingying Deng، Fan Tang، XingjiaPan، Weiming Dong، Chongyang Ma، Changsheng Xu تم اقتراح هذه الو...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <h1>StyTr^2 : نقل نمط الصورة باستخدام المحولات (CVPR2022)</h1>
<p><em>المؤلفون: <a href="https://diyiiyiii.github.io/">Yingying Deng</a>، Fan Tang، XingjiaPan، Weiming Dong، Chongyang Ma، Changsheng Xu</em></p>
<p>تم اقتراح هذه الورقة لتحقيق نقل نمط الصورة بدون تحيز بالاعتماد على نموذج المحول. يمكننا تعزيز تأثير التأنق مقارنةً بأحدث الطرق.
هذا المستودع هو التنفيذ الرسمي لـ <a href="https://arxiv.org/abs/2105.14576">SyTr^2 : Image Style Transfer with Transformers</a>.</p>
<h2>عرض النتائج</h2>
<p align="center">
<img src="https://github.com/diyiiyiii/StyTR-2/blob/main/Figure/Unbiased.png" width="90%" height="90%">
</p>
مقارنةً ببعض الخوارزميات المتقدمة، يتمتع أسلوبنا بقدرة قوية على تجنب تسرب المحتوى ويمتلك قدرة تمثيل ميزات أفضل.  <br>
<h2>الإطار العام</h2>
<p align="center">
<img src="https://github.com/diyiiyiii/StyTR-2/blob/main/Figure/network.png" width="100%" height="100%">
</p> 
المسار العام لإطار عمل StyTr^2 الخاص بنا. نقوم بتقسيم صور المحتوى والنمط إلى قطع، ونستخدم إسقاطًا خطيًا للحصول على تسلسلات الصور. ثم تُغذى تسلسلات المحتوى المضافة إليها CAPE إلى مشفر محول المحتوى، بينما تُغذى تسلسلات النمط إلى مشفر محول النمط. بعد مشفري المحول، يُعتمد مفكك ترميز متعدد الطبقات لتغيير نمط تسلسلات المحتوى وفقًا لتسلسلات النمط. أخيرًا، نستخدم مفكك ترميز تصعيدي تدريجي للحصول على الصور ذات النمط بدقة عالية.
<h2>التجربة</h2>
<h3>المتطلبات</h3>
<ul>
<li>python 3.6</li>
<li>pytorch 1.4.0</li>
<li>PIL، numpy، scipy</li>
<li>tqdm  <br></li>
</ul>
<h3>الاختبار</h3>
<p>نماذج مدربة مسبقًا: <a href="https://drive.google.com/file/d/1BinnwM5AmIcVubr16tPTqxMjUCE8iu5M/view?usp=sharing">vgg-model</a>،  <a href="https://drive.google.com/file/d/1C3xzTOWx8dUXXybxZwmjijZN8SrC3e4B/view?usp=sharing">vit_embedding</a>، <a href="https://drive.google.com/file/d/1fIIVMTA_tPuaAAFtqizr6sd1XV7CX6F9/view?usp=sharing">decoder</a>، <a href="https://drive.google.com/file/d/1dnobsaLeE889T_LncCkAA2RkqzwsfHYy/view?usp=sharing">Transformer_module</a>   <br>
يرجى تنزيلها ووضعها في المجلد ./experiments/  <br></p>
<pre><code>python test.py  --content_dir input/content/ --style_dir input/style/    --output out
</code></pre>
<h3>التدريب</h3>
<p>مجموعة بيانات الأنماط هي WikiArt تم جمعها من <a href="https://www.wikiart.org/">WIKIART</a>  <br><br />
مجموعة بيانات المحتوى هي COCO2014  <br></p>
<pre><code>python train.py --style_dir ../../datasets/Images/ --content_dir ../../datasets/train2014 --save_dir models/ --batch_size 8
</code></pre>
<h3>المرجع</h3>
<p>إذا وجدت أن عملنا مفيد في بحثك، يرجى الاستشهاد بورقتنا باستخدام إدخال BibTeX التالي ~ شكرًا لك ^ . ^. رابط الورقة <a href="https://arxiv.org/abs/2105.14576">pdf</a><br></p>
<pre><code>@inproceedings{deng2021stytr2,
      title={StyTr^2: Image Style Transfer with Transformers}, 
      author={Yingying Deng and Fan Tang and Weiming Dong and Chongyang Ma and Xingjia Pan and Lei Wang and Changsheng Xu},
      booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
      year={2022},
}
</code></pre>
<hr />
<p>Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx">Open Ai Tx</a> | Last indexed: 2025-06-09</p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Statcounter and other scripts can be added here -->
</body>
</html>