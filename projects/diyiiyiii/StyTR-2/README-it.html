<!DOCTYPE html>
<html lang="it">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>StyTR-2 - diyiiyiii/StyTR-2 it</title>
    <meta name="title" content="StyTR-2 - diyiiyiii/StyTR-2 it | StyTr^2 : Trasferimento di Stile delle Immagini con Transformer (CVPR2022) Autori: Yingying Deng, Fan Tang, Xingjia Pan, Weiming Dong, Chongyang Ma, Changsheng ...">
    <meta name="description" content="diyiiyiii/StyTR-2 - GitHub repository it documentation and information | StyTr^2 : Trasferimento di Stile delle Immagini con Transformer (CVPR2022) Autori: Yingying Deng, Fan Tang, Xingjia Pan, Weiming Dong, Chongyang Ma, Changsheng ...">
    <meta name="keywords" content="diyiiyiii, StyTR-2, GitHub, repository, it documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/diyiiyiii/StyTR-2/README-it.html">
    <meta property="og:title" content="StyTR-2 - diyiiyiii/StyTR-2 it | StyTr^2 : Trasferimento di Stile delle Immagini con Transformer (CVPR2022) Autori: Yingying Deng, Fan Tang, Xingjia Pan, Weiming Dong, Chongyang Ma, Changsheng ...">
    <meta property="og:description" content="diyiiyiii/StyTR-2 - GitHub repository it documentation and information | StyTr^2 : Trasferimento di Stile delle Immagini con Transformer (CVPR2022) Autori: Yingying Deng, Fan Tang, Xingjia Pan, Weiming Dong, Chongyang Ma, Changsheng ...">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/diyiiyiii/StyTR-2" id="githubRepoLink" target="_blank">diyiiyiii/StyTR-2</a>
<h1 style="display: none;">StyTr^2 : Trasferimento di Stile delle Immagini con Transformer (CVPR2022) Autori: Yingying Deng, Fan Tang, Xingjia Pan, Weiming Dong, Chongyang Ma, Changsheng ...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <h1>StyTr^2 : Trasferimento di Stile delle Immagini con Transformer (CVPR2022)</h1>
<p><em>Autori: <a href="https://diyiiyiii.github.io/">Yingying Deng</a>, Fan Tang, Xingjia Pan, Weiming Dong, Chongyang Ma, Changsheng Xu</em></p>
<p>Questo articolo è stato proposto per ottenere un trasferimento di stile delle immagini imparziale basato sul modello transformer. Possiamo migliorare l'effetto di stilizzazione rispetto ai metodi all'avanguardia.
Questo repository è l'implementazione ufficiale di <a href="https://arxiv.org/abs/2105.14576">SyTr^2 : Image Style Transfer with Transformers</a>.</p>
<h2>Presentazione dei risultati</h2>
<p align="center">
<img src="https://github.com/diyiiyiii/StyTR-2/blob/main/Figure/Unbiased.png" width="90%" height="90%">
</p>
Rispetto ad alcuni algoritmi all'avanguardia, il nostro metodo ha una forte capacità di evitare la perdita di contenuto e possiede una migliore capacità di rappresentazione delle caratteristiche.  <br>
<h2>Framework</h2>
<p align="center">
<img src="https://github.com/diyiiyiii/StyTR-2/blob/main/Figure/network.png" width="100%" height="100%">
</p> 
Il flusso generale del nostro framework StyTr^2. Suddividiamo le immagini di contenuto e di stile in patch e utilizziamo una proiezione lineare per ottenere sequenze di immagini. Quindi, le sequenze di contenuto aggiunte con CAPE vengono inserite nell'encoder transformer di contenuto, mentre le sequenze di stile vengono inserite nell'encoder transformer di stile. Dopo i due encoder transformer, viene adottato un decoder transformer multi-strato per stilizzare le sequenze di contenuto in base alle sequenze di stile. Infine, utilizziamo un decoder di upsampling progressivo per ottenere immagini stilizzate ad alta risoluzione.
<h2>Esperimenti</h2>
<h3>Requisiti</h3>
<ul>
<li>python 3.6</li>
<li>pytorch 1.4.0</li>
<li>PIL, numpy, scipy</li>
<li>tqdm  <br></li>
</ul>
<h3>Testing</h3>
<p>Modelli pre-addestrati: <a href="https://drive.google.com/file/d/1BinnwM5AmIcVubr16tPTqxMjUCE8iu5M/view?usp=sharing">vgg-model</a>,  <a href="https://drive.google.com/file/d/1C3xzTOWx8dUXXybxZwmjijZN8SrC3e4B/view?usp=sharing">vit_embedding</a>, <a href="https://drive.google.com/file/d/1fIIVMTA_tPuaAAFtqizr6sd1XV7CX6F9/view?usp=sharing">decoder</a>, <a href="https://drive.google.com/file/d/1dnobsaLeE889T_LncCkAA2RkqzwsfHYy/view?usp=sharing">Transformer_module</a>   <br>
Si prega di scaricarli e inserirli nella cartella ./experiments/  <br></p>
<pre><code>python test.py  --content_dir input/content/ --style_dir input/style/    --output out
</code></pre>
<h3>Addestramento</h3>
<p>Il dataset di stile è WikiArt raccolto da <a href="https://www.wikiart.org/">WIKIART</a>  <br><br />
Il dataset di contenuto è COCO2014  <br></p>
<pre><code>python train.py --style_dir ../../datasets/Images/ --content_dir ../../datasets/train2014 --save_dir models/ --batch_size 8
</code></pre>
<h3>Riferimenti</h3>
<p>Se trovi utile il nostro lavoro per la tua ricerca, cita il nostro articolo utilizzando la seguente voce BibTeX ~ Grazie ^ . ^. Link all'articolo <a href="https://arxiv.org/abs/2105.14576">pdf</a><br></p>
<pre><code>@inproceedings{deng2021stytr2,
      title={StyTr^2: Image Style Transfer with Transformers}, 
      author={Yingying Deng and Fan Tang and Weiming Dong and Chongyang Ma and Xingjia Pan and Lei Wang and Changsheng Xu},
      booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
      year={2022},
}
</code></pre>
<hr />
<p>Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx">Open Ai Tx</a> | Last indexed: 2025-06-09</p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
</body>
</html>