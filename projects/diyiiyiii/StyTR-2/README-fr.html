<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>StyTR-2 - diyiiyiii/StyTR-2 fr</title>
    <meta name="title" content="StyTR-2 - diyiiyiii/StyTR-2 fr | StyTr^2 : Transfert de style d’image avec Transformers (CVPR2022) Auteurs : Yingying Deng, Fan Tang, XingjiaPan, Weiming Dong, Chongyang Ma, Changsheng Xu Cet a...">
    <meta name="description" content="diyiiyiii/StyTR-2 - GitHub repository fr documentation and information | StyTr^2 : Transfert de style d’image avec Transformers (CVPR2022) Auteurs : Yingying Deng, Fan Tang, XingjiaPan, Weiming Dong, Chongyang Ma, Changsheng Xu Cet a...">
    <meta name="keywords" content="diyiiyiii, StyTR-2, GitHub, repository, fr documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/diyiiyiii/StyTR-2/README-fr.html">
    <meta property="og:title" content="StyTR-2 - diyiiyiii/StyTR-2 fr | StyTr^2 : Transfert de style d’image avec Transformers (CVPR2022) Auteurs : Yingying Deng, Fan Tang, XingjiaPan, Weiming Dong, Chongyang Ma, Changsheng Xu Cet a...">
    <meta property="og:description" content="diyiiyiii/StyTR-2 - GitHub repository fr documentation and information | StyTr^2 : Transfert de style d’image avec Transformers (CVPR2022) Auteurs : Yingying Deng, Fan Tang, XingjiaPan, Weiming Dong, Chongyang Ma, Changsheng Xu Cet a...">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/diyiiyiii/StyTR-2" id="githubRepoLink" target="_blank">diyiiyiii/StyTR-2</a>
<h1 style="display: none;">StyTr^2 : Transfert de style d’image avec Transformers (CVPR2022) Auteurs : Yingying Deng, Fan Tang, XingjiaPan, Weiming Dong, Chongyang Ma, Changsheng Xu Cet a...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <h1>StyTr^2 : Transfert de style d’image avec Transformers (CVPR2022)</h1>
<p><em>Auteurs : <a href="https://diyiiyiii.github.io/">Yingying Deng</a>, Fan Tang, XingjiaPan, Weiming Dong, Chongyang Ma, Changsheng Xu</em></p>
<p>Cet article propose de réaliser un transfert de style d’image impartial basé sur le modèle Transformer. Nous pouvons améliorer l’effet de stylisation par rapport aux méthodes de pointe actuelles.
Ce dépôt est l’implémentation officielle de <a href="https://arxiv.org/abs/2105.14576">SyTr^2 : Image Style Transfer with Transformers</a>.</p>
<h2>Présentation des résultats</h2>
<p align="center">
<img src="https://github.com/diyiiyiii/StyTR-2/blob/main/Figure/Unbiased.png" width="90%" height="90%">
</p>
Comparé à certains algorithmes de pointe, notre méthode présente une forte capacité à éviter la fuite de contenu et possède une meilleure capacité de représentation des caractéristiques.  <br>
<h2>Architecture</h2>
<p align="center">
<img src="https://github.com/diyiiyiii/StyTR-2/blob/main/Figure/network.png" width="100%" height="100%">
</p> 
Le pipeline global de notre cadre StyTr^2. Nous divisons les images de contenu et de style en patchs, puis utilisons une projection linéaire pour obtenir des séquences d’images. Ensuite, les séquences de contenu, additionnées de CAPE, sont introduites dans l’encodeur Transformer de contenu, tandis que les séquences de style sont introduites dans l’encodeur Transformer de style. Après les deux encodeurs Transformer, un décodeur Transformer multi-couches est adopté pour styliser les séquences de contenu selon les séquences de style. Enfin, nous utilisons un décodeur de suréchantillonnage progressif pour obtenir les images stylisées en haute résolution.
<h2>Expérience</h2>
<h3>Prérequis</h3>
<ul>
<li>python 3.6</li>
<li>pytorch 1.4.0</li>
<li>PIL, numpy, scipy</li>
<li>tqdm  <br></li>
</ul>
<h3>Test</h3>
<p>Modèles pré-entraînés : <a href="https://drive.google.com/file/d/1BinnwM5AmIcVubr16tPTqxMjUCE8iu5M/view?usp=sharing">vgg-model</a>,  <a href="https://drive.google.com/file/d/1C3xzTOWx8dUXXybxZwmjijZN8SrC3e4B/view?usp=sharing">vit_embedding</a>, <a href="https://drive.google.com/file/d/1fIIVMTA_tPuaAAFtqizr6sd1XV7CX6F9/view?usp=sharing">decoder</a>, <a href="https://drive.google.com/file/d/1dnobsaLeE889T_LncCkAA2RkqzwsfHYy/view?usp=sharing">Transformer_module</a>   <br>
Veuillez les télécharger et les placer dans le dossier ./experiments/  <br></p>
<pre><code>python test.py  --content_dir input/content/ --style_dir input/style/    --output out
</code></pre>
<h3>Entraînement</h3>
<p>Le jeu de données de style est WikiArt, collecté depuis <a href="https://www.wikiart.org/">WIKIART</a>  <br><br />
Le jeu de données de contenu est COCO2014  <br></p>
<pre><code>python train.py --style_dir ../../datasets/Images/ --content_dir ../../datasets/train2014 --save_dir models/ --batch_size 8
</code></pre>
<h3>Référence</h3>
<p>Si vous trouvez notre travail utile dans vos recherches, veuillez citer notre article en utilisant l’entrée BibTeX suivante ~ Merci ^ . ^. Lien vers l’article <a href="https://arxiv.org/abs/2105.14576">pdf</a><br></p>
<pre><code>@inproceedings{deng2021stytr2,
      title={StyTr^2: Image Style Transfer with Transformers}, 
      author={Yingying Deng and Fan Tang and Weiming Dong and Chongyang Ma and Xingjia Pan and Lei Wang and Changsheng Xu},
      booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
      year={2022},
}
</code></pre>
<hr />
<p>Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx">Open Ai Tx</a> | Last indexed: 2025-06-09</p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
</body>
</html>