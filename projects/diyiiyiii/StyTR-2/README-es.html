<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>StyTR-2 - diyiiyiii/StyTR-2</title>
    <meta name="title" content="StyTR-2 - diyiiyiii/StyTR-2">
    <meta name="description" content="diyiiyiii/StyTR-2 - GitHub repository es documentation and informationStyTr^2 : Transferencia de Estilo de Imagen con Transformers (CVPR2022) Autores: Yingying Deng, Fan Tang, Xingjia Pan, Weiming Dong, Chongyang Ma, Changsheng Xu...">
    <meta name="keywords" content="diyiiyiii, StyTR-2, GitHub, repository, es documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/diyiiyiii/StyTR-2/README-es.html">
    <meta property="og:title" content="StyTR-2 - diyiiyiii/StyTR-2">
    <meta property="og:description" content="diyiiyiii/StyTR-2 - GitHub repository es documentation and information">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/diyiiyiii/StyTR-2" id="githubRepoLink" target="_blank">diyiiyiii/StyTR-2</a>
<h1 style="display: none;">StyTr^2 : Transferencia de Estilo de Imagen con Transformers (CVPR2022) Autores: Yingying Deng, Fan Tang, Xingjia Pan, Weiming Dong, Chongyang Ma, Changsheng Xu...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <h1>StyTr^2 : Transferencia de Estilo de Imagen con Transformers (CVPR2022)</h1>
<p><em>Autores: <a href="https://diyiiyiii.github.io/">Yingying Deng</a>, Fan Tang, Xingjia Pan, Weiming Dong, Chongyang Ma, Changsheng Xu</em></p>
<p>Este artículo propone lograr una transferencia de estilo de imagen sin sesgos basada en el modelo transformer. Podemos mejorar el efecto de estilización en comparación con los métodos más avanzados.
Este repositorio es la implementación oficial de <a href="https://arxiv.org/abs/2105.14576">SyTr^2 : Image Style Transfer with Transformers</a>.</p>
<h2>Presentación de Resultados</h2>
<p align="center">
<img src="https://github.com/diyiiyiii/StyTR-2/blob/main/Figure/Unbiased.png" width="90%" height="90%">
</p>
En comparación con algunos algoritmos de última generación, nuestro método tiene una fuerte capacidad para evitar la fuga de contenido y una mejor capacidad de representación de características.  <br>
<h2>Marco de trabajo</h2>
<p align="center">
<img src="https://github.com/diyiiyiii/StyTR-2/blob/main/Figure/network.png" width="100%" height="100%">
</p> 
El flujo general de nuestra estructura StyTr^2. Dividimos las imágenes de contenido y estilo en parches, y usamos una proyección lineal para obtener secuencias de imágenes. Luego, las secuencias de contenido, a las que se les añade CAPE, se introducen en el codificador transformer de contenido, mientras que las secuencias de estilo se introducen en el codificador transformer de estilo. Después de los dos codificadores transformer, se adopta un decodificador transformer de múltiples capas para estilizar las secuencias de contenido según las secuencias de estilo. Finalmente, utilizamos un decodificador de aumento progresivo de resolución para obtener las imágenes estilizadas en alta resolución.
<h2>Experimento</h2>
<h3>Requisitos</h3>
<ul>
<li>python 3.6</li>
<li>pytorch 1.4.0</li>
<li>PIL, numpy, scipy</li>
<li>tqdm  <br></li>
</ul>
<h3>Pruebas</h3>
<p>Modelos preentrenados: <a href="https://drive.google.com/file/d/1BinnwM5AmIcVubr16tPTqxMjUCE8iu5M/view?usp=sharing">vgg-model</a>,  <a href="https://drive.google.com/file/d/1C3xzTOWx8dUXXybxZwmjijZN8SrC3e4B/view?usp=sharing">vit_embedding</a>, <a href="https://drive.google.com/file/d/1fIIVMTA_tPuaAAFtqizr6sd1XV7CX6F9/view?usp=sharing">decoder</a>, <a href="https://drive.google.com/file/d/1dnobsaLeE889T_LncCkAA2RkqzwsfHYy/view?usp=sharing">Transformer_module</a>   <br>
Por favor descárguelos y colóquelos en la carpeta ./experiments/  <br></p>
<pre><code>python test.py  --content_dir input/content/ --style_dir input/style/    --output out
</code></pre>
<h3>Entrenamiento</h3>
<p>El dataset de estilos es WikiArt recopilado de <a href="https://www.wikiart.org/">WIKIART</a>  <br><br />
El dataset de contenido es COCO2014  <br></p>
<pre><code>python train.py --style_dir ../../datasets/Images/ --content_dir ../../datasets/train2014 --save_dir models/ --batch_size 8
</code></pre>
<h3>Referencia</h3>
<p>Si encuentra útil nuestro trabajo en su investigación, por favor cite nuestro artículo usando la siguiente entrada BibTeX ~ Gracias ^ . ^. Enlace al artículo <a href="https://arxiv.org/abs/2105.14576">pdf</a><br></p>
<pre><code>@inproceedings{deng2021stytr2,
      title={StyTr^2: Image Style Transfer with Transformers}, 
      author={Yingying Deng and Fan Tang and Weiming Dong and Chongyang Ma and Xingjia Pan and Lei Wang and Changsheng Xu},
      booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
      year={2022},
}
</code></pre>
<hr />
<p>Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx">Open Ai Tx</a> | Last indexed: 2025-06-09</p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Statcounter and other scripts can be added here -->
</body>
</html>