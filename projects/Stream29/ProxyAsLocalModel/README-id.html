<!DOCTYPE html>
<html lang="id">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ProxyAsLocalModel - Indonesian Documentation</title>
    <meta name="description" content="Read ProxyAsLocalModel documentation in Indonesian. This project has 135 stars on GitHub.">
    <meta name="keywords" content="ProxyAsLocalModel, Indonesian, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "ProxyAsLocalModel",
  "description": "Documentation for ProxyAsLocalModel in Indonesian",
  "author": {
    "@type": "Person",
    "name": "Stream29"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 135
  },
  "url": "https://OpenAiTx.github.io/projects/Stream29/ProxyAsLocalModel/README-id.html",
  "sameAs": "https://raw.githubusercontent.com/Stream29/ProxyAsLocalModel/master/README.md",
  "datePublished": "2025-07-10",
  "dateModified": "2025-07-10"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            color: #24292e;
            margin-bottom: 8px;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">ProxyAsLocalModel</h1>
            <div class="project-meta">
                <span class="stars">⭐ 135 stars</span>
                <span class="language">Indonesian</span>
                <span>by Stream29</span>
            </div>
        </div>
        
        <div class="content">
            <h1>ProxyAsLocalModel</h1></p><p>Proxy API LLM jarak jauh sebagai model Lokal. Khususnya berfungsi untuk menggunakan LLM kustom di JetBrains AI Assistant.</p><p>Didukung oleh Ktor dan kotlinx.serialization. Terima kasih atas fitur tanpa refleksi mereka.</p><h2>Cerita dari proyek ini</h2></p><p>Saat ini, JetBrains AI Assistant menyediakan paket gratis dengan kuota yang sangat terbatas. Saya mencobanya dan kuota saya cepat habis.</p><p>Saya sudah membeli token API LLM lain, seperti Gemini dan Qwen. Jadi saya mulai berpikir untuk menggunakannya di AI Assistant. Sayangnya, hanya model lokal dari LM Studio dan Ollama yang didukung. Maka saya mulai mengerjakan aplikasi proxy ini yang memproxy API LLM pihak ketiga sebagai API LM Studio dan Ollama agar saya bisa menggunakannya di IDE JetBrains saya.</p><p>Ini hanyalah tugas sederhana, jadi saya mulai menggunakan SDK resmi sebagai klien dan menulis server Ktor sederhana yang menyediakan endpoint seperti LM Studio dan Ollama. Masalah muncul ketika saya mencoba mendistribusikannya sebagai image native GraalVM. SDK Java resmi menggunakan terlalu banyak fitur dinamis, sehingga sulit untuk dikompilasi menjadi image native, bahkan dengan tracing agent. Jadi saya memutuskan untuk mengimplementasikan klien sederhana untuk API chat completion streaming sendiri menggunakan Ktor dan kotlinx.serialization yang keduanya tanpa refleksi, fungsional, dan bergaya DSL.</p><p>Seperti yang Anda lihat, aplikasi ini didistribusikan sebagai fat runnable jar dan image native GraalVM, yang membuatnya lintas platform dan cepat untuk dijalankan.</p><p>Pengembangan aplikasi ini memberi saya kepercayaan diri pada Kotlin/Ktor/kotlinx.serialization. Dunia Kotlin lebih banyak menggunakan pemrograman fungsional dan lebih sedikit refleksi, sehingga lebih cocok untuk image native GraalVM, dengan waktu startup yang lebih cepat dan penggunaan memori yang lebih sedikit.</p><h2>Saat ini didukung</h2></p><p>Proxy dari: OpenAI, Claude, DashScope (Alibaba Qwen), Gemini, Deepseek, Mistral, SiliconFlow.</p><p>Proxy sebagai: LM Studio, Ollama.</p><p>Hanya API chat completion streaming.
<h2>Cara Penggunaan</h2></p><p>Aplikasi ini adalah server proxy, didistribusikan sebagai fat runnable jar dan GraalVM native image (Windows x64).</p><p>Jalankan aplikasi, dan Anda akan melihat pesan bantuan:</p><pre><code class="language-">2025-05-02 10:43:53 INFO  Help - Sepertinya Anda menjalankan program untuk pertama kalinya di sini.
2025-05-02 10:43:53 INFO  Help - File konfigurasi default telah dibuat di your_path\config.yml dengan anotasi skema.
2025-05-02 10:43:53 INFO  Config - Pemantau file konfigurasi dimulai di your_path\config.yml
2025-05-02 10:43:53 INFO  LM Studio Server - LM Studio Server dimulai pada 1234
2025-05-02 10:43:53 INFO  Ollama Server - Ollama Server dimulai pada 11434
2025-05-02 10:43:53 INFO  Model List - Daftar model dimuat dengan: []</code></pre></p><p>Kemudian Anda dapat mengedit file konfigurasi untuk mengatur server proxy Anda.</p><h2>File Konfigurasi</h2></p><p>File konfigurasi ini secara otomatis dimuat ulang (hot-reload) saat Anda mengubahnya. Hanya bagian server yang terpengaruh yang akan diperbarui.</p><p>Saat pertama kali menghasilkan file konfigurasi, file tersebut akan dibuat dengan anotasi skema. Ini akan memberikan fitur pelengkapan dan pemeriksaan di editor Anda.
<h2>Contoh file konfigurasi</h2></p><pre><code class="language-yaml"># $schema: https://github.com/Stream29/ProxyAsLocalModel/raw/master/config_v3.schema.json
lmStudio:
  port: 1234 # Ini adalah nilai default
  enabled: true # Ini adalah nilai default
  host: 0.0.0.0 # Ini adalah nilai default
  path: /your/path # Akan ditambahkan sebelum endpoint asli, nilai default adalah kosong
ollama:
  port: 11434 # Ini adalah nilai default
  enabled: true # Ini adalah nilai default
  host: 0.0.0.0 # Ini adalah nilai default
  path: /your/path # Akan ditambahkan sebelum endpoint asli, nilai default adalah kosong
client:
  socketTimeout: 1919810 # Long.MAX_VALUE adalah nilai default, dalam milidetik
  connectionTimeout: 1919810 # Long.MAX_VALUE adalah nilai default, dalam milidetik
  requestTimeout: 1919810 # Long.MAX_VALUE adalah nilai default, dalam milidetik
  retry: 3 # Ini adalah nilai default
  delayBeforeRetry: 1000 # Ini adalah nilai default, dalam milidetik</p><p>apiProviders:
  OpenAI:
    type: OpenAi
    baseUrl: https://api.openai.com/v1
    apiKey: <your_api_key>
    modelList:
      <ul><li>gpt-4o</li>
  </ul>Claude:
    type: Claude
    apiKey: <your_api_key>
    modelList:
      <ul><li>claude-3-7-sonnet</li>
  </ul>Qwen:
    type: DashScope
    apiKey: <your_api_key>
    modelList: # Ini adalah nilai default
      <ul><li>qwen-max</li>
      <li>qwen-plus</li>
      <li>qwen-turbo</li>
      <li>qwen-long</li>
  </ul>DeepSeek:
    type: DeepSeek
    apiKey: <your_api_key>
    modelList: # Ini adalah nilai default
      <ul><li>deepseek-chat</li>
      <li>deepseek-reasoner</li>
  </ul>Mistral:
    type: Mistral
    apiKey: <your_api_key>
    modelList: # Ini adalah nilai default
      <ul><li>codestral-latest</li>
      <li>mistral-large</li>
  </ul>SiliconFlow:
    type: SiliconFlow
    apiKey: <your_api_key>
    modelList:
      <ul><li>Qwen/Qwen3-235B-A22B</li>
      <li>Pro/deepseek-ai/DeepSeek-V3</li>
      <li>THUDM/GLM-4-32B-0414</li>
  </ul>OpenRouter:
    type: OpenRouter
    apiKey: <your_api_key>
    modelList:
      <ul><li>openai/gpt-4o</li>
  </ul>Gemini:
    type: Gemini
    apiKey: <your_api_key>
    modelList:
      <ul><li>gemini-2.5-flash-preview-04-17</code></pre></li>

</ul>---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-07-10

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/Stream29/ProxyAsLocalModel/master/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-07-10 
    </div>
    
</body>
</html>