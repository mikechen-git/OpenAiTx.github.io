<!DOCTYPE html>
<html lang="th">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ProxyAsLocalModel - Thai Documentation</title>
    <meta name="description" content="Read ProxyAsLocalModel documentation in Thai. This project has 135 stars on GitHub.">
    <meta name="keywords" content="ProxyAsLocalModel, Thai, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "ProxyAsLocalModel",
  "description": "Documentation for ProxyAsLocalModel in Thai",
  "author": {
    "@type": "Person",
    "name": "Stream29"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 135
  },
  "url": "https://OpenAiTx.github.io/projects/Stream29/ProxyAsLocalModel/README-th.html",
  "sameAs": "https://raw.githubusercontent.com/Stream29/ProxyAsLocalModel/master/README.md",
  "datePublished": "2025-07-10",
  "dateModified": "2025-07-10"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            color: #24292e;
            margin-bottom: 8px;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">ProxyAsLocalModel</h1>
            <div class="project-meta">
                <span class="stars">⭐ 135 stars</span>
                <span class="language">Thai</span>
                <span>by Stream29</span>
            </div>
        </div>
        
        <div class="content">
            <h1>ProxyAsLocalModel</h1></p><p>พร็อกซี่ LLM API ระยะไกลเป็นโมเดลโลคัล ใช้งานได้ดีโดยเฉพาะสำหรับการใช้ LLM แบบกำหนดเองใน JetBrains AI Assistant</p><p>ขับเคลื่อนด้วย Ktor และ kotlinx.serialization ขอบคุณฟีเจอร์ที่ไม่ใช้รีเฟล็กซ์ของพวกเขา</p><h2>เรื่องราวของโปรเจกต์นี้</h2></p><p>ปัจจุบัน JetBrains AI Assistant ให้บริการแผนฟรีแต่มีโควตาจำกัดมาก ฉันลองใช้งานและโควตาของฉันหมดอย่างรวดเร็ว</p><p>ฉันซื้อโทเค็น LLM API อื่นๆ ไว้อยู่แล้ว เช่น Gemini และ Qwen ดังนั้นฉันจึงเริ่มคิดที่จะใช้มันใน AI Assistant น่าเสียดายที่รองรับเฉพาะโมเดลโลคัลจาก LM Studio และ Ollama เท่านั้น ฉันจึงเริ่มพัฒนาแอปพลิเคชันพร็อกซี่นี้เพื่อทำหน้าที่เป็นพร็อกซี่ให้กับ LLM API ของบุคคลที่สามให้เหมือนกับ LM Studio และ Ollama API เพื่อให้สามารถใช้งานใน JetBrains IDEs ของฉันได้</p><p>นี่เป็นงานที่ง่ายมาก ฉันจึงเริ่มต้นด้วยการใช้ SDK อย่างเป็นทางการเป็นไคลเอนต์และเขียน Ktor เซิร์ฟเวอร์ง่ายๆ ที่ให้บริการ endpoint เหมือนกับ LM Studio และ Ollama ปัญหาเกิดขึ้นเมื่อฉันพยายามแจกจ่ายแอปนี้เป็น GraalVM native image SDK Java อย่างเป็นทางการใช้ฟีเจอร์ไดนามิกมากเกินไป ทำให้คอมไพล์เป็น native image ได้ยาก แม้จะใช้ tracing agent ก็ตาม ดังนั้นฉันจึงตัดสินใจพัฒนาไคลเอนต์แบบง่ายสำหรับ streaming chat completion API ด้วยตัวเองโดยใช้ Ktor และ kotlinx.serialization ซึ่งทั้งสองอย่างนี้ไม่ใช้รีเฟล็กซ์ ใช้งานแบบ functional และ DSL</p><p>ดังที่เห็น แอปพลิเคชันนี้แจกจ่ายเป็น fat runnable jar และ GraalVM native image ซึ่งทำให้ข้ามแพลตฟอร์มและเริ่มต้นได้รวดเร็ว</p><p>การพัฒนาแอปพลิเคชันนี้ทำให้ฉันมั่นใจใน Kotlin/Ktor/kotlinx.serialization โลกของ Kotlin ใช้ functional programming มากกว่า และใช้รีเฟล็กชันน้อยกว่า ซึ่งทำให้เหมาะกับ GraalVM native image มากกว่า เริ่มต้นได้เร็วและใช้หน่วยความจำน้อยกว่า</p><h2>รองรับในปัจจุบัน</h2></p><p>พร็อกซี่จาก: OpenAI, Claude, DashScope(Alibaba Qwen), Gemini, Deepseek, Mistral, SiliconFlow</p><p>พร็อกซี่เป็น: LM Studio, Ollama</p><p>รองรับเฉพาะ Streaming chat completion API
<h2>วิธีการใช้งาน</h2></p><p>แอปพลิเคชันนี้เป็น proxy server ซึ่งแจกจ่ายในรูปแบบ fat runnable jar และ GraalVM native image (Windows x64)</p><p>เมื่อรันแอปพลิเคชัน คุณจะเห็นข้อความช่วยเหลือดังนี้:</p><pre><code class="language-">2025-05-02 10:43:53 INFO  Help - ดูเหมือนว่าคุณกำลังเริ่มโปรแกรมนี้เป็นครั้งแรกที่นี่
2025-05-02 10:43:53 INFO  Help - ไฟล์ config เริ่มต้นถูกสร้างขึ้นที่ your_path\config.yml พร้อมคำอธิบาย schema
2025-05-02 10:43:53 INFO  Config - ตัวเฝ้าดูไฟล์ config เริ่มทำงานที่ your_path\config.yml
2025-05-02 10:43:53 INFO  LM Studio Server - LM Studio Server เริ่มทำงานที่ 1234
2025-05-02 10:43:53 INFO  Ollama Server - Ollama Server เริ่มทำงานที่ 11434
2025-05-02 10:43:53 INFO  Model List - รายการโมเดลถูกโหลดด้วย: []</code></pre></p><p>จากนั้นคุณสามารถแก้ไขไฟล์ config เพื่อกำหนดค่า proxy server ของคุณ</p><h2>ไฟล์ Config</h2></p><p>ไฟล์ config นี้จะถูก hot-reload โดยอัตโนมัติเมื่อคุณมีการเปลี่ยนแปลง เฉพาะส่วนที่ได้รับผลกระทบของเซิร์ฟเวอร์เท่านั้นที่จะถูกอัปเดต</p><p>เมื่อไฟล์ config ถูกสร้างขึ้นครั้งแรก จะมีคำอธิบาย schema อยู่ด้วย ซึ่งจะช่วยให้มีการเติมคำและตรวจสอบใน editor ของคุณ
<h2>ตัวอย่างไฟล์ config</h2></p><pre><code class="language-yaml"># $schema: https://github.com/Stream29/ProxyAsLocalModel/raw/master/config_v3.schema.json
lmStudio:
  port: 1234 # ค่านี้เป็นค่าเริ่มต้น
  enabled: true # ค่านี้เป็นค่าเริ่มต้น
  host: 0.0.0.0 # ค่านี้เป็นค่าเริ่มต้น
  path: /your/path # จะถูกเพิ่มก่อน endpoint เดิม, ค่าเริ่มต้นคือค่าว่าง
ollama:
  port: 11434 # ค่านี้เป็นค่าเริ่มต้น
  enabled: true # ค่านี้เป็นค่าเริ่มต้น
  host: 0.0.0.0 # ค่านี้เป็นค่าเริ่มต้น
  path: /your/path # จะถูกเพิ่มก่อน endpoint เดิม, ค่าเริ่มต้นคือค่าว่าง
client:
  socketTimeout: 1919810 # Long.MAX_VALUE คือค่าเริ่มต้น, หน่วยเป็นมิลลิวินาที
  connectionTimeout: 1919810 # Long.MAX_VALUE คือค่าเริ่มต้น, หน่วยเป็นมิลลิวินาที
  requestTimeout: 1919810 # Long.MAX_VALUE คือค่าเริ่มต้น, หน่วยเป็นมิลลิวินาที
  retry: 3 # ค่านี้เป็นค่าเริ่มต้น
  delayBeforeRetry: 1000 # ค่านี้เป็นค่าเริ่มต้น, หน่วยเป็นมิลลิวินาที</p><p>apiProviders:
  OpenAI:
    type: OpenAi
    baseUrl: https://api.openai.com/v1
    apiKey: <your_api_key>
    modelList:
      <ul><li>gpt-4o</li>
  </ul>Claude:
    type: Claude
    apiKey: <your_api_key>
    modelList:
      <ul><li>claude-3-7-sonnet</li>
  </ul>Qwen:
    type: DashScope
    apiKey: <your_api_key>
    modelList: # ค่านี้เป็นค่าเริ่มต้น
      <ul><li>qwen-max</li>
      <li>qwen-plus</li>
      <li>qwen-turbo</li>
      <li>qwen-long</li>
  </ul>DeepSeek:
    type: DeepSeek
    apiKey: <your_api_key>
    modelList: # ค่านี้เป็นค่าเริ่มต้น
      <ul><li>deepseek-chat</li>
      <li>deepseek-reasoner</li>
  </ul>Mistral:
    type: Mistral
    apiKey: <your_api_key>
    modelList: # ค่านี้เป็นค่าเริ่มต้น
      <ul><li>codestral-latest</li>
      <li>mistral-large</li>
  </ul>SiliconFlow:
    type: SiliconFlow
    apiKey: <your_api_key>
    modelList:
      <ul><li>Qwen/Qwen3-235B-A22B</li>
      <li>Pro/deepseek-ai/DeepSeek-V3</li>
      <li>THUDM/GLM-4-32B-0414</li>
  </ul>OpenRouter:
    type: OpenRouter
    apiKey: <your_api_key>
    modelList:
      <ul><li>openai/gpt-4o</li>
  </ul>Gemini:
    type: Gemini
    apiKey: <your_api_key>
    modelList:
      <ul><li>gemini-2.5-flash-preview-04-17</code></pre></li>

</ul>---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-07-10

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/Stream29/ProxyAsLocalModel/master/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-07-10 
    </div>
    
</body>
</html>