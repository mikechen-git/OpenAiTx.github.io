<!DOCTYPE html>
<html lang="tr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ProxyAsLocalModel - Stream29/ProxyAsLocalModel tr</title>
    <meta name="title" content="ProxyAsLocalModel - Stream29/ProxyAsLocalModel tr | ProxyAsLocalModel Uzaktaki LLM API'sini yerel model olarak proxy'le. Özellikle JetBrains AI Assistant'ta özel LLM kullanımı için çalışır. Ktor ve kotlinx.serial...">
    <meta name="description" content="Stream29/ProxyAsLocalModel - GitHub repository tr documentation and information | ProxyAsLocalModel Uzaktaki LLM API'sini yerel model olarak proxy'le. Özellikle JetBrains AI Assistant'ta özel LLM kullanımı için çalışır. Ktor ve kotlinx.serial...">
    <meta name="keywords" content="Stream29, ProxyAsLocalModel, GitHub, repository, tr documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/Stream29/ProxyAsLocalModel/README-tr.html">
    <meta property="og:title" content="ProxyAsLocalModel - Stream29/ProxyAsLocalModel tr | ProxyAsLocalModel Uzaktaki LLM API'sini yerel model olarak proxy'le. Özellikle JetBrains AI Assistant'ta özel LLM kullanımı için çalışır. Ktor ve kotlinx.serial...">
    <meta property="og:description" content="Stream29/ProxyAsLocalModel - GitHub repository tr documentation and information | ProxyAsLocalModel Uzaktaki LLM API'sini yerel model olarak proxy'le. Özellikle JetBrains AI Assistant'ta özel LLM kullanımı için çalışır. Ktor ve kotlinx.serial...">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div style="position: fixed; top: 2px; left: 2px; z-index: 2000; background: rgba(255,255,255,0.95); border-radius: 6px; box-shadow: 0 2px 8px rgba(0,0,0,0.06); padding: 4px 14px; font-size: 15px; color: #222; font-family: 'Segoe UI', Arial, sans-serif; font-weight: 500; letter-spacing: 0.5px;">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" style="color: #0366d6; text-decoration: none; font-weight: 600;">Open AI Tx</a>
    </div>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/Stream29/ProxyAsLocalModel" id="githubRepoLink" target="_blank">Stream29/ProxyAsLocalModel</a>
<h1 style="display: none;">ProxyAsLocalModel Uzaktaki LLM API'sini yerel model olarak proxy'le. Özellikle JetBrains AI Assistant'ta özel LLM kullanımı için çalışır. Ktor ve kotlinx.serial...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <h1>ProxyAsLocalModel</h1>
<p>Uzaktaki LLM API'sini yerel model olarak proxy'le. Özellikle JetBrains AI Assistant'ta özel LLM kullanımı için çalışır.</p>
<p>Ktor ve kotlinx.serialization tarafından desteklenmektedir. No-reflex özellikleri sayesinde.</p>
<h2>Bu projenin hikayesi</h2>
<p>Şu anda JetBrains AI Assistant, çok sınırlı kotalı ücretsiz bir plan sunuyor. Denedim ve kotam hızla tükendi.</p>
<p>Zaten Gemini ve Qwen gibi başka LLM API tokenları satın almıştım. Bu yüzden bunları AI Assistant'ta kullanmayı düşünmeye başladım. Ne yazık ki, yalnızca LM Studio ve Ollama'nın yerel modelleri destekleniyor. Bu nedenle, üçüncü parti LLM API'sini LM Studio ve Ollama API'si olarak proxy'leyen ve böylece JetBrains IDE'lerimde kullanabilmemi sağlayan bu proxy uygulaması üzerinde çalışmaya başladım.</p>
<p>Bu sadece basit bir iş, bu yüzden istemci olarak resmi SDK'ları kullanıp LM Studio ve Ollama olarak endpoint sağlayan basit bir Ktor sunucusu yazmaya başladım. Sorun, bunu GraalVM native image olarak dağıtmaya çalıştığımda ortaya çıktı. Resmi Java SDK'ları çok fazla dinamik özellik kullanıyor, bu da tracing agent ile bile native image olarak derlemeyi zorlaştırıyor. Bu yüzden, hem no-reflex, fonksiyonel ve DSL tarzında olan Ktor ve kotlinx.serialization ile streaming chat completion API için basit bir istemciyi kendim yazmaya karar verdim.</p>
<p>Görüldüğü üzere, bu uygulama platformlar arası ve hızlı başlatılabilen bir fat runnable jar ve GraalVM native image olarak dağıtılmaktadır.</p>
<p>Bu uygulamanın geliştirilmesi bana Kotlin/Ktor/kotlinx.serialization konusunda güven verdi. Kotlin dünyası daha fazla fonksiyonel programlama ve daha az refleksiyon kullanıyor, bu da onu GraalVM native image için daha uygun, daha hızlı başlatılan ve daha az bellek kullanan bir hale getiriyor.</p>
<h2>Şu anda desteklenenler</h2>
<p>Proxy kaynakları: OpenAI, Claude, DashScope(Alibaba Qwen), Gemini, Deepseek, Mistral, SiliconFlow.</p>
<p>Proxy olarak: LM Studio, Ollama.</p>
<p>Sadece streaming chat completion API.</p>
<h2>Nasıl Kullanılır</h2>
<p>Bu uygulama bir proxy sunucusudur ve çalıştırılabilir fat jar ile GraalVM yerel görüntüsü (Windows x64) olarak dağıtılır.</p>
<p>Uygulamayı çalıştırın, ardından bir yardım mesajı göreceksiniz:</p>
<pre><code>2025-05-02 10:43:53 INFO  Help - Görünüşe göre programı burada ilk kez başlatıyorsunuz.
2025-05-02 10:43:53 INFO  Help - Varsayılan bir yapılandırma dosyası your_path\config.yml konumunda şema açıklamalarıyla oluşturuldu.
2025-05-02 10:43:53 INFO  Config - Yapılandırma dosyası izleyicisi your_path\config.yml konumunda başlatıldı
2025-05-02 10:43:53 INFO  LM Studio Server - LM Studio Sunucusu 1234 üzerinde başlatıldı
2025-05-02 10:43:53 INFO  Ollama Server - Ollama Sunucusu 11434 üzerinde başlatıldı
2025-05-02 10:43:53 INFO  Model List - Model listesi şu şekilde yüklendi: []
</code></pre>
<p>Daha sonra proxy sunucunuzu kurmak için yapılandırma dosyasını düzenleyebilirsiniz.</p>
<h2>Yapılandırma Dosyası</h2>
<p>Bu yapılandırma dosyası, siz değiştirdiğinizde otomatik olarak sıcak yeniden yüklenir. Sunucunun yalnızca etkilenen bölümleri güncellenecektir.</p>
<p>Yapılandırma dosyası ilk oluşturulduğunda, şema açıklamaları ile birlikte gelir. Bu, editörünüzde tamamlama ve kontrol imkanı sağlar.</p>
<h2>Örnek yapılandırma dosyası</h2>
<pre><code class="language-yaml"># $schema: https://github.com/Stream29/ProxyAsLocalModel/raw/master/config_v3.schema.json
lmStudio:
  port: 1234 # Bu varsayılan değerdir
  enabled: true # Bu varsayılan değerdir
  host: 0.0.0.0 # Bu varsayılan değerdir
  path: /your/path # Orijinal uç noktalardan önce eklenecek, varsayılan değeri boştur
ollama:
  port: 11434 # Bu varsayılan değerdir
  enabled: true # Bu varsayılan değerdir
  host: 0.0.0.0 # Bu varsayılan değerdir
  path: /your/path # Orijinal uç noktalardan önce eklenecek, varsayılan değeri boştur
client:
  socketTimeout: 1919810 # Varsayılan değer Long.MAX_VALUE'dur, milisaniye cinsindendir
  connectionTimeout: 1919810 # Varsayılan değer Long.MAX_VALUE'dur, milisaniye cinsindendir
  requestTimeout: 1919810 # Varsayılan değer Long.MAX_VALUE'dur, milisaniye cinsindendir
  retry: 3 # Bu varsayılan değerdir
  delayBeforeRetry: 1000 # Bu varsayılan değerdir, milisaniye cinsindendir

apiProviders:
  OpenAI:
    type: OpenAi
    baseUrl: https://api.openai.com/v1
    apiKey: &lt;your_api_key&gt;
    modelList:
      - gpt-4o
  Claude:
    type: Claude
    apiKey: &lt;your_api_key&gt;
    modelList:
      - claude-3-7-sonnet
  Qwen:
    type: DashScope
    apiKey: &lt;your_api_key&gt;
    modelList: # Bu varsayılan değerdir
      - qwen-max
      - qwen-plus
      - qwen-turbo
      - qwen-long
  DeepSeek:
    type: DeepSeek
    apiKey: &lt;your_api_key&gt;
    modelList: # Bu varsayılan değerdir
      - deepseek-chat
      - deepseek-reasoner
  Mistral:
    type: Mistral
    apiKey: &lt;your_api_key&gt;
    modelList: # Bu varsayılan değerdir
      - codestral-latest
      - mistral-large
  SiliconFlow:
    type: SiliconFlow
    apiKey: &lt;your_api_key&gt;
    modelList:
      - Qwen/Qwen3-235B-A22B
      - Pro/deepseek-ai/DeepSeek-V3
      - THUDM/GLM-4-32B-0414
  OpenRouter:
    type: OpenRouter
    apiKey: &lt;your_api_key&gt;
    modelList:
      - openai/gpt-4o
  Gemini:
    type: Gemini
    apiKey: &lt;your_api_key&gt;
    modelList:
      - gemini-2.5-flash-preview-04-17
</code></pre>
<hr />
<p>Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx">Open Ai Tx</a> | Last indexed: 2025-07-10</p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
</body>
</html>