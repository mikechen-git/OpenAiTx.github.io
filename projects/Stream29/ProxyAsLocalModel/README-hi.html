<!DOCTYPE html>
<html lang="hi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ProxyAsLocalModel - Hindi Documentation</title>
    <meta name="description" content="Read ProxyAsLocalModel documentation in Hindi. This project has 135 stars on GitHub.">
    <meta name="keywords" content="ProxyAsLocalModel, Hindi, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "ProxyAsLocalModel",
  "description": "Documentation for ProxyAsLocalModel in Hindi",
  "author": {
    "@type": "Person",
    "name": "Stream29"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 135
  },
  "url": "https://OpenAiTx.github.io/projects/Stream29/ProxyAsLocalModel/README-hi.html",
  "sameAs": "https://raw.githubusercontent.com/Stream29/ProxyAsLocalModel/master/README.md",
  "datePublished": "2025-07-10",
  "dateModified": "2025-07-10"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            color: #24292e;
            margin-bottom: 8px;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">ProxyAsLocalModel</h1>
            <div class="project-meta">
                <span class="stars">⭐ 135 stars</span>
                <span class="language">Hindi</span>
                <span>by Stream29</span>
            </div>
        </div>
        
        <div class="content">
            <h1>ProxyAsLocalModel</h1></p><p>रिमोट LLM API को लोकल मॉडल के रूप में प्रॉक्सी करें। विशेष रूप से JetBrains AI Assistant में कस्टम LLM का उपयोग करने के लिए काम करता है।</p><p>Ktor और kotlinx.serialization द्वारा संचालित। उनके बिना-रिफ्लेक्स फीचर्स के लिए धन्यवाद।</p><h2>इस प्रोजेक्ट की कहानी</h2></p><p>वर्तमान में, JetBrains AI Assistant एक फ्री प्लान प्रदान करता है जिसमें बहुत सीमित कोट्स हैं। मैंने इसे आज़माया और मेरी कोटा जल्दी ही समाप्त हो गई।</p><p>मैंने पहले ही अन्य LLM API टोकन खरीद लिए थे, जैसे कि Gemini और Qwen। इसलिए मैंने सोचना शुरू किया कि इन्हें AI Assistant में कैसे उपयोग किया जाए। दुर्भाग्य से, केवल LM Studio और Ollama के लोकल मॉडल ही समर्थित हैं। इसलिए मैंने इस प्रॉक्सी एप्लिकेशन पर काम शुरू किया, जो थर्ड पार्टी LLM API को LM Studio और Ollama API के रूप में प्रॉक्सी करता है ताकि मैं इन्हें अपने JetBrains IDEs में उपयोग कर सकूं।</p><p>यह एक सरल कार्य था, इसलिए मैंने आधिकारिक SDKs का क्लाइंट के रूप में उपयोग करना शुरू किया और एक सरल Ktor सर्वर लिखा जो LM Studio और Ollama के रूप में एंडपॉइंट्स प्रदान करता है। समस्या तब आई जब मैंने इसे GraalVM नेटिव इमेज के रूप में वितरित करने की कोशिश की। आधिकारिक Java SDKs बहुत अधिक डायनेमिक फीचर्स का उपयोग करते हैं, जिससे इसे नेटिव इमेज में कंपाइल करना मुश्किल हो जाता है, यहां तक कि ट्रेसिंग एजेंट के साथ भी। इसलिए मैंने Ktor और kotlinx.serialization के साथ खुद ही स्ट्रीमिंग चैट कंप्लीशन API का एक सरल क्लाइंट इम्प्लीमेंट करने का निर्णय लिया, जो दोनों ही बिना-रिफ्लेक्स, फंक्शनल और DSL स्टाइल्ड हैं।</p><p>जैसा कि आप देख सकते हैं, यह एप्लिकेशन एक फैट रननेबल जार और एक GraalVM नेटिव इमेज के रूप में वितरित किया जाता है, जिससे यह क्रॉस-प्लेटफॉर्म और जल्दी स्टार्ट होने वाला बन जाता है।</p><p>इस एप्लिकेशन के विकास ने मुझे Kotlin/Ktor/kotlinx.serialization में आत्मविश्वास दिया। Kotlin वर्ल्ड अधिक फंक्शनल प्रोग्रामिंग और कम रिफ्लेक्शन का उपयोग करती है, जिससे यह GraalVM नेटिव इमेज के लिए अधिक उपयुक्त बनती है, तेज़ स्टार्टअप और कम मेमोरी उपयोग के साथ।</p><h2>वर्तमान में समर्थित</h2></p><p>प्रॉक्सी फ्रॉम: OpenAI, Claude, DashScope(Alibaba Qwen), Gemini, Deepseek, Mistral, SiliconFlow।</p><p>प्रॉक्सी ऐज़: LM Studio, Ollama।</p><p>सिर्फ स्ट्रीमिंग चैट कंप्लीशन API।
<h2>उपयोग कैसे करें</h2></p><p>यह एप्लिकेशन एक प्रॉक्सी सर्वर है, जो एक फैट रननेबल जार और GraalVM नेटिव इमेज (Windows x64) के रूप में वितरित किया गया है।</p><p>एप्लिकेशन चलाएँ, और आपको एक सहायता संदेश दिखाई देगा:</p><pre><code class="language-">2025-05-02 10:43:53 INFO  Help - ऐसा लगता है कि आप पहली बार यहाँ प्रोग्राम शुरू कर रहे हैं।
2025-05-02 10:43:53 INFO  Help - एक डिफ़ॉल्ट कॉन्फ़िग फाइल आपके_path\config.yml पर स्कीमा एनोटेशन के साथ बनाई गई है।
2025-05-02 10:43:53 INFO  Config - कॉन्फ़िग फाइल वॉचर आपके_path\config.yml पर शुरू हो गया है।
2025-05-02 10:43:53 INFO  LM Studio Server - LM Studio सर्वर 1234 पर शुरू हो गया है।
2025-05-02 10:43:53 INFO  Ollama Server - Ollama सर्वर 11434 पर शुरू हो गया है।
2025-05-02 10:43:53 INFO  Model List - मॉडल सूची लोड की गई: []</code></pre></p><p>इसके बाद आप अपने प्रॉक्सी सर्वर को सेटअप करने के लिए कॉन्फ़िग फाइल को एडिट कर सकते हैं।</p><h2>कॉन्फ़िग फाइल</h2></p><p>यह कॉन्फ़िग फाइल स्वचालित रूप से हॉट-रिलोड होती है जब भी आप इसमें बदलाव करते हैं। सर्वर के केवल प्रभावित हिस्से ही अपडेट होंगे।</p><p>जब पहली बार कॉन्फ़िग फाइल जेनरेट होती है, तो यह स्कीमा एनोटेशन के साथ बनाई जाएगी। यह आपके एडिटर में ऑटो-कम्प्लीशन और चेकिंग प्रदान करेगा।
<h2>उदाहरण कॉन्फ़िग फ़ाइल</h2></p><pre><code class="language-yaml"># $schema: https://github.com/Stream29/ProxyAsLocalModel/raw/master/config_v3.schema.json
lmStudio:
  port: 1234 # यह डिफ़ॉल्ट मान है
  enabled: true # यह डिफ़ॉल्ट मान है
  host: 0.0.0.0 # यह डिफ़ॉल्ट मान है
  path: /your/path # मूल एंडपॉइंट्स से पहले जोड़ा जाएगा, डिफ़ॉल्ट मान खाली है
ollama:
  port: 11434 # यह डिफ़ॉल्ट मान है
  enabled: true # यह डिफ़ॉल्ट मान है
  host: 0.0.0.0 # यह डिफ़ॉल्ट मान है
  path: /your/path # मूल एंडपॉइंट्स से पहले जोड़ा जाएगा, डिफ़ॉल्ट मान खाली है
client:
  socketTimeout: 1919810 # Long.MAX_VALUE डिफ़ॉल्ट मान है, मिलीसेकंड में
  connectionTimeout: 1919810 # Long.MAX_VALUE डिफ़ॉल्ट मान है, मिलीसेकंड में
  requestTimeout: 1919810 # Long.MAX_VALUE डिफ़ॉल्ट मान है, मिलीसेकंड में
  retry: 3 # यह डिफ़ॉल्ट मान है
  delayBeforeRetry: 1000 # यह डिफ़ॉल्ट मान है, मिलीसेकंड में</p><p>apiProviders:
  OpenAI:
    type: OpenAi
    baseUrl: https://api.openai.com/v1
    apiKey: <your_api_key>
    modelList:
      <ul><li>gpt-4o</li>
  </ul>Claude:
    type: Claude
    apiKey: <your_api_key>
    modelList:
      <ul><li>claude-3-7-sonnet</li>
  </ul>Qwen:
    type: DashScope
    apiKey: <your_api_key>
    modelList: # यह डिफ़ॉल्ट मान है
      <ul><li>qwen-max</li>
      <li>qwen-plus</li>
      <li>qwen-turbo</li>
      <li>qwen-long</li>
  </ul>DeepSeek:
    type: DeepSeek
    apiKey: <your_api_key>
    modelList: # यह डिफ़ॉल्ट मान है
      <ul><li>deepseek-chat</li>
      <li>deepseek-reasoner</li>
  </ul>Mistral:
    type: Mistral
    apiKey: <your_api_key>
    modelList: # यह डिफ़ॉल्ट मान है
      <ul><li>codestral-latest</li>
      <li>mistral-large</li>
  </ul>SiliconFlow:
    type: SiliconFlow
    apiKey: <your_api_key>
    modelList:
      <ul><li>Qwen/Qwen3-235B-A22B</li>
      <li>Pro/deepseek-ai/DeepSeek-V3</li>
      <li>THUDM/GLM-4-32B-0414</li>
  </ul>OpenRouter:
    type: OpenRouter
    apiKey: <your_api_key>
    modelList:
      <ul><li>openai/gpt-4o</li>
  </ul>Gemini:
    type: Gemini
    apiKey: <your_api_key>
    modelList:
      <ul><li>gemini-2.5-flash-preview-04-17</code></pre></li>

</ul>---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-07-10

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/Stream29/ProxyAsLocalModel/master/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-07-10 
    </div>
    
</body>
</html>