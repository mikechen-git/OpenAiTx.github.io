<!DOCTYPE html>
<html lang="vi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ProxyAsLocalModel - Vietnamese Documentation</title>
    <meta name="description" content="Read ProxyAsLocalModel documentation in Vietnamese. This project has 135 stars on GitHub.">
    <meta name="keywords" content="ProxyAsLocalModel, Vietnamese, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "ProxyAsLocalModel",
  "description": "Documentation for ProxyAsLocalModel in Vietnamese",
  "author": {
    "@type": "Person",
    "name": "Stream29"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 135
  },
  "url": "https://OpenAiTx.github.io/projects/Stream29/ProxyAsLocalModel/README-vi.html",
  "sameAs": "https://raw.githubusercontent.com/Stream29/ProxyAsLocalModel/master/README.md",
  "datePublished": "2025-07-10",
  "dateModified": "2025-07-10"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            color: #24292e;
            margin-bottom: 8px;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">ProxyAsLocalModel</h1>
            <div class="project-meta">
                <span class="stars">⭐ 135 stars</span>
                <span class="language">Vietnamese</span>
                <span>by Stream29</span>
            </div>
        </div>
        
        <div class="content">
            <h1>ProxyAsLocalModel</h1></p><p>Proxy API LLM từ xa như một mô hình cục bộ. Đặc biệt hoạt động hiệu quả khi sử dụng LLM tùy chỉnh trong JetBrains AI Assistant.</p><p>Được phát triển bởi Ktor và kotlinx.serialization. Cảm ơn các tính năng không sử dụng phản xạ của chúng.</p><h2>Câu chuyện về dự án này</h2></p><p>Hiện tại, JetBrains AI Assistant cung cấp một gói miễn phí với hạn mức rất hạn chế. Tôi đã thử sử dụng và hạn mức của tôi nhanh chóng hết.</p><p>Tôi đã mua các token API LLM khác, như Gemini và Qwen. Vì vậy, tôi bắt đầu nghĩ đến việc sử dụng chúng trong AI Assistant. Thật không may, chỉ có các mô hình cục bộ từ LM Studio và Ollama được hỗ trợ. Vì vậy, tôi bắt đầu phát triển ứng dụng proxy này, cho phép proxy API LLM bên thứ ba thành API của LM Studio và Ollama để tôi có thể sử dụng chúng trong các IDE JetBrains của mình.</p><p>Đây chỉ là một tác vụ đơn giản, vì vậy tôi bắt đầu sử dụng các SDK chính thức như các client và viết một server Ktor đơn giản cung cấp các endpoint như LM Studio và Ollama. Vấn đề xuất hiện khi tôi cố gắng phân phối nó dưới dạng native image của GraalVM. Các SDK Java chính thức sử dụng quá nhiều tính năng động, khiến cho việc biên dịch thành native image trở nên khó khăn, ngay cả khi sử dụng tracing agent. Vì vậy, tôi quyết định tự mình triển khai một client đơn giản cho API streaming chat completion bằng Ktor và kotlinx.serialization, cả hai đều không sử dụng phản xạ, có tính chức năng và kiểu DSL.</p><p>Như bạn có thể thấy, ứng dụng này được phân phối dưới dạng một fat runnable jar và native image GraalVM, giúp nó đa nền tảng và khởi động nhanh.</p><p>Việc phát triển ứng dụng này giúp tôi tự tin hơn với Kotlin/Ktor/kotlinx.serialization. Thế giới Kotlin sử dụng nhiều lập trình hàm hơn và ít phản xạ hơn, điều này khiến nó phù hợp hơn với native image của GraalVM, với thời gian khởi động nhanh hơn và sử dụng bộ nhớ ít hơn.</p><h2>Hiện tại hỗ trợ</h2></p><p>Proxy từ: OpenAI, Claude, DashScope (Alibaba Qwen), Gemini, Deepseek, Mistral, SiliconFlow.</p><p>Proxy thành: LM Studio, Ollama.</p><p>Chỉ hỗ trợ API hoàn thành chat dạng streaming.
<h2>Cách sử dụng</h2></p><p>Ứng dụng này là một máy chủ proxy, được phân phối dưới dạng một file jar chạy độc lập và một image native GraalVM (Windows x64).</p><p>Chạy ứng dụng, bạn sẽ thấy một thông báo trợ giúp:</p><pre><code class="language-">2025-05-02 10:43:53 INFO  Help - Có vẻ như bạn đang khởi động chương trình lần đầu tiên tại đây.
2025-05-02 10:43:53 INFO  Help - Một file cấu hình mặc định đã được tạo tại your_path\config.yml với chú thích schema.
2025-05-02 10:43:53 INFO  Config - Bộ theo dõi file cấu hình đã bắt đầu tại your_path\config.yml
2025-05-02 10:43:53 INFO  LM Studio Server - Máy chủ LM Studio đã khởi động tại 1234
2025-05-02 10:43:53 INFO  Ollama Server - Máy chủ Ollama đã khởi động tại 11434
2025-05-02 10:43:53 INFO  Model List - Danh sách mô hình đã được tải với: []</code></pre></p><p>Sau đó, bạn có thể chỉnh sửa file cấu hình để thiết lập máy chủ proxy của mình.</p><h2>File cấu hình</h2></p><p>File cấu hình này sẽ tự động được tải lại khi bạn thay đổi nó. Chỉ những phần bị ảnh hưởng của máy chủ mới được cập nhật.</p><p>Khi lần đầu tạo file cấu hình, nó sẽ được tạo với chú thích schema. Điều này sẽ giúp bạn hoàn thành và kiểm tra trong trình soạn thảo của mình.
<h2>Ví dụ tập tin cấu hình</h2></p><pre><code class="language-yaml"># $schema: https://github.com/Stream29/ProxyAsLocalModel/raw/master/config_v3.schema.json
lmStudio:
  port: 1234 # Đây là giá trị mặc định
  enabled: true # Đây là giá trị mặc định
  host: 0.0.0.0 # Đây là giá trị mặc định
  path: /your/path # Sẽ được thêm trước các endpoint gốc, giá trị mặc định là rỗng
ollama:
  port: 11434 # Đây là giá trị mặc định
  enabled: true # Đây là giá trị mặc định
  host: 0.0.0.0 # Đây là giá trị mặc định
  path: /your/path # Sẽ được thêm trước các endpoint gốc, giá trị mặc định là rỗng
client:
  socketTimeout: 1919810 # Long.MAX_VALUE là giá trị mặc định, tính bằng mili giây
  connectionTimeout: 1919810 # Long.MAX_VALUE là giá trị mặc định, tính bằng mili giây
  requestTimeout: 1919810 # Long.MAX_VALUE là giá trị mặc định, tính bằng mili giây
  retry: 3 # Đây là giá trị mặc định
  delayBeforeRetry: 1000 # Đây là giá trị mặc định, tính bằng mili giây</p><p>apiProviders:
  OpenAI:
    type: OpenAi
    baseUrl: https://api.openai.com/v1
    apiKey: <your_api_key>
    modelList:
      <ul><li>gpt-4o</li>
  </ul>Claude:
    type: Claude
    apiKey: <your_api_key>
    modelList:
      <ul><li>claude-3-7-sonnet</li>
  </ul>Qwen:
    type: DashScope
    apiKey: <your_api_key>
    modelList: # Đây là giá trị mặc định
      <ul><li>qwen-max</li>
      <li>qwen-plus</li>
      <li>qwen-turbo</li>
      <li>qwen-long</li>
  </ul>DeepSeek:
    type: DeepSeek
    apiKey: <your_api_key>
    modelList: # Đây là giá trị mặc định
      <ul><li>deepseek-chat</li>
      <li>deepseek-reasoner</li>
  </ul>Mistral:
    type: Mistral
    apiKey: <your_api_key>
    modelList: # Đây là giá trị mặc định
      <ul><li>codestral-latest</li>
      <li>mistral-large</li>
  </ul>SiliconFlow:
    type: SiliconFlow
    apiKey: <your_api_key>
    modelList:
      <ul><li>Qwen/Qwen3-235B-A22B</li>
      <li>Pro/deepseek-ai/DeepSeek-V3</li>
      <li>THUDM/GLM-4-32B-0414</li>
  </ul>OpenRouter:
    type: OpenRouter
    apiKey: <your_api_key>
    modelList:
      <ul><li>openai/gpt-4o</li>
  </ul>Gemini:
    type: Gemini
    apiKey: <your_api_key>
    modelList:
      <ul><li>gemini-2.5-flash-preview-04-17</code></pre></li>

</ul>---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-07-10

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/Stream29/ProxyAsLocalModel/master/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-07-10 
    </div>
    
</body>
</html>