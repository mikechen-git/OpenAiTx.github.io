<!DOCTYPE html>
<html lang="nl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ProxyAsLocalModel - Dutch Documentation</title>
    <meta name="description" content="Read ProxyAsLocalModel documentation in Dutch. This project has 135 stars on GitHub.">
    <meta name="keywords" content="ProxyAsLocalModel, Dutch, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "ProxyAsLocalModel",
  "description": "Documentation for ProxyAsLocalModel in Dutch",
  "author": {
    "@type": "Person",
    "name": "Stream29"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 135
  },
  "url": "https://OpenAiTx.github.io/projects/Stream29/ProxyAsLocalModel/README-nl.html",
  "sameAs": "https://raw.githubusercontent.com/Stream29/ProxyAsLocalModel/master/README.md",
  "datePublished": "2025-07-10",
  "dateModified": "2025-07-10"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            color: #24292e;
            margin-bottom: 8px;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">ProxyAsLocalModel</h1>
            <div class="project-meta">
                <span class="stars">⭐ 135 stars</span>
                <span class="language">Dutch</span>
                <span>by Stream29</span>
            </div>
        </div>
        
        <div class="content">
            <h1>ProxyAsLocalModel</h1></p><p>Proxy externe LLM API als lokaal model. Werkt vooral voor het gebruik van aangepaste LLM in JetBrains AI Assistant.</p><p>Aangedreven door Ktor en kotlinx.serialization. Dankzij hun no-reflex-functionaliteiten.</p><h2>Verhaal van dit project</h2></p><p>Momenteel biedt JetBrains AI Assistant een gratis plan met zeer beperkte quota. Ik heb het uitgeprobeerd en mijn quota was snel op.</p><p>Ik heb al tokens gekocht voor andere LLM API’s, zoals Gemini en Qwen. Dus begon ik na te denken over hoe ik deze in AI Assistant kon gebruiken. Helaas worden alleen lokale modellen van LM Studio en Ollama ondersteund. Daarom begon ik te werken aan deze proxy-applicatie die externe LLM API’s proxiet als LM Studio- en Ollama-API, zodat ik ze kan gebruiken in mijn JetBrains IDE’s.</p><p>Dit is slechts een eenvoudige taak, dus begon ik de officiële SDK’s als clients te gebruiken en schreef ik een eenvoudige Ktor-server die endpoints aanbiedt als LM Studio en Ollama. Het probleem ontstond toen ik het wilde distribueren als een GraalVM native image. De officiële Java SDK’s gebruiken te veel dynamische functionaliteiten, waardoor het moeilijk is om te compileren naar een native image, zelfs met een tracing agent. Daarom besloot ik zelf een eenvoudige client te implementeren voor de streaming chat completion API met Ktor en kotlinx.serialization, die beide no-reflex, functioneel en DSL-georiënteerd zijn.</p><p>Zoals je kunt zien, wordt deze applicatie gedistribueerd als een fat runnable jar en een GraalVM native image, waardoor het cross-platform is en snel opstart.</p><p>De ontwikkeling van deze applicatie heeft mij vertrouwen gegeven in Kotlin/Ktor/kotlinx.serialization. De Kotlin-wereld gebruikt meer functioneel programmeren en minder reflectie, wat het geschikter maakt voor GraalVM native image, met snellere opstart en minder geheugengebruik.</p><h2>Momenteel ondersteund</h2></p><p>Proxy van: OpenAI, Claude, DashScope (Alibaba Qwen), Gemini, Deepseek, Mistral, SiliconFlow.</p><p>Proxy als: LM Studio, Ollama.</p><p>Alleen streaming chat completion API.
<h2>Hoe te gebruiken</h2></p><p>Deze applicatie is een proxyserver, verspreid als een fat runnable jar en een GraalVM native image (Windows x64).</p><p>Start de applicatie en je ziet een helpbericht:</p><pre><code class="language-">2025-05-02 10:43:53 INFO  Help - Het lijkt erop dat je het programma hier voor de eerste keer start.
2025-05-02 10:43:53 INFO  Help - Een standaard configuratiebestand is aangemaakt op your_path\config.yml met schema-annotatie.
2025-05-02 10:43:53 INFO  Config - Configuratiebestand-watcher gestart op your_path\config.yml
2025-05-02 10:43:53 INFO  LM Studio Server - LM Studio Server gestart op 1234
2025-05-02 10:43:53 INFO  Ollama Server - Ollama Server gestart op 11434
2025-05-02 10:43:53 INFO  Model List - Modellenlijst geladen met: []</code></pre></p><p>Daarna kun je het configuratiebestand bewerken om je proxyserver in te stellen.</p><h2>Configuratiebestand</h2></p><p>Dit configuratiebestand wordt automatisch hot-geregeld wanneer je het wijzigt. Alleen de getroffen onderdelen van de server worden bijgewerkt.</p><p>Bij het eerste aanmaken van het configuratiebestand, wordt het aangemaakt met schema-annotaties. Dit zorgt voor aanvulling en controle in je editor.
<h2>Voorbeeld configuratiebestand</h2></p><pre><code class="language-yaml"># $schema: https://github.com/Stream29/ProxyAsLocalModel/raw/master/config_v3.schema.json
lmStudio:
  port: 1234 # Dit is de standaardwaarde
  enabled: true # Dit is de standaardwaarde
  host: 0.0.0.0 # Dit is de standaardwaarde
  path: /your/path # Wordt toegevoegd vóór de originele eindpunten, standaardwaarde is leeg
ollama:
  port: 11434 # Dit is de standaardwaarde
  enabled: true # Dit is de standaardwaarde
  host: 0.0.0.0 # Dit is de standaardwaarde
  path: /your/path # Wordt toegevoegd vóór de originele eindpunten, standaardwaarde is leeg
client:
  socketTimeout: 1919810 # Long.MAX_VALUE is de standaardwaarde, in milliseconden
  connectionTimeout: 1919810 # Long.MAX_VALUE is de standaardwaarde, in milliseconden
  requestTimeout: 1919810 # Long.MAX_VALUE is de standaardwaarde, in milliseconden
  retry: 3 # Dit is de standaardwaarde
  delayBeforeRetry: 1000 # Dit is de standaardwaarde, in milliseconden</p><p>apiProviders:
  OpenAI:
    type: OpenAi
    baseUrl: https://api.openai.com/v1
    apiKey: <your_api_key>
    modelList:
      <ul><li>gpt-4o</li>
  </ul>Claude:
    type: Claude
    apiKey: <your_api_key>
    modelList:
      <ul><li>claude-3-7-sonnet</li>
  </ul>Qwen:
    type: DashScope
    apiKey: <your_api_key>
    modelList: # Dit is de standaardwaarde
      <ul><li>qwen-max</li>
      <li>qwen-plus</li>
      <li>qwen-turbo</li>
      <li>qwen-long</li>
  </ul>DeepSeek:
    type: DeepSeek
    apiKey: <your_api_key>
    modelList: # Dit is de standaardwaarde
      <ul><li>deepseek-chat</li>
      <li>deepseek-reasoner</li>
  </ul>Mistral:
    type: Mistral
    apiKey: <your_api_key>
    modelList: # Dit is de standaardwaarde
      <ul><li>codestral-latest</li>
      <li>mistral-large</li>
  </ul>SiliconFlow:
    type: SiliconFlow
    apiKey: <your_api_key>
    modelList:
      <ul><li>Qwen/Qwen3-235B-A22B</li>
      <li>Pro/deepseek-ai/DeepSeek-V3</li>
      <li>THUDM/GLM-4-32B-0414</li>
  </ul>OpenRouter:
    type: OpenRouter
    apiKey: <your_api_key>
    modelList:
      <ul><li>openai/gpt-4o</li>
  </ul>Gemini:
    type: Gemini
    apiKey: <your_api_key>
    modelList:
      <ul><li>gemini-2.5-flash-preview-04-17</code></pre></li>

</ul>---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-07-10

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/Stream29/ProxyAsLocalModel/master/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-07-10 
    </div>
    
</body>
</html>