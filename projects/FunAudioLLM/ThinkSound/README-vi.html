<!DOCTYPE html>
<html lang="vi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ThinkSound - Vietnamese Documentation</title>
    <meta name="description" content="Read ThinkSound documentation in Vietnamese. This project has 116 stars on GitHub.">
    <meta name="keywords" content="ThinkSound, Vietnamese, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "ThinkSound",
  "description": "Documentation for ThinkSound in Vietnamese",
  "author": {
    "@type": "Person",
    "name": "FunAudioLLM"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 116
  },
  "url": "https://OpenAiTx.github.io/projects/FunAudioLLM/ThinkSound/README-vi.html",
  "sameAs": "https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/README.md",
  "datePublished": "2025-07-03",
  "dateModified": "2025-07-03"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            color: #24292e;
            margin-bottom: 8px;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">ThinkSound</h1>
            <div class="project-meta">
                <span class="stars">⭐ 116 stars</span>
                <span class="language">Vietnamese</span>
                <span>by FunAudioLLM</span>
            </div>
        </div>
        
        <div class="content">
            <h1>🎶 ThinkSound</h1></p><p><p align="center">
  Nếu bạn thấy dự án này hữu ích, một ngôi sao ⭐ trên GitHub sẽ được đánh giá rất cao!
</p></p><p><p align="center">
  <a href="https://arxiv.org/pdf/2506.21448">
    <img src="https://img.shields.io/badge/arXiv-2506.21448-b31b1b.svg" alt="arXiv"/>
  </a>
  &nbsp;
  <a href="https://thinksound-project.github.io/">
    <img src="https://img.shields.io/badge/Online%20Demo-🌐-blue" alt="Online Demo"/>
  </a>
  &nbsp;
  <a href="https://huggingface.co/spaces/FunAudioLLM/ThinkSound">
    <img src="https://img.shields.io/badge/HuggingFace-Spaces-orange?logo=huggingface" alt="Hugging Face"/>
  </a>
  &nbsp;
  <a href="https://modelscope.cn/studios/iic/ThinkSound">
    <img src="https://img.shields.io/badge/ModelScope-在线体验-green" alt="ModelScope"/>
  </a>
</p></p><hr></p><p><strong>ThinkSound</strong> là một framework hợp nhất cho Any2Audio với phương pháp flow matching được dẫn dắt bởi lý luận Chuỗi Suy Nghĩ (Chain-of-Thought - CoT).</p><p>Hiện thực PyTorch cho việc tạo và chỉnh sửa âm thanh đa phương tiện: tạo hoặc chỉnh sửa âm thanh từ video, văn bản, và âm thanh, được hỗ trợ bởi quá trình suy luận từng bước từ Mô hình Ngôn ngữ Lớn Đa phương tiện (MLLMs).</p><p><img src="https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig1_teaser.png" alt="Teaser">
<hr></p><h2>📰 Tin tức</h2>
<ul><li><strong>2025.07</strong> &nbsp; 🔥Demo trực tuyến trên <a href="https://huggingface.co/spaces/FunAudioLLM/ThinkSound" target="_blank" rel="noopener noreferrer">Hugging Face Spaces</a> và <a href="https://modelscope.cn/studios/iic/ThinkSound" target="_blank" rel="noopener noreferrer">ModelScope</a> cho trải nghiệm tương tác!</li>
<li><strong>2025.07</strong> &nbsp; 🔥Phát hành mã suy luận và giao diện web;</li>
<li><strong>2025.06</strong> &nbsp; 🔥<a href="https://arxiv.org/pdf/2506.21448" target="_blank" rel="noopener noreferrer">Bài báo ThinkSound</a> được phát hành trên arXiv!</li>
<li><strong>2025.06</strong> &nbsp; 🔥<a href="http://thinksound-project.github.io/" target="_blank" rel="noopener noreferrer">Demo trực tuyến</a> đã hoạt động - hãy thử ngay!</li></p><p></ul>---</p><h2>🚀 Tính năng</h2></p><ul><li><strong>Any2Audio</strong>: Tạo âm thanh từ bất kỳ loại dữ liệu nào — video, văn bản, âm thanh, hoặc kết hợp của chúng.</li>
<li><strong>Video-to-Audio SOTA</strong>: Đạt kết quả tốt nhất trên nhiều bộ chuẩn V2A.</li>
<li><strong>Lý luận dựa trên CoT</strong>: Lý luận Chuỗi Suy Nghĩ cho việc tạo âm thanh có tính thành phần và kiểm soát được thông qua MLLMs.</li>
<li><strong>Chỉnh sửa tập trung vào đối tượng tương tác</strong>: Tinh chỉnh hoặc chỉnh sửa sự kiện âm thanh cụ thể bằng cách nhấp vào đối tượng hình ảnh hoặc sử dụng hướng dẫn văn bản.</li>
<li><strong>Khung hợp nhất</strong>: Một mô hình nền tảng hỗ trợ tạo, chỉnh sửa và quy trình làm việc tương tác.</li></p><p></ul>---</p><h2>✨ Tổng quan phương pháp</h2></p><p>ThinkSound phân tách quá trình tạo và chỉnh sửa âm thanh thành ba giai đoạn tương tác, tất cả đều được dẫn dắt bởi lý luận Chuỗi Suy Nghĩ (CoT) dựa trên MLLM:</p><ul><li><strong>Tạo Foley:</strong> Tạo nền âm thanh cơ bản, phù hợp về ngữ nghĩa và thời gian từ video.</li>
<li><strong>Tinh chỉnh tập trung vào đối tượng:</strong> Tinh chỉnh hoặc thêm âm thanh cho các đối tượng do người dùng chỉ định thông qua click hoặc vùng chọn trong video.</li>
<li><strong>Chỉnh sửa âm thanh mục tiêu:</strong> Chỉnh sửa âm thanh đã tạo bằng hướng dẫn ngôn ngữ tự nhiên ở cấp độ cao.</li></p><p></ul><img src="https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig3_model.png" alt="Tổng quan ThinkSound">
<!-- Một bộ dữ liệu quy mô lớn được chú thích theo CoT (<strong>AudioCoT</strong>) được sử dụng để huấn luyện cả module lý luận và mô hình nền tảng âm thanh hợp nhất.
<img src="https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig2_dataset.png" alt="AudioCoT Pipeline"> --></p><hr></p><h2>⚡ Bắt đầu nhanh</h2></p><p><strong>Chuẩn bị môi trường:</strong>
<pre><code class="language-bash">git clone https://github.com/liuhuadai/ThinkSound.git
cd ThinkSound
pip install -r requirements.txt
conda install -y -c conda-forge 'ffmpeg<7'
<h1>Tải trọng số đã huấn luyện sẵn https://huggingface.co/liuhuadai/ThinkSound về thư mục ckpts/</h1>
<h1>Trọng số mô hình cũng có thể tải từ https://www.modelscope.cn/models/iic/ThinkSound</h1>
git lfs install
git clone https://huggingface.co/liuhuadai/ThinkSound ckpts</code></pre></p><p><strong>Cấp quyền thực thi</strong>
<pre><code class="language-bash">chmod +x scripts/demo.sh</code></pre></p><p><strong>Chạy script</strong>
<pre><code class="language-bash">./scripts/demo.sh <video_path> <caption> <CoT description></code></pre></p><h3>Sử dụng giao diện web</h3></p><p>Để có trải nghiệm tương tác, hãy khởi động giao diện web Gradio:</p><pre><code class="language-bash">python app.py</code></pre></p><hr>
<h2>📝 VIỆC CẦN LÀM</h2></p><ul><li>☐ Phát hành các script huấn luyện cho các mô hình ThinkSound</li>
<li>☐ Mã nguồn mở bộ dữ liệu AudioCoT và quy trình tự động hóa</li>
<li>☐ Cung cấp tài liệu chi tiết và tham khảo API</li>
<li>☐ Thêm hỗ trợ cho các kiểu dữ liệu và tác vụ hậu kỳ khác</li></p><p></ul>---</p><h2>📄 Giấy phép</h2></p><p>Dự án này được phát hành theo <a href="LICENSE" target="_blank" rel="noopener noreferrer">Giấy phép Apache 2.0</a>.</p><blockquote><strong>Lưu ý:</strong>  </blockquote>
<blockquote>Mã nguồn, mô hình và bộ dữ liệu <strong>chỉ dành cho mục đích nghiên cứu và giáo dục</strong>.  </blockquote>
<blockquote><strong>KHÔNG được phép sử dụng cho mục đích thương mại.</strong></blockquote>
>
<blockquote>Để xin giấy phép thương mại, vui lòng liên hệ tác giả.</blockquote></p><hr></p><h2>📖 Trích dẫn</h2></p><p>Nếu bạn thấy ThinkSound hữu ích trong nghiên cứu hoặc công việc của mình, vui lòng trích dẫn bài báo của chúng tôi:</p><pre><code class="language-bibtex">@misc{liu2025thinksoundchainofthoughtreasoningmultimodal,
      title={ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing}, 
      author={Huadai Liu and Jialei Wang and Kaicheng Luo and Wen Wang and Qian Chen and Zhou Zhao and Wei Xue},
      year={2025},
      eprint={2506.21448},
      archivePrefix={arXiv},
      primaryClass={eess.AS},
      url={https://arxiv.org/abs/2506.21448}, 
}</code></pre></p><hr></p><h2>📬 Liên hệ</h2></p><p>✨ Hãy <a href="https://github.com/liuhuadai/ThinkSound/issues" target="_blank" rel="noopener noreferrer">tạo issue mới</a> hoặc liên hệ với chúng tôi qua email (<a href="https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn" target="_blank" rel="noopener noreferrer">liuhuadai@zju.edu.cn</a>) nếu bạn có bất kỳ câu hỏi hoặc góp ý nào!

---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-07-03

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-07-03 
    </div>
    
</body>
</html>