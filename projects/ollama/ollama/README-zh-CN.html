<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ollama - ollama/ollama zh-CN</title>
    <meta name="title" content="ollama - ollama/ollama zh-CN | Ollama 快速上手大语言模型。 macOS 下载 Windows 下载 Linux curl -fsSL https://ollama.com/install.sh | sh 手动安装说明 Docker 官方 Ollama Docker 镜像 ollama/ollama 已发布在 Docker Hub。 库 oll...">
    <meta name="description" content="ollama/ollama - GitHub repository zh-CN documentation and information | Ollama 快速上手大语言模型。 macOS 下载 Windows 下载 Linux curl -fsSL https://ollama.com/install.sh | sh 手动安装说明 Docker 官方 Ollama Docker 镜像 ollama/ollama 已发布在 Docker Hub。 库 oll...">
    <meta name="keywords" content="ollama, ollama, GitHub, repository, zh-CN documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/ollama/ollama/README-zh-CN.html">
    <meta property="og:title" content="ollama - ollama/ollama zh-CN | Ollama 快速上手大语言模型。 macOS 下载 Windows 下载 Linux curl -fsSL https://ollama.com/install.sh | sh 手动安装说明 Docker 官方 Ollama Docker 镜像 ollama/ollama 已发布在 Docker Hub。 库 oll...">
    <meta property="og:description" content="ollama/ollama - GitHub repository zh-CN documentation and information | Ollama 快速上手大语言模型。 macOS 下载 Windows 下载 Linux curl -fsSL https://ollama.com/install.sh | sh 手动安装说明 Docker 官方 Ollama Docker 镜像 ollama/ollama 已发布在 Docker Hub。 库 oll...">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/ollama/ollama" id="githubRepoLink" target="_blank">ollama/ollama</a>
<h1 style="display: none;">Ollama 快速上手大语言模型。 macOS 下载 Windows 下载 Linux curl -fsSL https://ollama.com/install.sh | sh 手动安装说明 Docker 官方 Ollama Docker 镜像 ollama/ollama 已发布在 Docker Hub。 库 oll...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <div align="center">
  <a href="https://ollama.com">
    <img alt="ollama" height="200px" src="https://github.com/ollama/ollama/assets/3325447/0d0b44e2-8f4a-4e99-9b52-a5c1c741c8f7">
  </a>
</div>
<h1>Ollama</h1>
<p>快速上手大语言模型。</p>
<h3>macOS</h3>
<p><a href="https://ollama.com/download/Ollama-darwin.zip">下载</a></p>
<h3>Windows</h3>
<p><a href="https://ollama.com/download/OllamaSetup.exe">下载</a></p>
<h3>Linux</h3>
<pre><code class="language-shell">curl -fsSL https://ollama.com/install.sh | sh
</code></pre>
<p><a href="https://github.com/ollama/ollama/blob/main/docs/linux.md">手动安装说明</a></p>
<h3>Docker</h3>
<p>官方 <a href="https://hub.docker.com/r/ollama/ollama">Ollama Docker 镜像</a> <code>ollama/ollama</code> 已发布在 Docker Hub。</p>
<h3>库</h3>
<ul>
<li><a href="https://github.com/ollama/ollama-python">ollama-python</a></li>
<li><a href="https://github.com/ollama/ollama-js">ollama-js</a></li>
</ul>
<h3>社区</h3>
<ul>
<li><a href="https://discord.gg/ollama">Discord</a></li>
<li><a href="https://reddit.com/r/ollama">Reddit</a></li>
</ul>
<h2>快速开始</h2>
<p>运行并与 <a href="https://ollama.com/library/llama3.2">Llama 3.2</a> 聊天：</p>
<pre><code class="language-shell">ollama run llama3.2
</code></pre>
<h2>模型库</h2>
<p>Ollama 支持 <a href="https://ollama.com/library" title="ollama model library">ollama.com/library</a> 上的众多模型。</p>
<p>以下是部分可下载的示例模型：</p>
<p>| 模型名称           | 参数量     | 大小   | 下载命令                             |
| ------------------ | ---------- | ------ | ------------------------------------ |
| Gemma 3            | 1B         | 815MB  | <code>ollama run gemma3:1b</code>               |
| Gemma 3            | 4B         | 3.3GB  | <code>ollama run gemma3</code>                  |
| Gemma 3            | 12B        | 8.1GB  | <code>ollama run gemma3:12b</code>              |
| Gemma 3            | 27B        | 17GB   | <code>ollama run gemma3:27b</code>              |
| QwQ                | 32B        | 20GB   | <code>ollama run qwq</code>                     |
| DeepSeek-R1        | 7B         | 4.7GB  | <code>ollama run deepseek-r1</code>             |
| DeepSeek-R1        | 671B       | 404GB  | <code>ollama run deepseek-r1:671b</code>        |
| Llama 4            | 109B       | 67GB   | <code>ollama run llama4:scout</code>            |
| Llama 4            | 400B       | 245GB  | <code>ollama run llama4:maverick</code>         |
| Llama 3.3          | 70B        | 43GB   | <code>ollama run llama3.3</code>                |
| Llama 3.2          | 3B         | 2.0GB  | <code>ollama run llama3.2</code>                |
| Llama 3.2          | 1B         | 1.3GB  | <code>ollama run llama3.2:1b</code>             |
| Llama 3.2 Vision   | 11B        | 7.9GB  | <code>ollama run llama3.2-vision</code>         |
| Llama 3.2 Vision   | 90B        | 55GB   | <code>ollama run llama3.2-vision:90b</code>     |
| Llama 3.1          | 8B         | 4.7GB  | <code>ollama run llama3.1</code>                |
| Llama 3.1          | 405B       | 231GB  | <code>ollama run llama3.1:405b</code>           |
| Phi 4              | 14B        | 9.1GB  | <code>ollama run phi4</code>                    |
| Phi 4 Mini         | 3.8B       | 2.5GB  | <code>ollama run phi4-mini</code>               |
| Mistral            | 7B         | 4.1GB  | <code>ollama run mistral</code>                 |
| Moondream 2        | 1.4B       | 829MB  | <code>ollama run moondream</code>               |
| Neural Chat        | 7B         | 4.1GB  | <code>ollama run neural-chat</code>             |
| Starling           | 7B         | 4.1GB  | <code>ollama run starling-lm</code>             |
| Code Llama         | 7B         | 3.8GB  | <code>ollama run codellama</code>               |
| Llama 2 Uncensored | 7B         | 3.8GB  | <code>ollama run llama2-uncensored</code>       |
| LLaVA              | 7B         | 4.5GB  | <code>ollama run llava</code>                   |
| Granite-3.3         | 8B         | 4.9GB  | <code>ollama run granite3.3</code>              |</p>
<blockquote>
<p>[!NOTE]
运行 7B 模型至少需要 8 GB 内存，运行 13B 模型需要 16 GB，运行 33B 模型需要 32 GB 内存。</p>
</blockquote>
<h2>自定义模型</h2>
<h3>从 GGUF 导入</h3>
<p>Ollama 支持在 Modelfile 中导入 GGUF 格式模型：</p>
<ol>
<li><p>新建名为 <code>Modelfile</code> 的文件，并使用 <code>FROM</code> 指令指定要导入的本地模型文件路径。</p>
<pre><code>FROM ./vicuna-33b.Q4_0.gguf
</code></pre>
</li>
<li><p>在 Ollama 中创建模型</p>
<pre><code class="language-shell">ollama create example -f Modelfile
</code></pre>
</li>
<li><p>运行模型</p>
<pre><code class="language-shell">ollama run example
</code></pre>
</li>
</ol>
<h3>从 Safetensors 导入</h3>
<p>更多导入模型信息请参阅<a href="docs/import.md">指南</a>。</p>
<h3>自定义提示词</h3>
<p>Ollama 库中的模型可通过 prompt 进行自定义。例如，自定义 <code>llama3.2</code> 模型：</p>
<pre><code class="language-shell">ollama pull llama3.2
</code></pre>
<p>创建 <code>Modelfile</code>：</p>
<pre><code>FROM llama3.2

# 设置 temperature 为 1 [值越高越有创造力，值越低越连贯]
PARAMETER temperature 1

# 设置系统消息
SYSTEM &quot;&quot;&quot;
你是超级马里奥中的马里奥。仅以助手马里奥的身份回答。
&quot;&quot;&quot;
</code></pre>
<p>然后创建并运行模型：</p>
<pre><code>ollama create mario -f ./Modelfile
ollama run mario
&gt;&gt;&gt; hi
Hello! It's your friend Mario.
</code></pre>
<p>关于 Modelfile 的更多用法，请参阅 <a href="docs/modelfile.md">Modelfile</a> 文档。</p>
<h2>CLI 参考</h2>
<h3>创建模型</h3>
<p><code>ollama create</code> 用于从 Modelfile 创建模型。</p>
<pre><code class="language-shell">ollama create mymodel -f ./Modelfile
</code></pre>
<h3>拉取模型</h3>
<pre><code class="language-shell">ollama pull llama3.2
</code></pre>
<blockquote>
<p>该命令也可用于更新本地模型。只会拉取差异部分。</p>
</blockquote>
<h3>删除模型</h3>
<pre><code class="language-shell">ollama rm llama3.2
</code></pre>
<h3>复制模型</h3>
<pre><code class="language-shell">ollama cp llama3.2 my-model
</code></pre>
<h3>多行输入</h3>
<p>对于多行输入，可使用 <code>&quot;&quot;&quot;</code> 包裹文本：</p>
<pre><code>&gt;&gt;&gt; &quot;&quot;&quot;Hello,
... world!
... &quot;&quot;&quot;
我是一个基本程序，会在控制台输出著名的 &quot;Hello, world!&quot; 信息。
</code></pre>
<h3>多模态模型</h3>
<pre><code>ollama run llava &quot;What's in this image? /Users/jmorgan/Desktop/smile.png&quot;
</code></pre>
<blockquote>
<p><strong>输出</strong>：图片中有一个黄色笑脸，这可能是图片的核心内容。</p>
</blockquote>
<h3>作为参数传递 prompt</h3>
<pre><code class="language-shell">ollama run llama3.2 &quot;Summarize this file: $(cat README.md)&quot;
</code></pre>
<blockquote>
<p><strong>输出</strong>：Ollama 是一个轻量级、可扩展的本地大语言模型构建和运行框架。它提供了简单的 API 用于模型的创建、运行和管理，并包含了丰富的预置模型库，方便在多种应用中使用。</p>
</blockquote>
<h3>显示模型信息</h3>
<pre><code class="language-shell">ollama show llama3.2
</code></pre>
<h3>列出本机模型</h3>
<pre><code class="language-shell">ollama list
</code></pre>
<h3>列出当前已加载的模型</h3>
<pre><code class="language-shell">ollama ps
</code></pre>
<h3>停止正在运行的模型</h3>
<pre><code class="language-shell">ollama stop llama3.2
</code></pre>
<h3>启动 Ollama</h3>
<p><code>ollama serve</code> 用于在不运行桌面应用时启动 Ollama 服务。</p>
<h2>构建</h2>
<p>参见 <a href="https://github.com/ollama/ollama/blob/main/docs/development.md">开发者指南</a></p>
<h3>本地构建运行</h3>
<p>首先，启动服务端：</p>
<pre><code class="language-shell">./ollama serve
</code></pre>
<p>然后，在另一个终端窗口运行模型：</p>
<pre><code class="language-shell">./ollama run llama3.2
</code></pre>
<h2>REST API</h2>
<p>Ollama 提供 REST API 用于模型的运行和管理。</p>
<h3>生成回复</h3>
<pre><code class="language-shell">curl http://localhost:11434/api/generate -d '{
  &quot;model&quot;: &quot;llama3.2&quot;,
  &quot;prompt&quot;:&quot;Why is the sky blue?&quot;
}'
</code></pre>
<h3>聊天接口</h3>
<pre><code class="language-shell">curl http://localhost:11434/api/chat -d '{
  &quot;model&quot;: &quot;llama3.2&quot;,
  &quot;messages&quot;: [
    { &quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;why is the sky blue?&quot; }
  ]
}'
</code></pre>
<p>所有接口请参见 <a href="./docs/api.md">API 文档</a>。</p>
<h2>社区集成</h2>
<h3>Web &amp; 桌面端</h3>
<ul>
<li><a href="https://github.com/open-webui/open-webui">Open WebUI</a></li>
<li><a href="https://github.com/aws-samples/swift-chat">SwiftChat (macOS with ReactNative)</a></li>
<li><a href="https://github.com/AugustDev/enchanted">Enchanted (macOS 原生)</a></li>
<li><a href="https://github.com/fmaclen/hollama">Hollama</a></li>
<li><a href="https://github.com/ParisNeo/lollms-webui">Lollms-Webui</a></li>
<li><a href="https://github.com/danny-avila/LibreChat">LibreChat</a></li>
<li><a href="https://github.com/bionic-gpt/bionic-gpt">Bionic GPT</a></li>
<li><a href="https://github.com/rtcfirefly/ollama-ui">HTML UI</a></li>
<li><a href="https://github.com/jikkuatwork/saddle">Saddle</a></li>
<li><a href="https://www.tagspaces.org">TagSpaces</a>（文件型应用平台，<a href="https://docs.tagspaces.org/ai/">集成 Ollama 进行标签和描述生成</a>）</li>
<li><a href="https://github.com/ivanfioravanti/chatbot-ollama">Chatbot UI</a></li>
<li><a href="https://github.com/mckaywrigley/chatbot-ui">Chatbot UI v2</a></li>
<li><a href="https://github.com/ollama-interface/Ollama-Gui?tab=readme-ov-file">Typescript UI</a></li>
<li><a href="https://github.com/richawo/minimal-llm-ui">Minimalistic React UI for Ollama Models</a></li>
<li><a href="https://github.com/kevinhermawan/Ollamac">Ollamac</a></li>
<li><a href="https://github.com/enricoros/big-AGI">big-AGI</a></li>
<li><a href="https://github.com/cheshire-cat-ai/core">Cheshire Cat assistant framework</a></li>
<li><a href="https://github.com/semperai/amica">Amica</a></li>
<li><a href="https://github.com/BruceMacD/chatd">chatd</a></li>
<li><a href="https://github.com/kghandour/Ollama-SwiftUI">Ollama-SwiftUI</a></li>
<li><a href="https://github.com/langgenius/dify">Dify.AI</a></li>
<li><a href="https://mindmac.app">MindMac</a></li>
<li><a href="https://github.com/jakobhoeg/nextjs-ollama-llm-ui">NextJS Web Interface for Ollama</a></li>
<li><a href="https://msty.app">Msty</a></li>
<li><a href="https://github.com/Bin-Huang/Chatbox">Chatbox</a></li>
<li><a href="https://github.com/tgraupmann/WinForm_Ollama_Copilot">WinForm Ollama Copilot</a></li>
<li><a href="https://github.com/ChatGPTNextWeb/ChatGPT-Next-Web">NextChat</a>（<a href="https://docs.nextchat.dev/models/ollama">入门文档</a>）</li>
<li><a href="https://github.com/mmo80/alpaca-webui">Alpaca WebUI</a></li>
<li><a href="https://github.com/enoch1118/ollamaGUI">OllamaGUI</a></li>
<li><a href="https://github.com/InternLM/OpenAOE">OpenAOE</a></li>
<li><a href="https://github.com/leonid20000/OdinRunes">Odin Runes</a></li>
<li><a href="https://github.com/mrdjohnson/llm-x">LLM-X</a>（渐进式 Web App）</li>
<li><a href="https://github.com/Mintplex-Labs/anything-llm">AnythingLLM (Docker + MacOs/Windows/Linux 原生应用)</a></li>
<li><a href="https://github.com/rapidarchitect/ollama_basic_chat">Ollama Basic Chat: Uses HyperDiv Reactive UI</a></li>
<li><a href="https://github.com/drazdra/ollama-chats">Ollama-chats RPG</a></li>
<li><a href="https://intellibar.app/">IntelliBar</a>（macOS AI 助手）</li>
<li><a href="https://github.com/AliAhmedNada/jirapt">Jirapt</a>（Jira 集成，自动生成 issue、task、epic）</li>
<li><a href="https://github.com/AliAhmedNada/ojira">ojira</a>（Jira Chrome 插件，便捷生成任务描述）</li>
<li><a href="https://github.com/reid41/QA-Pilot">QA-Pilot</a>（可利用 Ollama 模型快速理解和导航 GitHub 代码库的交互式聊天工具）</li>
<li><a href="https://github.com/sugarforever/chat-ollama">ChatOllama</a>（基于 Ollama 的开源知识库聊天机器人）</li>
<li><a href="https://github.com/Nagi-ovo/CRAG-Ollama-Chat">CRAG Ollama Chat</a>（带纠错 RAG 的简单网页搜索）</li>
<li><a href="https://github.com/infiniflow/ragflow">RAGFlow</a>（基于深度文档理解的开源 RAG 引擎）</li>
<li><a href="https://github.com/StreamDeploy-DevRel/streamdeploy-llm-app-scaffold">StreamDeploy</a>（LLM 应用脚手架）</li>
<li><a href="https://github.com/swuecho/chat">chat</a>（团队聊天 web 应用）</li>
<li><a href="https://github.com/lobehub/lobe-chat">Lobe Chat</a>（<a href="https://lobehub.com/docs/self-hosting/examples/ollama">集成文档</a>）</li>
<li><a href="https://github.com/datvodinh/rag-chatbot.git">Ollama RAG Chatbot</a>（本地多 PDF 聊天，集成 Ollama 和 RAG）</li>
<li><a href="https://www.nurgo-software.com/products/brainsoup">BrainSoup</a>（灵活原生客户端，支持 RAG 和多智能体自动化）</li>
<li><a href="https://github.com/Renset/macai">macai</a>（Ollama、ChatGPT 及其他 API 后端 macOS 客户端）</li>
<li><a href="https://github.com/josStorer/RWKV-Runner">RWKV-Runner</a>（RWKV 离线 LLM 部署工具，也支持 ChatGPT 和 Ollama 客户端）</li>
<li><a href="https://github.com/dezoito/ollama-grid-search">Ollama Grid Search</a>（模型评测与对比应用）</li>
<li><a href="https://github.com/Otacon/olpaka">Olpaka</a>（易用 Flutter Web 应用）</li>
<li><a href="https://casibase.org">Casibase</a>（集成最新 RAG、SSO、Ollama 支持和多大语言模型的开源知识库和对话系统）</li>
<li><a href="https://github.com/CrazyNeil/OllamaSpring">OllamaSpring</a>（macOS 客户端）</li>
<li><a href="https://github.com/kartikm7/llocal">LLocal.in</a>（易用的 Electron 桌面客户端）</li>
<li><a href="https://github.com/dcSpark/shinkai-apps">Shinkai Desktop</a>（两步本地 AI 安装，含 Ollama + 文件 + RAG）</li>
<li><a href="https://github.com/zeyoyt/ailama">AiLama</a>（Discord 用户应用，随时在 Discord 与 Ollama 互动）</li>
<li><a href="https://github.com/rapidarchitect/ollama_mesop/">Ollama with Google Mesop</a>（Mesop 聊天客户端）</li>
<li><a href="https://github.com/SciPhi-AI/R2R">R2R</a>（开源 RAG 引擎）</li>
<li><a href="https://github.com/elearningshow/ollama-kis">Ollama-Kis</a>（简单易用 GUI，含定制驾驶员教育 LLM 示例）</li>
<li><a href="https://opengpa.org">OpenGPA</a>（开源、离线优先的企业级智能应用）</li>
<li><a href="https://github.com/mateuszmigas/painting-droid">Painting Droid</a>（集成 AI 的绘画应用）</li>
<li><a href="https://www.kerlig.com/">Kerlig AI</a>（macOS AI 写作助手）</li>
<li><a href="https://github.com/MindWorkAI/AI-Studio">AI Studio</a></li>
<li><a href="https://github.com/gyopak/sidellama">Sidellama</a>（基于浏览器的 LLM 客户端）</li>
<li><a href="https://github.com/trypromptly/LLMStack">LLMStack</a>（零代码多智能体框架）</li>
<li><a href="https://boltai.com">BoltAI for Mac</a>（Mac AI 聊天客户端）</li>
<li><a href="https://github.com/av/harbor">Harbor</a>（容器化 LLM 工具包，默认 Ollama 后端）</li>
<li><a href="https://github.com/szczyglis-dev/py-gpt">PyGPT</a>（Linux/Windows/Mac AI 桌面助手）</li>
<li><a href="https://github.com/Jeffser/Alpaca">Alpaca</a>（Linux/macOS 客户端，GTK4+Adwaita）</li>
<li><a href="https://github.com/Significant-Gravitas/AutoGPT/blob/master/docs/content/platform/ollama.md">AutoGPT</a>（AutoGPT 集成 Ollama）</li>
<li><a href="https://www.jonathanhecl.com/go-crew/">Go-CREW</a>（Go 实现的强大离线 RAG）</li>
<li><a href="https://github.com/openvmp/partcad/">PartCAD</a>（支持 OpenSCAD 和 CadQuery 的 CAD 模型生成）</li>
<li><a href="https://github.com/ollama4j/ollama4j-web-ui">Ollama4j Web UI</a> - 基于 Java 的 Web UI，使用 Vaadin、Spring Boot 和 Ollama4j</li>
<li><a href="https://github.com/kspviswa/pyOllaMx">PyOllaMx</a> - 支持与 Ollama 和 Apple MLX 聊天的 macOS 应用</li>
<li><a href="https://github.com/cline/cline">Cline</a> - VSCode 多文件/全库编码扩展</li>
<li><a href="https://github.com/kangfenmao/cherry-studio">Cherry Studio</a>（桌面客户端，支持 Ollama）</li>
<li><a href="https://github.com/1runeberg/confichat">ConfiChat</a>（轻量、独立、跨平台、隐私友好 LLM 聊天界面，支持可选加密）</li>
<li><a href="https://github.com/nickthecook/archyve">Archyve</a>（启用 RAG 的文档库）</li>
<li><a href="https://github.com/rapidarchitect/ollama-crew-mesop">crewAI with Mesop</a>（Mesop 界面运行 crewAI+Ollama）</li>
<li><a href="https://github.com/chyok/ollama-gui">Tkinter-based client</a>（Python tkinter 客户端）</li>
<li><a href="https://github.com/trendy-design/llmchat">LLMChat</a>（注重隐私，100%本地，直观 All-in-one 聊天界面）</li>
<li><a href="https://github.com/Leon-Sander/Local-Multimodal-AI-Chat">Local Multimodal AI Chat</a>（支持多功能，包括 PDF RAG、语音、图片交互、OpenAI 集成）</li>
<li><a href="https://github.com/xark-argo/argo">ARGO</a>（本地下载并运行 Ollama、Huggingface 模型，支持 RAG，适配多平台）</li>
<li><a href="https://github.com/EliasPereirah/OrionChat">OrionChat</a> - Web 界面，多 AI 提供商聊天</li>
<li><a href="https://github.com/bklieger-groq/g1">G1</a>（使用提示策略提升 LLM 推理能力的原型 app）</li>
<li><a href="https://github.com/lemonit-eric-mao/ollama-web-management">Web management</a>（Web 管理页面）</li>
<li><a href="https://github.com/promptery/promptery">Promptery</a>（Ollama 桌面客户端）</li>
<li><a href="https://github.com/JHubi1/ollama-app">Ollama App</a>（现代易用的多平台 Ollama 客户端）</li>
<li><a href="https://github.com/annilq/chat-ollama">chat-ollama</a>（React Native Ollama 客户端）</li>
<li><a href="https://github.com/tcsenpai/spacellama">SpaceLlama</a>（Firefox/Chrome 扩展，侧边栏摘要网页）</li>
<li><a href="https://github.com/tcsenpai/youlama">YouLama</a>（网页应用，快速摘要 YouTube，支持 Invidious）</li>
<li><a href="https://github.com/tcsenpai/dualmind">DualMind</a>（实验性 app，支持终端/网页界面双模型对话）</li>
<li><a href="https://github.com/h1ddenpr0cess20/ollamarama-matrix">ollamarama-matrix</a>（Matrix 聊天协议 Ollama 聊天机器人）</li>
<li><a href="https://github.com/anan1213095357/ollama-chat-app">ollama-chat-app</a>（Flutter 聊天应用）</li>
<li><a href="https://www.perfectmemory.ai/">Perfect Memory AI</a>（生产力 AI，个性化基于你所见所听所说）</li>
<li><a href="https://github.com/hexastack/hexabot">Hexabot</a>（AI 对话机器人构建工具）</li>
<li><a href="https://github.com/rapidarchitect/reddit_analyzer">Reddit Rate</a>（加权排序 Reddit 热门话题）</li>
<li><a href="https://github.com/adarshM84/OpenTalkGpt">OpenTalkGpt</a>（Chrome 扩展，管理本地模型，创建自定义模型，界面聊天）</li>
<li><a href="https://github.com/vinhnx/vt.ai">VT</a>（极简多模态 AI 聊天应用，动态对话路由，支持本地模型）</li>
<li><a href="https://github.com/nosia-ai/nosia">Nosia</a>（易用 RAG 平台，基于 Ollama）</li>
<li><a href="https://github.com/nbonamy/witsy">Witsy</a>（跨平台桌面 AI 聊天应用）</li>
<li><a href="https://github.com/US-Artificial-Intelligence/abbey">Abbey</a>（可配置 AI 界面服务器，支持笔记、文档、YouTube）</li>
<li><a href="https://github.com/dmayboroda/minima">Minima</a>（支持本地/自建 RAG 工作流）</li>
<li><a href="https://github.com/AidfulAI/aidful-ollama-model-delete">aidful-ollama-model-delete</a>（简化模型清理的界面）</li>
<li><a href="https://github.com/ItzCrazyKns/Perplexica">Perplexica</a>（AI 搜索引擎与 Perplexity AI 开源替代）</li>
<li><a href="https://github.com/oslook/ollama-webui">Ollama Chat WebUI for Docker </a>（支持本地 docker 部署，轻量 webui）</li>
<li><a href="https://aka.ms/ai-tooklit/ollama-docs">AI Toolkit for Visual Studio Code</a>（微软官方 VSCode 扩展，支持聊天、测试、评估 Ollama 模型）</li>
<li><a href="https://github.com/anilkay/MinimalNextOllamaChat">MinimalNextOllamaChat</a>（极简 Web 聊天与模型控制界面）</li>
<li><a href="https://github.com/TilmanGriesel/chipper">Chipper</a> AI tinkerer 界面（Ollama、Haystack RAG、Python）</li>
<li><a href="https://github.com/CosmicEventHorizon/ChibiChat">ChibiChat</a>（Kotlin Android Ollama/Koboldcpp 聊天 app）</li>
<li><a href="https://github.com/qusaismael/localllm">LocalLLM</a>（极简 GUI 本地模型聊天）</li>
<li><a href="https://github.com/buiducnhat/ollamazing">Ollamazing</a>（网页扩展，运行 Ollama 模型）</li>
<li><a href="https://github.com/benhaotang/OpenDeepResearcher-via-searxng">OpenDeepResearcher-via-searxng</a>（本地运行深度研究等价端点，支持 Ollama）</li>
<li><a href="https://github.com/AIDotNet/AntSK">AntSK</a>（开箱即用、可扩展 RAG 聊天机器人）</li>
<li><a href="https://github.com/1Panel-dev/MaxKB/">MaxKB</a>（即用灵活的 RAG 聊天机器人）</li>
<li><a href="https://github.com/danielekp/yla">yla</a>（自由互动自定义模型的 Web 界面）</li>
<li><a href="https://github.com/RockChinQ/LangBot">LangBot</a>（基于 LLM 的即时通讯机器人平台，支持 Agent、RAG、多平台）</li>
<li><a href="https://github.com/1Panel-dev/1Panel/">1Panel</a>（Web Linux 服务器管理工具）</li>
<li><a href="https://github.com/Soulter/AstrBot/">AstrBot</a>（用户友好、支持 RAG/智能体/插件的多平台聊天机器人）</li>
<li><a href="https://github.com/ibrahimcetin/reins">Reins</a>（每个聊天轻松调参，自定义系统 prompt，增强 AI 实验）</li>
<li><a href="https://github.com/Aharon-Bensadoun/Flufy">Flufy</a>（React+TypeScript+Material-UI 聊天界面）</li>
<li><a href="https://github.com/zeozeozeo/ellama">Ellama</a>（友好原生 Ollama 聊天 app）</li>
<li><a href="https://github.com/mediar-ai/screenpipe">screenpipe</a> 构建基于屏幕历史的智能体</li>
<li><a href="https://github.com/hengkysteen/ollamb">Ollamb</a>（Flutter 跨平台客户端，<a href="https://hengkysteen.github.io/demo/ollamb/">Web Demo</a>）</li>
<li><a href="https://github.com/Writeopia/Writeopia">Writeopia</a>（集成 Ollama 的文本编辑器）</li>
<li><a href="https://github.com/AppFlowy-IO/AppFlowy">AppFlowy</a>（支持 Ollama 的协作工作区，跨平台且自托管）</li>
<li><a href="https://github.com/cushydigit/lumina.git">Lumina</a>（极简 React.js Ollama 前端）</li>
<li><a href="https://pypi.org/project/tiny-notepad">Tiny Notepad</a>（轻量便签式聊天界面，PyPI 可用）</li>
<li><a href="https://github.com/hellotunamayo/macLlama">macLlama (macOS 原生)</a>（macOS 原生 GUI，聊天界面）</li>
</ul>
<h3>云端</h3>
<ul>
<li><a href="https://cloud.google.com/run/docs/tutorials/gpu-gemma2-with-ollama">Google Cloud</a></li>
<li><a href="https://fly.io/docs/python/do-more/add-ollama/">Fly.io</a></li>
<li><a href="https://www.koyeb.com/deploy/ollama">Koyeb</a></li>
</ul>
<h3>终端</h3>
<ul>
<li><a href="https://github.com/ggozad/oterm">oterm</a></li>
<li><a href="https://github.com/s-kostyaev/ellama">Ellama Emacs 客户端</a></li>
<li><a href="https://github.com/zweifisch/ollama">Emacs 客户端</a></li>
<li><a href="https://github.com/paradoxical-dev/neollama">neollama</a>（Neovim 内与模型交互的 UI 客户端）</li>
<li><a href="https://github.com/David-Kunz/gen.nvim">gen.nvim</a></li>
<li><a href="https://github.com/nomnivore/ollama.nvim">ollama.nvim</a></li>
<li><a href="https://github.com/marco-souza/ollero.nvim">ollero.nvim</a></li>
<li><a href="https://github.com/gerazov/ollama-chat.nvim">ollama-chat.nvim</a></li>
<li><a href="https://github.com/huynle/ogpt.nvim">ogpt.nvim</a></li>
<li><a href="https://github.com/karthink/gptel">gptel Emacs 客户端</a></li>
<li><a href="https://github.com/dustinblackman/oatmeal">Oatmeal</a></li>
<li><a href="https://github.com/pgibler/cmdh">cmdh</a></li>
<li><a href="https://github.com/npahlfer/ooo">ooo</a></li>
<li><a href="https://github.com/reid41/shell-pilot">shell-pilot</a>（Linux/macOS 下纯 Shell 脚本与模型交互）</li>
<li><a href="https://github.com/pythops/tenere">tenere</a></li>
<li><a href="https://github.com/taketwo/llm-ollama">llm-ollama</a>（<a href="https://llm.datasette.io/en/stable/">Datasette 的 LLM CLI</a>）</li>
<li><a href="https://github.com/anaisbetts/typechat-cli">typechat-cli</a></li>
<li><a href="https://github.com/djcopley/ShellOracle">ShellOracle</a></li>
<li><a href="https://github.com/yusufcanb/tlm">tlm</a></li>
<li><a href="https://github.com/ericcurtin/podman-ollama">podman-ollama</a></li>
<li><a href="https://github.com/sammcj/gollama">gollama</a></li>
<li><a href="https://github.com/paulrobello/parllama">ParLlama</a></li>
<li><a href="https://github.com/cognitivetech/ollama-ebook-summary/">Ollama eBook Summary</a></li>
<li><a href="https://github.com/rapidarchitect/ollama_moe">Ollama Mixture of Experts (MOE) in 50 lines of code</a></li>
<li><a href="https://github.com/pepo-ec/vim-intelligence-bridge">vim-intelligence-bridge</a>（简单集成 Vim 和 Ollama）</li>
<li><a href="https://x-cmd.com/mod/ollama">x-cmd ollama</a></li>
<li><a href="https://github.com/drunkwcodes/bb7">bb7</a></li>
<li><a href="https://github.com/marcusziade/Swollama">SwollamaCLI</a>（Swollama Swift 包含的 CLI，<a href="https://github.com/marcusziade/Swollama?tab=readme-ov-file#cli-usage">演示</a>）</li>
<li><a href="https://github.com/sigoden/aichat">aichat</a>（多合一 LLM CLI，包含 Shell 助手、Chat-REPL、RAG、AI 工具/代理，支持 OpenAI、Claude、Gemini、Ollama、Groq 等）</li>
<li><a href="https://github.com/rrg92/powershai">PowershAI</a>（Windows PowerShell 模块，支持 Ollama）</li>
<li><a href="https://github.com/Abyss-c0re/deepshell">DeepShell</a>（自托管 AI 助手，交互 Shell、文件/文件夹分析）</li>
<li><a href="https://github.com/xyproto/orbiton">orbiton</a>（零配置文本编辑器与 IDE，支持 Ollama 补全）</li>
<li><a href="https://github.com/molbal/orca-cli">orca-cli</a>（Ollama 注册表 CLI 应用，浏览、拉取、下载模型）</li>
<li><a href="https://github.com/jonathanhecl/gguf-to-ollama">GGUF-to-Ollama</a>（多平台 GGUF 导入 Ollama 工具）</li>
<li><a href="https://github.com/rapidarchitect/ollama_strands">AWS-Strands-With-Ollama</a>（AWS Strands 智能体 Ollama 集成示例）</li>
</ul>
<h3>Apple Vision Pro</h3>
<ul>
<li><a href="https://github.com/aws-samples/swift-chat">SwiftChat</a>（跨平台 AI 聊天，支持 Vision Pro）</li>
<li><a href="https://github.com/AugustDev/enchanted">Enchanted</a></li>
</ul>
<h3>数据库</h3>
<ul>
<li><a href="https://github.com/timescale/pgai">pgai</a> - PostgreSQL 向量数据库（使用 pgvector 调用 Ollama 生成/搜索嵌入向量）
<ul>
<li><a href="https://github.com/timescale/pgai/blob/main/docs/vectorizer-quick-start.md">入门指南</a></li>
</ul>
</li>
<li><a href="https://github.com/mindsdb/mindsdb/blob/staging/mindsdb/integrations/handlers/ollama_handler/README.md">MindsDB</a>（将 Ollama 模型连接至近 200 个数据平台与应用）</li>
<li><a href="https://github.com/philippgille/chromem-go/blob/v0.5.0/embed_ollama.go">chromem-go</a>（<a href="https://github.com/philippgille/chromem-go/tree/v0.5.0/examples/rag-wikipedia-ollama">示例</a>）</li>
<li><a href="https://github.com/dbkangaroo/kangaroo">Kangaroo</a>（AI 驱动的 SQL 客户端及管理工具）</li>
</ul>
<h3>包管理器</h3>
<ul>
<li><a href="https://archlinux.org/packages/extra/x86_64/ollama/">Pacman</a></li>
<li><a href="https://github.com/gentoo/guru/tree/master/app-misc/ollama">Gentoo</a></li>
<li><a href="https://formulae.brew.sh/formula/ollama">Homebrew</a></li>
<li><a href="https://artifacthub.io/packages/helm/ollama-helm/ollama">Helm Chart</a></li>
<li><a href="https://codeberg.org/tusharhero/ollama-guix">Guix channel</a></li>
<li><a href="https://search.nixos.org/packages?show=ollama&amp;from=0&amp;size=50&amp;sort=relevance&amp;type=packages&amp;query=ollama">Nix package</a></li>
<li><a href="https://flox.dev/blog/ollama-part-one">Flox</a></li>
</ul>
<h3>库</h3>
<ul>
<li><a href="https://python.langchain.com/docs/integrations/chat/ollama/">LangChain</a>、<a href="https://js.langchain.com/docs/integrations/chat/ollama/">LangChain.js</a>（<a href="https://js.langchain.com/docs/tutorials/local_rag/">示例</a>）</li>
<li><a href="https://firebase.google.com/docs/genkit/plugins/ollama">Firebase Genkit</a></li>
<li><a href="https://github.com/crewAIInc/crewAI">crewAI</a></li>
<li><a href="https://remembersoftwares.github.io/yacana/">Yacana</a>（多智能体流程框架，内建工具集成）</li>
<li><a href="https://github.com/spring-projects/spring-ai">Spring AI</a>（<a href="https://docs.spring.io/spring-ai/reference/api/chat/ollama-chat.html">参考</a>、<a href="https://github.com/tzolov/ollama-tools">示例</a>）</li>
<li><a href="https://github.com/tmc/langchaingo/">LangChainGo</a>（<a href="https://github.com/tmc/langchaingo/tree/main/examples/ollama-completion-example">示例</a>）</li>
<li><a href="https://github.com/langchain4j/langchain4j">LangChain4j</a>（<a href="https://github.com/langchain4j/langchain4j-examples/tree/main/ollama-examples/src/main/java">示例</a>）</li>
<li><a href="https://github.com/Abraxas-365/langchain-rust">LangChainRust</a>（<a href="https://github.com/Abraxas-365/langchain-rust/blob/main/examples/llm_ollama.rs">示例</a>）</li>
<li><a href="https://github.com/tryAGI/LangChain">LangChain for .NET</a>（<a href="https://github.com/tryAGI/LangChain/blob/main/examples/LangChain.Samples.OpenAI/Program.cs">示例</a>）</li>
<li><a href="https://github.com/theodo-group/LLPhant?tab=readme-ov-file#ollama">LLPhant</a></li>
<li><a href="https://docs.llamaindex.ai/en/stable/examples/llm/ollama/">LlamaIndex</a>、<a href="https://ts.llamaindex.ai/modules/llms/available_llms/ollama">LlamaIndexTS</a></li>
<li><a href="https://github.com/BerriAI/litellm">LiteLLM</a></li>
<li><a href="https://github.com/presbrey/ollamafarm">OllamaFarm for Go</a></li>
<li><a href="https://github.com/awaescher/OllamaSharp">OllamaSharp for .NET</a></li>
<li><a href="https://github.com/gbaptista/ollama-ai">Ollama for Ruby</a></li>
<li><a href="https://github.com/pepperoni21/ollama-rs">Ollama-rs for Rust</a></li>
<li><a href="https://github.com/jmont-dev/ollama-hpp">Ollama-hpp for C++</a></li>
<li><a href="https://github.com/ollama4j/ollama4j">Ollama4j for Java</a></li>
<li><a href="https://modelfusion.dev/integration/model-provider/ollama">ModelFusion Typescript Library</a></li>
<li><a href="https://github.com/kevinhermawan/OllamaKit">OllamaKit for Swift</a></li>
<li><a href="https://github.com/breitburg/dart-ollama">Ollama for Dart</a></li>
<li><a href="https://github.com/cloudstudio/ollama-laravel">Ollama for Laravel</a></li>
<li><a href="https://github.com/davidmigloz/langchain_dart">LangChainDart</a></li>
<li><a href="https://github.com/microsoft/semantic-kernel/tree/main/python/semantic_kernel/connectors/ai/ollama">Semantic Kernel - Python</a></li>
<li><a href="https://github.com/deepset-ai/haystack-integrations/blob/main/integrations/ollama.md">Haystack</a></li>
<li><a href="https://github.com/brainlid/langchain">Elixir LangChain</a></li>
<li><a href="https://github.com/JBGruber/rollama">Ollama for R - rollama</a></li>
<li><a href="https://github.com/hauselin/ollama-r">Ollama for R - ollama-r</a></li>
<li><a href="https://github.com/lebrunel/ollama-ex">Ollama-ex for Elixir</a></li>
<li><a href="https://github.com/b-tocs/abap_btocs_ollama">Ollama Connector for SAP ABAP</a></li>
<li><a href="https://testcontainers.com/modules/ollama/">Testcontainers</a></li>
<li><a href="https://portkey.ai/docs/welcome/integration-guides/ollama">Portkey</a></li>
<li><a href="https://github.com/svilupp/PromptingTools.jl">PromptingTools.jl</a>（<a href="https://svilupp.github.io/PromptingTools.jl/dev/examples/working_with_ollama">示例</a>）</li>
<li><a href="https://github.com/Project-Llama/llamascript">LlamaScript</a></li>
<li><a href="https://github.com/emirsahin1/llm-axe">llm-axe</a>（Python LLM 应用开发工具包）</li>
<li><a href="https://docs.gollm.co/examples/ollama-example">Gollm</a></li>
<li><a href="https://github.com/jonathanhecl/gollama">Gollama for Golang</a></li>
<li><a href="https://github.com/xyproto/ollamaclient">Ollamaclient for Golang</a></li>
<li><a href="https://gitlab.com/tozd/go/fun">Go 高级函数抽象</a></li>
<li><a href="https://github.com/ArdaGnsrn/ollama-php">Ollama PHP</a></li>
<li><a href="https://github.com/agents-flex/agents-flex">Agents-Flex for Java</a>（<a href="https://github.com/agents-flex/agents-flex/tree/main/agents-flex-llm/agents-flex-llm-ollama/src/test/java/com/agentsflex/llm/ollama">示例</a>）</li>
<li><a href="https://github.com/parakeet-nest/parakeet">Parakeet</a>（Go 轻量 LLM 应用开发库）</li>
<li><a href="https://github.com/andygill/haverscript">Haverscript</a>（<a href="https://github.com/andygill/haverscript/tree/main/examples">示例</a>）</li>
<li><a href="https://github.com/mattt/ollama-swift">Ollama for Swift</a></li>
<li><a href="https://github.com/marcusziade/Swollama">Swollama for Swift</a>（<a href="https://marcusziade.github.io/Swollama/documentation/swollama/">DocC</a>）</li>
<li><a href="https://github.com/prasad89/golamify">GoLamify</a></li>
<li><a href="https://github.com/tusharad/ollama-haskell">Ollama for Haskell</a></li>
<li><a href="https://github.com/nbonamy/multi-llm-ts">multi-llm-ts</a>（TS/JS 统一多 LLM 库）</li>
<li><a href="https://github.com/lofcz/llmtornado">LlmTornado</a>（C# 统一接口库，支持主流推理 API）</li>
<li><a href="https://github.com/dravenk/ollama-zig">Ollama for Zig</a></li>
<li><a href="https://github.com/lunary-ai/abso">Abso</a>（OpenAI 兼容 TypeScript SDK）</li>
<li><a href="https://github.com/goodreasonai/nichey">Nichey</a>（研究主题定制 wiki 生成 Python 包）</li>
<li><a href="https://github.com/kassane/ollama-d">Ollama for D</a></li>
<li><a href="https://github.com/HardCodeDev777/OllamaPlusPlus">OllamaPlusPlus</a>（极简 C++ Ollama 库）</li>
</ul>
<h3>移动端</h3>
<ul>
<li><a href="https://github.com/aws-samples/swift-chat">SwiftChat</a>（原生界面，极速跨平台 AI 聊天，支持 Android、iOS、iPad）</li>
<li><a href="https://github.com/AugustDev/enchanted">Enchanted</a></li>
<li><a href="https://github.com/Mobile-Artificial-Intelligence/maid">Maid</a></li>
<li><a href="https://github.com/JHubi1/ollama-app">Ollama App</a>（现代易用的多平台 Ollama 客户端）</li>
<li><a href="https://github.com/1runeberg/confichat">ConfiChat</a>（轻量、独立、跨平台、隐私友好 LLM 聊天界面，支持可选加密）</li>
<li><a href="https://github.com/sunshine0523/OllamaServer">Ollama Android Chat</a>（无需 Termux，安卓一键启动 Ollama 服务）</li>
<li><a href="https://github.com/ibrahimcetin/reins">Reins</a>（每个聊天轻松调参，自定义系统 prompt，增强 AI 实验）</li>
</ul>
<h3>扩展 &amp; 插件</h3>
<ul>
<li><a href="https://github.com/MassimilianoPasquini97/raycast_ollama">Raycast 扩展</a></li>
<li><a href="https://github.com/mxyng/discollama">Discollama</a>（Ollama Discord 频道机器人）</li>
<li><a href="https://github.com/continuedev/continue">Continue</a></li>
<li><a href="https://github.com/thewh1teagle/vibe">Vibe</a>（会议转录与分析）</li>
<li><a href="https://github.com/hinterdupfinger/obsidian-ollama">Obsidian Ollama 插件</a></li>
<li><a href="https://github.com/omagdy7/ollama-logseq">Logseq Ollama 插件</a></li>
<li><a href="https://github.com/andersrex/notesollama">NotesOllama</a>（Apple Notes Ollama 插件）</li>
<li><a href="https://github.com/samalba/dagger-chatbot">Dagger Chatbot</a></li>
<li><a href="https://github.com/mekb-turtle/discord-ai-bot">Discord AI Bot</a></li>
<li><a href="https://github.com/ruecat/ollama-telegram">Ollama Telegram Bot</a></li>
<li><a href="https://github.com/ej52/hass-ollama-conversation">Hass Ollama Conversation</a></li>
<li><a href="https://github.com/abrenneke/rivet-plugin-ollama">Rivet 插件</a></li>
<li><a href="https://github.com/longy2k/obsidian-bmo-chatbot">Obsidian BMO Chatbot 插件</a></li>
<li><a href="https://github.com/herval/cliobot">Cliobot</a>（支持 Ollama 的 Telegram 机器人）</li>
<li><a href="https://github.com/logancyang/obsidian-copilot">Copilot for Obsidian 插件</a></li>
<li><a href="https://github.com/pfrankov/obsidian-local-gpt">Obsidian Local GPT 插件</a></li>
<li><a href="https://docs.openinterpreter.com/language-model-setup/local-models/ollama">Open Interpreter</a></li>
<li><a href="https://github.com/ex3ndr/llama-coder">Llama Coder</a>（Ollama 替代 Copilot）</li>
<li><a href="https://github.com/bernardo-bruning/ollama-copilot">Ollama Copilot</a>（代理，将 Ollama 作为 Copilot 使用）</li>
<li><a href="https://github.com/rjmacarthy/twinny">twinny</a>（Ollama Copilot 及聊天替代）</li>
<li><a href="https://github.com/RussellCanfield/wingman-ai">Wingman-AI</a>（Ollama/Hugging Face Copilot 代码和聊天替代）</li>
<li><a href="https://github.com/n4ze3m/page-assist">Page Assist</a>（Chrome 扩展）</li>
<li><a href="https://github.com/imoize/plasmoid-ollamacontrol">Plasmoid Ollama Control</a>（KDE Plasma 快速管理/控制扩展）</li>
<li><a href="https://github.com/tusharhero/aitelegrambot">AI Telegram Bot</a>（后端集成 Ollama 的 Telegram 机器人）</li>
<li><a href="https://github.com/yaroslavyaroslav/OpenAI-sublime-text">AI ST Completion</a>（Sublime Text 4 AI 助手插件，支持 Ollama）</li>
<li><a href="https://github.com/kevinthedang/discord-ollama">Discord-Ollama Chat Bot</a>（通用 TypeScript Discord 机器人，含调优文档）</li>
<li><a href="https://github.com/josStorer/chatGPTBox">ChatGPTBox: All in one 浏览器扩展</a>（<a href="https://github.com/josStorer/chatGPTBox/issues/616#issuecomment-1975186467">集成教程</a>）</li>
<li><a href="https://github.com/rapmd73/Companion">Discord AI 聊天/管理机器人</a>（Python 实现，Ollama 个性化角色）</li>
<li><a href="https://github.com/nischalj10/headless-ollama">Headless Ollama</a>（自动安装 Ollama 客户端和模型的脚本）</li>
<li><a href="https://github.com/xuyangbocn/terraform-aws-self-host-llm">Terraform AWS Ollama &amp; Open WebUI</a>（一键在 AWS 部署 Ollama+Open WebUI）</li>
<li><a href="https://github.com/jakubburkiewicz/node-red-contrib-ollama">node-red-contrib-ollama</a></li>
<li><a href="https://github.com/ivostoykov/localAI">Local AI Helper</a>（Chrome/Firefox 扩展，支持自定义 API、标签安全存储）</li>
<li><a href="https://github.com/jake83741/vnc-lm">vnc-lm</a>（Discord 机器人，通过 Ollama/LiteLLM 消息，快速切换模型）</li>
<li><a href="https://github.com/SilasMarvin/lsp-ai">LSP-AI</a>（开源 AI 语言服务器）</li>
<li><a href="https://github.com/Palm1r/QodeAssist">QodeAssist</a>（Qt Creator AI 编码助手插件）</li>
<li><a href="https://github.com/ECuiDev/obsidian-quiz-generator">Obsidian Quiz Generator 插件</a></li>
<li><a href="https://github.com/philffm/ai-summary-helper">AI Summmary Helper 插件</a></li>
<li><a href="https://github.com/suncloudsmoon/TextCraft">TextCraft</a>（Word Copilot 替代）</li>
<li><a href="https://github.com/zeitlings/alfred-ollama">Alfred Ollama</a>（Alfred Workflow）</li>
<li><a href="https://github.com/adarshM84/TextLLaMA">TextLLaMA</a>（Chrome 扩展，邮件写作、语法纠错、翻译）</li>
<li><a href="https://github.com/zyphixor/simple-discord-ai">Simple-Discord-AI</a></li>
<li><a href="https://github.com/innightwolfsleep/llm_telegram_bot">LLM Telegram Bot</a>（主打 RP 的 Telegram 机器人，集成 A1111、按钮等）</li>
<li><a href="https://github.com/sammcj/mcp-llm">mcp-llm</a>（MCP 服务器，支持 LLM 间互调）</li>
<li><a href="https://github.com/HardCodeDev777/SimpleOllamaUnity">SimpleOllamaUnity</a>（Unity 扩展，几行代码集成 Ollama，支持运行时）</li>
<li><a href="https://github.com/HardCodeDev777/UnityCodeLama">UnityCodeLama</a>（Unity 编辑器脚本分析工具）</li>
</ul>
<h3>支持后端</h3>
<ul>
<li><a href="https://github.com/ggerganov/llama.cpp">llama.cpp</a>（Georgi Gerganov 发起）</li>
</ul>
<h3>可观测性</h3>
<ul>
<li><a href="https://www.comet.com/docs/opik/cookbook/ollama">Opik</a> 开源平台，支持 Ollama 的 LLM 应用/RAG/智能体工作流的调试、评估与监控，内置追踪、自动评测、生产级仪表盘。</li>
<li><a href="https://lunary.ai/docs/integrations/ollama">Lunary</a> 主流开源 LLM 可观测性平台，提供实时分析、模板管理、PII 遮蔽、智能体追踪等企业级特性。</li>
<li><a href="https://github.com/openlit/openlit">OpenLIT</a> 原生 OpenTelemetry 工具，监控 Ollama 应用与 GPU，追踪与指标一体化。</li>
<li><a href="https://docs.honeyhive.ai/integrations/ollama">HoneyHive</a> AI 可观测与评估平台，支持智能体性能评测、故障分析与生产质量监控。</li>
<li><a href="https://langfuse.com/docs/integrations/ollama">Langfuse</a> 开源 LLM 可观测性平台，协同监控、评估、调试 AI 应用。</li>
<li><a href="https://mlflow.org/docs/latest/llms/tracing/index.html#automatic-tracing">MLflow Tracing</a> 开源 LLM 可观测工具，API 简便，便于调试与评估 GenAI 应用。</li>
</ul>
<hr />
<p><a href="https://github.com/OpenAiTx/OpenAiTx">Powered By OpenAiTx</a></p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
</body>
</html>