<!DOCTYPE html>
<html lang="hi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>pytorch - pytorch/pytorch hi</title>
    <meta name="title" content="pytorch - pytorch/pytorch hi | PyTorch एक Python पैकेज है जो दो उच्च-स्तरीय विशेषताएँ प्रदान करता है: टेन्सर गणना (जैसे NumPy) के साथ मजबूत GPU त्वरण टेप-आधारित ऑटोग्रैड सिस्टम पर निर्मित गहर...">
    <meta name="description" content="pytorch/pytorch - GitHub repository hi documentation and information | PyTorch एक Python पैकेज है जो दो उच्च-स्तरीय विशेषताएँ प्रदान करता है: टेन्सर गणना (जैसे NumPy) के साथ मजबूत GPU त्वरण टेप-आधारित ऑटोग्रैड सिस्टम पर निर्मित गहर...">
    <meta name="keywords" content="pytorch, pytorch, GitHub, repository, hi documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/pytorch/pytorch/README-hi.html">
    <meta property="og:title" content="pytorch - pytorch/pytorch hi | PyTorch एक Python पैकेज है जो दो उच्च-स्तरीय विशेषताएँ प्रदान करता है: टेन्सर गणना (जैसे NumPy) के साथ मजबूत GPU त्वरण टेप-आधारित ऑटोग्रैड सिस्टम पर निर्मित गहर...">
    <meta property="og:description" content="pytorch/pytorch - GitHub repository hi documentation and information | PyTorch एक Python पैकेज है जो दो उच्च-स्तरीय विशेषताएँ प्रदान करता है: टेन्सर गणना (जैसे NumPy) के साथ मजबूत GPU त्वरण टेप-आधारित ऑटोग्रैड सिस्टम पर निर्मित गहर...">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div style="position: fixed; top: 2px; left: 2px; z-index: 2000; background: rgba(255,255,255,0.95); border-radius: 6px; box-shadow: 0 2px 8px rgba(0,0,0,0.06); padding: 4px 14px; font-size: 15px; color: #222; font-family: 'Segoe UI', Arial, sans-serif; font-weight: 500; letter-spacing: 0.5px;">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" style="color: #0366d6; text-decoration: none; font-weight: 600;">Open AI Tx</a>
    </div>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/pytorch/pytorch" id="githubRepoLink" target="_blank">pytorch/pytorch</a>
<h1 style="display: none;">PyTorch एक Python पैकेज है जो दो उच्च-स्तरीय विशेषताएँ प्रदान करता है: टेन्सर गणना (जैसे NumPy) के साथ मजबूत GPU त्वरण टेप-आधारित ऑटोग्रैड सिस्टम पर निर्मित गहर...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <p><img src="https://github.com/pytorch/pytorch/raw/main/docs/source/_static/img/pytorch-logo-dark.png" alt="PyTorch Logo" /></p>
<hr />
<p>PyTorch एक Python पैकेज है जो दो उच्च-स्तरीय विशेषताएँ प्रदान करता है:</p>
<ul>
<li>टेन्सर गणना (जैसे NumPy) के साथ मजबूत GPU त्वरण</li>
<li>टेप-आधारित ऑटोग्रैड सिस्टम पर निर्मित गहरे न्यूरल नेटवर्क</li>
</ul>
<p>आप अपनी पसंदीदा Python पैकेज जैसे NumPy, SciPy, और Cython का उपयोग PyTorch को आवश्यकता अनुसार बढ़ाने के लिए कर सकते हैं।</p>
<p>हमारे ट्रंक स्वास्थ्य (सतत एकीकरण संकेत) <a href="https://hud.pytorch.org/ci/pytorch/pytorch/main">hud.pytorch.org</a> पर पाए जा सकते हैं।</p>
<!-- toc -->
<ul>
<li><a href="#more-about-pytorch">PyTorch के बारे में और अधिक</a>
<ul>
<li><a href="#a-gpu-ready-tensor-library">एक GPU-तैयार टेन्सर लाइब्रेरी</a></li>
<li><a href="#dynamic-neural-networks-tape-based-autograd">डायनामिक न्यूरल नेटवर्क: टेप-आधारित ऑटोग्रैड</a></li>
<li><a href="#python-first">Python पहले</a></li>
<li><a href="#imperative-experiences">अनिवार्य अनुभव</a></li>
<li><a href="#fast-and-lean">तेज़ और हल्का</a></li>
<li><a href="#extensions-without-pain">बिना दर्द के एक्सटेंशन</a></li>
</ul>
</li>
<li><a href="#installation">इंस्टॉलेशन</a>
<ul>
<li><a href="#binaries">बाइनरीज़</a>
<ul>
<li><a href="#nvidia-jetson-platforms">NVIDIA Jetson प्लेटफॉर्म्स</a></li>
</ul>
</li>
<li><a href="#from-source">स्रोत से</a>
<ul>
<li><a href="#prerequisites">पूर्वापेक्षाएँ</a>
<ul>
<li><a href="#nvidia-cuda-support">NVIDIA CUDA सपोर्ट</a></li>
<li><a href="#amd-rocm-support">AMD ROCm सपोर्ट</a></li>
<li><a href="#intel-gpu-support">Intel GPU सपोर्ट</a></li>
</ul>
</li>
<li><a href="#get-the-pytorch-source">PyTorch स्रोत प्राप्त करें</a></li>
<li><a href="#install-dependencies">डिपेंडेंसीज़ इंस्टॉल करें</a></li>
<li><a href="#install-pytorch">PyTorch इंस्टॉल करें</a>
<ul>
<li><a href="#adjust-build-options-optional">बिल्ड विकल्प समायोजित करें (वैकल्पिक)</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#docker-image">डॉकर इमेज</a>
<ul>
<li><a href="#using-pre-built-images">पूर्व-निर्मित इमेजेस का उपयोग करना</a></li>
<li><a href="#building-the-image-yourself">इमेज को स्वयं बनाना</a></li>
</ul>
</li>
<li><a href="#building-the-documentation">डॉक्यूमेंटेशन बनाना</a>
<ul>
<li><a href="#building-a-pdf">PDF बनाना</a></li>
</ul>
</li>
<li><a href="#previous-versions">पिछले संस्करण</a></li>
</ul>
</li>
<li><a href="#getting-started">शुरुआत करना</a></li>
<li><a href="#resources">संसाधन</a></li>
<li><a href="#communication">संचार</a></li>
<li><a href="#releases-and-contributing">रिलीज़ और योगदान</a></li>
<li><a href="#the-team">टीम</a></li>
<li><a href="#license">लाइसेंस</a></li>
</ul>
<!-- tocstop -->
<h2>PyTorch के बारे में और अधिक</h2>
<p><a href="https://pytorch.org/tutorials/beginner/basics/intro.html">PyTorch के मूल बातें सीखें</a></p>
<p>सूक्ष्म स्तर पर, PyTorch एक लाइब्रेरी है जिसमें निम्नलिखित घटक होते हैं:</p>
<p>| घटक | विवरण |
| ---- | --- |
| <a href="https://pytorch.org/docs/stable/torch.html"><strong>torch</strong></a> | NumPy जैसी एक टेन्सर लाइब्रेरी, मजबूत GPU सपोर्ट के साथ |
| <a href="https://pytorch.org/docs/stable/autograd.html"><strong>torch.autograd</strong></a> | टेप-आधारित स्वचालित डिफरेंशिएशन लाइब्रेरी, जो torch में सभी डिफरेंशिएबल टेन्सर ऑपरेशन्स को सपोर्ट करती है |
| <a href="https://pytorch.org/docs/stable/jit.html"><strong>torch.jit</strong></a> | एक संकलन स्टैक (TorchScript) जो PyTorch कोड से सीरियलाइजेबल और ऑप्टिमाइजेबल मॉडल बनाता है  |
| <a href="https://pytorch.org/docs/stable/nn.html"><strong>torch.nn</strong></a> | एक न्यूरल नेटवर्क लाइब्रेरी, ऑटोग्रैड के साथ गहराई से एकीकृत, अधिकतम लचीलापन के लिए डिज़ाइन की गई |
| <a href="https://pytorch.org/docs/stable/multiprocessing.html"><strong>torch.multiprocessing</strong></a> | Python मल्टीप्रोसेसिंग, लेकिन torch टेन्सर की प्रक्रियाओं के बीच मैजिकल मेमोरी साझा करने के साथ। डेटा लोडिंग और Hogwild ट्रेनिंग के लिए उपयोगी |
| <a href="https://pytorch.org/docs/stable/data.html"><strong>torch.utils</strong></a> | सुविधा के लिए DataLoader और अन्य यूटिलिटी फंक्शन |</p>
<p>आम तौर पर, PyTorch का उपयोग या तो:</p>
<ul>
<li>GPU की शक्ति का उपयोग करने के लिए NumPy के विकल्प के रूप में।</li>
<li>एक डीप लर्निंग रिसर्च प्लेटफॉर्म के रूप में, जो अधिकतम लचीलापन और गति प्रदान करता है।</li>
</ul>
<p>आगे विस्तार से:</p>
<h3>एक GPU-तैयार टेन्सर लाइब्रेरी</h3>
<p>यदि आप NumPy का उपयोग करते हैं, तो आपने टेन्सर (a.k.a. ndarray) का उपयोग किया है।</p>
<p><img src="./docs/source/_static/img/tensor_illustration.png" alt="Tensor illustration" /></p>
<p>PyTorch ऐसे टेन्सर प्रदान करता है जो या तो CPU या GPU पर रह सकते हैं और गणना को
बहुत अधिक गति से तेज करते हैं।</p>
<p>हम विविध प्रकार की टेन्सर रूटीन प्रदान करते हैं, जो आपकी वैज्ञानिक गणना की जरूरतों को तेज और उपयुक्त बनाते हैं,
जैसे slicing, indexing, गणितीय ऑपरेशन, रेखीय बीजगणित, reductions।
और ये तेज हैं!</p>
<h3>डायनामिक न्यूरल नेटवर्क: टेप-आधारित ऑटोग्रैड</h3>
<p>PyTorch के पास न्यूरल नेटवर्क बनाने का एक अनोखा तरीका है: टेप रिकॉर्डर का उपयोग और पुनः चलाना।</p>
<p>अधिकतर फ्रेमवर्क जैसे TensorFlow, Theano, Caffe, और CNTK विश्व को स्थैतिक रूप में देखते हैं।
एक बार न्यूरल नेटवर्क बनाना होता है और बार-बार उसी संरचना का पुनः उपयोग करना होता है।
नेटवर्क के व्यवहार को बदलना है तो शून्य से शुरू करना पड़ता है।</p>
<p>PyTorch के साथ, हम एक तकनीक का उपयोग करते हैं जिसे रिवर्स-मोड ऑटो-डिफरेंशिएशन कहा जाता है, जो आपको
आपके नेटवर्क के व्यवहार को मनचाहे ढंग से बिना किसी विलंब या ओवरहेड के बदलने की अनुमति देती है। हमारी प्रेरणा इस विषय पर कई शोध पत्रों और
<a href="https://github.com/twitter/torch-autograd">torch-autograd</a>,
<a href="https://github.com/HIPS/autograd">autograd</a>,
<a href="https://chainer.org">Chainer</a> आदि कार्यों से मिलती है।</p>
<p>जबकि यह तकनीक केवल PyTorch तक सीमित नहीं है, यह इसकी सबसे तेज़ इम्प्लीमेंटेशन में से एक है।
आपको गति और लचीलापन दोनों का सर्वोत्तम संयोजन मिलता है।</p>
<p><img src="https://github.com/pytorch/pytorch/raw/main/docs/source/_static/img/dynamic_graph.gif" alt="Dynamic graph" /></p>
<h3>Python पहले</h3>
<p>PyTorch कोई मोनोलिथिक C++ फ्रेमवर्क में Python बाइंडिंग नहीं है।
इसे Python में गहराई से एकीकृत किया गया है।
आप इसे वैसे ही स्वाभाविक रूप से उपयोग कर सकते हैं जैसे <a href="https://www.numpy.org/">NumPy</a> / <a href="https://www.scipy.org/">SciPy</a> / <a href="https://scikit-learn.org">scikit-learn</a> आदि का करते हैं।
आप अपने नए न्यूरल नेटवर्क लेयर्स Python में ही लिख सकते हैं, अपनी पसंदीदा लाइब्रेरीज
और पैकेज जैसे <a href="https://cython.org/">Cython</a> और <a href="http://numba.pydata.org/">Numba</a> का उपयोग करके।
हमारा लक्ष्य है कि जहाँ उचित हो वहाँ पहिया पुनः न बनाएं।</p>
<h3>अनिवार्य अनुभव</h3>
<p>PyTorch को सहज, रैखिक सोच में और उपयोग में आसान होने के लिए डिज़ाइन किया गया है।
जब आप कोड की एक लाइन निष्पादित करते हैं, तो वह निष्पादित होती है। यहाँ कोई असिंक्रोनस दृश्य नहीं है।
जब आप डिबगर में जाते हैं या एरर मैसेज और स्टैक ट्रेस प्राप्त करते हैं, तो उन्हें समझना आसान है।
स्टैक ट्रेस ठीक उसी स्थान की ओर इशारा करता है जहाँ आपका कोड परिभाषित है।
हम आशा करते हैं कि आप कभी भी खराब स्टैक ट्रेस या असिंक्रोनस और अपारदर्शी निष्पादन इंजनों के कारण घंटों कोड डिबग करने में न बिताएं।</p>
<h3>तेज़ और हल्का</h3>
<p>PyTorch में न्यूनतम फ्रेमवर्क ओवरहेड है। हम त्वरण लाइब्रेरीज को एकीकृत करते हैं
जैसे <a href="https://software.intel.com/mkl">Intel MKL</a> और NVIDIA (<a href="https://developer.nvidia.com/cudnn">cuDNN</a>, <a href="https://developer.nvidia.com/nccl">NCCL</a>) अधिकतम गति के लिए।
मुख्य रूप से, इसके CPU और GPU टेन्सर और न्यूरल नेटवर्क बैकएंड्स
परिपक्व हैं और वर्षों से परीक्षण किए गए हैं।</p>
<p>इसलिए, PyTorch काफी तेज़ है — चाहे आप छोटे या बड़े न्यूरल नेटवर्क चलाएं।</p>
<p>PyTorch में मेमोरी उपयोग अत्यंत कुशल है, Torch या कुछ अन्य विकल्पों की तुलना में।
हमने GPU के लिए कस्टम मेमोरी एलोकेटर्स लिखे हैं ताकि
आपके डीप लर्निंग मॉडल अधिकतम मेमोरी कुशल बन सकें।
यह आपको पहले से बड़े डीप लर्निंग मॉडल ट्रेन करने में सक्षम बनाता है।</p>
<h3>बिना दर्द के एक्सटेंशन</h3>
<p>नए न्यूरल नेटवर्क मॉड्यूल लिखना, या PyTorch के टेन्सर API से इंटरफेस करना,
सीधा और न्यूनतम एब्स्ट्रैक्शंस के साथ डिज़ाइन किया गया है।</p>
<p>आप torch API का उपयोग करके नए न्यूरल नेटवर्क लेयर Python में लिख सकते हैं
<a href="https://pytorch.org/tutorials/advanced/numpy_extensions_tutorial.html">या अपनी पसंदीदा NumPy-आधारित लाइब्रेरी जैसे SciPy</a> का उपयोग करके भी कर सकते हैं।</p>
<p>यदि आप अपने लेयर C/C++ में लिखना चाहते हैं, तो हम एक सुविधाजनक एक्सटेंशन API प्रदान करते हैं जो कुशल और न्यूनतम बोइलरप्लेट के साथ है।
कोई रैपर कोड लिखने की आवश्यकता नहीं है। आप <a href="https://pytorch.org/tutorials/advanced/cpp_extension.html">यहाँ एक ट्यूटोरियल देख सकते हैं</a> और <a href="https://github.com/pytorch/extension-cpp">यहाँ एक उदाहरण</a>।</p>
<h2>इंस्टॉलेशन</h2>
<h3>बाइनरीज़</h3>
<p>Conda या pip व्हील्स के माध्यम से बाइनरीज़ इंस्टॉल करने के लिए कमांड्स हमारी वेबसाइट पर हैं: <a href="https://pytorch.org/get-started/locally/">https://pytorch.org/get-started/locally/</a></p>
<h4>NVIDIA Jetson प्लेटफॉर्म्स</h4>
<p>NVIDIA के Jetson Nano, Jetson TX1/TX2, Jetson Xavier NX/AGX, और Jetson AGX Orin के लिए Python व्हील्स <a href="https://forums.developer.nvidia.com/t/pytorch-for-jetson-version-1-10-now-available/72048">यहाँ</a> उपलब्ध हैं और L4T कंटेनर <a href="https://catalog.ngc.nvidia.com/orgs/nvidia/containers/l4t-pytorch">यहाँ</a> प्रकाशित है।</p>
<p>इनके लिए JetPack 4.2 या उससे ऊपर की आवश्यकता है, और <a href="https://github.com/dusty-nv">@dusty-nv</a> तथा <a href="https://github.com/ptrblck">@ptrblck</a> इन्हें बनाए रख रहे हैं।</p>
<h3>स्रोत से</h3>
<h4>पूर्वापेक्षाएँ</h4>
<p>यदि आप स्रोत से इंस्टॉल कर रहे हैं, तो आपको चाहिए:</p>
<ul>
<li>Python 3.9 या उसके बाद का संस्करण</li>
<li>एक कंपाइलर जो C++17 को पूरी तरह सपोर्ट करता हो, जैसे clang या gcc (Linux पर gcc 9.4.0 या नया आवश्यक है)</li>
<li>Visual Studio या Visual Studio Build Tool (केवल Windows के लिए)</li>
</ul>
<p>* PyTorch CI Visual C++ BuildTools का उपयोग करता है, जो Visual Studio Enterprise, Professional, या Community Editions के साथ आते हैं। आप इन्हें https://visualstudio.microsoft.com/visual-cpp-build-tools/ से भी इंस्टॉल कर सकते हैं। ये बिल्ड टूल्स डिफ़ॉल्ट रूप से Visual Studio Code के साथ नहीं आते।</p>
<p>पर्यावरण सेटअप का एक उदाहरण नीचे दिखाया गया है:</p>
<ul>
<li>Linux:</li>
</ul>
<pre><code class="language-bash">$ source &lt;CONDA_INSTALL_DIR&gt;/bin/activate
$ conda create -y -n &lt;CONDA_NAME&gt;
$ conda activate &lt;CONDA_NAME&gt;
</code></pre>
<ul>
<li>Windows:</li>
</ul>
<pre><code class="language-bash">$ source &lt;CONDA_INSTALL_DIR&gt;\Scripts\activate.bat
$ conda create -y -n &lt;CONDA_NAME&gt;
$ conda activate &lt;CONDA_NAME&gt;
$ call &quot;C:\Program Files\Microsoft Visual Studio\&lt;VERSION&gt;\Community\VC\Auxiliary\Build\vcvarsall.bat&quot; x64
</code></pre>
<h5>NVIDIA CUDA सपोर्ट</h5>
<p>यदि आप CUDA सपोर्ट के साथ कंपाइल करना चाहते हैं, तो <a href="https://pytorch.org/get-started/locally/">हमारे सपोर्ट मैट्रिक्स से CUDA का सपोर्टेड वर्शन चुनें</a>, फिर निम्नलिखित इंस्टॉल करें:</p>
<ul>
<li><a href="https://developer.nvidia.com/cuda-downloads">NVIDIA CUDA</a></li>
<li><a href="https://developer.nvidia.com/cudnn">NVIDIA cuDNN</a> v8.5 या ऊपर</li>
<li><a href="https://gist.github.com/ax3l/9489132">Compiler</a> जो CUDA के साथ संगत हो</li>
</ul>
<p>नोट: आप <a href="https://docs.nvidia.com/deeplearning/cudnn/backend/latest/reference/support-matrix.html">cuDNN Support Matrix</a> में विभिन्न CUDA, CUDA ड्राइवर और NVIDIA हार्डवेयर के साथ cuDNN के वर्शन देख सकते हैं।</p>
<p>यदि आप CUDA सपोर्ट को निष्क्रिय करना चाहते हैं, तो पर्यावरण वेरिएबल <code>USE_CUDA=0</code> एक्सपोर्ट करें।
अन्य उपयोगी पर्यावरण वेरिएबल्स <code>setup.py</code> में पाए जा सकते हैं।</p>
<p>यदि आप NVIDIA के Jetson प्लेटफॉर्म्स (Jetson Nano, TX1, TX2, AGX Xavier) के लिए बना रहे हैं, तो Jetson Nano के लिए PyTorch इंस्टॉल करने के निर्देश <a href="https://devtalk.nvidia.com/default/topic/1049071/jetson-nano/pytorch-for-jetson-nano/">यहाँ उपलब्ध हैं</a></p>
<h5>AMD ROCm सपोर्ट</h5>
<p>यदि आप ROCm सपोर्ट के साथ कंपाइल करना चाहते हैं, तो इंस्टॉल करें</p>
<ul>
<li><a href="https://rocm.docs.amd.com/en/latest/deploy/linux/quick_start.html">AMD ROCm</a> 4.0 और ऊपर</li>
<li>ROCm फिलहाल केवल Linux सिस्टम के लिए सपोर्टेड है।</li>
</ul>
<p>डिफ़ॉल्ट रूप से बिल्ड सिस्टम <code>/opt/rocm</code> में ROCm की अपेक्षा करता है। यदि ROCm किसी अन्य डायरेक्टरी में इंस्टॉल है, तो <code>ROCM_PATH</code> पर्यावरण वेरिएबल को ROCm इंस्टॉलेशन डायरेक्टरी पर सेट करना होगा। बिल्ड सिस्टम स्वचालित रूप से AMD GPU आर्किटेक्चर का पता लगाता है। वैकल्पिक रूप से, AMD GPU आर्किटेक्चर को <code>PYTORCH_ROCM_ARCH</code> पर्यावरण वेरिएबल से स्पष्ट रूप से सेट किया जा सकता है <a href="https://rocm.docs.amd.com/projects/install-on-linux/en/latest/reference/system-requirements.html#supported-gpus">AMD GPU आर्किटेक्चर</a></p>
<p>यदि आप ROCm सपोर्ट को निष्क्रिय करना चाहते हैं, तो पर्यावरण वेरिएबल <code>USE_ROCM=0</code> एक्सपोर्ट करें।
अन्य उपयोगी पर्यावरण वेरिएबल्स <code>setup.py</code> में पाए जा सकते हैं।</p>
<h5>Intel GPU सपोर्ट</h5>
<p>यदि आप Intel GPU सपोर्ट के साथ कंपाइल करना चाहते हैं, तो</p>
<ul>
<li><a href="https://www.intel.com/content/www/us/en/developer/articles/tool/pytorch-prerequisites-for-intel-gpus.html">PyTorch Prerequisites for Intel GPUs</a> के निर्देशों का पालन करें।</li>
<li>Intel GPU Linux और Windows के लिए सपोर्टेड है।</li>
</ul>
<p>यदि आप Intel GPU सपोर्ट को निष्क्रिय करना चाहते हैं, तो पर्यावरण वेरिएबल <code>USE_XPU=0</code> एक्सपोर्ट करें।
अन्य उपयोगी पर्यावरण वेरिएबल्स <code>setup.py</code> में पाए जा सकते हैं।</p>
<h4>PyTorch स्रोत प्राप्त करें</h4>
<pre><code class="language-bash">git clone https://github.com/pytorch/pytorch
cd pytorch
# यदि आप मौजूदा चेकआउट अपडेट कर रहे हैं
git submodule sync
git submodule update --init --recursive
</code></pre>
<h4>डिपेंडेंसीज़ इंस्टॉल करें</h4>
<p><strong>सामान्य</strong></p>
<pre><code class="language-bash">conda install cmake ninja
# नीचे दिए &quot;PyTorch स्रोत प्राप्त करें&quot; अनुभाग का उपयोग करके सोर्स कोड क्लोन करने के बाद, इस कमांड को PyTorch डायरेक्टरी से चलाएँ
pip install -r requirements.txt
</code></pre>
<p><strong>Linux पर</strong></p>
<pre><code class="language-bash">pip install mkl-static mkl-include
# केवल CUDA: यदि आवश्यकता हो तो GPU के लिए LAPACK सपोर्ट जोड़ें
# magma इंस्टॉलेशन: एक्टिव conda एनवायरनमेंट के साथ चलाएँ। इंस्टॉल करने के लिए CUDA वर्शन निर्दिष्ट करें
.ci/docker/common/install_magma_conda.sh 12.4

# (वैकल्पिक) यदि torch.compile का उपयोग inductor/triton के साथ कर रहे हैं, तो मेल खाती triton वर्शन इंस्टॉल करें
# क्लोन करने के बाद pytorch डायरेक्टरी से चलाएँ
# Intel GPU सपोर्ट के लिए, कृपया कमांड चलाने से पहले स्पष्ट रूप से `export USE_XPU=1` करें।
make triton
</code></pre>
<p><strong>MacOS पर</strong></p>
<pre><code class="language-bash"># केवल Intel x86 प्रोसेसर मशीनों पर इस पैकेज को जोड़ें
pip install mkl-static mkl-include
# यदि torch.distributed की आवश्यकता है तो ये पैकेज जोड़ें
conda install pkg-config libuv
</code></pre>
<p><strong>Windows पर</strong></p>
<pre><code class="language-bash">pip install mkl-static mkl-include
# यदि torch.distributed की आवश्यकता है तो ये पैकेज जोड़ें।
# Windows पर Distributed पैकेज सपोर्ट प्रोटोटाइप फीचर है और परिवर्तन के अधीन है।
conda install -c conda-forge libuv=1.39
</code></pre>
<h4>PyTorch इंस्टॉल करें</h4>
<p><strong>Linux पर</strong></p>
<p>यदि आप AMD ROCm के लिए कंपाइल कर रहे हैं तो पहले यह कमांड चलाएँ:</p>
<pre><code class="language-bash"># केवल ROCm के लिए कंपाइल कर रहे हैं तो चलाएँ
python tools/amd_build/build_amd.py
</code></pre>
<p>PyTorch इंस्टॉल करें</p>
<pre><code class="language-bash">export CMAKE_PREFIX_PATH=&quot;${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}&quot;
python setup.py develop
</code></pre>
<p><strong>macOS पर</strong></p>
<pre><code class="language-bash">python3 setup.py develop
</code></pre>
<p><strong>Windows पर</strong></p>
<p>यदि आप पुराने python कोड के लिए बिल्ड करना चाहते हैं, तो कृपया <a href="https://github.com/pytorch/pytorch/blob/main/CONTRIBUTING.md#building-on-legacy-code-and-cuda">Building on legacy code and CUDA</a> देखें</p>
<p><strong>केवल CPU-बिल्ड</strong></p>
<p>इस मोड में PyTorch की गणनाएँ आपके CPU पर चलेंगी, GPU पर नहीं।</p>
<pre><code class="language-cmd">python setup.py develop
</code></pre>
<p>OpenMP नोट: वांछित OpenMP इम्प्लीमेंटेशन Intel OpenMP (iomp) है। iomp के खिलाफ लिंक करने के लिए, आपको लाइब्रेरी को मैन्युअली डाउनलोड करना और बिल्डिंग एनवायरनमेंट सेटअप करना होगा, <code>CMAKE_INCLUDE_PATH</code> और <code>LIB</code> को समायोजित करके। <a href="https://github.com/pytorch/pytorch/blob/main/docs/source/notes/windows.rst#building-from-source">यहाँ</a> एक उदाहरण है। CMake के लिए इन कॉन्फ़िगरेशन के बिना, Microsoft Visual C OpenMP रनटाइम (vcomp) का उपयोग होगा।</p>
<p><strong>CUDA आधारित बिल्ड</strong></p>
<p>इस मोड में PyTorch की गणनाएँ आपके GPU का उपयोग CUDA के माध्यम से तेज़ी से करेंगी</p>
<p><a href="https://docs.nvidia.com/gameworks/content/gameworkslibrary/nvtx/nvidia_tools_extension_library_nvtx.htm">NVTX</a> आवश्यक है।
NVTX, CUDA डिस्ट्रीब्यूशन का हिस्सा है, जहाँ इसे &quot;Nsight Compute&quot; कहा जाता है। इंस्टॉल करने के लिए, CUDA इंस्टॉलेशन को फिर से चलाएँ और उपयुक्त चेकबॉक्स चुनें।
सुनिश्चित करें कि Nsight Compute के साथ CUDA Visual Studio के बाद इंस्टॉल हो।</p>
<p>फिलहाल, VS 2017/2019, और Ninja CMake के जेनरेटर के रूप में सपोर्टेड हैं। यदि <code>ninja.exe</code> <code>PATH</code> में है, तो Ninja डिफ़ॉल्ट जेनरेटर होगा, अन्यथा VS 2017/2019।
<br/> यदि Ninja चुना जाता है, तो नवीनतम MSVC टूलचेन चुना जाएगा।</p>
<p>अतिरिक्त लाइब्रेरीज़ जैसे
<a href="https://developer.nvidia.com/magma">Magma</a>, <a href="https://github.com/oneapi-src/oneDNN">oneDNN, जिसे MKLDNN या DNNL भी कहते हैं</a>, और <a href="https://github.com/mozilla/sccache">Sccache</a> अक्सर जरूरी होती हैं। कृपया <a href="https://github.com/pytorch/pytorch/tree/main/.ci/pytorch/win-test-helpers/installation-helpers">installation-helper</a> देखें।</p>
<p>आप कुछ अन्य पर्यावरण वेरिएबल्स कॉन्फ़िगरेशन के लिए <a href="https://github.com/pytorch/pytorch/blob/main/.ci/pytorch/win-test-helpers/build_pytorch.bat">build_pytorch.bat</a> स्क्रिप्ट भी देख सकते हैं।</p>
<pre><code class="language-cmd">cmd

:: mkl पैकेज डाउनलोड और अनज़िप करने के बाद पर्यावरण वेरिएबल्स सेट करें,
:: अन्यथा CMake `Could NOT find OpenMP` त्रुटि देगा।
set CMAKE_INCLUDE_PATH={Your directory}\mkl\include
set LIB={Your directory}\mkl\lib;%LIB%

:: पिछले अनुभाग की सामग्री ध्यान से पढ़ें।
:: [वैकल्पिक] यदि आप Ninja और Visual Studio के साथ CUDA के लिए टूलसेट ओवरराइड करना चाहते हैं, तो निम्नलिखित स्क्रिप्ट ब्लॉक चलाएँ।
:: &quot;Visual Studio 2019 Developer Command Prompt&quot; स्वतः चलाया जाएगा।
:: Visual Studio जेनरेटर का उपयोग करते समय सुनिश्चित करें कि आपके पास CMake &gt;= 3.12 है।
set CMAKE_GENERATOR_TOOLSET_VERSION=14.27
set DISTUTILS_USE_SDK=1
for /f &quot;usebackq tokens=*&quot; %i in (`&quot;%ProgramFiles(x86)%\Microsoft Visual Studio\Installer\vswhere.exe&quot; -version [15^,17^) -products * -latest -property installationPath`) do call &quot;%i\VC\Auxiliary\Build\vcvarsall.bat&quot; x64 -vcvars_ver=%CMAKE_GENERATOR_TOOLSET_VERSION%

:: [वैकल्पिक] यदि आप CUDA होस्ट कंपाइलर ओवरराइड करना चाहते हैं
set CUDAHOSTCXX=C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.27.29110\bin\HostX64\x64\cl.exe

python setup.py develop

</code></pre>
<p><strong>Intel GPU बिल्ड्स</strong></p>
<p>इस मोड में Intel GPU सपोर्ट के साथ PyTorch बनेगा।</p>
<p>कृपया सुनिश्चित करें कि <a href="#prerequisites">आम पूर्वापेक्षाएँ</a> और <a href="#intel-gpu-support">Intel GPU के लिए पूर्वापेक्षाएँ</a> ठीक से इंस्टॉल हैं और पर्यावरण वेरिएबल्स कॉन्फ़िगर किए गए हैं। बिल्ड टूल सपोर्ट के लिए, <code>Visual Studio 2022</code> आवश्यक है।</p>
<p>फिर PyTorch निम्न कमांड से बनाया जा सकता है:</p>
<pre><code class="language-cmd">:: CMD Commands:
:: संबंधित पैकेज खोजने में सहायता के लिए CMAKE_PREFIX_PATH सेट करें
:: %CONDA_PREFIX% केवल `conda activate custom_env` के बाद काम करता है

if defined CMAKE_PREFIX_PATH (
    set &quot;CMAKE_PREFIX_PATH=%CONDA_PREFIX%\Library;%CMAKE_PREFIX_PATH%&quot;
) else (
    set &quot;CMAKE_PREFIX_PATH=%CONDA_PREFIX%\Library&quot;
)

python setup.py develop
</code></pre>
<h5>बिल्ड विकल्प समायोजित करें (वैकल्पिक)</h5>
<p>आप cmake वेरिएबल्स की कॉन्फ़िगरेशन को वैकल्पिक रूप से (पहले बनाए बिना) समायोजित कर सकते हैं। उदाहरण के लिए, CuDNN या BLAS के पूर्व-निर्धारित डिरेक्ट्रीज को समायोजित करना इस तरह किया जा सकता है।</p>
<p>Linux पर</p>
<pre><code class="language-bash">export CMAKE_PREFIX_PATH=&quot;${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}&quot;
python setup.py build --cmake-only
ccmake build  # या cmake-gui build
</code></pre>
<p>macOS पर</p>
<pre><code class="language-bash">export CMAKE_PREFIX_PATH=&quot;${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}&quot;
MACOSX_DEPLOYMENT_TARGET=10.9 CC=clang CXX=clang++ python setup.py build --cmake-only
ccmake build  # या cmake-gui build
</code></pre>
<h3>डॉकर इमेज</h3>
<h4>पूर्व-निर्मित इमेजेस का उपयोग करना</h4>
<p>आप Docker Hub से पूर्व-निर्मित डॉकर इमेज भी खींच सकते हैं और docker v19.03+ के साथ चला सकते हैं</p>
<pre><code class="language-bash">docker run --gpus all --rm -ti --ipc=host pytorch/pytorch:latest
</code></pre>
<p>कृपया ध्यान दें कि PyTorch डेटा साझा करने के लिए साझा मेमोरी का उपयोग करता है, इसलिए यदि torch मल्टीप्रोसेसिंग का उपयोग किया जाता है (जैसे मल्टीथ्रेडेड डेटा लोडर्स के लिए) तो कंटेनर के साथ चलने वाला डिफ़ॉल्ट साझा मेमोरी खंड आकार पर्याप्त नहीं है, और आपको साझा मेमोरी आकार या तो <code>--ipc=host</code> या <code>--shm-size</code> कमांड लाइन विकल्पों के साथ बढ़ाना चाहिए।</p>
<h4>इमेज को स्वयं बनाना</h4>
<p><strong>नोट:</strong> डॉकर वर्शन &gt; 18.06 के साथ बनाना आवश्यक है</p>
<p><code>Dockerfile</code> CUDA 11.1 सपोर्ट और cuDNN v8 के साथ इमेज बनाने के लिए दिया गया है।
आप <code>PYTHON_VERSION=x.y</code> make वेरिएबल पास कर सकते हैं, जिससे Miniconda द्वारा उपयोग किए जाने वाले Python वर्शन को निर्दिष्ट किया जा सकता है, या डिफ़ॉल्ट वर्शन का उपयोग किया जा सकता है।</p>
<pre><code class="language-bash">make -f docker.Makefile
# images टैग किए जाते हैं docker.io/${your_docker_username}/pytorch के रूप में
</code></pre>
<p>आप <code>CMAKE_VARS=&quot;...&quot;</code> पर्यावरण वेरिएबल भी पास कर सकते हैं, जिससे बिल्ड के दौरान CMake को अतिरिक्त वेरिएबल्स भेजी जा सकती हैं।
<a href="./setup.py">setup.py</a> में उपलब्ध वेरिएबल्स की सूची देखें।</p>
<pre><code class="language-bash">make -f docker.Makefile
</code></pre>
<h3>डॉक्यूमेंटेशन बनाना</h3>
<p>विभिन्न स्वरूपों में डॉक्यूमेंटेशन बनाने के लिए, आपको <a href="http://www.sphinx-doc.org">Sphinx</a>
और pytorch_sphinx_theme2 की आवश्यकता होगी।</p>
<p>स्थानीय रूप से डॉक्यूमेंटेशन बनाने से पहले, सुनिश्चित करें कि आपके पर्यावरण में <code>torch</code>
इंस्टॉल है। छोटे फिक्सेस के लिए, आप <a href="https://pytorch.org/get-started/locally/">Getting Started</a> में वर्णित nightly वर्शन इंस्टॉल कर सकते हैं।</p>
<p>अधिक जटिल फिक्सेस के लिए, जैसे एक नया मॉड्यूल और उसके लिए docstrings जोड़ना, आपको torch <a href="#from-source">स्रोत से</a> इंस्टॉल करना पड़ सकता है।
<a href="https://github.com/pytorch/pytorch/wiki/Docstring-Guidelines">Docstring Guidelines</a>
भी देखें।</p>
<pre><code class="language-bash">cd docs/
pip install -r requirements.txt
make html
make serve
</code></pre>
<p>सभी उपलब्ध आउटपुट स्वरूपों की सूची के लिए <code>make</code> चलाएँ।</p>
<p>यदि आपको katex त्रुटि मिले तो <code>npm install katex</code> चलाएँ। यदि समस्या बनी रहती है, तो
<code>npm install -g katex</code> आज़माएँ</p>
<blockquote>
<p>[!NOTE]
यदि आपने <code>nodejs</code> किसी अन्य पैकेज मैनेजर (जैसे,
<code>conda</code>) से इंस्टॉल किया है, तो <code>npm</code> संभवतः <code>katex</code> का ऐसा वर्शन इंस्टॉल करेगा जो आपके nodejs वर्शन के अनुकूल नहीं है और डॉक्यूमेंटेशन बिल्ड विफल हो जाएगा।
एक ज्ञात कार्यशील वर्शन संयोजन है <code>node@6.13.1</code> और
<code>katex@0.13.18</code>। बाद वाले को <code>npm</code> से इंस्टॉल करने के लिए
<code>npm install -g katex@0.13.18</code></p>
</blockquote>
<blockquote>
<p>[!NOTE]
यदि आपको numpy असंगति त्रुटि मिले, तो चलाएँ:</p>
<pre><code>pip install 'numpy&lt;2'
</code></pre>
</blockquote>
<p>जब आप CI द्वारा चलाए जाने वाली डिपेंडेंसीज़ बदलें, <code>.ci/docker/requirements-docs.txt</code> फ़ाइल संपादित करें।</p>
<h4>PDF बनाना</h4>
<p>सभी PyTorch डॉक्यूमेंटेशन का PDF बनाने के लिए, सुनिश्चित करें कि आपके पास
<code>texlive</code> और LaTeX इंस्टॉल है। macOS पर, आप इन्हें इस प्रकार इंस्टॉल कर सकते हैं:</p>
<pre><code>brew install --cask mactex
</code></pre>
<p>PDF बनाने के लिए:</p>
<ol>
<li><p>चलाएँ:</p>
<pre><code>make latexpdf
</code></pre>
<p>इससे <code>build/latex</code> डिरेक्टरी में आवश्यक फाइलें बनेंगी।</p>
</li>
<li><p>इस डिरेक्टरी में जाएँ और चलाएँ:</p>
<pre><code>make LATEXOPTS=&quot;-interaction=nonstopmode&quot;
</code></pre>
<p>इससे वांछित सामग्री के साथ <code>pytorch.pdf</code> बनेगा। सही table of contents और index के लिए यह कमांड एक बार और चलाएँ।</p>
</li>
</ol>
<blockquote>
<p>[!NOTE]
Table of Contents देखने के लिए, अपने PDF viewer में <strong>Table of Contents</strong>
दृश्य पर जाएँ।</p>
</blockquote>
<h3>पिछले संस्करण</h3>
<p>पिछले PyTorch संस्करणों के इंस्टॉलेशन निर्देश और बाइनरीज़
<a href="https://pytorch.org/get-started/previous-versions">हमारी वेबसाइट</a> पर मिल सकते हैं।</p>
<h2>शुरुआत करना</h2>
<p>शुरुआत के लिए तीन सूत्र:</p>
<ul>
<li><a href="https://pytorch.org/tutorials/">ट्यूटोरियल: PyTorch को समझने और उपयोग करने के लिए</a></li>
<li><a href="https://github.com/pytorch/examples">उदाहरण: सभी डोमेन के लिए आसान PyTorch कोड</a></li>
<li><a href="https://pytorch.org/docs/">API संदर्भ</a></li>
<li><a href="https://github.com/pytorch/pytorch/blob/main/GLOSSARY.md">शब्दावली</a></li>
</ul>
<h2>संसाधन</h2>
<ul>
<li><a href="https://pytorch.org/">PyTorch.org</a></li>
<li><a href="https://pytorch.org/tutorials/">PyTorch ट्यूटोरियल्स</a></li>
<li><a href="https://github.com/pytorch/examples">PyTorch उदाहरण</a></li>
<li><a href="https://pytorch.org/hub/">PyTorch मॉडल</a></li>
<li><a href="https://www.udacity.com/course/deep-learning-pytorch--ud188">Udacity से PyTorch के साथ डीप लर्निंग का परिचय</a></li>
<li><a href="https://www.udacity.com/course/intro-to-machine-learning-nanodegree--nd229">Udacity से PyTorch के साथ मशीन लर्निंग का परिचय</a></li>
<li><a href="https://www.coursera.org/learn/deep-neural-networks-with-pytorch">Coursera से PyTorch के साथ डीप न्यूरल नेटवर्क्स</a></li>
<li><a href="https://twitter.com/PyTorch">PyTorch Twitter</a></li>
<li><a href="https://pytorch.org/blog/">PyTorch ब्लॉग</a></li>
<li><a href="https://www.youtube.com/channel/UCWXI5YeOsh03QvJ59PMaXFw">PyTorch YouTube</a></li>
</ul>
<h2>संचार</h2>
<ul>
<li>फोरम: कार्यान्वयन, शोध आदि पर चर्चा करें। https://discuss.pytorch.org</li>
<li>GitHub Issues: बग रिपोर्ट, फीचर अनुरोध, इंस्टॉल समस्याएँ, RFCs, विचार आदि।</li>
<li>Slack: <a href="https://pytorch.slack.com/">PyTorch Slack</a> मुख्य रूप से मध्यम से अनुभवी PyTorch उपयोगकर्ताओं और डेवलपर्स के लिए सामान्य चैट, ऑनलाइन चर्चाएँ, सहयोग आदि के लिए है। यदि आप शुरुआती हैं, तो <a href="https://discuss.pytorch.org">PyTorch Forums</a> प्राथमिक माध्यम है। यदि आपको Slack निमंत्रण चाहिए, तो कृपया यह फॉर्म भरें: https://goo.gl/forms/PP1AGvNHpSaJP8to1</li>
<li>न्यूज़लेटर: बिना शोर-शराबे के, एकतरफा ईमेल न्यूज़लेटर जिसमें PyTorch के बारे में महत्वपूर्ण घोषणाएँ होती हैं। आप यहाँ साइन-अप कर सकते हैं: https://eepurl.com/cbG0rv</li>
<li>Facebook पेज: PyTorch के बारे में महत्वपूर्ण घोषणाएँ। https://www.facebook.com/pytorch</li>
<li>ब्रांड गाइडलाइंस के लिए, कृपया हमारी वेबसाइट देखें <a href="https://pytorch.org/">pytorch.org</a></li>
</ul>
<h2>रिलीज़ और योगदान</h2>
<p>आम तौर पर, PyTorch का साल में तीन बार माइनर रिलीज़ होता है। यदि आपको कोई बग मिलता है तो कृपया <a href="https://github.com/pytorch/pytorch/issues">issue दर्ज करें</a>।</p>
<p>हम सभी योगदानों की सराहना करते हैं। यदि आप बग-फिक्सेस वापस योगदान करना चाहते हैं, तो कृपया बिना किसी अतिरिक्त चर्चा के ऐसा करें।</p>
<p>यदि आप नई विशेषताएँ, यूटिलिटी फंक्शन या कोर के लिए एक्सटेंशन योगदान करना चाहते हैं, तो पहले एक issue खोलें और हमारे साथ चर्चा करें।
बिना चर्चा के PR भेजना अस्वीकार किए गए PR में बदल सकता है क्योंकि हो सकता है कि हम कोर को उस दिशा में न ले जा रहे हों, जिसकी आपको जानकारी न हो।</p>
<p>PyTorch में योगदान के बारे में अधिक जानने के लिए, कृपया हमारा <a href="CONTRIBUTING.md">Contribution page</a> देखें। PyTorch रिलीज़ के बारे में अधिक जानकारी के लिए <a href="RELEASE.md">Release page</a> देखें।</p>
<h2>टीम</h2>
<p>PyTorch एक समुदाय-आधारित प्रोजेक्ट है जिसमें कई कुशल इंजीनियर और शोधकर्ता योगदान देते हैं।</p>
<p>PyTorch वर्तमान में <a href="http://soumith.ch">Soumith Chintala</a>, <a href="https://github.com/gchanan">Gregory Chanan</a>, <a href="https://github.com/dzhulgakov">Dmytro Dzhulgakov</a>, <a href="https://github.com/ezyang">Edward Yang</a>, और <a href="https://github.com/malfet">Nikita Shulga</a> द्वारा मेंटेन किया जाता है, और सैकड़ों प्रतिभाशाली व्यक्तियों से प्रमुख योगदान आते हैं।
एक अपूर्ण लेकिन बढ़ती सूची में उल्लेखनीय हैं: <a href="https://github.com/killeent">Trevor Killeen</a>, <a href="https://github.com/chsasank">Sasank Chilamkurthy</a>, <a href="https://github.com/szagoruyko">Sergey Zagoruyko</a>, <a href="https://github.com/adamlerer">Adam Lerer</a>, <a href="https://github.com/fmassa">Francisco Massa</a>, <a href="https://github.com/alykhantejani">Alykhan Tejani</a>, <a href="https://github.com/lantiga">Luca Antiga</a>, <a href="https://github.com/albanD">Alban Desmaison</a>, <a href="https://github.com/andreaskoepf">Andreas Koepf</a>, <a href="https://github.com/jekbradbury">James Bradbury</a>, <a href="https://github.com/ebetica">Zeming Lin</a>, <a href="https://github.com/yuandong-tian">Yuandong Tian</a>, <a href="https://github.com/glample">Guillaume Lample</a>, <a href="https://github.com/Maratyszcza">Marat Dukhan</a>, <a href="https://github.com/ngimel">Natalia Gimelshein</a>, <a href="https://github.com/csarofeen">Christian Sarofeen</a>, <a href="https://github.com/martinraison">Martin Raison</a>, <a href="https://github.com/ezyang">Edward Yang</a>, <a href="https://github.com/zdevito">Zachary Devito</a>।</p>
<p>नोट: यह प्रोजेक्ट <a href="https://github.com/hughperkins/pytorch">hughperkins/pytorch</a> से असंबंधित है, जिसका नाम वही है। Hugh Torch समुदाय के एक मूल्यवान योगदानकर्ता हैं और उन्होंने Torch और PyTorch के लिए कई चीजों में मदद की है।</p>
<h2>लाइसेंस</h2>
<p>PyTorch में BSD-शैली का लाइसेंस है, जैसा कि <a href="LICENSE">LICENSE</a> फ़ाइल में पाया गया है।</p>
<hr />
<p><a href="https://github.com/OpenAiTx/OpenAiTx">Powered By OpenAiTx</a></p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
</body>
</html>