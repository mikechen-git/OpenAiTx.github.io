<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>pytorch - pytorch/pytorch zh-TW</title>
    <meta name="title" content="pytorch - pytorch/pytorch zh-TW | PyTorch 是一個 Python 套件，提供兩個高階功能： 張量運算（類似 NumPy），具有強大的 GPU 加速能力 基於 tape-based 自動微分系統構建的深度神經網路 你可以在需要時重複利用你喜愛的 Python 套件，如 NumPy、SciPy 和 Cython 來擴展 PyTorch。 我們的主幹健...">
    <meta name="description" content="pytorch/pytorch - GitHub repository zh-TW documentation and information | PyTorch 是一個 Python 套件，提供兩個高階功能： 張量運算（類似 NumPy），具有強大的 GPU 加速能力 基於 tape-based 自動微分系統構建的深度神經網路 你可以在需要時重複利用你喜愛的 Python 套件，如 NumPy、SciPy 和 Cython 來擴展 PyTorch。 我們的主幹健...">
    <meta name="keywords" content="pytorch, pytorch, GitHub, repository, zh-TW documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/pytorch/pytorch/README-zh-TW.html">
    <meta property="og:title" content="pytorch - pytorch/pytorch zh-TW | PyTorch 是一個 Python 套件，提供兩個高階功能： 張量運算（類似 NumPy），具有強大的 GPU 加速能力 基於 tape-based 自動微分系統構建的深度神經網路 你可以在需要時重複利用你喜愛的 Python 套件，如 NumPy、SciPy 和 Cython 來擴展 PyTorch。 我們的主幹健...">
    <meta property="og:description" content="pytorch/pytorch - GitHub repository zh-TW documentation and information | PyTorch 是一個 Python 套件，提供兩個高階功能： 張量運算（類似 NumPy），具有強大的 GPU 加速能力 基於 tape-based 自動微分系統構建的深度神經網路 你可以在需要時重複利用你喜愛的 Python 套件，如 NumPy、SciPy 和 Cython 來擴展 PyTorch。 我們的主幹健...">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/pytorch/pytorch" id="githubRepoLink" target="_blank">pytorch/pytorch</a>
<h1 style="display: none;">PyTorch 是一個 Python 套件，提供兩個高階功能： 張量運算（類似 NumPy），具有強大的 GPU 加速能力 基於 tape-based 自動微分系統構建的深度神經網路 你可以在需要時重複利用你喜愛的 Python 套件，如 NumPy、SciPy 和 Cython 來擴展 PyTorch。 我們的主幹健...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <p><img src="https://github.com/pytorch/pytorch/raw/main/docs/source/_static/img/pytorch-logo-dark.png" alt="PyTorch Logo" /></p>
<hr />
<p>PyTorch 是一個 Python 套件，提供兩個高階功能：</p>
<ul>
<li>張量運算（類似 NumPy），具有強大的 GPU 加速能力</li>
<li>基於 tape-based 自動微分系統構建的深度神經網路</li>
</ul>
<p>你可以在需要時重複利用你喜愛的 Python 套件，如 NumPy、SciPy 和 Cython 來擴展 PyTorch。</p>
<p>我們的主幹健康狀態（持續整合訊號）可在 <a href="https://hud.pytorch.org/ci/pytorch/pytorch/main">hud.pytorch.org</a> 查詢。</p>
<!-- toc -->
<ul>
<li><a href="#more-about-pytorch">更多關於 PyTorch</a>
<ul>
<li><a href="#a-gpu-ready-tensor-library">支援 GPU 的張量函式庫</a></li>
<li><a href="#dynamic-neural-networks-tape-based-autograd">動態神經網路：基於 Tape 的自動微分</a></li>
<li><a href="#python-first">以 Python 為核心</a></li>
<li><a href="#imperative-experiences">命令式體驗</a></li>
<li><a href="#fast-and-lean">快速精簡</a></li>
<li><a href="#extensions-without-pain">輕鬆擴充</a></li>
</ul>
</li>
<li><a href="#installation">安裝</a>
<ul>
<li><a href="#binaries">二進位檔</a>
<ul>
<li><a href="#nvidia-jetson-platforms">NVIDIA Jetson 平台</a></li>
</ul>
</li>
<li><a href="#from-source">由原始碼安裝</a>
<ul>
<li><a href="#prerequisites">先決條件</a>
<ul>
<li><a href="#nvidia-cuda-support">NVIDIA CUDA 支援</a></li>
<li><a href="#amd-rocm-support">AMD ROCm 支援</a></li>
<li><a href="#intel-gpu-support">Intel GPU 支援</a></li>
</ul>
</li>
<li><a href="#get-the-pytorch-source">取得 PyTorch 原始碼</a></li>
<li><a href="#install-dependencies">安裝相依套件</a></li>
<li><a href="#install-pytorch">安裝 PyTorch</a>
<ul>
<li><a href="#adjust-build-options-optional">調整編譯選項（可選）</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#docker-image">Docker 映像檔</a>
<ul>
<li><a href="#using-pre-built-images">使用預建映像檔</a></li>
<li><a href="#building-the-image-yourself">自行構建映像檔</a></li>
</ul>
</li>
<li><a href="#building-the-documentation">構建文件</a>
<ul>
<li><a href="#building-a-pdf">產生 PDF</a></li>
</ul>
</li>
<li><a href="#previous-versions">舊版本</a></li>
</ul>
</li>
<li><a href="#getting-started">快速入門</a></li>
<li><a href="#resources">資源</a></li>
<li><a href="#communication">溝通</a></li>
<li><a href="#releases-and-contributing">發佈與貢獻</a></li>
<li><a href="#the-team">開發團隊</a></li>
<li><a href="#license">授權</a></li>
</ul>
<!-- tocstop -->
<h2>更多關於 PyTorch</h2>
<p><a href="https://pytorch.org/tutorials/beginner/basics/intro.html">學習 PyTorch 的基礎知識</a></p>
<p>從細節來看，PyTorch 是一個包含以下元件的函式庫：</p>
<p>| 元件 | 說明 |
| ---- | --- |
| <a href="https://pytorch.org/docs/stable/torch.html"><strong>torch</strong></a> | 類似 NumPy 的張量庫，具備強大的 GPU 支援 |
| <a href="https://pytorch.org/docs/stable/autograd.html"><strong>torch.autograd</strong></a> | 基於 tape 的自動微分函式庫，支援 torch 中所有可微分的張量操作 |
| <a href="https://pytorch.org/docs/stable/jit.html"><strong>torch.jit</strong></a> | 編譯堆疊（TorchScript），可從 PyTorch 程式碼創建可序列化、可優化的模型 |
| <a href="https://pytorch.org/docs/stable/nn.html"><strong>torch.nn</strong></a> | 深度整合自動微分的神經網路函式庫，設計上極具彈性 |
| <a href="https://pytorch.org/docs/stable/multiprocessing.html"><strong>torch.multiprocessing</strong></a> | Python 多進程，但能神奇地在進程間共享 torch 張量記憶體。適用於資料加載和 Hogwild 訓練 |
| <a href="https://pytorch.org/docs/stable/data.html"><strong>torch.utils</strong></a> | DataLoader 及其他方便的實用功能 |</p>
<p>通常，PyTorch 可用於：</p>
<ul>
<li>作為 NumPy 的替代品，發揮 GPU 的運算能力。</li>
<li>作為深度學習研究平台，提供最大彈性與速度。</li>
</ul>
<p>進一步說明：</p>
<h3>支援 GPU 的張量函式庫</h3>
<p>如果你用過 NumPy，就用過張量（即 ndarray）。</p>
<p><img src="./docs/source/_static/img/tensor_illustration.png" alt="Tensor illustration" /></p>
<p>PyTorch 提供可在 CPU 或 GPU 上運作的張量，大幅加速運算。</p>
<p>我們提供各種張量操作例程，滿足你的科學運算需求，如切片、索引、數學運算、線性代數、縮減等，
而且速度很快！</p>
<h3>動態神經網路：基於 Tape 的自動微分</h3>
<p>PyTorch 具有獨特的神經網路構建方式：使用並重播錄音帶。</p>
<p>大多數框架如 TensorFlow、Theano、Caffe 和 CNTK 都是靜態世界觀。
必須構建一個神經網路並反覆使用相同結構。
若要改變網路行為，必須從頭開始。</p>
<p>在 PyTorch 中，我們採用一種稱為反向模式自動微分的技術，讓你可以隨意改變網路行為，且無延遲或額外負擔。
我們的靈感來自多篇相關研究論文，以及 <a href="https://github.com/twitter/torch-autograd">torch-autograd</a>、<a href="https://github.com/HIPS/autograd">autograd</a>、<a href="https://chainer.org">Chainer</a> 等目前和過去的工作。</p>
<p>雖然這種技術並非 PyTorch 所獨有，但 PyTorch 是目前最快的實作之一。
你能同時獲得速度與彈性，適合大膽的研究探索。</p>
<p><img src="https://github.com/pytorch/pytorch/raw/main/docs/source/_static/img/dynamic_graph.gif" alt="Dynamic graph" /></p>
<h3>以 Python 為核心</h3>
<p>PyTorch 不是將 Python 綁定到龐大的 C++ 框架。
它設計上與 Python 深度整合。
你可以像使用 <a href="https://www.numpy.org/">NumPy</a> / <a href="https://www.scipy.org/">SciPy</a> / <a href="https://scikit-learn.org">scikit-learn</a> 那樣自然地使用它。
你可直接在 Python 中撰寫新神經網路層，結合你喜愛的函式庫，並利用 <a href="https://cython.org/">Cython</a> 和 <a href="http://numba.pydata.org/">Numba</a> 等套件。
我們的目標是在合適的地方不重造輪子。</p>
<h3>命令式體驗</h3>
<p>PyTorch 設計直觀、思路線性且易於使用。
你執行哪一行程式，哪一行就會被執行。沒有非同步的世界觀。
當你進入除錯器或收到錯誤訊息和堆疊追蹤時，理解起來很直接。
堆疊追蹤會指出你程式碼定義的確切位置。
我們希望你永遠不必因為糟糕的堆疊追蹤或非同步、晦澀的執行引擎而花數小時除錯。</p>
<h3>快速精簡</h3>
<p>PyTorch 框架開銷極小。我們整合了加速函式庫，如 <a href="https://software.intel.com/mkl">Intel MKL</a> 和 NVIDIA（<a href="https://developer.nvidia.com/cudnn">cuDNN</a>、<a href="https://developer.nvidia.com/nccl">NCCL</a>），以極大化速度。
其 CPU 與 GPU 張量及神經網路後端已成熟，並經多年測試。</p>
<p>因此，無論你運行大網路還是小網路，PyTorch 都非常快。</p>
<p>PyTorch 在記憶體使用上比 Torch 或其他替代方案更有效率。
我們為 GPU 撰寫了自訂記憶體配置器，確保你的深度學習模型最大化記憶體效率。
這讓你能訓練更大的深度學習模型。</p>
<h3>輕鬆擴充</h3>
<p>撰寫新神經網路模組，或與 PyTorch 的張量 API 介接，設計上都很直接，抽象層極少。</p>
<p>你可以直接用 torch API 在 Python 中撰寫新神經網路層，
<a href="https://pytorch.org/tutorials/advanced/numpy_extensions_tutorial.html">或你熟悉的基於 NumPy 的函式庫如 SciPy</a>。</p>
<p>若你想用 C/C++ 撰寫新層，我們也提供高效、極少樣板碼的擴充 API。
無需額外包裝程式碼。你可以參考<a href="https://pytorch.org/tutorials/advanced/cpp_extension.html">這裡的教學</a>和<a href="https://github.com/pytorch/extension-cpp">這裡的範例</a>。</p>
<h2>安裝</h2>
<h3>二進位檔</h3>
<p>透過 Conda 或 pip 安裝二進位檔的指令，請參見我們的網站：<a href="https://pytorch.org/get-started/locally/">https://pytorch.org/get-started/locally/</a></p>
<h4>NVIDIA Jetson 平台</h4>
<p>NVIDIA Jetson Nano、Jetson TX1/TX2、Jetson Xavier NX/AGX、Jetson AGX Orin 的 Python 安裝檔提供於<a href="https://forums.developer.nvidia.com/t/pytorch-for-jetson-version-1-10-now-available/72048">此處</a>，L4T 容器則發佈於<a href="https://catalog.ngc.nvidia.com/orgs/nvidia/containers/l4t-pytorch">此處</a></p>
<p>它們需要 JetPack 4.2 及以上版本，由 <a href="https://github.com/dusty-nv">@dusty-nv</a> 和 <a href="https://github.com/ptrblck">@ptrblck</a> 維護。</p>
<h3>由原始碼安裝</h3>
<h4>先決條件</h4>
<p>若你要從原始碼安裝，需準備：</p>
<ul>
<li>Python 3.9 或更高版本</li>
<li>完全支援 C++17 的編譯器，如 clang 或 gcc（Linux 上需 gcc 9.4.0 或以上）</li>
<li>Visual Studio 或 Visual Studio Build Tool（僅限 Windows）</li>
</ul>
<p>* PyTorch CI 使用 Visual C++ BuildTools，這些隨 Visual Studio Enterprise、Professional 或 Community 版提供。你也可從 https://visualstudio.microsoft.com/visual-cpp-build-tools/ 安裝建構工具。預設情況下，這些建構工具<em>不會</em>隨 Visual Studio Code 提供。</p>
<p>環境設置範例如下：</p>
<ul>
<li>Linux:</li>
</ul>
<pre><code class="language-bash">$ source &lt;CONDA_INSTALL_DIR&gt;/bin/activate
$ conda create -y -n &lt;CONDA_NAME&gt;
$ conda activate &lt;CONDA_NAME&gt;
</code></pre>
<ul>
<li>Windows:</li>
</ul>
<pre><code class="language-bash">$ source &lt;CONDA_INSTALL_DIR&gt;\Scripts\activate.bat
$ conda create -y -n &lt;CONDA_NAME&gt;
$ conda activate &lt;CONDA_NAME&gt;
$ call &quot;C:\Program Files\Microsoft Visual Studio\&lt;VERSION&gt;\Community\VC\Auxiliary\Build\vcvarsall.bat&quot; x64
</code></pre>
<h5>NVIDIA CUDA 支援</h5>
<p>若要支援 CUDA，<a href="https://pytorch.org/get-started/locally/">請由支援矩陣選擇合適版本的 CUDA</a>，然後安裝下列項目：</p>
<ul>
<li><a href="https://developer.nvidia.com/cuda-downloads">NVIDIA CUDA</a></li>
<li><a href="https://developer.nvidia.com/cudnn">NVIDIA cuDNN</a> v8.5 或以上</li>
<li><a href="https://gist.github.com/ax3l/9489132">與 CUDA 相容的編譯器</a></li>
</ul>
<p>註：你可參考 <a href="https://docs.nvidia.com/deeplearning/cudnn/backend/latest/reference/support-matrix.html">cuDNN 支援矩陣</a>，了解 cuDNN 與各種 CUDA、CUDA 驅動及 NVIDIA 硬體的對應版本。</p>
<p>若要關閉 CUDA 支援，請設定環境變數 <code>USE_CUDA=0</code>。
其他有用的環境變數可於 <code>setup.py</code> 查找。</p>
<p>若你在為 NVIDIA Jetson 平台（Jetson Nano、TX1、TX2、AGX Xavier）建構，Jetson Nano 的安裝指南可參考<a href="https://devtalk.nvidia.com/default/topic/1049071/jetson-nano/pytorch-for-jetson-nano/">這裡</a></p>
<h5>AMD ROCm 支援</h5>
<p>若要支援 ROCm，請安裝：</p>
<ul>
<li><a href="https://rocm.docs.amd.com/en/latest/deploy/linux/quick_start.html">AMD ROCm</a> 4.0 及以上版本</li>
<li>ROCm 目前僅支援 Linux 系統。</li>
</ul>
<p>預設建構系統會假設 ROCm 安裝於 <code>/opt/rocm</code>。若安裝於其他目錄，需設定 <code>ROCM_PATH</code> 環境變數指向該安裝目錄。建構系統會自動偵測 AMD GPU 架構。也可選擇以 <code>PYTORCH_ROCM_ARCH</code> 環境變數顯式指定 <a href="https://rocm.docs.amd.com/projects/install-on-linux/en/latest/reference/system-requirements.html#supported-gpus">AMD GPU 架構</a>。</p>
<p>若要關閉 ROCm 支援，請設定環境變數 <code>USE_ROCM=0</code>。
其他有用的環境變數可於 <code>setup.py</code> 查找。</p>
<h5>Intel GPU 支援</h5>
<p>若要支援 Intel GPU，請依照下列</p>
<ul>
<li><a href="https://www.intel.com/content/www/us/en/developer/articles/tool/pytorch-prerequisites-for-intel-gpus.html">Intel GPU 的 PyTorch 先決條件</a> 說明操作。</li>
<li>Intel GPU 支援 Linux 與 Windows。</li>
</ul>
<p>若要關閉 Intel GPU 支援，請設定環境變數 <code>USE_XPU=0</code>。
其他有用的環境變數可於 <code>setup.py</code> 查找。</p>
<h4>取得 PyTorch 原始碼</h4>
<pre><code class="language-bash">git clone https://github.com/pytorch/pytorch
cd pytorch
# 若為現有檢出進行更新
git submodule sync
git submodule update --init --recursive
</code></pre>
<h4>安裝相依套件</h4>
<p><strong>共用</strong></p>
<pre><code class="language-bash">conda install cmake ninja
# 請在從原始碼下載的 PyTorch 目錄下執行
pip install -r requirements.txt
</code></pre>
<p><strong>Linux 上</strong></p>
<pre><code class="language-bash">pip install mkl-static mkl-include
# 僅 CUDA：如需為 GPU 加入 LAPACK 支援
# 安裝 magma：需在已啟用 conda 環境下，指定 CUDA 版本
.ci/docker/common/install_magma_conda.sh 12.4

# （可選）若使用 torch.compile 搭配 inductor/triton，請安裝相符版本的 triton
# 請在 pytorch 目錄下執行
# 若支援 Intel GPU，請在執行前明確 `export USE_XPU=1`
make triton
</code></pre>
<p><strong>MacOS 上</strong></p>
<pre><code class="language-bash"># 僅於 intel x86 處理器機器需加裝此套件
pip install mkl-static mkl-include
# 若需 torch.distributed，請加裝以下套件
conda install pkg-config libuv
</code></pre>
<p><strong>Windows 上</strong></p>
<pre><code class="language-bash">pip install mkl-static mkl-include
# 若需 torch.distributed，請加裝以下套件
# Windows 上的 distributed package 支援屬原型功能，隨時可能變動
conda install -c conda-forge libuv=1.39
</code></pre>
<h4>安裝 PyTorch</h4>
<p><strong>Linux 上</strong></p>
<p>若為 AMD ROCm 編譯，先執行：</p>
<pre><code class="language-bash"># 僅 ROCm 編譯需執行
python tools/amd_build/build_amd.py
</code></pre>
<p>安裝 PyTorch</p>
<pre><code class="language-bash">export CMAKE_PREFIX_PATH=&quot;${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}&quot;
python setup.py develop
</code></pre>
<p><strong>macOS 上</strong></p>
<pre><code class="language-bash">python3 setup.py develop
</code></pre>
<p><strong>Windows 上</strong></p>
<p>若要建構 legacy python 程式碼，請參考 <a href="https://github.com/pytorch/pytorch/blob/main/CONTRIBUTING.md#building-on-legacy-code-and-cuda">Building on legacy code and CUDA</a></p>
<p><strong>僅 CPU 編譯</strong></p>
<p>此模式下，PyTorch 運算僅於 CPU 執行，不使用 GPU。</p>
<pre><code class="language-cmd">python setup.py develop
</code></pre>
<p>關於 OpenMP：建議使用 Intel OpenMP（iomp）。要連結 iomp，需手動下載函式庫並透過調整 <code>CMAKE_INCLUDE_PATH</code> 和 <code>LIB</code> 設定建構環境。相關設定說明可參考<a href="https://github.com/pytorch/pytorch/blob/main/docs/source/notes/windows.rst#building-from-source">這裡</a>（同時設置 MKL 與 Intel OpenMP）。若未配置，則預設會用 Microsoft Visual C OpenMP 執行階段（vcomp）。</p>
<p><strong>CUDA 編譯</strong></p>
<p>此模式下，PyTorch 運算將利用 GPU 的 CUDA 加速。</p>
<p><a href="https://docs.nvidia.com/gameworks/content/gameworkslibrary/nvtx/nvidia_tools_extension_library_nvtx.htm">Pytorch with CUDA 需 NVTX</a>。
NVTX 為 CUDA 發行包的一部分，稱為 &quot;Nsight Compute&quot;。若 CUDA 已安裝，需再次執行安裝並勾選相關選項。
確保 CUDA 及 Nsight Compute 安裝於 Visual Studio 之後。</p>
<p>目前 VS 2017 / 2019 與 Ninja 可作為 CMake 產生器。若 <code>PATH</code> 中偵測到 <code>ninja.exe</code>，預設會用 Ninja，否則用 VS 2017 / 2019。
<br/> 若選用 Ninja，則會自動選擇最新 MSVC 做為底層工具鏈。</p>
<p>常用額外函式庫如
<a href="https://developer.nvidia.com/magma">Magma</a>、<a href="https://github.com/oneapi-src/oneDNN">oneDNN, 又稱 MKLDNN 或 DNNL</a>、<a href="https://github.com/mozilla/sccache">Sccache</a> 等，請參考 <a href="https://github.com/pytorch/pytorch/tree/main/.ci/pytorch/win-test-helpers/installation-helpers">installation-helper</a> 安裝。</p>
<p>更多環境變數設定可參考 <a href="https://github.com/pytorch/pytorch/blob/main/.ci/pytorch/win-test-helpers/build_pytorch.bat">build_pytorch.bat</a> 腳本。</p>
<pre><code class="language-cmd">cmd

:: 下載並解壓 mkl 套件後，設定環境變數，否則 CMake 會報錯 `Could NOT find OpenMP`
set CMAKE_INCLUDE_PATH={Your directory}\mkl\include
set LIB={Your directory}\mkl\lib;%LIB%

:: 請仔細閱讀上述內容再繼續
:: [可選] 若要覆蓋 Ninja 與 Visual Studio 所用底層工具鏈，請執行下列指令
:: &quot;Visual Studio 2019 Developer Command Prompt&quot; 會自動開啟。
:: 若用 Visual Studio 產生器，請確保 CMake &gt;= 3.12
set CMAKE_GENERATOR_TOOLSET_VERSION=14.27
set DISTUTILS_USE_SDK=1
for /f &quot;usebackq tokens=*&quot; %i in (`&quot;%ProgramFiles(x86)%\Microsoft Visual Studio\Installer\vswhere.exe&quot; -version [15^,17^) -products * -latest -property installationPath`) do call &quot;%i\VC\Auxiliary\Build\vcvarsall.bat&quot; x64 -vcvars_ver=%CMAKE_GENERATOR_TOOLSET_VERSION%

:: [可選] 若要覆蓋 CUDA 主機編譯器
set CUDAHOSTCXX=C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.27.29110\bin\HostX64\x64\cl.exe

python setup.py develop

</code></pre>
<p><strong>Intel GPU 編譯</strong></p>
<p>此模式下將建構支援 Intel GPU 的 PyTorch。</p>
<p>請確保<a href="#prerequisites">共用先決條件</a>及<a href="#intel-gpu-support">Intel GPU 先決條件</a>皆已安裝且環境變數正確設置。建構工具需使用 <code>Visual Studio 2022</code>。</p>
<p>然後執行下列指令建構 PyTorch：</p>
<pre><code class="language-cmd">:: CMD 指令：
:: 設定 CMAKE_PREFIX_PATH 以協助尋找對應套件
:: %CONDA_PREFIX% 僅在 `conda activate custom_env` 後有效

if defined CMAKE_PREFIX_PATH (
    set &quot;CMAKE_PREFIX_PATH=%CONDA_PREFIX%\Library;%CMAKE_PREFIX_PATH%&quot;
) else (
    set &quot;CMAKE_PREFIX_PATH=%CONDA_PREFIX%\Library&quot;
)

python setup.py develop
</code></pre>
<h5>調整編譯選項（可選）</h5>
<p>你可以選擇性先調整 cmake 變數配置（不需立即編譯），例如調整 CuDNN 或 BLAS 的預設目錄。</p>
<p>Linux 上</p>
<pre><code class="language-bash">export CMAKE_PREFIX_PATH=&quot;${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}&quot;
python setup.py build --cmake-only
ccmake build  # 或 cmake-gui build
</code></pre>
<p>macOS 上</p>
<pre><code class="language-bash">export CMAKE_PREFIX_PATH=&quot;${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}&quot;
MACOSX_DEPLOYMENT_TARGET=10.9 CC=clang CXX=clang++ python setup.py build --cmake-only
ccmake build  # 或 cmake-gui build
</code></pre>
<h3>Docker 映像檔</h3>
<h4>使用預建映像檔</h4>
<p>你也可以直接由 Docker Hub 下載預建映像檔，需 Docker v19.03+：</p>
<pre><code class="language-bash">docker run --gpus all --rm -ti --ipc=host pytorch/pytorch:latest
</code></pre>
<p>請注意，PyTorch 會用 shared memory 在進程間共享資料，因此若用到 torch 多進程（如多執行緒資料加載器），預設 shared memory segment 大小不夠，需用 <code>--ipc=host</code> 或 <code>--shm-size</code> 參數提升 shared memory 大小。</p>
<h4>自行構建映像檔</h4>
<p><strong>注意：</strong> 需 Docker 版本 &gt; 18.06</p>
<p><code>Dockerfile</code> 提供支援 CUDA 11.1 及 cuDNN v8 的映像構建。
你可透過 <code>PYTHON_VERSION=x.y</code> 指定 Miniconda 使用的 Python 版本，未指定則用預設值。</p>
<pre><code class="language-bash">make -f docker.Makefile
# 映像檔標記為 docker.io/${your_docker_username}/pytorch
</code></pre>
<p>你也可透過 <code>CMAKE_VARS=&quot;...&quot;</code> 環境變數，指定其他 CMake 參數給 CMake。
可參閱 <a href="./setup.py">setup.py</a> 了解可用變數。</p>
<pre><code class="language-bash">make -f docker.Makefile
</code></pre>
<h3>構建文件</h3>
<p>若要以各種格式構建文件，你需要 <a href="http://www.sphinx-doc.org">Sphinx</a> 及 pytorch_sphinx_theme2。</p>
<p>本地構建文件前，請確保已安裝 <code>torch</code>。若僅需小修正，可依 <a href="https://pytorch.org/get-started/locally/">快速入門</a> 安裝 nightly 版。</p>
<p>如需複雜修正（如新增模組及其 docstring），可能需<a href="#from-source">從原始碼安裝 torch</a>。
docstring 撰寫請參考 <a href="https://github.com/pytorch/pytorch/wiki/Docstring-Guidelines">Docstring Guidelines</a>。</p>
<pre><code class="language-bash">cd docs/
pip install -r requirements.txt
make html
make serve
</code></pre>
<p>執行 <code>make</code> 可列出所有可用輸出格式。</p>
<p>若遇到 katex 錯誤，請執行 <code>npm install katex</code>。若仍有問題，試試
<code>npm install -g katex</code></p>
<blockquote>
<p>[!NOTE]
若你用其他套件管理器（如 <code>conda</code>）安裝 <code>nodejs</code>，則 <code>npm</code> 可能會安裝與你 nodejs 版本不相容的 <code>katex</code>，導致文件建構失敗。
已知可用組合為 <code>node@6.13.1</code> 與 <code>katex@0.13.18</code>。安裝方式如下：
<code>npm install -g katex@0.13.18</code></p>
</blockquote>
<blockquote>
<p>[!NOTE]
若遇到 numpy 相容性錯誤，請執行：</p>
<pre><code>pip install 'numpy&lt;2'
</code></pre>
</blockquote>
<p>如你有更改 CI 執行的相依套件，請編輯
<code>.ci/docker/requirements-docs.txt</code> 文件。</p>
<h4>產生 PDF</h4>
<p>要編譯所有 PyTorch 文件為 PDF，需先安裝 <code>texlive</code> 與 LaTeX。macOS 可用下述指令安裝：</p>
<pre><code>brew install --cask mactex
</code></pre>
<p>產生 PDF 步驟：</p>
<ol>
<li><p>執行：</p>
<pre><code>make latexpdf
</code></pre>
<p>會於 <code>build/latex</code> 目錄產生所需檔案。</p>
</li>
<li><p>進入該目錄並執行：</p>
<pre><code>make LATEXOPTS=&quot;-interaction=nonstopmode&quot;
</code></pre>
<p>這會產生含所需內容的 <code>pytorch.pdf</code>。請再執行一次，以正確生成目錄與索引。</p>
</li>
</ol>
<blockquote>
<p>[!NOTE]
若要查看目錄，請在 PDF 閱讀器中切換至 <strong>Table of Contents</strong> 檢視。</p>
</blockquote>
<h3>舊版本</h3>
<p>舊版 PyTorch 的安裝說明與二進位檔，可於
<a href="https://pytorch.org/get-started/previous-versions">官方網站</a> 查詢。</p>
<h2>快速入門</h2>
<p>三個上手指引：</p>
<ul>
<li><a href="https://pytorch.org/tutorials/">教學：幫助你理解並開始使用 PyTorch</a></li>
<li><a href="https://github.com/pytorch/examples">範例：涵蓋各領域，易於理解的 PyTorch 程式碼</a></li>
<li><a href="https://pytorch.org/docs/">API 參考</a></li>
<li><a href="https://github.com/pytorch/pytorch/blob/main/GLOSSARY.md">術語表</a></li>
</ul>
<h2>資源</h2>
<ul>
<li><a href="https://pytorch.org/">PyTorch.org</a></li>
<li><a href="https://pytorch.org/tutorials/">PyTorch 教學</a></li>
<li><a href="https://github.com/pytorch/examples">PyTorch 範例</a></li>
<li><a href="https://pytorch.org/hub/">PyTorch 模型</a></li>
<li><a href="https://www.udacity.com/course/deep-learning-pytorch--ud188">Udacity 的 PyTorch 深度學習入門</a></li>
<li><a href="https://www.udacity.com/course/intro-to-machine-learning-nanodegree--nd229">Udacity 的 PyTorch 機器學習入門</a></li>
<li><a href="https://www.coursera.org/learn/deep-neural-networks-with-pytorch">Coursera 的 PyTorch 深度神經網路</a></li>
<li><a href="https://twitter.com/PyTorch">PyTorch Twitter</a></li>
<li><a href="https://pytorch.org/blog/">PyTorch 部落格</a></li>
<li><a href="https://www.youtube.com/channel/UCWXI5YeOsh03QvJ59PMaXFw">PyTorch YouTube</a></li>
</ul>
<h2>溝通</h2>
<ul>
<li>論壇：討論實作、研究等 https://discuss.pytorch.org</li>
<li>GitHub 問題：錯誤回報、功能請求、安裝問題、RFC、建議等</li>
<li>Slack：<a href="https://pytorch.slack.com/">PyTorch Slack</a> 主要為中高階使用者與開發者的討論、協作交流等。新手請優先使用 <a href="https://discuss.pytorch.org">PyTorch 論壇</a>。若需邀請，可填表申請：https://goo.gl/forms/PP1AGvNHpSaJP8to1</li>
<li>電子報：重要 PyTorch 公告，一向單向發送。訂閱：https://eepurl.com/cbG0rv</li>
<li>Facebook 粉專：重要公告 https://www.facebook.com/pytorch</li>
<li>品牌規範，請參考官網 <a href="https://pytorch.org/">pytorch.org</a></li>
</ul>
<h2>發佈與貢獻</h2>
<p>PyTorch 通常一年有三次次要版本發佈。如遇到錯誤請<a href="https://github.com/pytorch/pytorch/issues">提交 issue</a>。</p>
<p>我們歡迎所有貢獻。若你打算回報錯誤修正，請直接提交，無需討論。</p>
<p>若打算貢獻新功能、實用函式或核心擴充，請先開 issue 與我們討論。
未經討論直接發 PR，可能因為我們的開發方向不同而被拒絕。</p>
<p>想了解更多貢獻 PyTorch 的方式，請見<a href="CONTRIBUTING.md">貢獻指南</a>。PyTorch 發佈相關訊息請見<a href="RELEASE.md">發佈說明</a>。</p>
<h2>開發團隊</h2>
<p>PyTorch 是一個社群驅動的專案，由許多優秀的工程師和研究人員共同貢獻。</p>
<p>目前由 <a href="http://soumith.ch">Soumith Chintala</a>、<a href="https://github.com/gchanan">Gregory Chanan</a>、<a href="https://github.com/dzhulgakov">Dmytro Dzhulgakov</a>、<a href="https://github.com/ezyang">Edward Yang</a>、<a href="https://github.com/malfet">Nikita Shulga</a> 維護，並有來自數百位傑出個人的重大貢獻。
不完全但持續成長的名單還包括：<a href="https://github.com/killeent">Trevor Killeen</a>、<a href="https://github.com/chsasank">Sasank Chilamkurthy</a>、<a href="https://github.com/szagoruyko">Sergey Zagoruyko</a>、<a href="https://github.com/adamlerer">Adam Lerer</a>、<a href="https://github.com/fmassa">Francisco Massa</a>、<a href="https://github.com/alykhantejani">Alykhan Tejani</a>、<a href="https://github.com/lantiga">Luca Antiga</a>、<a href="https://github.com/albanD">Alban Desmaison</a>、<a href="https://github.com/andreaskoepf">Andreas Koepf</a>、<a href="https://github.com/jekbradbury">James Bradbury</a>、<a href="https://github.com/ebetica">Zeming Lin</a>、<a href="https://github.com/yuandong-tian">Yuandong Tian</a>、<a href="https://github.com/glample">Guillaume Lample</a>、<a href="https://github.com/Maratyszcza">Marat Dukhan</a>、<a href="https://github.com/ngimel">Natalia Gimelshein</a>、<a href="https://github.com/csarofeen">Christian Sarofeen</a>、<a href="https://github.com/martinraison">Martin Raison</a>、<a href="https://github.com/ezyang">Edward Yang</a>、<a href="https://github.com/zdevito">Zachary Devito</a>。</p>
<p>註：本專案與同名的 <a href="https://github.com/hughperkins/pytorch">hughperkins/pytorch</a> 無關。Hugh 是 Torch 社群的重要貢獻者，對 Torch 與 PyTorch 有許多幫助。</p>
<h2>授權</h2>
<p>PyTorch 採 BSD 風格授權，詳見 <a href="LICENSE">LICENSE</a> 檔案。</p>
<hr />
<p><a href="https://github.com/OpenAiTx/OpenAiTx">Powered By OpenAiTx</a></p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
</body>
</html>