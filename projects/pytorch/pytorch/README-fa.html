<!DOCTYPE html>
<html lang="fa">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>pytorch - pytorch/pytorch fa</title>
    <meta name="title" content="pytorch - pytorch/pytorch fa | PyTorch یک بسته پایتون است که دو ویژگی سطح بالای زیر را فراهم می‌کند: محاسبه تنسور (مانند NumPy) با شتاب‌دهی قدرتمند GPU شبکه‌های عصبی عمیق ساخته شده بر پایه سی...">
    <meta name="description" content="pytorch/pytorch - GitHub repository fa documentation and information | PyTorch یک بسته پایتون است که دو ویژگی سطح بالای زیر را فراهم می‌کند: محاسبه تنسور (مانند NumPy) با شتاب‌دهی قدرتمند GPU شبکه‌های عصبی عمیق ساخته شده بر پایه سی...">
    <meta name="keywords" content="pytorch, pytorch, GitHub, repository, fa documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/pytorch/pytorch/README-fa.html">
    <meta property="og:title" content="pytorch - pytorch/pytorch fa | PyTorch یک بسته پایتون است که دو ویژگی سطح بالای زیر را فراهم می‌کند: محاسبه تنسور (مانند NumPy) با شتاب‌دهی قدرتمند GPU شبکه‌های عصبی عمیق ساخته شده بر پایه سی...">
    <meta property="og:description" content="pytorch/pytorch - GitHub repository fa documentation and information | PyTorch یک بسته پایتون است که دو ویژگی سطح بالای زیر را فراهم می‌کند: محاسبه تنسور (مانند NumPy) با شتاب‌دهی قدرتمند GPU شبکه‌های عصبی عمیق ساخته شده بر پایه سی...">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div style="position: fixed; top: 2px; left: 2px; z-index: 2000; background: rgba(255,255,255,0.95); border-radius: 6px; box-shadow: 0 2px 8px rgba(0,0,0,0.06); padding: 4px 14px; font-size: 15px; color: #222; font-family: 'Segoe UI', Arial, sans-serif; font-weight: 500; letter-spacing: 0.5px;">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" style="color: #0366d6; text-decoration: none; font-weight: 600;">Open AI Tx</a>
    </div>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/pytorch/pytorch" id="githubRepoLink" target="_blank">pytorch/pytorch</a>
<h1 style="display: none;">PyTorch یک بسته پایتون است که دو ویژگی سطح بالای زیر را فراهم می‌کند: محاسبه تنسور (مانند NumPy) با شتاب‌دهی قدرتمند GPU شبکه‌های عصبی عمیق ساخته شده بر پایه سی...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <p><img src="https://github.com/pytorch/pytorch/raw/main/docs/source/_static/img/pytorch-logo-dark.png" alt="لوگوی PyTorch" /></p>
<hr />
<p>PyTorch یک بسته پایتون است که دو ویژگی سطح بالای زیر را فراهم می‌کند:</p>
<ul>
<li>محاسبه تنسور (مانند NumPy) با شتاب‌دهی قدرتمند GPU</li>
<li>شبکه‌های عصبی عمیق ساخته شده بر پایه سیستم autograd مبتنی بر نوار</li>
</ul>
<p>شما می‌توانید بسته‌های محبوب پایتون مانند NumPy، SciPy و Cython را برای گسترش PyTorch در مواقع مورد نیاز مجدداً استفاده کنید.</p>
<p>سلامت شاخه اصلی ما (سیگنال‌های ادغام مداوم) در <a href="https://hud.pytorch.org/ci/pytorch/pytorch/main">hud.pytorch.org</a> قابل مشاهده است.</p>
<!-- toc -->
<ul>
<li><a href="#%D8%A7%D8%B7%D9%84%D8%A7%D8%B9%D8%A7%D8%AA-%D8%A8%DB%8C%D8%B4%D8%AA%D8%B1-%D8%AF%D8%B1%D8%A8%D8%A7%D8%B1%D9%87-pytorch">اطلاعات بیشتر درباره PyTorch</a>
<ul>
<li><a href="#%DA%A9%D8%AA%D8%A7%D8%A8%D8%AE%D8%A7%D9%86%D9%87-%D8%AA%D9%86%D8%B3%D9%88%D8%B1-%D8%A2%D9%85%D8%A7%D8%AF%D9%87-gpu">کتابخانه تنسور آماده GPU</a></li>
<li><a href="#%D8%B4%D8%A8%DA%A9%D9%87%E2%80%8C%D9%87%D8%A7%DB%8C-%D8%B9%D8%B5%D8%A8%DB%8C-%D9%BE%D9%88%DB%8C%D8%A7-autograd-%D9%85%D8%A8%D8%AA%D9%86%DB%8C-%D8%A8%D8%B1-%D9%86%D9%88%D8%A7%D8%B1">شبکه‌های عصبی پویا: Autograd مبتنی بر نوار</a></li>
<li><a href="#%D8%A7%D9%88%D9%84-%D9%BE%D8%A7%DB%8C%D8%AA%D9%88%D9%86">اول پایتون</a></li>
<li><a href="#%D8%AA%D8%AC%D8%B1%D8%A8%DB%8C%D8%A7%D8%AA-%D8%AF%D8%B3%D8%AA%D9%88%D8%B1%DB%8C">تجربیات دستوری</a></li>
<li><a href="#%D8%B3%D8%B1%DB%8C%D8%B9-%D9%88-%DA%A9%D9%85%E2%80%8C%D8%AD%D8%AC%D9%85">سریع و کم‌حجم</a></li>
<li><a href="#%DA%AF%D8%B3%D8%AA%D8%B1%D8%B4-%D8%A8%D8%AF%D9%88%D9%86-%D8%AF%D8%B1%D8%AF%D8%B3%D8%B1">گسترش بدون دردسر</a></li>
</ul>
</li>
<li><a href="#%D9%86%D8%B5%D8%A8">نصب</a>
<ul>
<li><a href="#%D8%A8%D8%A7%DB%8C%D9%86%D8%B1%DB%8C%E2%80%8C%D9%87%D8%A7">باینری‌ها</a>
<ul>
<li><a href="#%D9%BE%D9%84%D8%AA%D9%81%D8%B1%D9%85%E2%80%8C%D9%87%D8%A7%DB%8C-nvidia-jetson">پلتفرم‌های NVIDIA Jetson</a></li>
</ul>
</li>
<li><a href="#%D8%A7%D8%B2-%D8%B3%D9%88%D8%B1%D8%B3">از سورس</a>
<ul>
<li><a href="#%D9%BE%DB%8C%D8%B4%E2%80%8C%D9%86%DB%8C%D8%A7%D8%B2%D9%87%D8%A7">پیش‌نیازها</a>
<ul>
<li><a href="#%D9%BE%D8%B4%D8%AA%DB%8C%D8%A8%D8%A7%D9%86%DB%8C-nvidia-cuda">پشتیبانی NVIDIA CUDA</a></li>
<li><a href="#%D9%BE%D8%B4%D8%AA%DB%8C%D8%A8%D8%A7%D9%86%DB%8C-amd-rocm">پشتیبانی AMD ROCm</a></li>
<li><a href="#%D9%BE%D8%B4%D8%AA%DB%8C%D8%A8%D8%A7%D9%86%DB%8C-gpu-%D8%A7%DB%8C%D9%86%D8%AA%D9%84">پشتیبانی GPU اینتل</a></li>
</ul>
</li>
<li><a href="#%D8%AF%D8%B1%DB%8C%D8%A7%D9%81%D8%AA-%D8%B3%D9%88%D8%B1%D8%B3-pytorch">دریافت سورس PyTorch</a></li>
<li><a href="#%D9%86%D8%B5%D8%A8-%D9%88%D8%A7%D8%A8%D8%B3%D8%AA%DA%AF%DB%8C%E2%80%8C%D9%87%D8%A7">نصب وابستگی‌ها</a></li>
<li><a href="#%D9%86%D8%B5%D8%A8-pytorch">نصب PyTorch</a>
<ul>
<li><a href="#%D8%AA%D9%86%D8%B8%DB%8C%D9%85-%DA%AF%D8%B2%DB%8C%D9%86%D9%87%E2%80%8C%D9%87%D8%A7%DB%8C-%D8%B3%D8%A7%D8%AE%D8%AA-%D8%A7%D8%AE%D8%AA%DB%8C%D8%A7%D8%B1%DB%8C">تنظیم گزینه‌های ساخت (اختیاری)</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#%D8%A7%DB%8C%D9%85%DB%8C%D8%AC-%D8%AF%D8%A7%DA%A9%D8%B1">ایمیج داکر</a>
<ul>
<li><a href="#%D8%A7%D8%B3%D8%AA%D9%81%D8%A7%D8%AF%D9%87-%D8%A7%D8%B2-%D8%A7%DB%8C%D9%85%DB%8C%D8%AC%E2%80%8C%D9%87%D8%A7%DB%8C-%D8%A2%D9%85%D8%A7%D8%AF%D9%87">استفاده از ایمیج‌های آماده</a></li>
<li><a href="#%D8%B3%D8%A7%D8%AE%D8%AA-%D8%A7%DB%8C%D9%85%DB%8C%D8%AC-%D8%A8%D9%87-%D8%B5%D9%88%D8%B1%D8%AA-%D8%AF%D8%B3%D8%AA%DB%8C">ساخت ایمیج به صورت دستی</a></li>
</ul>
</li>
<li><a href="#%D8%B3%D8%A7%D8%AE%D8%AA-%D9%85%D8%B3%D8%AA%D9%86%D8%AF%D8%A7%D8%AA">ساخت مستندات</a>
<ul>
<li><a href="#%D8%B3%D8%A7%D8%AE%D8%AA-pdf">ساخت PDF</a></li>
</ul>
</li>
<li><a href="#%D9%86%D8%B3%D8%AE%D9%87%E2%80%8C%D9%87%D8%A7%DB%8C-%D9%82%D8%A8%D9%84%DB%8C">نسخه‌های قبلی</a></li>
</ul>
</li>
<li><a href="#%D8%B4%D8%B1%D9%88%D8%B9-%D8%A8%D9%87-%DA%A9%D8%A7%D8%B1">شروع به کار</a></li>
<li><a href="#%D9%85%D9%86%D8%A7%D8%A8%D8%B9">منابع</a></li>
<li><a href="#%D8%A7%D8%B1%D8%AA%D8%A8%D8%A7%D8%B7%D8%A7%D8%AA">ارتباطات</a></li>
<li><a href="#%D8%A7%D9%86%D8%AA%D8%B4%D8%A7%D8%B1%D9%87%D8%A7-%D9%88-%D9%85%D8%B4%D8%A7%D8%B1%DA%A9%D8%AA">انتشارها و مشارکت</a></li>
<li><a href="#%D8%AA%DB%8C%D9%85">تیم</a></li>
<li><a href="#%D9%85%D8%AC%D9%88%D8%B2">مجوز</a></li>
</ul>
<!-- tocstop -->
<h2>اطلاعات بیشتر درباره PyTorch</h2>
<p><a href="https://pytorch.org/tutorials/beginner/basics/intro.html">مبانی PyTorch را بیاموزید</a></p>
<p>در سطح جزئی‌تر، PyTorch کتابخانه‌ای است که از اجزای زیر تشکیل شده است:</p>
<p>| مؤلفه | توضیحات |
| ---- | --- |
| <a href="https://pytorch.org/docs/stable/torch.html"><strong>torch</strong></a> | کتابخانه تنسور مانند NumPy با پشتیبانی قدرتمند GPU |
| <a href="https://pytorch.org/docs/stable/autograd.html"><strong>torch.autograd</strong></a> | کتابخانه مشتق‌گیری خودکار مبتنی بر نوار که همه عملیات‌های تنسور قابل مشتق در torch را پشتیبانی می‌کند |
| <a href="https://pytorch.org/docs/stable/jit.html"><strong>torch.jit</strong></a> | پشته کامپایل (TorchScript) برای ایجاد مدل‌های قابل سریال‌سازی و بهینه‌سازی از کد PyTorch |
| <a href="https://pytorch.org/docs/stable/nn.html"><strong>torch.nn</strong></a> | کتابخانه شبکه‌های عصبی که با autograd یکپارچه شده و برای بیشینه انعطاف‌پذیری طراحی شده است |
| <a href="https://pytorch.org/docs/stable/multiprocessing.html"><strong>torch.multiprocessing</strong></a> | چندفرایندی پایتون، اما با اشتراک‌گذاری جادویی حافظه تنسورها بین فرایندها. مفید برای بارگذاری داده و آموزش Hogwild |
| <a href="https://pytorch.org/docs/stable/data.html"><strong>torch.utils</strong></a> | DataLoader و سایر توابع کمکی برای راحتی بیشتر |</p>
<p>معمولاً PyTorch به دو صورت استفاده می‌شود:</p>
<ul>
<li>جایگزینی برای NumPy برای بهره‌گیری از قدرت GPUها.</li>
<li>پلتفرم تحقیقاتی یادگیری عمیق که بیشینه انعطاف‌پذیری و سرعت را فراهم می‌کند.</li>
</ul>
<p>توضیحات بیشتر:</p>
<h3>کتابخانه تنسور آماده GPU</h3>
<p>اگر از NumPy استفاده کرده‌اید، پس با تنسورها (همان ndarray) آشنا هستید.</p>
<p><img src="./docs/source/_static/img/tensor_illustration.png" alt="تصویرسازی تنسور" /></p>
<p>PyTorch تنسورهایی ارائه می‌دهد که می‌توانند روی CPU یا GPU قرار گیرند و محاسبات را با شتاب بسیار بالا انجام می‌دهند.</p>
<p>ما مجموعه‌ای گسترده از توابع تنسور برای پاسخ‌گویی به نیازهای محاسبات علمی شما ارائه می‌دهیم، مانند برش، اندیس‌گذاری، عملیات ریاضی، جبر خطی، کاهش‌ها و غیره.
و بسیار سریع هستند!</p>
<h3>شبکه‌های عصبی پویا: Autograd مبتنی بر نوار</h3>
<p>PyTorch روشی منحصربه‌فرد برای ساخت شبکه‌های عصبی دارد: استفاده و بازپخش ضبط‌کننده نوار.</p>
<p>بیشتر فریم‌ورک‌ها مانند TensorFlow، Theano، Caffe و CNTK دیدگاه ایستا دارند.
باید یک شبکه عصبی بسازید و بارها از همان ساختار استفاده کنید.
تغییر رفتار شبکه به معنای شروع از ابتدا است.</p>
<p>در PyTorch از تکنیکی به نام مشتق‌گیری خودکار معکوس (reverse-mode auto-differentiation) استفاده می‌کنیم که به شما اجازه می‌دهد رفتار شبکه خود را به طور دلخواه و بدون تأخیر یا سربار تغییر دهید. الهام ما از چندین مقاله تحقیقاتی و پروژه‌هایی مانند <a href="https://github.com/twitter/torch-autograd">torch-autograd</a>، <a href="https://github.com/HIPS/autograd">autograd</a>، <a href="https://chainer.org">Chainer</a> و غیره گرفته شده است.</p>
<p>در حالی که این تکنیک منحصراً متعلق به PyTorch نیست، اما یکی از سریع‌ترین پیاده‌سازی‌های آن تا به امروز است.
شما بهترین سرعت و انعطاف‌پذیری را برای تحقیقات پیشرفته خود خواهید داشت.</p>
<p><img src="https://github.com/pytorch/pytorch/raw/main/docs/source/_static/img/dynamic_graph.gif" alt="گراف پویا" /></p>
<h3>اول پایتون</h3>
<p>PyTorch یک اتصال پایتون به یک فریم‌ورک C++ یکپارچه نیست.
بلکه به گونه‌ای ساخته شده که عمیقاً با پایتون یکپارچه باشد.
می‌توانید به طور طبیعی مانند <a href="https://www.numpy.org/">NumPy</a> / <a href="https://www.scipy.org/">SciPy</a> / <a href="https://scikit-learn.org">scikit-learn</a> و غیره از آن استفاده کنید.
می‌توانید لایه‌های جدید شبکه عصبی را مستقیماً در پایتون با استفاده از کتابخانه‌های مورد علاقه خود بنویسید و از بسته‌هایی مانند <a href="https://cython.org/">Cython</a> و <a href="http://numba.pydata.org/">Numba</a> بهره ببرید.
هدف ما این است که در صورت امکان، چرخ را از نو اختراع نکنیم.</p>
<h3>تجربیات دستوری</h3>
<p>PyTorch طوری طراحی شده که شهودی، خطی در تفکر و آسان برای استفاده باشد.
هر خط کد را که اجرا می‌کنید، همان لحظه اجرا می‌شود. هیچ دیدگاه غیرهمزمانی وجود ندارد.
وقتی وارد اشکال‌زدا می‌شوید یا پیام خطا و trace می‌گیرید، فهم آن‌ها مستقیم است.
trace دقیقاً به جایی اشاره می‌کند که کد شما تعریف شده است.
امیدواریم هیچ‌گاه ساعت‌ها وقت خود را صرف اشکال‌زدایی به خاطر traceهای بد یا موتورهای اجرای غیرهمزمان و مبهم نکنید.</p>
<h3>سریع و کم‌حجم</h3>
<p>PyTorch سربار چارچوبی حداقلی دارد. ما کتابخانه‌های شتاب‌دهنده‌ای مانند <a href="https://software.intel.com/mkl">Intel MKL</a> و NVIDIA (<a href="https://developer.nvidia.com/cudnn">cuDNN</a>، <a href="https://developer.nvidia.com/nccl">NCCL</a>) را برای بیشینه سرعت یکپارچه کرده‌ایم.
در هسته خود، backendهای تنسور و شبکه عصبی PyTorch برای CPU و GPU بالغ هستند و سال‌ها تست شده‌اند.</p>
<p>در نتیجه، PyTorch بسیار سریع است، چه شبکه‌های کوچک و چه بزرگ اجرا کنید.</p>
<p>مصرف حافظه در PyTorch نسبت به Torch یا برخی جایگزین‌ها بسیار کارآمد است.
ما برای GPU تخصیص‌دهنده حافظه اختصاصی نوشته‌ایم تا مدل‌های یادگیری عمیق شما بیشینه بهره‌وری حافظه را داشته باشند.
این امکان را فراهم می‌کند تا مدل‌های یادگیری عمیق بزرگ‌تری نسبت به گذشته آموزش دهید.</p>
<h3>گسترش بدون دردسر</h3>
<p>نوشتن ماژول‌های جدید شبکه عصبی یا ارتباط با API تنسور PyTorch طوری طراحی شده که ساده و با کمترین انتزاع باشد.</p>
<p>می‌توانید لایه‌های جدید شبکه عصبی را در پایتون با استفاده از API torch <a href="https://pytorch.org/tutorials/advanced/numpy_extensions_tutorial.html">یا کتابخانه‌های مبتنی بر NumPy مانند SciPy</a> بنویسید.</p>
<p>اگر می‌خواهید لایه‌های خود را در C/C++ بنویسید، ما یک API گسترش آسان و کارآمد با حداقل کد اضافی ارائه می‌دهیم.
نیازی به نوشتن کد wrapper نیست. <a href="https://pytorch.org/tutorials/advanced/cpp_extension.html">آموزش اینجا</a> و <a href="https://github.com/pytorch/extension-cpp">مثال اینجا</a> را ببینید.</p>
<h2>نصب</h2>
<h3>باینری‌ها</h3>
<p>دستورات نصب باینری‌ها از طریق Conda یا pip wheel در سایت ما موجود است: <a href="https://pytorch.org/get-started/locally/">https://pytorch.org/get-started/locally/</a></p>
<h4>پلتفرم‌های NVIDIA Jetson</h4>
<p>Wheelهای پایتون برای Jetson Nano، Jetson TX1/TX2، Jetson Xavier NX/AGX و Jetson AGX Orin <a href="https://forums.developer.nvidia.com/t/pytorch-for-jetson-version-1-10-now-available/72048">اینجا</a> ارائه شده‌اند و کانتینر L4T <a href="https://catalog.ngc.nvidia.com/orgs/nvidia/containers/l4t-pytorch">اینجا</a> منتشر شده است.</p>
<p>آن‌ها نیازمند JetPack 4.2 به بالا هستند و <a href="https://github.com/dusty-nv">@dusty-nv</a> و <a href="https://github.com/ptrblck">@ptrblck</a> نگهداری آن‌ها را بر عهده دارند.</p>
<h3>از سورس</h3>
<h4>پیش‌نیازها</h4>
<p>اگر قصد نصب از سورس را دارید، به موارد زیر نیاز دارید:</p>
<ul>
<li>پایتون ۳.۹ یا بالاتر</li>
<li>کامپایلری که کاملاً از C++17 پشتیبانی کند، مانند clang یا gcc (در لینوکس gcc 9.4.0 یا جدیدتر مورد نیاز است)</li>
<li>Visual Studio یا Visual Studio Build Tool (فقط ویندوز)</li>
</ul>
<p>* CI PyTorch از Visual C++ BuildTools استفاده می‌کند، که همراه با نسخه‌های Enterprise، Professional یا Community ویژوال استودیو ارائه می‌شود. همچنین می‌توانید ابزار ساخت را از آدرس https://visualstudio.microsoft.com/visual-cpp-build-tools/ نصب کنید. ابزار ساخت به طور پیش‌فرض همراه Visual Studio Code ارائه نمی‌شود.</p>
<p>یک نمونه تنظیم محیط به شرح زیر است:</p>
<ul>
<li>لینوکس:</li>
</ul>
<pre><code class="language-bash">$ source &lt;CONDA_INSTALL_DIR&gt;/bin/activate
$ conda create -y -n &lt;CONDA_NAME&gt;
$ conda activate &lt;CONDA_NAME&gt;
</code></pre>
<ul>
<li>ویندوز:</li>
</ul>
<pre><code class="language-bash">$ source &lt;CONDA_INSTALL_DIR&gt;\Scripts\activate.bat
$ conda create -y -n &lt;CONDA_NAME&gt;
$ conda activate &lt;CONDA_NAME&gt;
$ call &quot;C:\Program Files\Microsoft Visual Studio\&lt;VERSION&gt;\Community\VC\Auxiliary\Build\vcvarsall.bat&quot; x64
</code></pre>
<h5>پشتیبانی NVIDIA CUDA</h5>
<p>اگر می‌خواهید با پشتیبانی CUDA کامپایل کنید، <a href="https://pytorch.org/get-started/locally/">یک نسخه پشتیبانی‌شده CUDA از جدول پشتیبانی ما انتخاب کنید</a>، سپس موارد زیر را نصب کنید:</p>
<ul>
<li><a href="https://developer.nvidia.com/cuda-downloads">NVIDIA CUDA</a></li>
<li><a href="https://developer.nvidia.com/cudnn">NVIDIA cuDNN</a> نسخه ۸.۵ یا بالاتر</li>
<li><a href="https://gist.github.com/ax3l/9489132">کامپایلر</a> سازگار با CUDA</li>
</ul>
<p>توجه: می‌توانید به <a href="https://docs.nvidia.com/deeplearning/cudnn/backend/latest/reference/support-matrix.html">جدول پشتیبانی cuDNN</a> برای نسخه‌های cuDNN با CUDAهای مختلف، درایور CUDA و سخت‌افزار NVIDIA مراجعه کنید.</p>
<p>اگر می‌خواهید پشتیبانی CUDA را غیرفعال کنید، متغیر محیطی <code>USE_CUDA=0</code> را صادر کنید.
سایر متغیرهای محیطی مفید در <code>setup.py</code> موجود است.</p>
<p>اگر برای پلتفرم‌های Jetson شرکت NVIDIA (Jetson Nano، TX1، TX2، AGX Xavier) کامپایل می‌کنید، <a href="https://devtalk.nvidia.com/default/topic/1049071/jetson-nano/pytorch-for-jetson-nano/">دستورالعمل نصب PyTorch برای Jetson Nano اینجاست</a></p>
<h5>پشتیبانی AMD ROCm</h5>
<p>اگر می‌خواهید با پشتیبانی ROCm کامپایل کنید، نصب کنید:</p>
<ul>
<li><a href="https://rocm.docs.amd.com/en/latest/deploy/linux/quick_start.html">AMD ROCm</a> نسخه ۴.۰ به بالا</li>
<li>ROCm در حال حاضر فقط برای سیستم‌های لینوکس پشتیبانی می‌شود.</li>
</ul>
<p>به طور پیش‌فرض، سیستم ساخت انتظار دارد ROCm در مسیر <code>/opt/rocm</code> نصب شده باشد. اگر ROCm در مسیر دیگری نصب شده، متغیر محیطی <code>ROCM_PATH</code> را به مسیر نصب ROCm تنظیم کنید. سیستم ساخت به طور خودکار معماری GPUهای AMD را تشخیص می‌دهد. در صورت نیاز، معماری GPUهای AMD را می‌توان با متغیر محیطی <code>PYTORCH_ROCM_ARCH</code> به صورت صریح تنظیم کرد. <a href="https://rocm.docs.amd.com/projects/install-on-linux/en/latest/reference/system-requirements.html#supported-gpus">لیست GPUهای پشتیبانی شده</a></p>
<p>اگر می‌خواهید پشتیبانی ROCm را غیرفعال کنید، متغیر محیطی <code>USE_ROCM=0</code> را صادر کنید.
سایر متغیرهای محیطی مفید در <code>setup.py</code> موجود است.</p>
<h5>پشتیبانی GPU اینتل</h5>
<p>اگر می‌خواهید با پشتیبانی GPU اینتل کامپایل کنید، مراحل زیر را دنبال کنید:</p>
<ul>
<li><a href="https://www.intel.com/content/www/us/en/developer/articles/tool/pytorch-prerequisites-for-intel-gpus.html">دستورالعمل‌های پیش‌نیاز PyTorch برای GPU اینتل</a></li>
<li>GPU اینتل برای لینوکس و ویندوز پشتیبانی می‌شود.</li>
</ul>
<p>اگر می‌خواهید پشتیبانی GPU اینتل را غیرفعال کنید، متغیر محیطی <code>USE_XPU=0</code> را صادر کنید.
سایر متغیرهای محیطی مفید در <code>setup.py</code> موجود است.</p>
<h4>دریافت سورس PyTorch</h4>
<pre><code class="language-bash">git clone https://github.com/pytorch/pytorch
cd pytorch
# اگر checkout قبلی دارید
git submodule sync
git submodule update --init --recursive
</code></pre>
<h4>نصب وابستگی‌ها</h4>
<p><strong>مشترک</strong></p>
<pre><code class="language-bash">conda install cmake ninja
# پس از کلون سورس کد طبق بخش “دریافت سورس PyTorch” این دستور را اجرا کنید
pip install -r requirements.txt
</code></pre>
<p><strong>در لینوکس</strong></p>
<pre><code class="language-bash">pip install mkl-static mkl-include
# فقط CUDA: اگر نیاز است پشتیبانی LAPACK برای GPU اضافه کنید
# نصب magma: این دستور را با محیط فعال conda و با تعیین نسخه CUDA اجرا کنید
.ci/docker/common/install_magma_conda.sh 12.4

# (اختیاری) اگر از torch.compile با inductor/triton استفاده می‌کنید، نسخه متناسب triton را نصب کنید
# از مسیر پوشه pytorch پس از کلون اجرا کنید
# برای پشتیبانی GPU اینتل، لطفا قبل از اجرا صراحتاً `export USE_XPU=1` را تنظیم کنید.
make triton
</code></pre>
<p><strong>در macOS</strong></p>
<pre><code class="language-bash"># این بسته را فقط روی ماشین‌های پردازنده x86 اینتل اضافه کنید
pip install mkl-static mkl-include
# اگر torch.distributed نیاز است این بسته‌ها را اضافه کنید
conda install pkg-config libuv
</code></pre>
<p><strong>در ویندوز</strong></p>
<pre><code class="language-bash">pip install mkl-static mkl-include
# اگر torch.distributed نیاز است این بسته‌ها را اضافه کنید.
# پشتیبانی بسته distributed در ویندوز ویژگی نمونه‌ای است و ممکن است تغییر کند.
conda install -c conda-forge libuv=1.39
</code></pre>
<h4>نصب PyTorch</h4>
<p><strong>در لینوکس</strong></p>
<p>اگر برای AMD ROCm کامپایل می‌کنید ابتدا این دستور را اجرا کنید:</p>
<pre><code class="language-bash"># فقط اگر برای ROCm کامپایل می‌کنید اجرا کنید
python tools/amd_build/build_amd.py
</code></pre>
<p>نصب PyTorch</p>
<pre><code class="language-bash">export CMAKE_PREFIX_PATH=&quot;${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}&quot;
python setup.py develop
</code></pre>
<p><strong>در macOS</strong></p>
<pre><code class="language-bash">python3 setup.py develop
</code></pre>
<p><strong>در ویندوز</strong></p>
<p>اگر می‌خواهید کد پایتون قدیمی را کامپایل کنید، به <a href="https://github.com/pytorch/pytorch/blob/main/CONTRIBUTING.md#building-on-legacy-code-and-cuda">ساخت روی کد قدیمی و CUDA</a> مراجعه کنید.</p>
<p><strong>ساخت فقط برای CPU</strong></p>
<p>در این حالت محاسبات PyTorch روی CPU اجرا می‌شود، نه روی GPU.</p>
<pre><code class="language-cmd">python setup.py develop
</code></pre>
<p>نکته درباره OpenMP: پیاده‌سازی مورد نظر OpenMP، Intel OpenMP (iomp) است. برای لینک با iomp باید کتابخانه را به صورت دستی دانلود و محیط ساخت را با تغییر <code>CMAKE_INCLUDE_PATH</code> و <code>LIB</code> تنظیم کنید. دستورالعمل <a href="https://github.com/pytorch/pytorch/blob/main/docs/source/notes/windows.rst#building-from-source">اینجا</a> مثالی برای تنظیم هر دو MKL و Intel OpenMP است. بدون این تنظیمات، runtime پیش‌فرض Microsoft Visual C OpenMP (vcomp) استفاده خواهد شد.</p>
<p><strong>ساخت مبتنی بر CUDA</strong></p>
<p>در این حالت محاسبات PyTorch از GPU شما از طریق CUDA برای سرعت بیشتر استفاده می‌کند.</p>
<p><a href="https://docs.nvidia.com/gameworks/content/gameworkslibrary/nvtx/nvidia_tools_extension_library_nvtx.htm">NVTX</a> برای ساخت PyTorch با CUDA مورد نیاز است.
NVTX بخشی از بسته CUDA است و به نام &quot;Nsight Compute&quot; شناخته می‌شود. برای نصب آن روی CUDA نصب‌شده، نصب CUDA را مجدداً اجرا و چک‌باکس مربوطه را فعال کنید.
اطمینان حاصل کنید CUDA با Nsight Compute پس از Visual Studio نصب شده باشد.</p>
<p>در حال حاضر، VS 2017 / 2019 و Ninja به عنوان generator CMake پشتیبانی می‌شوند. اگر <code>ninja.exe</code> در <code>PATH</code> باشد، Ninja به عنوان generator پیش‌فرض استفاده می‌شود، در غیر این صورت VS 2017 / 2019.
<br/> اگر Ninja انتخاب شود، جدیدترین MSVC به عنوان toolchain زیرین انتخاب می‌شود.</p>
<p>کتابخانه‌های اضافی مانند
<a href="https://developer.nvidia.com/magma">Magma</a>، <a href="https://github.com/oneapi-src/oneDNN">oneDNN، با نام MKLDNN یا DNNL</a> و <a href="https://github.com/mozilla/sccache">Sccache</a> اغلب نیاز هستند. لطفاً برای نصب آن‌ها به <a href="https://github.com/pytorch/pytorch/tree/main/.ci/pytorch/win-test-helpers/installation-helpers">installation-helper</a> مراجعه کنید.</p>
<p>می‌توانید برای پیکربندی متغیرهای محیطی دیگر به اسکریپت <a href="https://github.com/pytorch/pytorch/blob/main/.ci/pytorch/win-test-helpers/build_pytorch.bat">build_pytorch.bat</a> مراجعه کنید.</p>
<pre><code class="language-cmd">cmd

:: متغیرهای محیطی را پس از دانلود و استخراج بسته mkl تنظیم کنید،
:: در غیر این صورت CMake خطای `Could NOT find OpenMP` می‌دهد.
set CMAKE_INCLUDE_PATH={Your directory}\mkl\include
set LIB={Your directory}\mkl\lib;%LIB%

:: محتوای بخش قبلی را با دقت بخوانید قبل از ادامه.
:: [اختیاری] اگر می‌خواهید toolset زیرین Ninja و Visual Studio با CUDA را override کنید، اسکریپت زیر را اجرا کنید.
:: &quot;Visual Studio 2019 Developer Command Prompt&quot; به طور خودکار اجرا می‌شود.
:: اطمینان حاصل کنید CMake &gt;= 3.12 را قبل از این کار دارید (در صورت استفاده از Visual Studio generator).
set CMAKE_GENERATOR_TOOLSET_VERSION=14.27
set DISTUTILS_USE_SDK=1
for /f &quot;usebackq tokens=*&quot; %i in (`&quot;%ProgramFiles(x86)%\Microsoft Visual Studio\Installer\vswhere.exe&quot; -version [15^,17^) -products * -latest -property installationPath`) do call &quot;%i\VC\Auxiliary\Build\vcvarsall.bat&quot; x64 -vcvars_ver=%CMAKE_GENERATOR_TOOLSET_VERSION%

:: [اختیاری] اگر می‌خواهید CUDA host compiler را override کنید
set CUDAHOSTCXX=C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.27.29110\bin\HostX64\x64\cl.exe

python setup.py develop

</code></pre>
<p><strong>ساخت GPU اینتل</strong></p>
<p>در این حالت PyTorch با پشتیبانی GPU اینتل ساخته می‌شود.</p>
<p>لطفاً اطمینان حاصل کنید <a href="#%D9%BE%DB%8C%D8%B4%E2%80%8C%D9%86%DB%8C%D8%A7%D8%B2%D9%87%D8%A7">پیش‌نیازهای مشترک</a> و همچنین <a href="#%D9%BE%D8%B4%D8%AA%DB%8C%D8%A8%D8%A7%D9%86%DB%8C-gpu-%D8%A7%DB%8C%D9%86%D8%AA%D9%84">پیش‌نیازهای GPU اینتل</a> به درستی نصب و متغیرهای محیطی قبل از شروع ساخت تنظیم شده باشند. برای پشتیبانی ابزار ساخت، <code>Visual Studio 2022</code> مورد نیاز است.</p>
<p>سپس می‌توانید PyTorch را با دستور زیر بسازید:</p>
<pre><code class="language-cmd">:: دستورات CMD:
:: CMAKE_PREFIX_PATH را تنظیم کنید تا بسته‌های مربوطه پیدا شوند
:: %CONDA_PREFIX% فقط پس از `conda activate custom_env` کار می‌کند

if defined CMAKE_PREFIX_PATH (
    set &quot;CMAKE_PREFIX_PATH=%CONDA_PREFIX%\Library;%CMAKE_PREFIX_PATH%&quot;
) else (
    set &quot;CMAKE_PREFIX_PATH=%CONDA_PREFIX%\Library&quot;
)

python setup.py develop
</code></pre>
<h5>تنظیم گزینه‌های ساخت (اختیاری)</h5>
<p>می‌توانید پیکربندی متغیرهای cmake را به طور اختیاری (بدون ساخت اولیه) با انجام موارد زیر تنظیم کنید. برای مثال، تنظیم مسیرهای پیش‌فرض تشخیص داده شده برای CuDNN یا BLAS با این روش انجام می‌شود.</p>
<p>در لینوکس</p>
<pre><code class="language-bash">export CMAKE_PREFIX_PATH=&quot;${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}&quot;
python setup.py build --cmake-only
ccmake build  # یا cmake-gui build
</code></pre>
<p>در macOS</p>
<pre><code class="language-bash">export CMAKE_PREFIX_PATH=&quot;${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}&quot;
MACOSX_DEPLOYMENT_TARGET=10.9 CC=clang CXX=clang++ python setup.py build --cmake-only
ccmake build  # یا cmake-gui build
</code></pre>
<h3>ایمیج داکر</h3>
<h4>استفاده از ایمیج‌های آماده</h4>
<p>همچنین می‌توانید یک ایمیج آماده داکر را از Docker Hub بکشید و با docker v19.03+ اجرا کنید</p>
<pre><code class="language-bash">docker run --gpus all --rm -ti --ipc=host pytorch/pytorch:latest
</code></pre>
<p>توجه داشته باشید که PyTorch برای اشتراک داده بین فرایندها از حافظه اشتراکی استفاده می‌کند، بنابراین اگر از multiprocessing در torch استفاده می‌شود (مانند بارگذاری داده چندریسمانی)، اندازه پیش‌فرض بخش حافظه اشتراکی کانتینر کافی نیست و باید اندازه حافظه اشتراکی را با گزینه‌های خط فرمان <code>--ipc=host</code> یا <code>--shm-size</code> برای <code>nvidia-docker run</code> افزایش دهید.</p>
<h4>ساخت ایمیج به صورت دستی</h4>
<p><strong>نکته:</strong> باید با نسخه داکر بالاتر از ۱۸.۰۶ ساخته شود</p>
<p><code>Dockerfile</code> برای ساخت ایمیج با پشتیبانی CUDA 11.1 و cuDNN v8 ارائه شده است.
می‌توانید متغیر PYTHON_VERSION=x.y را برای تعیین نسخه پایتون مورد استفاده Miniconda تعیین کنید، یا آن را خالی بگذارید تا مقدار پیش‌فرض استفاده شود.</p>
<pre><code class="language-bash">make -f docker.Makefile
# ایمیج‌ها با docker.io/${your_docker_username}/pytorch تگ می‌شوند
</code></pre>
<p>همچنین می‌توانید متغیر محیطی <code>CMAKE_VARS=&quot;...&quot;</code> را برای تعیین متغیرهای اضافی CMake به عنوان آرگومان‌های build به کار ببرید.
برای لیست متغیرهای موجود به <a href="./setup.py">setup.py</a> مراجعه کنید.</p>
<pre><code class="language-bash">make -f docker.Makefile
</code></pre>
<h3>ساخت مستندات</h3>
<p>برای ساخت مستندات در قالب‌های مختلف به <a href="http://www.sphinx-doc.org">Sphinx</a>
و پوسته pytorch_sphinx_theme2 نیاز دارید.</p>
<p>قبل از ساخت مستندات به صورت محلی، اطمینان حاصل کنید که <code>torch</code>
در محیط شما نصب است. برای اصلاحات جزئی می‌توانید نسخه nightly را طبق <a href="https://pytorch.org/get-started/locally/">شروع به کار</a> نصب کنید.</p>
<p>برای اصلاحات پیچیده‌تر، مانند افزودن ماژول جدید و docstringهای آن، شاید نیاز باشد torch را <a href="#%D8%A7%D8%B2-%D8%B3%D9%88%D8%B1%D8%B3">از سورس</a> نصب کنید.
برای راهنمایی نگارش docstring به <a href="https://github.com/pytorch/pytorch/wiki/Docstring-Guidelines">Docstring Guidelines</a> مراجعه کنید.</p>
<pre><code class="language-bash">cd docs/
pip install -r requirements.txt
make html
make serve
</code></pre>
<p>برای دریافت لیست فرمت‌های خروجی موجود، دستور <code>make</code> را اجرا کنید.</p>
<p>اگر خطای katex دریافت کردید، <code>npm install katex</code> را اجرا کنید. اگر ادامه داشت،
<code>npm install -g katex</code> را امتحان کنید.</p>
<blockquote>
<p>[!نکته]
اگر <code>nodejs</code> را با یک package manager دیگر (مثلاً
<code>conda</code>) نصب کرده‌اید، احتمالاً <code>npm</code> نسخه‌ای از <code>katex</code> نصب می‌کند که با نسخه <code>nodejs</code> شما ناسازگار است و ساخت مستندات شکست می‌خورد.
ترکیب نسخه‌هایی که کار می‌کند: <code>node@6.13.1</code> و
<code>katex@0.13.18</code>. برای نصب دومی با <code>npm</code> اجرا کنید
<code>npm install -g katex@0.13.18</code></p>
</blockquote>
<blockquote>
<p>[!نکته]
اگر خطای ناسازگاری numpy مشاهده کردید، اجرا کنید:</p>
<pre><code>pip install 'numpy&lt;2'
</code></pre>
</blockquote>
<p>زمانی که وابستگی‌های اجراشده توسط CI را تغییر می‌دهید، فایل
<code>.ci/docker/requirements-docs.txt</code> را ویرایش کنید.</p>
<h4>ساخت PDF</h4>
<p>برای کامپایل PDF از کل مستندات PyTorch، اطمینان حاصل کنید
<code>texlive</code> و LaTeX نصب است. در macOS، می‌توانید با دستور زیر نصب کنید:</p>
<pre><code>brew install --cask mactex
</code></pre>
<p>برای ساخت PDF:</p>
<ol>
<li><p>اجرا کنید:</p>
<pre><code>make latexpdf
</code></pre>
<p>این کار فایل‌های لازم را در مسیر <code>build/latex</code> ایجاد می‌کند.</p>
</li>
<li><p>به این پوشه بروید و اجرا کنید:</p>
<pre><code>make LATEXOPTS=&quot;-interaction=nonstopmode&quot;
</code></pre>
<p>این کار یک فایل <code>pytorch.pdf</code> با محتوای مورد نظر ایجاد می‌کند. این دستور را یک بار دیگر اجرا کنید تا فهرست مطالب و نمایه به درستی تولید شود.</p>
</li>
</ol>
<blockquote>
<p>[!نکته]
برای مشاهده فهرست مطالب، در نمایشگر PDF به نمای <strong>Table of Contents</strong>
بروید.</p>
</blockquote>
<h3>نسخه‌های قبلی</h3>
<p>دستورالعمل نصب و باینری‌های نسخه‌های قبلی PyTorch را می‌توانید
در <a href="https://pytorch.org/get-started/previous-versions">سایت ما</a> بیابید.</p>
<h2>شروع به کار</h2>
<p>سه راهنما برای شروع:</p>
<ul>
<li><a href="https://pytorch.org/tutorials/">آموزش‌ها: برای شروع یادگیری و استفاده از PyTorch</a></li>
<li><a href="https://github.com/pytorch/examples">مثال‌ها: کدهای ساده و قابل فهم PyTorch در همه حوزه‌ها</a></li>
<li><a href="https://pytorch.org/docs/">مرجع API</a></li>
<li><a href="https://github.com/pytorch/pytorch/blob/main/GLOSSARY.md">واژه‌نامه</a></li>
</ul>
<h2>منابع</h2>
<ul>
<li><a href="https://pytorch.org/">PyTorch.org</a></li>
<li><a href="https://pytorch.org/tutorials/">آموزش‌های PyTorch</a></li>
<li><a href="https://github.com/pytorch/examples">مثال‌های PyTorch</a></li>
<li><a href="https://pytorch.org/hub/">مدل‌های PyTorch</a></li>
<li><a href="https://www.udacity.com/course/deep-learning-pytorch--ud188">مقدمه‌ای بر یادگیری عمیق با PyTorch از Udacity</a></li>
<li><a href="https://www.udacity.com/course/intro-to-machine-learning-nanodegree--nd229">مقدمه‌ای بر یادگیری ماشین با PyTorch از Udacity</a></li>
<li><a href="https://www.coursera.org/learn/deep-neural-networks-with-pytorch">شبکه‌های عصبی عمیق با PyTorch از Coursera</a></li>
<li><a href="https://twitter.com/PyTorch">PyTorch توییتر</a></li>
<li><a href="https://pytorch.org/blog/">PyTorch بلاگ</a></li>
<li><a href="https://www.youtube.com/channel/UCWXI5YeOsh03QvJ59PMaXFw">PyTorch یوتیوب</a></li>
</ul>
<h2>ارتباطات</h2>
<ul>
<li>انجمن‌ها: بحث درباره پیاده‌سازی‌ها، پژوهش و غیره https://discuss.pytorch.org</li>
<li>مشکلات گیت‌هاب: گزارش باگ، درخواست ویژگی، مشکلات نصب، RFC، ایده‌ها و غیره.</li>
<li>اسلک: <a href="https://pytorch.slack.com/">اسلک PyTorch</a> میزبان کاربران و توسعه‌دهندگان متوسط تا حرفه‌ای برای گپ عمومی، بحث آنلاین، همکاری و غیره است. اگر مبتدی هستید و کمک می‌خواهید، انجمن اصلی <a href="https://discuss.pytorch.org">PyTorch Forums</a> است. برای دعوت به اسلک، این فرم را پر کنید: https://goo.gl/forms/PP1AGvNHpSaJP8to1</li>
<li>خبرنامه: خبرنامه‌ای یک‌طرفه و بدون اسپم برای اطلاع‌رسانی‌های مهم PyTorch. ثبت‌نام: https://eepurl.com/cbG0rv</li>
<li>صفحه فیسبوک: اطلاعیه‌های مهم درباره PyTorch. https://www.facebook.com/pytorch</li>
<li>برای راهنمای برندینگ به سایت <a href="https://pytorch.org/">pytorch.org</a> مراجعه کنید.</li>
</ul>
<h2>انتشارها و مشارکت</h2>
<p>معمولاً PyTorch سه انتشار جزئی در سال دارد. اگر باگی مشاهده کردید لطفاً با <a href="https://github.com/pytorch/pytorch/issues">ثبت issue</a> ما را مطلع کنید.</p>
<p>از همه مشارکت‌ها استقبال می‌کنیم. اگر قصد دارید باگ‌فیکس ارسال کنید، لطفاً بدون نیاز به بحث بیشتر این کار را انجام دهید.</p>
<p>اگر قصد دارید ویژگی جدید، توابع کمکی یا گسترش برای هسته ارسال کنید، ابتدا issue باز کنید و درباره آن ویژگی با ما بحث کنید.
ارسال PR بدون بحث ممکن است به رد آن منجر شود چرا که شاید ما هسته را در جهتی متفاوت پیش می‌بریم.</p>
<p>برای اطلاعات بیشتر درباره مشارکت به <a href="CONTRIBUTING.md">صفحه مشارکت</a> و برای اطلاعات درباره انتشارها به <a href="RELEASE.md">صفحه انتشار</a> مراجعه کنید.</p>
<h2>تیم</h2>
<p>PyTorch پروژه‌ای مبتنی بر جامعه با مشارکت چندین مهندس و پژوهشگر ماهر است.</p>
<p>PyTorch هم‌اکنون توسط <a href="http://soumith.ch">Soumith Chintala</a>، <a href="https://github.com/gchanan">Gregory Chanan</a>، <a href="https://github.com/dzhulgakov">Dmytro Dzhulgakov</a>، <a href="https://github.com/ezyang">Edward Yang</a> و <a href="https://github.com/malfet">Nikita Shulga</a> نگهداری می‌شود و کمک‌های عمده از صدها نفر با استعداد در قالب‌ها و روش‌های مختلف صورت گرفته است.
لیست ناقص اما رو به رشدی از مشارکت‌کنندگان: <a href="https://github.com/killeent">Trevor Killeen</a>، <a href="https://github.com/chsasank">Sasank Chilamkurthy</a>، <a href="https://github.com/szagoruyko">Sergey Zagoruyko</a>، <a href="https://github.com/adamlerer">Adam Lerer</a>، <a href="https://github.com/fmassa">Francisco Massa</a>، <a href="https://github.com/alykhantejani">Alykhan Tejani</a>، <a href="https://github.com/lantiga">Luca Antiga</a>، <a href="https://github.com/albanD">Alban Desmaison</a>، <a href="https://github.com/andreaskoepf">Andreas Koepf</a>، <a href="https://github.com/jekbradbury">James Bradbury</a>، <a href="https://github.com/ebetica">Zeming Lin</a>، <a href="https://github.com/yuandong-tian">Yuandong Tian</a>، <a href="https://github.com/glample">Guillaume Lample</a>، <a href="https://github.com/Maratyszcza">Marat Dukhan</a>، <a href="https://github.com/ngimel">Natalia Gimelshein</a>، <a href="https://github.com/csarofeen">Christian Sarofeen</a>، <a href="https://github.com/martinraison">Martin Raison</a>، <a href="https://github.com/ezyang">Edward Yang</a>، <a href="https://github.com/zdevito">Zachary Devito</a>.</p>
<p>نکته: این پروژه هیچ ارتباطی با <a href="https://github.com/hughperkins/pytorch">hughperkins/pytorch</a> با همین نام ندارد. Hugh از مشارکت‌کنندگان ارزشمند جامعه Torch است و در بسیاری از امور Torch و PyTorch کمک کرده است.</p>
<h2>مجوز</h2>
<p>PyTorch دارای مجوز سبک BSD است که در فایل <a href="LICENSE">LICENSE</a> آمده است.</p>
<hr />
<p><a href="https://github.com/OpenAiTx/OpenAiTx">Powered By OpenAiTx</a></p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
</body>
</html>