<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>pytorch - pytorch/pytorch ja</title>
    <meta name="title" content="pytorch - pytorch/pytorch ja | PyTorch は、次の2つの高レベル機能を提供する Python パッケージです。 強力な GPU アクセラレーションを備えた Tensor 計算（NumPy のようなもの） テープベースの自動微分システム上に構築されたディープニューラルネットワーク 必要に応じて、NumPy、SciPy、Cython などお好きな ...">
    <meta name="description" content="pytorch/pytorch - GitHub repository ja documentation and information | PyTorch は、次の2つの高レベル機能を提供する Python パッケージです。 強力な GPU アクセラレーションを備えた Tensor 計算（NumPy のようなもの） テープベースの自動微分システム上に構築されたディープニューラルネットワーク 必要に応じて、NumPy、SciPy、Cython などお好きな ...">
    <meta name="keywords" content="pytorch, pytorch, GitHub, repository, ja documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/pytorch/pytorch/README-ja.html">
    <meta property="og:title" content="pytorch - pytorch/pytorch ja | PyTorch は、次の2つの高レベル機能を提供する Python パッケージです。 強力な GPU アクセラレーションを備えた Tensor 計算（NumPy のようなもの） テープベースの自動微分システム上に構築されたディープニューラルネットワーク 必要に応じて、NumPy、SciPy、Cython などお好きな ...">
    <meta property="og:description" content="pytorch/pytorch - GitHub repository ja documentation and information | PyTorch は、次の2つの高レベル機能を提供する Python パッケージです。 強力な GPU アクセラレーションを備えた Tensor 計算（NumPy のようなもの） テープベースの自動微分システム上に構築されたディープニューラルネットワーク 必要に応じて、NumPy、SciPy、Cython などお好きな ...">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div style="position: fixed; top: 2px; left: 2px; z-index: 2000; background: rgba(255,255,255,0.95); border-radius: 6px; box-shadow: 0 2px 8px rgba(0,0,0,0.06); padding: 4px 14px; font-size: 15px; color: #222; font-family: 'Segoe UI', Arial, sans-serif; font-weight: 500; letter-spacing: 0.5px;">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" style="color: #0366d6; text-decoration: none; font-weight: 600;">Open AI Tx</a>
    </div>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/pytorch/pytorch" id="githubRepoLink" target="_blank">pytorch/pytorch</a>
<h1 style="display: none;">PyTorch は、次の2つの高レベル機能を提供する Python パッケージです。 強力な GPU アクセラレーションを備えた Tensor 計算（NumPy のようなもの） テープベースの自動微分システム上に構築されたディープニューラルネットワーク 必要に応じて、NumPy、SciPy、Cython などお好きな ...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <p><img src="https://github.com/pytorch/pytorch/raw/main/docs/source/_static/img/pytorch-logo-dark.png" alt="PyTorch ロゴ" /></p>
<hr />
<p>PyTorch は、次の2つの高レベル機能を提供する Python パッケージです。</p>
<ul>
<li>強力な GPU アクセラレーションを備えた Tensor 計算（NumPy のようなもの）</li>
<li>テープベースの自動微分システム上に構築されたディープニューラルネットワーク</li>
</ul>
<p>必要に応じて、NumPy、SciPy、Cython などお好きな Python パッケージを再利用して、PyTorch を拡張できます。</p>
<p>私たちの trunk health（継続的インテグレーションのシグナル）は <a href="https://hud.pytorch.org/ci/pytorch/pytorch/main">hud.pytorch.org</a> で確認できます。</p>
<!-- toc -->
<ul>
<li><a href="#more-about-pytorch">PyTorch についてさらに詳しく</a>
<ul>
<li><a href="#a-gpu-ready-tensor-library">GPU 対応のテンソルライブラリ</a></li>
<li><a href="#dynamic-neural-networks-tape-based-autograd">動的ニューラルネットワーク: テープベース自動微分</a></li>
<li><a href="#python-first">Python ファースト</a></li>
<li><a href="#imperative-experiences">命令型の体験</a></li>
<li><a href="#fast-and-lean">高速かつ軽量</a></li>
<li><a href="#extensions-without-pain">簡単な拡張性</a></li>
</ul>
</li>
<li><a href="#installation">インストール</a>
<ul>
<li><a href="#binaries">バイナリ</a>
<ul>
<li><a href="#nvidia-jetson-platforms">NVIDIA Jetson プラットフォーム</a></li>
</ul>
</li>
<li><a href="#from-source">ソースからのビルド</a>
<ul>
<li><a href="#prerequisites">前提条件</a>
<ul>
<li><a href="#nvidia-cuda-support">NVIDIA CUDA サポート</a></li>
<li><a href="#amd-rocm-support">AMD ROCm サポート</a></li>
<li><a href="#intel-gpu-support">Intel GPU サポート</a></li>
</ul>
</li>
<li><a href="#get-the-pytorch-source">PyTorch ソースの取得</a></li>
<li><a href="#install-dependencies">依存関係のインストール</a></li>
<li><a href="#install-pytorch">PyTorch のインストール</a>
<ul>
<li><a href="#adjust-build-options-optional">ビルドオプションの調整（オプション）</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#docker-image">Docker イメージ</a>
<ul>
<li><a href="#using-pre-built-images">事前ビルドイメージの利用</a></li>
<li><a href="#building-the-image-yourself">イメージの自作</a></li>
</ul>
</li>
<li><a href="#building-the-documentation">ドキュメントのビルド</a>
<ul>
<li><a href="#building-a-pdf">PDF のビルド</a></li>
</ul>
</li>
<li><a href="#previous-versions">過去バージョン</a></li>
</ul>
</li>
<li><a href="#getting-started">はじめに</a></li>
<li><a href="#resources">リソース</a></li>
<li><a href="#communication">コミュニケーション</a></li>
<li><a href="#releases-and-contributing">リリースとコントリビュート</a></li>
<li><a href="#the-team">チーム</a></li>
<li><a href="#license">ライセンス</a></li>
</ul>
<!-- tocstop -->
<h2>PyTorch についてさらに詳しく</h2>
<p><a href="https://pytorch.org/tutorials/beginner/basics/intro.html">PyTorch の基本を学ぶ</a></p>
<p>詳細レベルでは、PyTorch は以下のコンポーネントから成るライブラリです。</p>
<p>| コンポーネント | 説明 |
| ---- | --- |
| <a href="https://pytorch.org/docs/stable/torch.html"><strong>torch</strong></a> | NumPy のようなテンソルライブラリで、強力な GPU サポートを持つ |
| <a href="https://pytorch.org/docs/stable/autograd.html"><strong>torch.autograd</strong></a> | torch の全ての微分可能なテンソル操作をサポートするテープベース自動微分ライブラリ |
| <a href="https://pytorch.org/docs/stable/jit.html"><strong>torch.jit</strong></a> | PyTorch コードからシリアライズ可能かつ最適化可能なモデルを作成するためのコンパイルスタック（TorchScript） |
| <a href="https://pytorch.org/docs/stable/nn.html"><strong>torch.nn</strong></a> | autograd と深く統合されたニューラルネットワークライブラリ。最大の柔軟性を持つよう設計 |
| <a href="https://pytorch.org/docs/stable/multiprocessing.html"><strong>torch.multiprocessing</strong></a> | Python のマルチプロセッシング。ただし、torch テンソルの魔法のようなメモリ共有機能付き。データローディングや Hogwild トレーニングに便利 |
| <a href="https://pytorch.org/docs/stable/data.html"><strong>torch.utils</strong></a> | DataLoader やその他のユーティリティ関数 |</p>
<p>通常、PyTorch は以下の用途で使われます：</p>
<ul>
<li>NumPy の代替として、GPU の力を活用したい場合</li>
<li>最大限の柔軟性と速度を提供するディープラーニング研究プラットフォームとして</li>
</ul>
<p>詳細解説：</p>
<h3>GPU 対応のテンソルライブラリ</h3>
<p>NumPy を使ったことがあれば、テンソル（別名 ndarray）を使ったことがあるはずです。</p>
<p><img src="./docs/source/_static/img/tensor_illustration.png" alt="Tensor illustration" /></p>
<p>PyTorch は、CPU または GPU 上で動作するテンソルを提供し、計算を大幅に高速化します。</p>
<p>スライス、インデックス操作、数学演算、線形代数、リダクションなど、幅広いテンソル操作ルーチンを提供し、
科学計算のニーズに合うよう設計されています。
そして、とても高速です！</p>
<h3>動的ニューラルネットワーク: テープベース自動微分</h3>
<p>PyTorch には、ニューラルネットワークを構築するユニークな方法があります：テープレコーダーを使って記録・再生します。</p>
<p>TensorFlow、Theano、Caffe、CNTK などほとんどのフレームワークは静的なネットワーク構造を持っています。
一度ネットワークを構築すると、同じ構造を何度も再利用しなければなりません。
ネットワークの挙動を変えるには、一からやり直す必要があります。</p>
<p>PyTorch では、逆モード自動微分（reverse-mode auto-differentiation）という技術を使い、
ネットワークの挙動を遅延やオーバーヘッドなしに自由に変更できます。
この発想は、いくつかの研究論文や
<a href="https://github.com/twitter/torch-autograd">torch-autograd</a>、
<a href="https://github.com/HIPS/autograd">autograd</a>、
<a href="https://chainer.org">Chainer</a> など現在・過去の実装からインスパイアされています。</p>
<p>この技術は PyTorch 固有ではありませんが、PyTorch の実装は現時点で最速クラスです。
スピードと柔軟性の両方を手に入れることができます。</p>
<p><img src="https://github.com/pytorch/pytorch/raw/main/docs/source/_static/img/dynamic_graph.gif" alt="Dynamic graph" /></p>
<h3>Python ファースト</h3>
<p>PyTorch は、巨大な C++ フレームワークへの Python バインディングではありません。
Python との深い統合を前提に設計されています。
<a href="https://www.numpy.org/">NumPy</a> / <a href="https://www.scipy.org/">SciPy</a> / <a href="https://scikit-learn.org">scikit-learn</a> のように自然に使えます。
お気に入りのライブラリを使って Python でニューラルネットワーク層を記述したり、
<a href="https://cython.org/">Cython</a> や <a href="http://numba.pydata.org/">Numba</a> などのパッケージも利用できます。
再発明する必要のないところは、再発明しないことを目指しています。</p>
<h3>命令型の体験</h3>
<p>PyTorch は直感的で、思考の流れに沿った、使いやすい設計です。
コードを1行書くと、その行が即実行されます。非同期的な世界観はありません。
デバッガに入ったりエラーメッセージやスタックトレースを受け取る場合も、理解が容易です。
スタックトレースは、まさに自分が書いたコードの箇所を指します。
悪いスタックトレースや非同期・ブラックボックスな実行エンジンのせいで
何時間もデバッグに費やすことがないよう願っています。</p>
<h3>高速かつ軽量</h3>
<p>PyTorch はフレームワークとしてのオーバーヘッドが最小限です。
<a href="https://software.intel.com/mkl">Intel MKL</a> や NVIDIA の
(<a href="https://developer.nvidia.com/cudnn">cuDNN</a>, <a href="https://developer.nvidia.com/nccl">NCCL</a>) などの
アクセラレーションライブラリと統合し、最大限の速度を実現しています。
コアとなる CPU・GPU のテンソルやニューラルネットワークのバックエンドは
成熟しており、長年にわたってテストされています。</p>
<p>そのため、PyTorch は小さなニューラルネットワークでも大きなニューラルネットワークでも
非常に高速です。</p>
<p>PyTorch のメモリ使用量は Torch や一部の代替案に比べて非常に効率的です。
GPU 用のカスタムメモリアロケータを作成し、
ディープラーニングモデルが最大限メモリ効率良くなるよう設計しています。
これにより、より大きなディープラーニングモデルの学習が可能になります。</p>
<h3>簡単な拡張性</h3>
<p>新しいニューラルネットワークモジュールの作成や、PyTorch の Tensor API とのインターフェースは
シンプルで最小限の抽象化で実現できるよう設計されています。</p>
<p>torch API を用いて Python で新しいニューラルネットワーク層を記述したり、
<a href="https://pytorch.org/tutorials/advanced/numpy_extensions_tutorial.html">NumPy ベースのライブラリ（SciPy など）</a> を使うこともできます。</p>
<p>C/C++ で層を書きたい場合は、効率的でボイラープレートの少ない便利な拡張 API を提供しています。
ラッパーコードを書く必要はありません。
<a href="https://pytorch.org/tutorials/advanced/cpp_extension.html">チュートリアルはこちら</a>、
<a href="https://github.com/pytorch/extension-cpp">サンプルはこちら</a> をご参照ください。</p>
<h2>インストール</h2>
<h3>バイナリ</h3>
<p>Conda または pip wheels でバイナリをインストールするためのコマンドは公式サイトにあります: <a href="https://pytorch.org/get-started/locally/">https://pytorch.org/get-started/locally/</a></p>
<h4>NVIDIA Jetson プラットフォーム</h4>
<p>NVIDIA の Jetson Nano, Jetson TX1/TX2, Jetson Xavier NX/AGX, Jetson AGX Orin 向けの Python wheels は <a href="https://forums.developer.nvidia.com/t/pytorch-for-jetson-version-1-10-now-available/72048">こちら</a> で提供されており、L4T コンテナは <a href="https://catalog.ngc.nvidia.com/orgs/nvidia/containers/l4t-pytorch">こちら</a> で公開されています。</p>
<p>JetPack 4.2 以上が必要です。<a href="https://github.com/dusty-nv"><code>@dusty-nv</code></a> および <a href="https://github.com/ptrblck"><code>@ptrblck</code></a> がメンテナンスしています。</p>
<h3>ソースからのビルド</h3>
<h4>前提条件</h4>
<p>ソースからインストールする場合、以下が必要です：</p>
<ul>
<li>Python 3.9 以上</li>
<li>C++17 を完全サポートするコンパイラ（clang または gcc、Linux では gcc 9.4.0 以上が必要）</li>
<li>Visual Studio または Visual Studio Build Tool（Windows のみ）</li>
</ul>
<p>* PyTorch CI では Visual C++ BuildTools を使用しています。これは Visual Studio Enterprise, Professional, Community Edition に付属しています。ビルドツールは https://visualstudio.microsoft.com/visual-cpp-build-tools/ からもインストール可能です。ビルドツールは Visual Studio Code にはデフォルトでは付属しません。</p>
<p>環境構築例を以下に示します。</p>
<ul>
<li>Linux:</li>
</ul>
<pre><code class="language-bash">$ source &lt;CONDA_INSTALL_DIR&gt;/bin/activate
$ conda create -y -n &lt;CONDA_NAME&gt;
$ conda activate &lt;CONDA_NAME&gt;
</code></pre>
<ul>
<li>Windows:</li>
</ul>
<pre><code class="language-bash">$ source &lt;CONDA_INSTALL_DIR&gt;\Scripts\activate.bat
$ conda create -y -n &lt;CONDA_NAME&gt;
$ conda activate &lt;CONDA_NAME&gt;
$ call &quot;C:\Program Files\Microsoft Visual Studio\&lt;VERSION&gt;\Community\VC\Auxiliary\Build\vcvarsall.bat&quot; x64
</code></pre>
<h5>NVIDIA CUDA サポート</h5>
<p>CUDA サポート付きでコンパイルする場合は、<a href="https://pytorch.org/get-started/locally/">サポートマトリクスから対応 CUDA バージョンを選択</a>し、下記をインストールしてください：</p>
<ul>
<li><a href="https://developer.nvidia.com/cuda-downloads">NVIDIA CUDA</a></li>
<li><a href="https://developer.nvidia.com/cudnn">NVIDIA cuDNN</a> v8.5 以上</li>
<li>CUDA に対応した <a href="https://gist.github.com/ax3l/9489132">コンパイラ</a></li>
</ul>
<p>注：cuDNN のバージョンと各種対応 CUDA・CUDA ドライバ・NVIDIA ハードウェアについては <a href="https://docs.nvidia.com/deeplearning/cudnn/backend/latest/reference/support-matrix.html">cuDNN Support Matrix</a> を参照してください。</p>
<p>CUDA サポートを無効化する場合は、環境変数 <code>USE_CUDA=0</code> をエクスポートしてください。
他にも有用な環境変数は <code>setup.py</code> に記載されています。</p>
<p>NVIDIA の Jetson プラットフォーム（Jetson Nano, TX1, TX2, AGX Xavier）向けのビルドの場合、Jetson Nano 用 PyTorch インストール手順は <a href="https://devtalk.nvidia.com/default/topic/1049071/jetson-nano/pytorch-for-jetson-nano/">こちら</a> を参照してください。</p>
<h5>AMD ROCm サポート</h5>
<p>ROCm サポート付きでコンパイルする場合は、下記をインストールしてください。</p>
<ul>
<li><a href="https://rocm.docs.amd.com/en/latest/deploy/linux/quick_start.html">AMD ROCm</a> 4.0 以上</li>
<li>ROCm は現在 Linux システムのみサポートしています。</li>
</ul>
<p>デフォルトではビルドシステムは ROCm を <code>/opt/rocm</code> にインストールされているものと期待します。別ディレクトリの場合、環境変数 <code>ROCM_PATH</code> で ROCm のインストールディレクトリを指定してください。ビルドシステムは自動で AMD GPU アーキテクチャを検出します。必要なら <code>PYTORCH_ROCM_ARCH</code> で明示的指定も可能です。<a href="https://rocm.docs.amd.com/projects/install-on-linux/en/latest/reference/system-requirements.html#supported-gpus">AMD GPU アーキテクチャ</a> を参照。</p>
<p>ROCm サポートを無効化する場合は、環境変数 <code>USE_ROCM=0</code> をエクスポートしてください。
他にも有用な環境変数は <code>setup.py</code> に記載されています。</p>
<h5>Intel GPU サポート</h5>
<p>Intel GPU サポート付きでコンパイルする場合は、下記を参照してください。</p>
<ul>
<li><a href="https://www.intel.com/content/www/us/en/developer/articles/tool/pytorch-prerequisites-for-intel-gpus.html">PyTorch Prerequisites for Intel GPUs</a> の手順</li>
<li>Intel GPU は Linux および Windows をサポート</li>
</ul>
<p>Intel GPU サポートを無効化する場合は、環境変数 <code>USE_XPU=0</code> をエクスポートしてください。
他にも有用な環境変数は <code>setup.py</code> に記載されています。</p>
<h4>PyTorch ソースの取得</h4>
<pre><code class="language-bash">git clone https://github.com/pytorch/pytorch
cd pytorch
# 既存のチェックアウトを更新する場合
git submodule sync
git submodule update --init --recursive
</code></pre>
<h4>依存関係のインストール</h4>
<p><strong>共通</strong></p>
<pre><code class="language-bash">conda install cmake ninja
# ソースコード取得後、PyTorch ディレクトリで実行
pip install -r requirements.txt
</code></pre>
<p><strong>Linux の場合</strong></p>
<pre><code class="language-bash">pip install mkl-static mkl-include
# CUDA のみ: GPU 向け LAPACK サポートが必要な場合
# magma インストール: 有効な conda 環境で実行し、CUDA バージョンを指定
.ci/docker/common/install_magma_conda.sh 12.4

# （オプション）torch.compile with inductor/triton 利用時、対応バージョンの triton をインストール
# クローン後、pytorch ディレクトリで実行
# Intel GPU サポート時は、コマンド実行前に明示的に `export USE_XPU=1` してください。
make triton
</code></pre>
<p><strong>MacOS の場合</strong></p>
<pre><code class="language-bash"># Intel x86 プロセッサ搭載機のみ追加
pip install mkl-static mkl-include
# torch.distributed が必要な場合のみ追加
conda install pkg-config libuv
</code></pre>
<p><strong>Windows の場合</strong></p>
<pre><code class="language-bash">pip install mkl-static mkl-include
# torch.distributed が必要な場合のみ追加
# Windows での distributed パッケージサポートはプロトタイプ機能です。変更されることがあります。
conda install -c conda-forge libuv=1.39
</code></pre>
<h4>PyTorch のインストール</h4>
<p><strong>Linux の場合</strong></p>
<p>AMD ROCm 向けにコンパイルする場合、最初に以下を実行してください：</p>
<pre><code class="language-bash"># ROCm 用コンパイル時のみ実行
python tools/amd_build/build_amd.py
</code></pre>
<p>PyTorch のインストール</p>
<pre><code class="language-bash">export CMAKE_PREFIX_PATH=&quot;${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}&quot;
python setup.py develop
</code></pre>
<p><strong>macOS の場合</strong></p>
<pre><code class="language-bash">python3 setup.py develop
</code></pre>
<p><strong>Windows の場合</strong></p>
<p>レガシー Python コードのビルド方法は <a href="https://github.com/pytorch/pytorch/blob/main/CONTRIBUTING.md#building-on-legacy-code-and-cuda">Building on legacy code and CUDA</a> を参照してください。</p>
<p><strong>CPU のみのビルド</strong></p>
<p>このモードでは、PyTorch の計算は GPU ではなく CPU で実行されます。</p>
<pre><code class="language-cmd">python setup.py develop
</code></pre>
<p>OpenMP に関する注意：推奨される OpenMP 実装は Intel OpenMP（iomp）です。iomp にリンクするには、ライブラリを手動でダウンロードし、<code>CMAKE_INCLUDE_PATH</code> および <code>LIB</code> を調整してください。<a href="https://github.com/pytorch/pytorch/blob/main/docs/source/notes/windows.rst#building-from-source">こちらの手順</a> を参照。設定しない場合、Microsoft Visual C OpenMP ランタイム（vcomp）が使われます。</p>
<p><strong>CUDA ベースのビルド</strong></p>
<p>このモードでは、CUDA を介して PyTorch の計算が GPU で高速化されます。</p>
<p><a href="https://docs.nvidia.com/gameworks/content/gameworkslibrary/nvtx/nvidia_tools_extension_library_nvtx.htm">NVTX</a> が CUDA ビルドに必要です。
NVTX は CUDA 配布物の一部で &quot;Nsight Compute&quot; と呼ばれています。すでに CUDA をインストール済みなら、再度 CUDA インストールを実行し、該当チェックボックスをオンにしてください。
CUDA + Nsight Compute は Visual Studio の後にインストールしてください。</p>
<p>現在、VS 2017 / 2019、および Ninja が CMake のジェネレータとしてサポートされています。<code>ninja.exe</code> が <code>PATH</code> に見つかった場合は Ninja がデフォルト、なければ VS 2017/2019 が使われます。
<br/> Ninja 使用時は最新の MSVC がツールチェーンとして選択されます。</p>
<p>追加ライブラリとして
<a href="https://developer.nvidia.com/magma">Magma</a>, <a href="https://github.com/oneapi-src/oneDNN">oneDNN（MKLDNN/DNNL）</a>, <a href="https://github.com/mozilla/sccache">Sccache</a> などが必要なことがあります。<a href="https://github.com/pytorch/pytorch/tree/main/.ci/pytorch/win-test-helpers/installation-helpers">インストールヘルパー</a> を参照してください。</p>
<p>他環境変数の設定例は <a href="https://github.com/pytorch/pytorch/blob/main/.ci/pytorch/win-test-helpers/build_pytorch.bat">build_pytorch.bat</a> を参照してください。</p>
<pre><code class="language-cmd">cmd

:: mkl パッケージをダウンロード・解凍後に環境変数を設定してください。
:: そうでないと CMake が `Could NOT find OpenMP` エラーを出します。
set CMAKE_INCLUDE_PATH={Your directory}\mkl\include
set LIB={Your directory}\mkl\lib;%LIB%

:: 前セクション内容をよく読んでから実行してください。
:: [オプション] Ninja および Visual Studio で使うツールセットを上書きしたい場合は下記スクリプトを実行。
:: &quot;Visual Studio 2019 Developer Command Prompt&quot; が自動で起動します。
:: Visual Studio ジェネレータ利用時は CMake &gt;= 3.12 が必要です。
set CMAKE_GENERATOR_TOOLSET_VERSION=14.27
set DISTUTILS_USE_SDK=1
for /f &quot;usebackq tokens=*&quot; %i in (`&quot;%ProgramFiles(x86)%\Microsoft Visual Studio\Installer\vswhere.exe&quot; -version [15^,17^) -products * -latest -property installationPath`) do call &quot;%i\VC\Auxiliary\Build\vcvarsall.bat&quot; x64 -vcvars_ver=%CMAKE_GENERATOR_TOOLSET_VERSION%

:: [オプション] CUDA のホストコンパイラを上書きしたい場合
set CUDAHOSTCXX=C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.27.29110\bin\HostX64\x64\cl.exe

python setup.py develop

</code></pre>
<p><strong>Intel GPU ビルド</strong></p>
<p>このモードでは Intel GPU サポート付きで PyTorch をビルドします。</p>
<p><a href="#prerequisites">共通の前提条件</a> および <a href="#intel-gpu-support">Intel GPU 用の前提条件</a> を事前にインストールし、
環境変数を構成してください。ビルドツールは <code>Visual Studio 2022</code> が必要です。</p>
<p>その後、以下のコマンドでビルドできます。</p>
<pre><code class="language-cmd">:: CMD コマンド:
:: CMAKE_PREFIX_PATH をセットして対応パッケージを見つけやすくします
:: %CONDA_PREFIX% は `conda activate custom_env` 後のみ機能します

if defined CMAKE_PREFIX_PATH (
    set &quot;CMAKE_PREFIX_PATH=%CONDA_PREFIX%\Library;%CMAKE_PREFIX_PATH%&quot;
) else (
    set &quot;CMAKE_PREFIX_PATH=%CONDA_PREFIX%\Library&quot;
)

python setup.py develop
</code></pre>
<h5>ビルドオプションの調整（オプション）</h5>
<p>cmake 変数の設定を（ビルド前に）調整できます。たとえば CuDNN や BLAS のディレクトリを手動設定したい場合など。</p>
<p>Linux の場合</p>
<pre><code class="language-bash">export CMAKE_PREFIX_PATH=&quot;${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}&quot;
python setup.py build --cmake-only
ccmake build  # または cmake-gui build
</code></pre>
<p>macOS の場合</p>
<pre><code class="language-bash">export CMAKE_PREFIX_PATH=&quot;${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}&quot;
MACOSX_DEPLOYMENT_TARGET=10.9 CC=clang CXX=clang++ python setup.py build --cmake-only
ccmake build  # または cmake-gui build
</code></pre>
<h3>Docker イメージ</h3>
<h4>事前ビルドイメージの利用</h4>
<p>Docker Hub から事前ビルドの docker イメージを pull し、docker v19.03+ で実行できます。</p>
<pre><code class="language-bash">docker run --gpus all --rm -ti --ipc=host pytorch/pytorch:latest
</code></pre>
<p>PyTorch はプロセス間でデータ共有のため共有メモリを使うため、torch のマルチプロセッシング機能
（例：マルチスレッドデータローダ）が使われる場合、コンテナのデフォルト共有メモリサイズでは足りません。
<code>--ipc=host</code> または <code>--shm-size</code> オプションで共有メモリサイズを増やしてください。</p>
<h4>イメージの自作</h4>
<p><strong>注意:</strong> docker バージョン &gt; 18.06 でビルドしてください。</p>
<p><code>Dockerfile</code> は CUDA 11.1 サポート・cuDNN v8 対応イメージをビルドするためのものです。
<code>PYTHON_VERSION=x.y</code> を make 変数で指定すれば、Miniconda で使う Python バージョンを指定できます。
未指定ならデフォルト値が使われます。</p>
<pre><code class="language-bash">make -f docker.Makefile
# イメージは docker.io/${your_docker_username}/pytorch でタグ付けされます
</code></pre>
<p>ビルド時に追加の CMake 変数を指定したい場合は、<code>CMAKE_VARS=&quot;...&quot;</code> 環境変数を使ってください。
利用可能な変数一覧は <a href="./setup.py">setup.py</a> を参照。</p>
<pre><code class="language-bash">make -f docker.Makefile
</code></pre>
<h3>ドキュメントのビルド</h3>
<p>さまざまな形式でドキュメントをビルドするには、<a href="http://www.sphinx-doc.org">Sphinx</a> と pytorch_sphinx_theme2 が必要です。</p>
<p>ローカルでドキュメントをビルドする前に、<code>torch</code> を環境にインストールしてください。
小さな修正であれば <a href="https://pytorch.org/get-started/locally/">Getting Started</a> の説明に従い
nightly バージョンをインストールできます。</p>
<p>新しいモジュール追加や docstring 追加のような大きな修正の場合、<a href="#from-source">ソースからインストール</a>が必要です。
docstring 規約については <a href="https://github.com/pytorch/pytorch/wiki/Docstring-Guidelines">Docstring Guidelines</a> を参照。</p>
<pre><code class="language-bash">cd docs/
pip install -r requirements.txt
make html
make serve
</code></pre>
<p><code>make</code> を実行すると全出力形式の一覧が得られます。</p>
<p>katex エラーが出た場合は <code>npm install katex</code> を実行してください。解決しない場合は
<code>npm install -g katex</code> を試してください。</p>
<blockquote>
<p>[!NOTE]
<code>nodejs</code> を別のパッケージマネージャ（例：<code>conda</code>）でインストールした場合、<code>npm</code> でインストールされる <code>katex</code> バージョンが
<code>nodejs</code> のバージョンと互換性がなくなり、ドキュメントビルドが失敗することがあります。
動作確認済みの組み合わせは <code>node@6.13.1</code> と <code>katex@0.13.18</code> です。後者は
<code>npm install -g katex@0.13.18</code> でインストールできます。</p>
</blockquote>
<blockquote>
<p>[!NOTE]
numpy の互換性エラーが出る場合は、次を実行してください:</p>
<pre><code>pip install 'numpy&lt;2'
</code></pre>
</blockquote>
<p>CI で実行される依存関係に変更を加えた場合は、
<code>.ci/docker/requirements-docs.txt</code> ファイルを編集してください。</p>
<h4>PDF のビルド</h4>
<p>PyTorch ドキュメント全体の PDF をビルドするには、
<code>texlive</code> および LaTeX をインストールしてください。macOS では下記でインストールできます：</p>
<pre><code>brew install --cask mactex
</code></pre>
<p>PDF 作成手順：</p>
<ol>
<li><p>実行：</p>
<pre><code>make latexpdf
</code></pre>
<p><code>build/latex</code> ディレクトリに必要ファイルが生成されます。</p>
</li>
<li><p>このディレクトリに移動して下記を実行：</p>
<pre><code>make LATEXOPTS=&quot;-interaction=nonstopmode&quot;
</code></pre>
<p>これで <code>pytorch.pdf</code> が生成されます。目次やインデックスを正しく生成するために、もう一度このコマンドを実行してください。</p>
</li>
</ol>
<blockquote>
<p>[!NOTE]
PDF ビューアの <strong>Table of Contents</strong> 表示を使うと目次が見られます。</p>
</blockquote>
<h3>過去バージョン</h3>
<p>過去の PyTorch バージョンのインストール手順やバイナリは
<a href="https://pytorch.org/get-started/previous-versions">公式サイト</a> で確認できます。</p>
<h2>はじめに</h2>
<p>入門に役立つ3つのポイント：</p>
<ul>
<li><a href="https://pytorch.org/tutorials/">チュートリアル: PyTorch の理解と利用を始める</a></li>
<li><a href="https://github.com/pytorch/examples">サンプル: 各ドメイン向けの分かりやすい PyTorch コード</a></li>
<li><a href="https://pytorch.org/docs/">API リファレンス</a></li>
<li><a href="https://github.com/pytorch/pytorch/blob/main/GLOSSARY.md">用語集</a></li>
</ul>
<h2>リソース</h2>
<ul>
<li><a href="https://pytorch.org/">PyTorch.org</a></li>
<li><a href="https://pytorch.org/tutorials/">PyTorch チュートリアル</a></li>
<li><a href="https://github.com/pytorch/examples">PyTorch サンプル</a></li>
<li><a href="https://pytorch.org/hub/">PyTorch モデル</a></li>
<li><a href="https://www.udacity.com/course/deep-learning-pytorch--ud188">Udacity による PyTorch 入門</a></li>
<li><a href="https://www.udacity.com/course/intro-to-machine-learning-nanodegree--nd229">Udacity による PyTorch で始める機械学習</a></li>
<li><a href="https://www.coursera.org/learn/deep-neural-networks-with-pytorch">Coursera による PyTorch で学ぶディープニューラルネットワーク</a></li>
<li><a href="https://twitter.com/PyTorch">PyTorch Twitter</a></li>
<li><a href="https://pytorch.org/blog/">PyTorch ブログ</a></li>
<li><a href="https://www.youtube.com/channel/UCWXI5YeOsh03QvJ59PMaXFw">PyTorch YouTube</a></li>
</ul>
<h2>コミュニケーション</h2>
<ul>
<li>フォーラム: 実装・研究などの議論 https://discuss.pytorch.org</li>
<li>GitHub Issues: バグ報告、機能要望、インストール問題、RFC、意見交換など</li>
<li>Slack: <a href="https://pytorch.slack.com/">PyTorch Slack</a> には中級～上級 PyTorch ユーザー・開発者向けのチャットや議論の場があります。初心者の方は主に <a href="https://discuss.pytorch.org">PyTorch Forums</a> をご利用ください。Slack 招待が必要な場合は次のフォームを記入してください: https://goo.gl/forms/PP1AGvNHpSaJP8to1</li>
<li>ニュースレター: ノイズなしで重要なお知らせのみの一方向メールニュース。登録はこちら: https://eepurl.com/cbG0rv</li>
<li>Facebook ページ: PyTorch の重要なお知らせ https://www.facebook.com/pytorch</li>
<li>ブランドガイドラインは <a href="https://pytorch.org/">pytorch.org</a> をご参照ください。</li>
</ul>
<h2>リリースとコントリビュート</h2>
<p>通常、PyTorch は年3回のマイナーリリースを行っています。バグを見つけたら <a href="https://github.com/pytorch/pytorch/issues">Issue を登録</a> してください。</p>
<p>全てのコントリビュートを歓迎します。バグ修正のコントリビュートは事前相談なしで構いません。</p>
<p>新機能・ユーティリティ・コア拡張などを提案したい場合は、まず issue を立ててご相談ください。
事前相談なしで PR を送ると、プロジェクトの方向性次第でリジェクトされる場合があります。</p>
<p>PyTorch へのコントリビュート方法は <a href="CONTRIBUTING.md">Contribution ページ</a> を、
リリース情報は <a href="RELEASE.md">Release ページ</a> を参照してください。</p>
<h2>チーム</h2>
<p>PyTorch は、多くの優れたエンジニア・研究者によるコミュニティ主導のプロジェクトです。</p>
<p>現在の PyTorch メンテナーは <a href="http://soumith.ch">Soumith Chintala</a>, <a href="https://github.com/gchanan">Gregory Chanan</a>, <a href="https://github.com/dzhulgakov">Dmytro Dzhulgakov</a>, <a href="https://github.com/ezyang">Edward Yang</a>, <a href="https://github.com/malfet">Nikita Shulga</a> です。その他、多数の才能ある個人が多様な形で貢献しています。
（抜粋・随時拡大中）：<a href="https://github.com/killeent">Trevor Killeen</a>, <a href="https://github.com/chsasank">Sasank Chilamkurthy</a>, <a href="https://github.com/szagoruyko">Sergey Zagoruyko</a>, <a href="https://github.com/adamlerer">Adam Lerer</a>, <a href="https://github.com/fmassa">Francisco Massa</a>, <a href="https://github.com/alykhantejani">Alykhan Tejani</a>, <a href="https://github.com/lantiga">Luca Antiga</a>, <a href="https://github.com/albanD">Alban Desmaison</a>, <a href="https://github.com/andreaskoepf">Andreas Koepf</a>, <a href="https://github.com/jekbradbury">James Bradbury</a>, <a href="https://github.com/ebetica">Zeming Lin</a>, <a href="https://github.com/yuandong-tian">Yuandong Tian</a>, <a href="https://github.com/glample">Guillaume Lample</a>, <a href="https://github.com/Maratyszcza">Marat Dukhan</a>, <a href="https://github.com/ngimel">Natalia Gimelshein</a>, <a href="https://github.com/csarofeen">Christian Sarofeen</a>, <a href="https://github.com/martinraison">Martin Raison</a>, <a href="https://github.com/ezyang">Edward Yang</a>, <a href="https://github.com/zdevito">Zachary Devito</a> など。</p>
<p>注意：このプロジェクトは、同名の <a href="https://github.com/hughperkins/pytorch">hughperkins/pytorch</a> とは無関係です。Hugh 氏は Torch コミュニティの貴重な貢献者であり、Torch および PyTorch の多くの事柄に協力しています。</p>
<h2>ライセンス</h2>
<p>PyTorch は BSD スタイルのライセンスです。詳細は <a href="LICENSE">LICENSE</a> ファイルをご覧ください。</p>
<hr />
<p><a href="https://github.com/OpenAiTx/OpenAiTx">Powered By OpenAiTx</a></p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
</body>
</html>