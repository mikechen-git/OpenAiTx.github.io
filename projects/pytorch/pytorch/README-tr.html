<!DOCTYPE html>
<html lang="tr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>pytorch - pytorch/pytorch</title>
    <meta name="title" content="pytorch - pytorch/pytorch">
    <meta name="description" content="pytorch/pytorch - GitHub repository tr documentation and informationPyTorch, iki üst düzey özelliğe sahip bir Python paketidir: Güçlü GPU hızlandırmalı tensör hesaplaması (NumPy gibi) Bant tabanlı otomatik türev sistemiyle oluşt...">
    <meta name="keywords" content="pytorch, pytorch, GitHub, repository, tr documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/pytorch/pytorch/README-tr.html">
    <meta property="og:title" content="pytorch - pytorch/pytorch">
    <meta property="og:description" content="pytorch/pytorch - GitHub repository tr documentation and information">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/pytorch/pytorch" id="githubRepoLink" target="_blank">pytorch/pytorch</a>
<h1 style="display: none;">PyTorch, iki üst düzey özelliğe sahip bir Python paketidir: Güçlü GPU hızlandırmalı tensör hesaplaması (NumPy gibi) Bant tabanlı otomatik türev sistemiyle oluşt...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <p><img src="https://github.com/pytorch/pytorch/raw/main/docs/source/_static/img/pytorch-logo-dark.png" alt="PyTorch Logosu" /></p>
<hr />
<p>PyTorch, iki üst düzey özelliğe sahip bir Python paketidir:</p>
<ul>
<li>Güçlü GPU hızlandırmalı tensör hesaplaması (NumPy gibi)</li>
<li>Bant tabanlı otomatik türev sistemiyle oluşturulmuş derin sinir ağları</li>
</ul>
<p>İhtiyaç duyduğunuzda PyTorch'u genişletmek için NumPy, SciPy ve Cython gibi favori Python paketlerinizi yeniden kullanabilirsiniz.</p>
<p>Ana daldaki sağlık durumu (Sürekli Entegrasyon sinyalleri) <a href="https://hud.pytorch.org/ci/pytorch/pytorch/main">hud.pytorch.org</a> adresinde bulunabilir.</p>
<!-- toc -->
<ul>
<li><a href="#more-about-pytorch">PyTorch Hakkında Daha Fazlası</a>
<ul>
<li><a href="#a-gpu-ready-tensor-library">GPU'ya Hazır Bir Tensör Kütüphanesi</a></li>
<li><a href="#dynamic-neural-networks-tape-based-autograd">Dinamik Sinir Ağları: Bant Tabanlı Otomatik Türev</a></li>
<li><a href="#python-first">Öncelik Python'da</a></li>
<li><a href="#imperative-experiences">Emirsel Deneyimler</a></li>
<li><a href="#fast-and-lean">Hızlı ve Hafif</a></li>
<li><a href="#extensions-without-pain">Sorunsuz Genişletmeler</a></li>
</ul>
</li>
<li><a href="#installation">Kurulum</a>
<ul>
<li><a href="#binaries">İkili Dosyalar</a>
<ul>
<li><a href="#nvidia-jetson-platforms">NVIDIA Jetson Platformları</a></li>
</ul>
</li>
<li><a href="#from-source">Kaynaktan Kurulum</a>
<ul>
<li><a href="#prerequisites">Önkoşullar</a>
<ul>
<li><a href="#nvidia-cuda-support">NVIDIA CUDA Desteği</a></li>
<li><a href="#amd-rocm-support">AMD ROCm Desteği</a></li>
<li><a href="#intel-gpu-support">Intel GPU Desteği</a></li>
</ul>
</li>
<li><a href="#get-the-pytorch-source">PyTorch Kaynağını Edinin</a></li>
<li><a href="#install-dependencies">Bağımlılıkları Kurun</a></li>
<li><a href="#install-pytorch">PyTorch'u Kurun</a>
<ul>
<li><a href="#adjust-build-options-optional">Derleme Seçeneklerini Ayarlama (İsteğe Bağlı)</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#docker-image">Docker İmajı</a>
<ul>
<li><a href="#using-pre-built-images">Hazır İmajların Kullanılması</a></li>
<li><a href="#building-the-image-yourself">Kendi İmajınızı Oluşturma</a></li>
</ul>
</li>
<li><a href="#building-the-documentation">Dokümantasyonu Derleme</a>
<ul>
<li><a href="#building-a-pdf">PDF Oluşturma</a></li>
</ul>
</li>
<li><a href="#previous-versions">Önceki Sürümler</a></li>
</ul>
</li>
<li><a href="#getting-started">Başlangıç</a></li>
<li><a href="#resources">Kaynaklar</a></li>
<li><a href="#communication">İletişim</a></li>
<li><a href="#releases-and-contributing">Sürümler ve Katkı</a></li>
<li><a href="#the-team">Ekip</a></li>
<li><a href="#license">Lisans</a></li>
</ul>
<!-- tocstop -->
<h2>PyTorch Hakkında Daha Fazlası</h2>
<p><a href="https://pytorch.org/tutorials/beginner/basics/intro.html">PyTorch'un temellerini öğrenin</a></p>
<p>Detaylı olarak, PyTorch aşağıdaki bileşenlerden oluşan bir kütüphanedir:</p>
<p>| Bileşen | Açıklama |
| ---- | --- |
| <a href="https://pytorch.org/docs/stable/torch.html"><strong>torch</strong></a> | NumPy gibi bir Tensör kütüphanesi, güçlü GPU desteğiyle |
| <a href="https://pytorch.org/docs/stable/autograd.html"><strong>torch.autograd</strong></a> | torch içindeki tüm türevlenebilir Tensör işlemlerini destekleyen bant tabanlı otomatik türev kütüphanesi |
| <a href="https://pytorch.org/docs/stable/jit.html"><strong>torch.jit</strong></a> | PyTorch kodundan serileştirilebilir ve optimize edilebilir modeller oluşturan bir derleme yığını (TorchScript) |
| <a href="https://pytorch.org/docs/stable/nn.html"><strong>torch.nn</strong></a> | Maksimum esneklik için autograd ile derinlemesine entegre edilmiş bir sinir ağları kütüphanesi |
| <a href="https://pytorch.org/docs/stable/multiprocessing.html"><strong>torch.multiprocessing</strong></a> | torch Tensörlerinin işlemler arasında sihirli bellek paylaşımı ile Python çoklu işlem. Veri yükleme ve Hogwild eğitimi için faydalı |
| <a href="https://pytorch.org/docs/stable/data.html"><strong>torch.utils</strong></a> | Kolaylık için DataLoader ve diğer yardımcı işlevler |</p>
<p>Genellikle, PyTorch ya:</p>
<ul>
<li>GPU’ların gücünü kullanmak için NumPy yerine,</li>
<li>Maksimum esneklik ve hız sağlayan bir derin öğrenme araştırma platformu olarak kullanılır.</li>
</ul>
<p>Daha Fazlası:</p>
<h3>GPU'ya Hazır Bir Tensör Kütüphanesi</h3>
<p>NumPy kullanıyorsanız, zaten Tensörleri (veya ndarray) kullanıyorsunuz demektir.</p>
<p><img src="./docs/source/_static/img/tensor_illustration.png" alt="Tensör illüstrasyonu" /></p>
<p>PyTorch, CPU veya GPU üzerinde yaşayabilen Tensörler sağlar ve
hesaplamayı büyük ölçüde hızlandırır.</p>
<p>Bilimsel hesaplama ihtiyaçlarınızı karşılamak ve hızlandırmak için çok çeşitli tensör rutinleri sağlıyoruz:
bölütleme, indeksleme, matematiksel işlemler, lineer cebir, indirgemeler gibi.
Ve bunlar oldukça hızlıdır!</p>
<h3>Dinamik Sinir Ağları: Bant Tabanlı Otomatik Türev</h3>
<p>PyTorch, sinir ağlarını kurmak için benzersiz bir yol sunar: bir bant kaydedici kullanmak ve tekrar oynatmak.</p>
<p>TensorFlow, Theano, Caffe ve CNTK gibi çoğu framework dünyayı statik olarak görür.
Bir sinir ağı inşa edilir ve aynı yapı tekrar tekrar kullanılır.
Ağın davranışını değiştirmek için sıfırdan başlamak gerekir.</p>
<p>PyTorch ile, ters mod otomatik türevleme (reverse-mode auto-differentiation) adı verilen bir teknik kullanıyoruz; bu, ağınızın davranışını gecikmesiz ve ek yük olmadan keyfi olarak değiştirmenize olanak tanır. İlham kaynağımız bu konudaki çeşitli araştırma makaleleri ile <a href="https://github.com/twitter/torch-autograd">torch-autograd</a>,
<a href="https://github.com/HIPS/autograd">autograd</a>,
<a href="https://chainer.org">Chainer</a> gibi önceki ve güncel çalışmalardır.</p>
<p>Bu teknik sadece PyTorch'a özgü olmasa da, bugüne kadarki en hızlı uygulamalardan biridir.
Çılgın araştırmalarınız için hız ve esnekliğin en iyisini elde edersiniz.</p>
<p><img src="https://github.com/pytorch/pytorch/raw/main/docs/source/_static/img/dynamic_graph.gif" alt="Dinamik grafik" /></p>
<h3>Öncelik Python'da</h3>
<p>PyTorch, tekdüze bir C++ framework'üne Python bağlaması değildir.
Python ile derinlemesine entegre olacak şekilde inşa edilmiştir.
<a href="https://www.numpy.org/">NumPy</a> / <a href="https://www.scipy.org/">SciPy</a> / <a href="https://scikit-learn.org">scikit-learn</a> gibi doğal olarak kullanabilirsiniz.
Yeni sinir ağı katmanlarınızı doğrudan Python'da, favori kütüphanelerinizi kullanarak yazabilirsiniz
ve <a href="https://cython.org/">Cython</a> ile <a href="http://numba.pydata.org/">Numba</a> gibi paketler kullanabilirsiniz.
Amacımız, uygun olan yerde tekerleği yeniden icat etmemektir.</p>
<h3>Emirsel Deneyimler</h3>
<p>PyTorch, sezgisel, doğrusal düşünceye uygun ve kullanımı kolay olacak şekilde tasarlanmıştır.
Bir kod satırı çalıştırdığınızda, hemen çalışır. Asenkron bir dünya yoktur.
Bir hata mesajı veya stack trace aldığınızda, anlaması kolaydır.
Stack trace doğrudan kodunuzun tanımlandığı yere işaret eder.
Kötü stack trace'ler veya asenkron ve opak yürütme motorları yüzünden saatlerce hata ayıklamak zorunda kalmamanızı umuyoruz.</p>
<h3>Hızlı ve Hafif</h3>
<p>PyTorch, minimum framework yüküne sahiptir. <a href="https://software.intel.com/mkl">Intel MKL</a> ve NVIDIA (<a href="https://developer.nvidia.com/cudnn">cuDNN</a>, <a href="https://developer.nvidia.com/nccl">NCCL</a>) gibi hızlandırıcı kütüphaneler entegre ediyoruz.
Çekirdekteki CPU ve GPU Tensör ile sinir ağı arka uçları
oldukça olgundur ve yıllardır test edilmektedir.</p>
<p>Bu nedenle, PyTorch oldukça hızlıdır — ister küçük ister büyük sinir ağları çalıştırıyor olun.</p>
<p>PyTorch'taki bellek kullanımı, Torch veya bazı alternatiflerle karşılaştırıldığında son derece verimlidir.
GPU için özel bellek ayırıcılar yazdık, böylece
derin öğrenme modelleriniz maksimum bellek verimliliğine sahip olur.
Bu, daha önceki modellere göre daha büyük derin öğrenme modelleri eğitmenizi sağlar.</p>
<h3>Sorunsuz Genişletmeler</h3>
<p>Yeni sinir ağı modülleri yazmak veya PyTorch'un Tensör API'siyle arayüz oluşturmak, basit ve minimum soyutlamalarla tasarlanmıştır.</p>
<p>torch API'sini kullanarak Python'da yeni sinir ağı katmanları
<a href="https://pytorch.org/tutorials/advanced/numpy_extensions_tutorial.html">veya SciPy gibi favori NumPy tabanlı kütüphanelerinizle</a> yazabilirsiniz.</p>
<p>Katmanlarınızı C/C++'ta yazmak isterseniz, verimli ve az kod gerektiren uygun bir genişletme API'si sağlıyoruz.
Ek bir sarmalayıcı kod yazmanız gerekmez. <a href="https://pytorch.org/tutorials/advanced/cpp_extension.html">Burada bir eğitim</a> ve <a href="https://github.com/pytorch/extension-cpp">örnek</a> bulabilirsiniz.</p>
<h2>Kurulum</h2>
<h3>İkili Dosyalar</h3>
<p>Conda veya pip wheels ile ikili dosyaları yüklemek için komutlar web sitemizdedir: <a href="https://pytorch.org/get-started/locally/">https://pytorch.org/get-started/locally/</a></p>
<h4>NVIDIA Jetson Platformları</h4>
<p>NVIDIA'nın Jetson Nano, Jetson TX1/TX2, Jetson Xavier NX/AGX ve Jetson AGX Orin için Python wheel dosyaları <a href="https://forums.developer.nvidia.com/t/pytorch-for-jetson-version-1-10-now-available/72048">burada</a> sağlanmıştır ve L4T container <a href="https://catalog.ngc.nvidia.com/orgs/nvidia/containers/l4t-pytorch">burada</a> yayınlanmıştır.</p>
<p>JetPack 4.2 ve üstü gereklidir, ve <a href="https://github.com/dusty-nv">@dusty-nv</a> ile <a href="https://github.com/ptrblck">@ptrblck</a> tarafından bakım yapılmaktadır.</p>
<h3>Kaynaktan Kurulum</h3>
<h4>Önkoşullar</h4>
<p>Kaynak koddan kurulum yapacaksanız, şunlara ihtiyacınız olacak:</p>
<ul>
<li>Python 3.9 veya üstü</li>
<li>C++17'yi tamamen destekleyen bir derleyici, örn. clang veya gcc (Linux'ta gcc 9.4.0 veya üstü gereklidir)</li>
<li>Visual Studio veya Visual Studio Build Tool (sadece Windows için)</li>
</ul>
<p>* PyTorch CI, Visual Studio Enterprise, Professional veya Community Sürümleriyle gelen Visual C++ BuildTools'u kullanır. Build tools'u ayrıca https://visualstudio.microsoft.com/visual-cpp-build-tools/ adresinden kurabilirsiniz. Build tools <em>varsayılan olarak</em> Visual Studio Code ile gelmez.</p>
<p>Aşağıda bir ortam kurulumu örneği gösterilmiştir:</p>
<ul>
<li>Linux:</li>
</ul>
<pre><code class="language-bash">$ source &lt;CONDA_INSTALL_DIR&gt;/bin/activate
$ conda create -y -n &lt;CONDA_NAME&gt;
$ conda activate &lt;CONDA_NAME&gt;
</code></pre>
<ul>
<li>Windows:</li>
</ul>
<pre><code class="language-bash">$ source &lt;CONDA_INSTALL_DIR&gt;\Scripts\activate.bat
$ conda create -y -n &lt;CONDA_NAME&gt;
$ conda activate &lt;CONDA_NAME&gt;
$ call &quot;C:\Program Files\Microsoft Visual Studio\&lt;VERSION&gt;\Community\VC\Auxiliary\Build\vcvarsall.bat&quot; x64
</code></pre>
<h5>NVIDIA CUDA Desteği</h5>
<p>CUDA desteğiyle derleme yapmak istiyorsanız, <a href="https://pytorch.org/get-started/locally/">destek matrisimizden desteklenen bir CUDA sürümü seçin</a>, ardından şunları yükleyin:</p>
<ul>
<li><a href="https://developer.nvidia.com/cuda-downloads">NVIDIA CUDA</a></li>
<li><a href="https://developer.nvidia.com/cudnn">NVIDIA cuDNN</a> v8.5 veya üstü</li>
<li>CUDA ile uyumlu <a href="https://gist.github.com/ax3l/9489132">Derleyici</a></li>
</ul>
<p>Not: <a href="https://docs.nvidia.com/deeplearning/cudnn/backend/latest/reference/support-matrix.html">cuDNN Destek Matrisi</a> üzerinden, farklı CUDA, CUDA sürücüsü ve NVIDIA donanımlarıyla uyumlu cuDNN sürümlerine bakabilirsiniz.</p>
<p>CUDA desteğini devre dışı bırakmak isterseniz, <code>USE_CUDA=0</code> ortam değişkenini dışa aktarın.
Diğer faydalı ortam değişkenleri <code>setup.py</code> içinde bulunabilir.</p>
<p>NVIDIA'nın Jetson platformları (Jetson Nano, TX1, TX2, AGX Xavier) için derleme yapıyorsanız, Jetson Nano için PyTorch kurulum talimatları <a href="https://devtalk.nvidia.com/default/topic/1049071/jetson-nano/pytorch-for-jetson-nano/">burada</a> mevcuttur.</p>
<h5>AMD ROCm Desteği</h5>
<p>ROCm desteğiyle derleme yapmak istiyorsanız, şunları yükleyin:</p>
<ul>
<li><a href="https://rocm.docs.amd.com/en/latest/deploy/linux/quick_start.html">AMD ROCm</a> 4.0 ve üstü</li>
<li>ROCm şu anda sadece Linux sistemlerinde desteklenmektedir.</li>
</ul>
<p>Varsayılan olarak derleme sistemi, ROCm'un <code>/opt/rocm</code> dizinine kurulu olduğunu varsayar. ROCm farklı bir dizine kuruluysa, <code>ROCM_PATH</code> ortam değişkeni ROCm kurulum dizinine ayarlanmalıdır. Derleme sistemi AMD GPU mimarisini otomatik olarak algılar. İsteğe bağlı olarak, AMD GPU mimarisi <code>PYTORCH_ROCM_ARCH</code> ortam değişkeniyle açıkça ayarlanabilir <a href="https://rocm.docs.amd.com/projects/install-on-linux/en/latest/reference/system-requirements.html#supported-gpus">AMD GPU mimarisi</a></p>
<p>ROCm desteğini devre dışı bırakmak için <code>USE_ROCM=0</code> ortam değişkenini dışa aktarın.
Diğer faydalı ortam değişkenleri <code>setup.py</code> içinde bulunabilir.</p>
<h5>Intel GPU Desteği</h5>
<p>Intel GPU desteğiyle derleme yapmak istiyorsanız, şunları takip edin:</p>
<ul>
<li><a href="https://www.intel.com/content/www/us/en/developer/articles/tool/pytorch-prerequisites-for-intel-gpus.html">Intel GPU'lar için PyTorch Önkoşulları</a> talimatları.</li>
<li>Intel GPU desteği Linux ve Windows için mevcuttur.</li>
</ul>
<p>Intel GPU desteğini devre dışı bırakmak için <code>USE_XPU=0</code> ortam değişkenini dışa aktarın.
Diğer faydalı ortam değişkenleri <code>setup.py</code> içinde bulunabilir.</p>
<h4>PyTorch Kaynağını Edinin</h4>
<pre><code class="language-bash">git clone https://github.com/pytorch/pytorch
cd pytorch
# mevcut bir checkout'u güncelliyorsanız
git submodule sync
git submodule update --init --recursive
</code></pre>
<h4>Bağımlılıkları Kurun</h4>
<p><strong>Ortak</strong></p>
<pre><code class="language-bash">conda install cmake ninja
# Aşağıdaki “PyTorch Kaynağını Edinin” bölümünden kaynak kodunu klonladıktan sonra bu komutu PyTorch dizininde çalıştırın
pip install -r requirements.txt
</code></pre>
<p><strong>Linux'ta</strong></p>
<pre><code class="language-bash">pip install mkl-static mkl-include
# Sadece CUDA: Gerekirse GPU için LAPACK desteği ekleyin
# magma kurulumu: aktif conda ortamında çalıştırın. kurulacak CUDA sürümünü belirtin
.ci/docker/common/install_magma_conda.sh 12.4

# (isteğe bağlı) torch.compile ile inductor/triton kullanıyorsanız, triton'un uyumlu sürümünü kurun
# pytorch dizininde çalıştırın
# Intel GPU desteği için, komutu çalıştırmadan önce `export USE_XPU=1` komutunu açıkça verin.
make triton
</code></pre>
<p><strong>MacOS'ta</strong></p>
<pre><code class="language-bash"># Sadece intel x86 işlemcili makinelerde bu paketi ekleyin
pip install mkl-static mkl-include
# torch.distributed gerekiyorsa bu paketleri ekleyin
conda install pkg-config libuv
</code></pre>
<p><strong>Windows'ta</strong></p>
<pre><code class="language-bash">pip install mkl-static mkl-include
# torch.distributed gerekiyorsa bu paketleri ekleyin.
# Windows'ta distributed paket desteği prototip aşamasındadır ve değişebilir.
conda install -c conda-forge libuv=1.39
</code></pre>
<h4>PyTorch'u Kurun</h4>
<p><strong>Linux'ta</strong></p>
<p>AMD ROCm için derleme yapıyorsanız öncelikle bu komutu çalıştırın:</p>
<pre><code class="language-bash"># Sadece ROCm için derliyorsanız çalıştırın
python tools/amd_build/build_amd.py
</code></pre>
<p>PyTorch'u Kurun</p>
<pre><code class="language-bash">export CMAKE_PREFIX_PATH=&quot;${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}&quot;
python setup.py develop
</code></pre>
<p><strong>macOS'ta</strong></p>
<pre><code class="language-bash">python3 setup.py develop
</code></pre>
<p><strong>Windows'ta</strong></p>
<p>Eski python kodu için derleme yapmak isterseniz, <a href="https://github.com/pytorch/pytorch/blob/main/CONTRIBUTING.md#building-on-legacy-code-and-cuda">Eski kod ve CUDA ile Derleme</a> başvurusuna bakın.</p>
<p><strong>Sadece CPU derlemesi</strong></p>
<p>Bu modda PyTorch hesaplamaları GPU yerine CPU'nuzda çalışacaktır.</p>
<pre><code class="language-cmd">python setup.py develop
</code></pre>
<p>OpenMP notu: İstenen OpenMP uygulaması Intel OpenMP (iomp)'dur. iomp'a bağlanmak için kütüphaneyi manuel indirmeniz ve <code>CMAKE_INCLUDE_PATH</code> ile <code>LIB</code> ortamlarını ayarlamanız gerekir. <a href="https://github.com/pytorch/pytorch/blob/main/docs/source/notes/windows.rst#building-from-source">Buradaki</a> talimatlar MKL ve Intel OpenMP'nin nasıl kurulacağına dair örnektir. Bu CMake yapılandırmaları olmadan, Microsoft Visual C OpenMP runtime (vcomp) kullanılacaktır.</p>
<p><strong>CUDA tabanlı derleme</strong></p>
<p>Bu modda PyTorch hesaplamaları, daha hızlı hesaplama için GPU'nuzu CUDA üzerinden kullanacaktır.</p>
<p>PyTorch'u CUDA ile derlemek için <a href="https://docs.nvidia.com/gameworks/content/gameworkslibrary/nvtx/nvidia_tools_extension_library_nvtx.htm">NVTX</a> gereklidir.
NVTX, CUDA dağıtımının bir parçasıdır ve &quot;Nsight Compute&quot; olarak adlandırılır. Zaten kurulu bir CUDA'ya eklemek için CUDA kurulumunu tekrar çalıştırıp ilgili seçeneği işaretleyin.
CUDA ve Nsight Compute'un Visual Studio'dan sonra kurulu olduğundan emin olun.</p>
<p>Şu anda, CMake için VS 2017 / 2019 ve Ninja desteklenmektedir. <code>ninja.exe</code> <code>PATH</code> içinde tespit edilirse, Ninja varsayılan jeneratör olarak kullanılır, aksi takdirde VS 2017 / 2019 kullanılır.
<br/> Jeneratör olarak Ninja seçilirse, en son MSVC altta yatan araç seti olarak seçilecektir.</p>
<p>Ek kütüphaneler olarak
<a href="https://developer.nvidia.com/magma">Magma</a>, <a href="https://github.com/oneapi-src/oneDNN">oneDNN, diğer adıyla MKLDNN veya DNNL</a> ve <a href="https://github.com/mozilla/sccache">Sccache</a> çoğunlukla gereklidir. Kurulum için <a href="https://github.com/pytorch/pytorch/tree/main/.ci/pytorch/win-test-helpers/installation-helpers">installation-helper</a> başvurusuna bakabilirsiniz.</p>
<p>Bazı diğer ortam değişkenleri ayarları için <a href="https://github.com/pytorch/pytorch/blob/main/.ci/pytorch/win-test-helpers/build_pytorch.bat">build_pytorch.bat</a> scriptine bakabilirsiniz.</p>
<pre><code class="language-cmd">cmd

:: mkl paketini indirip açtıktan sonra ortam değişkenlerini ayarlayın,
:: aksi halde CMake `Could NOT find OpenMP` hatası verecektir.
set CMAKE_INCLUDE_PATH={Your directory}\mkl\include
set LIB={Your directory}\mkl\lib;%LIB%

:: Önceki bölümü dikkatlice okuyun.
:: [İsteğe Bağlı] Ninja ve Visual Studio ile CUDA kullanırken alt araç setini değiştirmek isterseniz aşağıdaki komut bloğunu çalıştırın.
:: &quot;Visual Studio 2019 Developer Command Prompt&quot; otomatik olarak çalışacaktır.
:: Visual Studio jeneratörü kullanırken CMake &gt;= 3.12 gereklidir.
set CMAKE_GENERATOR_TOOLSET_VERSION=14.27
set DISTUTILS_USE_SDK=1
for /f &quot;usebackq tokens=*&quot; %i in (`&quot;%ProgramFiles(x86)%\Microsoft Visual Studio\Installer\vswhere.exe&quot; -version [15^,17^) -products * -latest -property installationPath`) do call &quot;%i\VC\Auxiliary\Build\vcvarsall.bat&quot; x64 -vcvars_ver=%CMAKE_GENERATOR_TOOLSET_VERSION%

:: [İsteğe Bağlı] CUDA ana derleyicisini değiştirmek isterseniz
set CUDAHOSTCXX=C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.27.29110\bin\HostX64\x64\cl.exe

python setup.py develop

</code></pre>
<p><strong>Intel GPU derlemesi</strong></p>
<p>Bu modda Intel GPU desteğiyle PyTorch derlenecektir.</p>
<p><a href="#prerequisites">Lütfen ortak önkoşullar</a> ve <a href="#intel-gpu-support">Intel GPU için önkoşullar</a> düzgün yüklendiğinden ve ortam değişkenleri ayarlandığından emin olun. Derleme aracı desteği için <code>Visual Studio 2022</code> gereklidir.</p>
<p>Daha sonra PyTorch şu komutla derlenebilir:</p>
<pre><code class="language-cmd">:: CMD Komutları:
:: Karşılık gelen paketleri bulmak için CMAKE_PREFIX_PATH ayarlayın
:: %CONDA_PREFIX% sadece `conda activate custom_env` sonrası çalışır

if defined CMAKE_PREFIX_PATH (
    set &quot;CMAKE_PREFIX_PATH=%CONDA_PREFIX%\Library;%CMAKE_PREFIX_PATH%&quot;
) else (
    set &quot;CMAKE_PREFIX_PATH=%CONDA_PREFIX%\Library&quot;
)

python setup.py develop
</code></pre>
<h5>Derleme Seçeneklerini Ayarlama (İsteğe Bağlı)</h5>
<p>Cmake değişkenlerinin yapılandırmasını isteğe bağlı olarak (önceden derleme yapmadan) aşağıdaki gibi ayarlayabilirsiniz. Örneğin, CuDNN veya BLAS için önceden tespit edilen dizinleri ayarlamak bu adımla mümkündür.</p>
<p>Linux'ta</p>
<pre><code class="language-bash">export CMAKE_PREFIX_PATH=&quot;${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}&quot;
python setup.py build --cmake-only
ccmake build  # veya cmake-gui build
</code></pre>
<p>macOS'ta</p>
<pre><code class="language-bash">export CMAKE_PREFIX_PATH=&quot;${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}&quot;
MACOSX_DEPLOYMENT_TARGET=10.9 CC=clang CXX=clang++ python setup.py build --cmake-only
ccmake build  # veya cmake-gui build
</code></pre>
<h3>Docker İmajı</h3>
<h4>Hazır İmajların Kullanılması</h4>
<p>Docker Hub'dan önceden hazırlanmış bir docker imajını çekebilir ve docker v19.03+ ile çalıştırabilirsiniz</p>
<pre><code class="language-bash">docker run --gpus all --rm -ti --ipc=host pytorch/pytorch:latest
</code></pre>
<p>PyTorch'un işlemler arasında veri paylaşımı için shared memory kullandığını unutmayın, bu nedenle torch multiprocessing kullanılırsa (ör. çoklu iş parçacıklı veri yükleyiciler için) konteynerin varsayılan shared memory segment boyutu yeterli olmayacaktır; bu nedenle, shared memory boyutunu <code>--ipc=host</code> veya <code>--shm-size</code> komut satırı seçenekleriyle artırmalısınız.</p>
<h4>Kendi İmajınızı Oluşturma</h4>
<p><strong>NOT:</strong> Docker'ın 18.06'dan büyük bir sürümüyle oluşturulmalıdır.</p>
<p><code>Dockerfile</code>, CUDA 11.1 desteği ve cuDNN v8 ile imaj oluşturmak için sağlanmıştır.
Hangi Python sürümünün Miniconda tarafından kullanılacağını belirtmek için <code>PYTHON_VERSION=x.y</code> make değişkenini iletebilir veya varsayılanı kullanmak için bırakabilirsiniz.</p>
<pre><code class="language-bash">make -f docker.Makefile
# imajlar docker.io/${your_docker_username}/pytorch olarak etiketlenir
</code></pre>
<p>Ek CMake değişkenlerini derleme sırasında CMake'e iletmek için <code>CMAKE_VARS=&quot;...&quot;</code> ortam değişkenini de verebilirsiniz.
Kullanılabilir değişkenlerin listesi için <a href="./setup.py">setup.py</a> dosyasına bakınız.</p>
<pre><code class="language-bash">make -f docker.Makefile
</code></pre>
<h3>Dokümantasyonu Derleme</h3>
<p>Dokümantasyonu çeşitli formatlarda oluşturmak için <a href="http://www.sphinx-doc.org">Sphinx</a>
ve pytorch_sphinx_theme2 gereklidir.</p>
<p>Dokümantasyonu yerel olarak oluşturmadan önce, ortamınıza <code>torch</code> kurulu olduğundan emin olun. Küçük düzeltmeler için, <a href="https://pytorch.org/get-started/locally/">Başlangıç</a> bölümünde anlatıldığı gibi nightly sürümü kurabilirsiniz.</p>
<p>Yeni bir modül eklemek ve bunun için docstring eklemek gibi daha karmaşık düzeltmeler için, torch'u <a href="#from-source">kaynak koddan</a> yüklemeniz gerekebilir.
Docstring kuralları için <a href="https://github.com/pytorch/pytorch/wiki/Docstring-Guidelines">Docstring Guidelines</a> sayfasına bakınız.</p>
<pre><code class="language-bash">cd docs/
pip install -r requirements.txt
make html
make serve
</code></pre>
<p>Tüm mevcut çıktı formatları listesini almak için <code>make</code> komutunu çalıştırın.</p>
<p>Eğer katex hatası alırsanız <code>npm install katex</code> çalıştırın. Sorun devam ederse
<code>npm install -g katex</code> deneyin.</p>
<blockquote>
<p>[!NOT]
Eğer <code>nodejs</code>'i farklı bir paket yöneticisiyle (örn. <code>conda</code>) yüklediyseniz, <code>npm</code> büyük olasılıkla <code>nodejs</code> sürümünüzle uyumlu olmayan bir <code>katex</code> sürümü yükleyecek ve dokümantasyon derlemesi başarısız olacaktır.
Bilinen çalışan bir sürüm kombinasyonu <code>node@6.13.1</code> ve
<code>katex@0.13.18</code>'dir. Sonuncuyu yüklemek için:
<code>npm install -g katex@0.13.18</code></p>
</blockquote>
<blockquote>
<p>[!NOT]
numpy uyumsuzluk hatası görürseniz:</p>
<pre><code>pip install 'numpy&lt;2'
</code></pre>
</blockquote>
<p>CI tarafından çalıştırılan bağımlılıkları değiştirdiğinizde
<code>.ci/docker/requirements-docs.txt</code> dosyasını düzenleyin.</p>
<h4>PDF Oluşturma</h4>
<p>Tüm PyTorch dokümantasyonunun PDF'ini derlemek için,
<code>texlive</code> ve LaTeX kurulu olmalıdır. macOS'ta, şunlarla kurabilirsiniz:</p>
<pre><code>brew install --cask mactex
</code></pre>
<p>PDF oluşturmak için:</p>
<ol>
<li><p>Şunu çalıştırın:</p>
<pre><code>make latexpdf
</code></pre>
<p>Gerekli dosyalar <code>build/latex</code> dizininde oluşturulacaktır.</p>
</li>
<li><p>Bu dizine gidip şunu çalıştırın:</p>
<pre><code>make LATEXOPTS=&quot;-interaction=nonstopmode&quot;
</code></pre>
<p>Bu, istenen içeriğe sahip bir <code>pytorch.pdf</code> oluşturacaktır. Doğru içindekiler tablosu ve indeksin oluşturulması için komutu bir kez daha çalıştırın.</p>
</li>
</ol>
<blockquote>
<p>[!NOT]
İçindekiler Tablosunu görmek için, PDF görüntüleyicinizde <strong>Table of Contents</strong> görünümüne geçin.</p>
</blockquote>
<h3>Önceki Sürümler</h3>
<p>Önceki PyTorch sürümlerinin kurulum talimatları ve ikili dosyalar
<a href="https://pytorch.org/get-started/previous-versions">web sitemizde</a> bulunabilir.</p>
<h2>Başlangıç</h2>
<p>Başlamak için üç öneri:</p>
<ul>
<li><a href="https://pytorch.org/tutorials/">Eğitimler: PyTorch'u anlamak ve kullanmak için</a></li>
<li><a href="https://github.com/pytorch/examples">Örnekler: Tüm alanlarda kolay anlaşılır PyTorch kodları</a></li>
<li><a href="https://pytorch.org/docs/">API Referansı</a></li>
<li><a href="https://github.com/pytorch/pytorch/blob/main/GLOSSARY.md">Sözlük</a></li>
</ul>
<h2>Kaynaklar</h2>
<ul>
<li><a href="https://pytorch.org/">PyTorch.org</a></li>
<li><a href="https://pytorch.org/tutorials/">PyTorch Eğitimleri</a></li>
<li><a href="https://github.com/pytorch/examples">PyTorch Örnekleri</a></li>
<li><a href="https://pytorch.org/hub/">PyTorch Modelleri</a></li>
<li><a href="https://www.udacity.com/course/deep-learning-pytorch--ud188">Udacity'den PyTorch ile Derin Öğrenmeye Giriş</a></li>
<li><a href="https://www.udacity.com/course/intro-to-machine-learning-nanodegree--nd229">Udacity'den PyTorch ile Makine Öğrenimine Giriş</a></li>
<li><a href="https://www.coursera.org/learn/deep-neural-networks-with-pytorch">Coursera'dan PyTorch ile Derin Sinir Ağları</a></li>
<li><a href="https://twitter.com/PyTorch">PyTorch Twitter</a></li>
<li><a href="https://pytorch.org/blog/">PyTorch Blog</a></li>
<li><a href="https://www.youtube.com/channel/UCWXI5YeOsh03QvJ59PMaXFw">PyTorch YouTube</a></li>
</ul>
<h2>İletişim</h2>
<ul>
<li>Forumlar: Uygulama, araştırma vb. tartışmaları için: https://discuss.pytorch.org</li>
<li>GitHub Issues: Hata raporları, özellik talepleri, kurulum sorunları, RFC'ler, düşünceler vb.</li>
<li>Slack: <a href="https://pytorch.slack.com/">PyTorch Slack</a> esas olarak orta ve ileri seviye PyTorch kullanıcıları ve geliştiricilerine hitap eder; genel sohbet, çevrimiçi tartışmalar, iş birliği vs. Başlangıç seviyesindeyseniz ana ortam <a href="https://discuss.pytorch.org">PyTorch Forumları</a>'dur. Slack davetiyesi için şu formu doldurun: https://goo.gl/forms/PP1AGvNHpSaJP8to1</li>
<li>Bülten: Gürültüsüz, tek yönlü e-posta bülteniyle PyTorch ile ilgili önemli duyurular. Buradan kayıt olabilirsiniz: https://eepurl.com/cbG0rv</li>
<li>Facebook Sayfası: PyTorch ile ilgili önemli duyurular. https://www.facebook.com/pytorch</li>
<li>Marka yönergeleri için lütfen <a href="https://pytorch.org/">web sitemizi</a> ziyaret edin.</li>
</ul>
<h2>Sürümler ve Katkı</h2>
<p>Genellikle, PyTorch yılda üç küçük sürüm yayınlar. Bir hata ile karşılaşırsanız lütfen <a href="https://github.com/pytorch/pytorch/issues">bir issue açarak</a> bize bildirin.</p>
<p>Tüm katkılarınız için minnettarız. Hata düzeltmeleri yapmak istiyorsanız, herhangi bir ek tartışma olmadan katkıda bulunabilirsiniz.</p>
<p>Yeni özellikler, yardımcı işlevler veya çekirdeğe eklenecek genişletmeler katkısı yapmayı planlıyorsanız, önce bir issue açıp bizimle tartışın.
Tartışma olmadan PR göndermek, çekirdek başka bir yöne gidiyorsa reddedilmiş bir PR ile sonuçlanabilir.</p>
<p>PyTorch'a katkı hakkında daha fazla bilgi için <a href="CONTRIBUTING.md">Katkı sayfamıza</a> bakabilirsiniz. PyTorch sürümleriyle ilgili daha fazla bilgi için <a href="RELEASE.md">Sürüm sayfasına</a> bakabilirsiniz.</p>
<h2>Ekip</h2>
<p>PyTorch, çok sayıda yetenekli mühendis ve araştırmacının katkıda bulunduğu topluluk odaklı bir projedir.</p>
<p>PyTorch şu anda <a href="http://soumith.ch">Soumith Chintala</a>, <a href="https://github.com/gchanan">Gregory Chanan</a>, <a href="https://github.com/dzhulgakov">Dmytro Dzhulgakov</a>, <a href="https://github.com/ezyang">Edward Yang</a> ve <a href="https://github.com/malfet">Nikita Shulga</a> tarafından sürdürülmektedir ve yüzlerce yetenekli bireyin çeşitli katkılarıyla gelişmektedir.
Eksik ama büyüyen bir liste olarak: <a href="https://github.com/killeent">Trevor Killeen</a>, <a href="https://github.com/chsasank">Sasank Chilamkurthy</a>, <a href="https://github.com/szagoruyko">Sergey Zagoruyko</a>, <a href="https://github.com/adamlerer">Adam Lerer</a>, <a href="https://github.com/fmassa">Francisco Massa</a>, <a href="https://github.com/alykhantejani">Alykhan Tejani</a>, <a href="https://github.com/lantiga">Luca Antiga</a>, <a href="https://github.com/albanD">Alban Desmaison</a>, <a href="https://github.com/andreaskoepf">Andreas Koepf</a>, <a href="https://github.com/jekbradbury">James Bradbury</a>, <a href="https://github.com/ebetica">Zeming Lin</a>, <a href="https://github.com/yuandong-tian">Yuandong Tian</a>, <a href="https://github.com/glample">Guillaume Lample</a>, <a href="https://github.com/Maratyszcza">Marat Dukhan</a>, <a href="https://github.com/ngimel">Natalia Gimelshein</a>, <a href="https://github.com/csarofeen">Christian Sarofeen</a>, <a href="https://github.com/martinraison">Martin Raison</a>, <a href="https://github.com/ezyang">Edward Yang</a>, <a href="https://github.com/zdevito">Zachary Devito</a>.</p>
<p>Not: Bu proje, aynı ada sahip <a href="https://github.com/hughperkins/pytorch">hughperkins/pytorch</a> ile ilişkili değildir. Hugh, Torch topluluğuna değerli katkılarda bulunmuş ve Torch ile PyTorch'a birçok konuda yardımcı olmuştur.</p>
<h2>Lisans</h2>
<p>PyTorch, <a href="LICENSE">LICENSE</a> dosyasında bulunan BSD tarzı bir lisansa sahiptir.</p>
<hr />
<p><a href="https://github.com/OpenAiTx/OpenAiTx">Powered By OpenAiTx</a></p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
</body>
</html>