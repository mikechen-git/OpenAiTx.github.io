<!DOCTYPE html>
<html lang="ar">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>pytorch - pytorch/pytorch</title>
    <meta name="title" content="pytorch - pytorch/pytorch">
    <meta name="description" content="pytorch/pytorch - GitHub repository ar documentation and informationبايتورتش هي حزمة بايثون توفر ميزتين عاليتي المستوى: حساب الموترات (مثل NumPy) مع تسريع قوي باستخدام وحدة معالجة الرسومات (GPU) الشبكات العصبية العميقة مبنية على...">
    <meta name="keywords" content="pytorch, pytorch, GitHub, repository, ar documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/pytorch/pytorch/README-ar.html">
    <meta property="og:title" content="pytorch - pytorch/pytorch">
    <meta property="og:description" content="pytorch/pytorch - GitHub repository ar documentation and information">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/pytorch/pytorch" id="githubRepoLink" target="_blank">pytorch/pytorch</a>
<h1 style="display: none;">بايتورتش هي حزمة بايثون توفر ميزتين عاليتي المستوى: حساب الموترات (مثل NumPy) مع تسريع قوي باستخدام وحدة معالجة الرسومات (GPU) الشبكات العصبية العميقة مبنية على...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <p><img src="https://github.com/pytorch/pytorch/raw/main/docs/source/_static/img/pytorch-logo-dark.png" alt="شعار بايتورتش" /></p>
<hr />
<p>بايتورتش هي حزمة بايثون توفر ميزتين عاليتي المستوى:</p>
<ul>
<li>حساب الموترات (مثل NumPy) مع تسريع قوي باستخدام وحدة معالجة الرسومات (GPU)</li>
<li>الشبكات العصبية العميقة مبنية على نظام تفاضل تلقائي يعتمد على الشريط (Tape-based Autograd)</li>
</ul>
<p>يمكنك إعادة استخدام حزم بايثون المفضلة لديك مثل NumPy وSciPy وCython لتوسيع بايتورتش عند الحاجة.</p>
<p>حالة التطوير المستمر (إشارات التكامل المستمر) يمكن العثور عليها على <a href="https://hud.pytorch.org/ci/pytorch/pytorch/main">hud.pytorch.org</a>.</p>
<!-- toc -->
<ul>
<li><a href="#more-about-pytorch">المزيد عن بايتورتش</a>
<ul>
<li><a href="#a-gpu-ready-tensor-library">مكتبة موترات جاهزة لـ GPU</a></li>
<li><a href="#dynamic-neural-networks-tape-based-autograd">الشبكات العصبية الديناميكية: تفاضل تلقائي معتمد على الشريط</a></li>
<li><a href="#python-first">أولاً بايثون</a></li>
<li><a href="#imperative-experiences">تجارب أمرية</a></li>
<li><a href="#fast-and-lean">سريع وخفيف</a></li>
<li><a href="#extensions-without-pain">توسعات بدون عناء</a></li>
</ul>
</li>
<li><a href="#installation">التثبيت</a>
<ul>
<li><a href="#binaries">الحزم الجاهزة</a>
<ul>
<li><a href="#nvidia-jetson-platforms">منصات NVIDIA Jetson</a></li>
</ul>
</li>
<li><a href="#from-source">من المصدر</a>
<ul>
<li><a href="#prerequisites">المتطلبات الأساسية</a>
<ul>
<li><a href="#nvidia-cuda-support">دعم NVIDIA CUDA</a></li>
<li><a href="#amd-rocm-support">دعم AMD ROCm</a></li>
<li><a href="#intel-gpu-support">دعم وحدة معالجة الرسومات من Intel</a></li>
</ul>
</li>
<li><a href="#get-the-pytorch-source">الحصول على مصدر بايتورتش</a></li>
<li><a href="#install-dependencies">تثبيت التبعيات</a></li>
<li><a href="#install-pytorch">تثبيت بايتورتش</a>
<ul>
<li><a href="#adjust-build-options-optional">ضبط خيارات البناء (اختياري)</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#docker-image">صورة Docker</a>
<ul>
<li><a href="#using-pre-built-images">استخدام الصور الجاهزة</a></li>
<li><a href="#building-the-image-yourself">بناء الصورة بنفسك</a></li>
</ul>
</li>
<li><a href="#building-the-documentation">بناء التوثيق</a>
<ul>
<li><a href="#building-a-pdf">بناء PDF</a></li>
</ul>
</li>
<li><a href="#previous-versions">الإصدارات السابقة</a></li>
</ul>
</li>
<li><a href="#getting-started">البدء</a></li>
<li><a href="#resources">الموارد</a></li>
<li><a href="#communication">التواصل</a></li>
<li><a href="#releases-and-contributing">الإصدارات والمساهمة</a></li>
<li><a href="#the-team">الفريق</a></li>
<li><a href="#license">الرخصة</a></li>
</ul>
<!-- tocstop -->
<h2>المزيد عن بايتورتش</h2>
<p><a href="https://pytorch.org/tutorials/beginner/basics/intro.html">تعلم أساسيات بايتورتش</a></p>
<p>على مستوى دقيق، بايتورتش هو مكتبة تتكون من المكونات التالية:</p>
<p>| المكون | الوصف |
| ---- | --- |
| <a href="https://pytorch.org/docs/stable/torch.html"><strong>torch</strong></a> | مكتبة موترات مثل NumPy، مع دعم قوي لوحدة معالجة الرسومات (GPU) |
| <a href="https://pytorch.org/docs/stable/autograd.html"><strong>torch.autograd</strong></a> | مكتبة تفاضل تلقائي تعتمد على الشريط تدعم جميع العمليات القابلة للتفاضل على الموترات في torch |
| <a href="https://pytorch.org/docs/stable/jit.html"><strong>torch.jit</strong></a> | حزمة ترجمة (TorchScript) لإنشاء نماذج قابلة للتسلسل والتحسين من كود بايتورتش |
| <a href="https://pytorch.org/docs/stable/nn.html"><strong>torch.nn</strong></a> | مكتبة شبكات عصبية متكاملة بعمق مع autograd ومصممة لأقصى درجات المرونة |
| <a href="https://pytorch.org/docs/stable/multiprocessing.html"><strong>torch.multiprocessing</strong></a> | معالجة متعددة في بايثون، مع مشاركة سحرية للذاكرة الخاصة بموترات torch بين العمليات. مفيد لتحميل البيانات والتدريب بطريقة Hogwild |
| <a href="https://pytorch.org/docs/stable/data.html"><strong>torch.utils</strong></a> | DataLoader ووظائف مساعدة أخرى للراحة |</p>
<p>عادةً ما يُستخدم بايتورتش كالتالي:</p>
<ul>
<li>بديل لـ NumPy للاستفادة من قوة وحدات معالجة الرسومات.</li>
<li>منصة بحث في التعلم العميق توفر أقصى قدر من المرونة والسرعة.</li>
</ul>
<p>توضيح أكثر:</p>
<h3>مكتبة موترات جاهزة لـ GPU</h3>
<p>إذا كنت تستخدم NumPy، إذًا أنت تستخدم الموترات (أو ما يُسمى ndarray).</p>
<p><img src="./docs/source/_static/img/tensor_illustration.png" alt="رسم توضيحي للموتر" /></p>
<p>يوفر بايتورتش موترات يمكن أن تتواجد إما على وحدة المعالجة المركزية (CPU) أو وحدة معالجة الرسومات (GPU) ويُسرّع العمليات الحسابية بشكل كبير.</p>
<p>نحن نوفر مجموعة واسعة من إجراءات الموترات لتسريع وتلبية احتياجاتك في الحساب العلمي مثل التقطيع والفهرسة والعمليات الرياضية والجبر الخطي والتقليصات.
وهي سريعة!</p>
<h3>الشبكات العصبية الديناميكية: تفاضل تلقائي معتمد على الشريط</h3>
<p>يمتلك بايتورتش طريقة فريدة لبناء الشبكات العصبية: باستخدام وتشغيل مسجل شريط.</p>
<p>معظم الأطر مثل TensorFlow وTheano وCaffe وCNTK لديها نظرة ثابتة للعالم.
يجب بناء شبكة عصبية وإعادة استخدام نفس الهيكل مرارًا وتكرارًا.
تغيير سلوك الشبكة يعني أنه يجب البدء من الصفر.</p>
<p>مع بايتورتش، نستخدم تقنية تُسمى التفاضل التلقائي العكسي، والتي تسمح لك
بتغيير سلوك شبكتك بشكل عشوائي دون أي تأخير أو عبء. استوحينا ذلك
من عدة أوراق بحثية في هذا الموضوع، بالإضافة إلى أعمال حالية وسابقة مثل
<a href="https://github.com/twitter/torch-autograd">torch-autograd</a>،
<a href="https://github.com/HIPS/autograd">autograd</a>،
<a href="https://chainer.org">Chainer</a>، وغيرها.</p>
<p>مع أن هذه التقنية ليست حصرية لبايتورتش، إلا أنها من أسرع التطبيقات لها حتى الآن.
تحصل على أفضل سرعة ومرونة لأبحاثك المتقدمة.</p>
<p><img src="https://github.com/pytorch/pytorch/raw/main/docs/source/_static/img/dynamic_graph.gif" alt="رسم توضيحي للرسم البياني الديناميكي" /></p>
<h3>أولاً بايثون</h3>
<p>بايتورتش ليس مجرد ربط بايثون بإطار C++ ضخم.
بل بُني ليكون متكاملًا بعمق مع بايثون.
يمكنك استخدامه بشكل طبيعي كما تستخدم <a href="https://www.numpy.org/">NumPy</a> أو <a href="https://www.scipy.org/">SciPy</a> أو <a href="https://scikit-learn.org">scikit-learn</a> وغيرها.
يمكنك كتابة طبقات الشبكة العصبية الجديدة الخاصة بك في بايثون نفسه، باستخدام مكتباتك المفضلة
واستخدام حزم مثل <a href="https://cython.org/">Cython</a> و<a href="http://numba.pydata.org/">Numba</a>.
هدفنا ألا نعيد اختراع العجلة حيثما كان ذلك مناسبًا.</p>
<h3>تجارب أمرية</h3>
<p>تم تصميم بايتورتش ليكون بديهيًا، وخطيًا في التفكير، وسهل الاستخدام.
عندما تنفذ سطرًا من الكود، يتم تنفيذه فورًا. لا توجد نظرة غير متزامنة للعالم.
عندما تدخل في مصحح الأخطاء أو تتلقى رسائل خطأ وتتبع مكدس، يكون فهمها مباشرًا.
يشير تتبع المكدس بالضبط إلى المكان الذي تم فيه تعريف كودك.
نأمل ألا تقضي ساعات طويلة في تصحيح الكود بسبب تتبع مكدس سيء أو محركات تنفيذ غير شفافة وغير متزامنة.</p>
<h3>سريع وخفيف</h3>
<p>لدى بايتورتش عبء إطار عمل منخفض للغاية. نحن ندمج مكتبات التسريع
مثل <a href="https://software.intel.com/mkl">Intel MKL</a> وNVIDIA (<a href="https://developer.nvidia.com/cudnn">cuDNN</a>، <a href="https://developer.nvidia.com/nccl">NCCL</a>) لتحقيق أقصى سرعة.
في الجوهر، تعتمد موترات CPU وGPU وواجهات الشبكات العصبية
على أكواد ناضجة ومجربة لسنوات.</p>
<p>لذا، بايتورتش سريع جدًا — سواءً كنت تشغل شبكات عصبية صغيرة أو كبيرة.</p>
<p>استهلاك الذاكرة في بايتورتش فعال للغاية مقارنة بـ Torch أو بعض البدائل الأخرى.
لقد كتبنا مخصصات ذاكرة مخصصة لـ GPU لضمان أن
نماذج التعلم العميق الخاصة بك فعالة إلى أقصى حد في استهلاك الذاكرة.
هذا يمكّنك من تدريب نماذج تعلم عميق أكبر من ذي قبل.</p>
<h3>توسعات بدون عناء</h3>
<p>كتابة وحدات شبكات عصبية جديدة، أو التعامل مع واجهة برمجة تطبيقات موترات بايتورتش تم تصميمها لتكون مباشرة
وبأقل قدر من التجريدات.</p>
<p>يمكنك كتابة طبقات الشبكة العصبية الجديدة في بايثون باستخدام واجهة torch
<a href="https://pytorch.org/tutorials/advanced/numpy_extensions_tutorial.html">أو مكتباتك المفضلة المعتمدة على NumPy مثل SciPy</a>.</p>
<p>إذا رغبت في كتابة طبقاتك بـ C/C++، نوفر واجهة توسعة سهلة الاستخدام وفعالة وبأقل متطلبات كود.
لا حاجة لكتابة كود تغليف. يمكنك مشاهدة <a href="https://pytorch.org/tutorials/advanced/cpp_extension.html">دليل هنا</a> و<a href="https://github.com/pytorch/extension-cpp">مثال هنا</a>.</p>
<h2>التثبيت</h2>
<h3>الحزم الجاهزة</h3>
<p>أوامر تثبيت الحزم الجاهزة عبر Conda أو pip متوفرة على موقعنا: <a href="https://pytorch.org/get-started/locally/">https://pytorch.org/get-started/locally/</a></p>
<h4>منصات NVIDIA Jetson</h4>
<p>عجلات بايثون لمنصات Jetson Nano وJetson TX1/TX2 وJetson Xavier NX/AGX وJetson AGX Orin من NVIDIA متوفرة <a href="https://forums.developer.nvidia.com/t/pytorch-for-jetson-version-1-10-now-available/72048">هنا</a> وحاوية L4T منشورة <a href="https://catalog.ngc.nvidia.com/orgs/nvidia/containers/l4t-pytorch">هنا</a></p>
<p>تتطلب JetPack 4.2 وما فوق، ويتم صيانتها من قبل <a href="https://github.com/dusty-nv">@dusty-nv</a> و<a href="https://github.com/ptrblck">@ptrblck</a>.</p>
<h3>من المصدر</h3>
<h4>المتطلبات الأساسية</h4>
<p>إذا كنت تقوم بالتثبيت من المصدر، ستحتاج إلى:</p>
<ul>
<li>بايثون 3.9 أو أحدث</li>
<li>مترجم يدعم C++17 بالكامل، مثل clang أو gcc (يتطلب gcc 9.4.0 أو أحدث على لينكس)</li>
<li>Visual Studio أو Visual Studio Build Tool (للويندوز فقط)</li>
</ul>
<p>* يستخدم بايتورتش CI أدوات بناء Visual C++، والتي تأتي مع إصدارات Visual Studio Enterprise أو Professional أو Community. يمكنك أيضًا تثبيت أدوات البناء من
https://visualstudio.microsoft.com/visual-cpp-build-tools/. أدوات البناء <em>لا تأتي</em>
افتراضيًا مع Visual Studio Code.</p>
<p>مثال على إعداد البيئة موضح أدناه:</p>
<ul>
<li>لينكس:</li>
</ul>
<pre><code class="language-bash">$ source &lt;CONDA_INSTALL_DIR&gt;/bin/activate
$ conda create -y -n &lt;CONDA_NAME&gt;
$ conda activate &lt;CONDA_NAME&gt;
</code></pre>
<ul>
<li>ويندوز:</li>
</ul>
<pre><code class="language-bash">$ source &lt;CONDA_INSTALL_DIR&gt;\Scripts\activate.bat
$ conda create -y -n &lt;CONDA_NAME&gt;
$ conda activate &lt;CONDA_NAME&gt;
$ call &quot;C:\Program Files\Microsoft Visual Studio\&lt;VERSION&gt;\Community\VC\Auxiliary\Build\vcvarsall.bat&quot; x64
</code></pre>
<h5>دعم NVIDIA CUDA</h5>
<p>إذا كنت ترغب في الترجمة مع دعم CUDA، <a href="https://pytorch.org/get-started/locally/">اختر إصدارًا مدعومًا من CUDA من جدول الدعم لدينا</a>، ثم قم بتثبيت التالي:</p>
<ul>
<li><a href="https://developer.nvidia.com/cuda-downloads">NVIDIA CUDA</a></li>
<li><a href="https://developer.nvidia.com/cudnn">NVIDIA cuDNN</a> v8.5 أو أحدث</li>
<li><a href="https://gist.github.com/ax3l/9489132">مترجم</a> متوافق مع CUDA</li>
</ul>
<p>ملاحظة: يمكنك الرجوع إلى <a href="https://docs.nvidia.com/deeplearning/cudnn/backend/latest/reference/support-matrix.html">جدول دعم cuDNN</a> لإصدارات cuDNN مع CUDA المدعومة وبرامج تشغيل CUDA وأجهزة NVIDIA المختلفة.</p>
<p>إذا كنت ترغب في تعطيل دعم CUDA، صدّر متغير البيئة <code>USE_CUDA=0</code>.
قد تجد متغيرات بيئة أخرى مفيدة في <code>setup.py</code>.</p>
<p>إذا كنت تبني لمنصات NVIDIA Jetson (Jetson Nano, TX1, TX2, AGX Xavier)، تعليمات تثبيت بايتورتش لـ Jetson Nano متوفرة <a href="https://devtalk.nvidia.com/default/topic/1049071/jetson-nano/pytorch-for-jetson-nano/">هنا</a></p>
<h5>دعم AMD ROCm</h5>
<p>إذا كنت ترغب في الترجمة مع دعم ROCm، قم بتثبيت:</p>
<ul>
<li><a href="https://rocm.docs.amd.com/en/latest/deploy/linux/quick_start.html">AMD ROCm</a> 4.0 أو أحدث</li>
<li>ROCm مدعوم حاليًا فقط على أنظمة لينكس.</li>
</ul>
<p>يفترض نظام البناء افتراضيًا أن ROCm مثبت في <code>/opt/rocm</code>. إذا كان ROCm مثبتًا في مجلد مختلف، يجب تعيين متغير البيئة <code>ROCM_PATH</code> إلى مجلد التثبيت. يكتشف نظام البناء تلقائيًا معمارية GPU من AMD. اختياريًا، يمكن ضبط معمارية AMD GPU بشكل صريح باستخدام متغير البيئة <code>PYTORCH_ROCM_ARCH</code> <a href="https://rocm.docs.amd.com/projects/install-on-linux/en/latest/reference/system-requirements.html#supported-gpus">معمارية AMD GPU</a></p>
<p>إذا كنت ترغب في تعطيل دعم ROCm، صدّر متغير البيئة <code>USE_ROCM=0</code>.
قد تجد متغيرات بيئة أخرى مفيدة في <code>setup.py</code>.</p>
<h5>دعم وحدة معالجة الرسومات من Intel</h5>
<p>إذا كنت ترغب في الترجمة مع دعم وحدة معالجة الرسومات من Intel، اتبع التالي:</p>
<ul>
<li><a href="https://www.intel.com/content/www/us/en/developer/articles/tool/pytorch-prerequisites-for-intel-gpus.html">متطلبات بايتورتش لوحدات معالجة الرسومات من Intel</a>.</li>
<li>وحدة معالجة الرسومات من Intel مدعومة على لينكس وويندوز.</li>
</ul>
<p>إذا كنت ترغب في تعطيل دعم وحدة معالجة الرسومات من Intel، صدّر متغير البيئة <code>USE_XPU=0</code>.
قد تجد متغيرات بيئة أخرى مفيدة في <code>setup.py</code>.</p>
<h4>الحصول على مصدر بايتورتش</h4>
<pre><code class="language-bash">git clone https://github.com/pytorch/pytorch
cd pytorch
# إذا كنت تحدث نسخة موجودة بالفعل
git submodule sync
git submodule update --init --recursive
</code></pre>
<h4>تثبيت التبعيات</h4>
<p><strong>مشترك</strong></p>
<pre><code class="language-bash">conda install cmake ninja
# شغل هذا الأمر من مجلد بايتورتش بعد استنساخ الكود المصدر من قسم &quot;الحصول على مصدر بايتورتش&quot; بالأعلى
pip install -r requirements.txt
</code></pre>
<p><strong>على لينكس</strong></p>
<pre><code class="language-bash">pip install mkl-static mkl-include
# CUDA فقط: أضف دعم LAPACK لـ GPU إذا لزم الأمر
# تثبيت magma: شغل مع تفعيل بيئة conda. حدد إصدار CUDA للتثبيت
.ci/docker/common/install_magma_conda.sh 12.4

# (اختياري) إذا كنت تستخدم torch.compile مع inductor/triton، ثبت النسخة المطابقة من triton
# شغل من مجلد pytorch بعد الاستنساخ
# لدعم وحدة معالجة الرسومات من Intel، يرجى تصدير `USE_XPU=1` صراحة قبل تنفيذ الأمر.
make triton
</code></pre>
<p><strong>على macOS</strong></p>
<pre><code class="language-bash"># أضف هذه الحزمة فقط على أجهزة المعالج intel x86
pip install mkl-static mkl-include
# أضف هذه الحزم إذا كنت بحاجة إلى torch.distributed
conda install pkg-config libuv
</code></pre>
<p><strong>على ويندوز</strong></p>
<pre><code class="language-bash">pip install mkl-static mkl-include
# أضف هذه الحزم إذا كنت بحاجة إلى torch.distributed.
# دعم الحزمة الموزعة على ويندوز ميزة تجريبية وقابلة للتغيير.
conda install -c conda-forge libuv=1.39
</code></pre>
<h4>تثبيت بايتورتش</h4>
<p><strong>على لينكس</strong></p>
<p>إذا كنت تترجم لـ AMD ROCm فعليك أولاً تشغيل هذا الأمر:</p>
<pre><code class="language-bash"># شغل هذا فقط إذا كنت تترجم لـ ROCm
python tools/amd_build/build_amd.py
</code></pre>
<p>تثبيت بايتورتش</p>
<pre><code class="language-bash">export CMAKE_PREFIX_PATH=&quot;${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}&quot;
python setup.py develop
</code></pre>
<p><strong>على macOS</strong></p>
<pre><code class="language-bash">python3 setup.py develop
</code></pre>
<p><strong>على ويندوز</strong></p>
<p>إذا كنت ترغب في بناء كود بايثون قديم، يرجى الرجوع إلى <a href="https://github.com/pytorch/pytorch/blob/main/CONTRIBUTING.md#building-on-legacy-code-and-cuda">البناء على الكود القديم وCUDA</a></p>
<p><strong>بناء باستخدام CPU فقط</strong></p>
<p>في هذا الوضع ستعمل حسابات بايتورتش على وحدة المعالجة المركزية فقط، وليس وحدة معالجة الرسومات.</p>
<pre><code class="language-cmd">python setup.py develop
</code></pre>
<p>ملاحظة حول OpenMP: التطبيق المطلوب لـ OpenMP هو Intel OpenMP (iomp). للربط مع iomp، ستحتاج إلى تحميل المكتبة يدويًا وضبط بيئة البناء عن طريق تعديل <code>CMAKE_INCLUDE_PATH</code> و<code>LIB</code>. التعليمات <a href="https://github.com/pytorch/pytorch/blob/main/docs/source/notes/windows.rst#building-from-source">هنا</a> مثال لإعداد كل من MKL وIntel OpenMP. بدون هذه الإعدادات لـ CMake، سيتم استخدام Microsoft Visual C OpenMP runtime (vcomp).</p>
<p><strong>بناء باستخدام CUDA</strong></p>
<p>في هذا الوضع ستستفيد حسابات بايتورتش من وحدة معالجة الرسومات عبر CUDA لزيادة سرعة العمليات الحسابية.</p>
<p><a href="https://docs.nvidia.com/gameworks/content/gameworkslibrary/nvtx/nvidia_tools_extension_library_nvtx.htm">NVTX</a> مطلوب لبناء بايتورتش مع CUDA.
NVTX جزء من توزيعة CUDA، حيث يسمى &quot;Nsight Compute&quot;. لتثبيته على CUDA المثبت بالفعل، أعد تشغيل التثبيت وحدد المربع المناسب.
تأكد من أن CUDA مع Nsight Compute مثبّت بعد Visual Studio.</p>
<p>حاليًا، VS 2017 / 2019 وNinja مدعومون كمولدات لـ CMake. إذا تم اكتشاف <code>ninja.exe</code> في <code>PATH</code>، سيتم استخدام Ninja كمولد افتراضي، وإلا سيتم استخدام VS 2017/2019.
<br/> إذا تم اختيار Ninja كمولد، سيتم اختيار أحدث MSVC كأداة أساسية.</p>
<p>مكتبات إضافية مثل
<a href="https://developer.nvidia.com/magma">Magma</a>، <a href="https://github.com/oneapi-src/oneDNN">oneDNN، المعروف أيضًا باسم MKLDNN أو DNNL</a>، و<a href="https://github.com/mozilla/sccache">Sccache</a> غالبًا ما تكون مطلوبة. يرجى الرجوع إلى <a href="https://github.com/pytorch/pytorch/tree/main/.ci/pytorch/win-test-helpers/installation-helpers">installation-helper</a> لتثبيتها.</p>
<p>يمكنك الرجوع إلى سكربت <a href="https://github.com/pytorch/pytorch/blob/main/.ci/pytorch/win-test-helpers/build_pytorch.bat">build_pytorch.bat</a> لبعض إعدادات متغيرات البيئة الأخرى.</p>
<pre><code class="language-cmd">cmd

:: اضبط متغيرات البيئة بعد تحميل وفك ضغط حزمة mkl،
:: وإلا سيرمي CMake خطأ &quot;Could NOT find OpenMP&quot;.
set CMAKE_INCLUDE_PATH={Your directory}\mkl\include
set LIB={Your directory}\mkl\lib;%LIB%

:: اقرأ محتوى القسم السابق بعناية قبل المتابعة.
:: [اختياري] إذا رغبت في تجاوز أداة البناء الأساسية المستخدمة بواسطة Ninja وVisual Studio مع CUDA، شغل السكربت التالي.
:: سيتم تشغيل &quot;Visual Studio 2019 Developer Command Prompt&quot; تلقائيًا.
:: تأكد من وجود CMake &gt;= 3.12 قبل ذلك إذا كنت تستخدم مولد Visual Studio.
set CMAKE_GENERATOR_TOOLSET_VERSION=14.27
set DISTUTILS_USE_SDK=1
for /f &quot;usebackq tokens=*&quot; %i in (`&quot;%ProgramFiles(x86)%\Microsoft Visual Studio\Installer\vswhere.exe&quot; -version [15^,17^) -products * -latest -property installationPath`) do call &quot;%i\VC\Auxiliary\Build\vcvarsall.bat&quot; x64 -vcvars_ver=%CMAKE_GENERATOR_TOOLSET_VERSION%

:: [اختياري] إذا رغبت في تجاوز مترجم مضيف CUDA
set CUDAHOSTCXX=C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.27.29110\bin\HostX64\x64\cl.exe

python setup.py develop

</code></pre>
<p><strong>بناء لوحدة معالجة الرسومات من Intel</strong></p>
<p>في هذا الوضع سيتم بناء بايتورتش مع دعم وحدة معالجة الرسومات من Intel.</p>
<p>يرجى التأكد من أن <a href="#prerequisites">المتطلبات الأساسية المشتركة</a> وكذلك <a href="#intel-gpu-support">متطلبات وحدة معالجة الرسومات من Intel</a> مثبّتة بشكل صحيح ومتغيرات البيئة مضبوطة قبل بدء البناء. لدعم أدوات البناء، يتطلب <code>Visual Studio 2022</code>.</p>
<p>بعدها يمكن بناء بايتورتش بالأمر التالي:</p>
<pre><code class="language-cmd">:: أوامر CMD:
:: اضبط CMAKE_PREFIX_PATH للمساعدة في العثور على الحزم المناسبة
:: %CONDA_PREFIX% يعمل فقط بعد تنفيذ `conda activate custom_env`

if defined CMAKE_PREFIX_PATH (
    set &quot;CMAKE_PREFIX_PATH=%CONDA_PREFIX%\Library;%CMAKE_PREFIX_PATH%&quot;
) else (
    set &quot;CMAKE_PREFIX_PATH=%CONDA_PREFIX%\Library&quot;
)

python setup.py develop
</code></pre>
<h5>ضبط خيارات البناء (اختياري)</h5>
<p>يمكنك ضبط إعدادات متغيرات cmake بشكل اختياري (دون البناء أولاً)، من خلال التالي. مثلًا، يمكن ضبط مجلدات cuDNN أو BLAS المكتشفة مسبقًا بهذه الخطوة.</p>
<p>على لينكس</p>
<pre><code class="language-bash">export CMAKE_PREFIX_PATH=&quot;${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}&quot;
python setup.py build --cmake-only
ccmake build  # أو cmake-gui build
</code></pre>
<p>على macOS</p>
<pre><code class="language-bash">export CMAKE_PREFIX_PATH=&quot;${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}&quot;
MACOSX_DEPLOYMENT_TARGET=10.9 CC=clang CXX=clang++ python setup.py build --cmake-only
ccmake build  # أو cmake-gui build
</code></pre>
<h3>صورة Docker</h3>
<h4>استخدام الصور الجاهزة</h4>
<p>يمكنك أيضًا سحب صورة Docker جاهزة من Docker Hub وتشغيلها مع docker v19.03+</p>
<pre><code class="language-bash">docker run --gpus all --rm -ti --ipc=host pytorch/pytorch:latest
</code></pre>
<p>يرجى ملاحظة أن بايتورتش يستخدم الذاكرة المشتركة لمشاركة البيانات بين العمليات، لذا إذا تم استخدام torch multiprocessing (مثلاً
لمحمل البيانات متعدد الخيوط) فإن حجم مقطع الذاكرة المشتركة الافتراضي الذي تعمل به الحاوية غير كافٍ، ويجب عليك
زيادة حجم الذاكرة المشتركة إما باستخدام <code>--ipc=host</code> أو خيار السطر <code>--shm-size</code> مع <code>nvidia-docker run</code>.</p>
<h4>بناء الصورة بنفسك</h4>
<p><strong>ملاحظة:</strong> يجب أن يتم البناء مع نسخة Docker &gt; 18.06</p>
<p>يتم توفير ملف <code>Dockerfile</code> لبناء الصور مع دعم CUDA 11.1 وcuDNN v8.
يمكنك تمرير متغير make باسم <code>PYTHON_VERSION=x.y</code> لتحديد إصدار بايثون الذي سيستخدمه Miniconda، أو اتركه بدون تعيين لاستخدام الافتراضي.</p>
<pre><code class="language-bash">make -f docker.Makefile
# الصور موسومة كـ docker.io/${your_docker_username}/pytorch
</code></pre>
<p>يمكنك أيضًا تمرير متغير البيئة <code>CMAKE_VARS=&quot;...&quot;</code> لتحديد متغيرات CMake إضافية أثناء البناء.
انظر <a href="./setup.py">setup.py</a> لقائمة المتغيرات المتاحة.</p>
<pre><code class="language-bash">make -f docker.Makefile
</code></pre>
<h3>بناء التوثيق</h3>
<p>لبناء التوثيق بصيغ مختلفة، ستحتاج إلى <a href="http://www.sphinx-doc.org">Sphinx</a>
وthème pytorch_sphinx_theme2.</p>
<p>قبل بناء التوثيق محليًا، تأكد من تثبيت <code>torch</code>
في بيئتك. للتعديلات الصغيرة، يمكنك تثبيت
الإصدار الليلي كما هو موضح في <a href="https://pytorch.org/get-started/locally/">البدء</a>.</p>
<p>للتعديلات الأكبر، مثل إضافة وحدة جديدة وسلاسل توثيق للوحدة الجديدة، قد تحتاج إلى تثبيت torch <a href="#from-source">من المصدر</a>.
انظر <a href="https://github.com/pytorch/pytorch/wiki/Docstring-Guidelines">إرشادات السلاسل التوضيحية</a>
للتعرف على معايير السلاسل التوضيحية.</p>
<pre><code class="language-bash">cd docs/
pip install -r requirements.txt
make html
make serve
</code></pre>
<p>شغّل <code>make</code> للحصول على قائمة بجميع صيغ الإخراج المتاحة.</p>
<p>إذا حصلت على خطأ katex شغّل <code>npm install katex</code>. إذا استمر الخطأ، جرب
<code>npm install -g katex</code></p>
<blockquote>
<p>[!ملاحظة]
إذا قمت بتثبيت <code>nodejs</code> بواسطة مدير حزم مختلف (مثلاً،
<code>conda</code>) فربما سيقوم <code>npm</code> بتثبيت نسخة من <code>katex</code> غير متوافقة
مع إصدار <code>nodejs</code> الخاص بك وسيفشل بناء التوثيق.
مجموعة إصدارات معروفة بأنها تعمل هي <code>node@6.13.1</code> و
<code>katex@0.13.18</code>. لتثبيت الأخيرة مع <code>npm</code> يمكنك تشغيل
<code>npm install -g katex@0.13.18</code></p>
</blockquote>
<blockquote>
<p>[!ملاحظة]
إذا رأيت خطأ عدم توافق numpy، شغّل:</p>
<pre><code>pip install 'numpy&lt;2'
</code></pre>
</blockquote>
<p>عند إجراء تغييرات على التبعيات المستخدمة في CI، عدل ملف
<code>.ci/docker/requirements-docs.txt</code>.</p>
<h4>بناء PDF</h4>
<p>لإنشاء PDF لجميع توثيقات بايتورتش، تأكد من تثبيت
<code>texlive</code> وLaTeX. على macOS، يمكنك تثبيتها باستخدام:</p>
<pre><code>brew install --cask mactex
</code></pre>
<p>لإنشاء PDF:</p>
<ol>
<li><p>شغّل:</p>
<pre><code>make latexpdf
</code></pre>
<p>هذا سينشئ الملفات اللازمة في مجلد <code>build/latex</code>.</p>
</li>
<li><p>انتقل إلى هذا المجلد ونفذ:</p>
<pre><code>make LATEXOPTS=&quot;-interaction=nonstopmode&quot;
</code></pre>
<p>هذا سينتج <code>pytorch.pdf</code> بالمحتوى المطلوب. شغّل هذا
الأمر مرة أخرى ليتم إنشاء جدول المحتويات والفهرس بشكل صحيح.</p>
</li>
</ol>
<blockquote>
<p>[!ملاحظة]
لعرض جدول المحتويات، انتقل إلى <strong>Table of Contents</strong>
في عارض PDF الخاص بك.</p>
</blockquote>
<h3>الإصدارات السابقة</h3>
<p>تعليمات التثبيت والحزم للإصدارات السابقة من بايتورتش يمكن العثور عليها
على <a href="https://pytorch.org/get-started/previous-versions">موقعنا</a>.</p>
<h2>البدء</h2>
<p>ثلاثة مصادر للبدء:</p>
<ul>
<li><a href="https://pytorch.org/tutorials/">الدروس: لتبدأ بفهم واستخدام بايتورتش</a></li>
<li><a href="https://github.com/pytorch/examples">الأمثلة: كود بايتورتش سهل الفهم لجميع المجالات</a></li>
<li><a href="https://pytorch.org/docs/">مرجع واجهة البرمجة API</a></li>
<li><a href="https://github.com/pytorch/pytorch/blob/main/GLOSSARY.md">المصطلحات</a></li>
</ul>
<h2>الموارد</h2>
<ul>
<li><a href="https://pytorch.org/">PyTorch.org</a></li>
<li><a href="https://pytorch.org/tutorials/">دروس بايتورتش</a></li>
<li><a href="https://github.com/pytorch/examples">أمثلة بايتورتش</a></li>
<li><a href="https://pytorch.org/hub/">نماذج بايتورتش</a></li>
<li><a href="https://www.udacity.com/course/deep-learning-pytorch--ud188">مقدمة في التعلم العميق مع بايتورتش من Udacity</a></li>
<li><a href="https://www.udacity.com/course/intro-to-machine-learning-nanodegree--nd229">مقدمة في تعلم الآلة مع بايتورتش من Udacity</a></li>
<li><a href="https://www.coursera.org/learn/deep-neural-networks-with-pytorch">الشبكات العصبية العميقة مع بايتورتش من Coursera</a></li>
<li><a href="https://twitter.com/PyTorch">تويتر بايتورتش</a></li>
<li><a href="https://pytorch.org/blog/">مدونة بايتورتش</a></li>
<li><a href="https://www.youtube.com/channel/UCWXI5YeOsh03QvJ59PMaXFw">قناة بايتورتش على يوتيوب</a></li>
</ul>
<h2>التواصل</h2>
<ul>
<li>المنتديات: مناقشة التطبيقات والبحث وغيره https://discuss.pytorch.org</li>
<li>قضايا GitHub: تقارير الأخطاء، طلبات الميزات، مشكلات التثبيت، RFCs، الأفكار، إلخ.</li>
<li>Slack: قناة <a href="https://pytorch.slack.com/">PyTorch Slack</a> تستضيف جمهورًا أساسيًا من مستخدمي ومطوري بايتورتش المتوسطين إلى المتقدمين للدردشة العامة والمناقشات والتعاون. إذا كنت مبتدئًا وتبحث عن مساعدة، الوسيلة الرئيسية هي <a href="https://discuss.pytorch.org">منتديات بايتورتش</a>. إذا كنت بحاجة لدعوة Slack، يرجى تعبئة هذا النموذج: https://goo.gl/forms/PP1AGvNHpSaJP8to1</li>
<li>النشرة البريدية: بريد إلكتروني من جهة واحدة مع إعلانات مهمة عن بايتورتش. يمكنك الاشتراك هنا: https://eepurl.com/cbG0rv</li>
<li>صفحة فيسبوك: إعلانات مهمة عن بايتورتش. https://www.facebook.com/pytorch</li>
<li>لإرشادات العلامة التجارية، يرجى زيارة موقعنا على <a href="https://pytorch.org/">pytorch.org</a></li>
</ul>
<h2>الإصدارات والمساهمة</h2>
<p>عادةً ما يصدر بايتورتش ثلاث إصدارات فرعية سنويًا. يرجى إبلاغنا إذا واجهت خطأ عبر <a href="https://github.com/pytorch/pytorch/issues">فتح قضية</a>.</p>
<p>نحن نقدّر جميع المساهمات. إذا كنت تخطط للمساهمة بإصلاحات للأخطاء، يرجى القيام بذلك دون أي نقاش إضافي.</p>
<p>إذا كنت تخطط للمساهمة بميزات جديدة أو وظائف مساعدة أو توسعات للنواة، يرجى أولاً فتح قضية ومناقشة الميزة معنا.
إرسال PR بدون نقاش قد يؤدي إلى رفضه لأننا قد نأخذ النواة في اتجاه مختلف عما تعلمه.</p>
<p>لمعرفة المزيد حول المساهمة في بايتورتش، يرجى زيارة <a href="CONTRIBUTING.md">صفحة المساهمة</a>. لمزيد من المعلومات حول إصدارات بايتورتش، انظر <a href="RELEASE.md">صفحة الإصدارات</a>.</p>
<h2>الفريق</h2>
<p>بايتورتش مشروع مدفوع من المجتمع مع العديد من المهندسين والباحثين المهرة يساهمون فيه.</p>
<p>يتم صيانة بايتورتش حاليًا من قبل <a href="http://soumith.ch">Soumith Chintala</a>، <a href="https://github.com/gchanan">Gregory Chanan</a>، <a href="https://github.com/dzhulgakov">Dmytro Dzhulgakov</a>، <a href="https://github.com/ezyang">Edward Yang</a>، و<a href="https://github.com/malfet">Nikita Shulga</a> مع مساهمات رئيسية من مئات الأفراد الموهوبين بأشكال ووسائل مختلفة.
قائمة غير شاملة ولكنها تنمو باستمرار يجب أن تذكر: <a href="https://github.com/killeent">Trevor Killeen</a>، <a href="https://github.com/chsasank">Sasank Chilamkurthy</a>، <a href="https://github.com/szagoruyko">Sergey Zagoruyko</a>، <a href="https://github.com/adamlerer">Adam Lerer</a>، <a href="https://github.com/fmassa">Francisco Massa</a>، <a href="https://github.com/alykhantejani">Alykhan Tejani</a>، <a href="https://github.com/lantiga">Luca Antiga</a>، <a href="https://github.com/albanD">Alban Desmaison</a>، <a href="https://github.com/andreaskoepf">Andreas Koepf</a>، <a href="https://github.com/jekbradbury">James Bradbury</a>، <a href="https://github.com/ebetica">Zeming Lin</a>، <a href="https://github.com/yuandong-tian">Yuandong Tian</a>، <a href="https://github.com/glample">Guillaume Lample</a>، <a href="https://github.com/Maratyszcza">Marat Dukhan</a>، <a href="https://github.com/ngimel">Natalia Gimelshein</a>، <a href="https://github.com/csarofeen">Christian Sarofeen</a>، <a href="https://github.com/martinraison">Martin Raison</a>، <a href="https://github.com/ezyang">Edward Yang</a>، <a href="https://github.com/zdevito">Zachary Devito</a>.</p>
<p>ملاحظة: هذا المشروع غير مرتبط بـ <a href="https://github.com/hughperkins/pytorch">hughperkins/pytorch</a> الذي يحمل نفس الاسم. Hugh هو مساهم قيّم في مجتمع Torch وساعد في العديد من الأمور الخاصة بـ Torch وPyTorch.</p>
<h2>الرخصة</h2>
<p>بايتورتش تحت رخصة BSD، كما هو موضح في ملف <a href="LICENSE">LICENSE</a>.</p>
<hr />
<p><a href="https://github.com/OpenAiTx/OpenAiTx">Powered By OpenAiTx</a></p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
</body>
</html>