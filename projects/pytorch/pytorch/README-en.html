<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>pytorch - pytorch/pytorch</title>
    <meta name="title" content="pytorch - pytorch/pytorch">
    <meta name="description" content="pytorch/pytorch - GitHub repository en documentation and informationPyTorch 是一个 Python 包，提供了两个高级特性： 张量计算（类似于 NumPy），并具备强大的 GPU 加速能力 基于 tape 的自动微分系统构建的深度神经网络 你可以复用你喜欢的 Python 包（如 NumPy、SciPy 和 Cython）在需要时扩展 PyTorch。 我们的主干健康状况（持续集...">
    <meta name="keywords" content="pytorch, pytorch, GitHub, repository, en documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/pytorch/pytorch/README-en.html">
    <meta property="og:title" content="pytorch - pytorch/pytorch">
    <meta property="og:description" content="pytorch/pytorch - GitHub repository en documentation and information">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/pytorch/pytorch" id="githubRepoLink" target="_blank">pytorch/pytorch</a>
<h1 style="display: none;">PyTorch 是一个 Python 包，提供了两个高级特性： 张量计算（类似于 NumPy），并具备强大的 GPU 加速能力 基于 tape 的自动微分系统构建的深度神经网络 你可以复用你喜欢的 Python 包（如 NumPy、SciPy 和 Cython）在需要时扩展 PyTorch。 我们的主干健康状况（持续集...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <p><img src="https://github.com/pytorch/pytorch/raw/main/docs/source/_static/img/pytorch-logo-dark.png" alt="PyTorch Logo" /></p>
<hr />
<p>PyTorch 是一个 Python 包，提供了两个高级特性：</p>
<ul>
<li>张量计算（类似于 NumPy），并具备强大的 GPU 加速能力</li>
<li>基于 tape 的自动微分系统构建的深度神经网络</li>
</ul>
<p>你可以复用你喜欢的 Python 包（如 NumPy、SciPy 和 Cython）在需要时扩展 PyTorch。</p>
<p>我们的主干健康状况（持续集成信号）可在 <a href="https://hud.pytorch.org/ci/pytorch/pytorch/main">hud.pytorch.org</a> 查看。</p>
<!-- toc -->
<ul>
<li><a href="#more-about-pytorch">更多关于 PyTorch</a>
<ul>
<li><a href="#a-gpu-ready-tensor-library">GPU 就绪的张量库</a></li>
<li><a href="#dynamic-neural-networks-tape-based-autograd">动态图神经网络：基于 tape 的自动微分</a></li>
<li><a href="#python-first">Python 优先</a></li>
<li><a href="#imperative-experiences">命令式体验</a></li>
<li><a href="#fast-and-lean">快速且精简</a></li>
<li><a href="#extensions-without-pain">无痛扩展</a></li>
</ul>
</li>
<li><a href="#installation">安装</a>
<ul>
<li><a href="#binaries">二进制包</a>
<ul>
<li><a href="#nvidia-jetson-platforms">NVIDIA Jetson 平台</a></li>
</ul>
</li>
<li><a href="#from-source">源码编译</a>
<ul>
<li><a href="#prerequisites">先决条件</a>
<ul>
<li><a href="#nvidia-cuda-support">NVIDIA CUDA 支持</a></li>
<li><a href="#amd-rocm-support">AMD ROCm 支持</a></li>
<li><a href="#intel-gpu-support">Intel GPU 支持</a></li>
</ul>
</li>
<li><a href="#get-the-pytorch-source">获取 PyTorch 源码</a></li>
<li><a href="#install-dependencies">安装依赖</a></li>
<li><a href="#install-pytorch">安装 PyTorch</a>
<ul>
<li><a href="#adjust-build-options-optional">调整构建选项（可选）</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#docker-image">Docker 镜像</a>
<ul>
<li><a href="#using-pre-built-images">使用预构建镜像</a></li>
<li><a href="#building-the-image-yourself">自行构建镜像</a></li>
</ul>
</li>
<li><a href="#building-the-documentation">构建文档</a>
<ul>
<li><a href="#building-a-pdf">构建 PDF</a></li>
</ul>
</li>
<li><a href="#previous-versions">历史版本</a></li>
</ul>
</li>
<li><a href="#getting-started">快速入门</a></li>
<li><a href="#resources">资源</a></li>
<li><a href="#communication">交流</a></li>
<li><a href="#releases-and-contributing">版本与贡献</a></li>
<li><a href="#the-team">团队</a></li>
<li><a href="#license">许可证</a></li>
</ul>
<!-- tocstop -->
<h2>更多关于 PyTorch</h2>
<p><a href="https://pytorch.org/tutorials/beginner/basics/intro.html">学习 PyTorch 基础知识</a></p>
<p>在细粒度层面，PyTorch 是一个包含以下组件的库：</p>
<p>| 组件 | 描述 |
| ---- | --- |
| <a href="https://pytorch.org/docs/stable/torch.html"><strong>torch</strong></a> | 类似于 NumPy 的张量库，具备强大的 GPU 支持 |
| <a href="https://pytorch.org/docs/stable/autograd.html"><strong>torch.autograd</strong></a> | 基于 tape 的自动微分库，支持 torch 中所有可微分的张量操作 |
| <a href="https://pytorch.org/docs/stable/jit.html"><strong>torch.jit</strong></a> | 编译栈（TorchScript），可将 PyTorch 代码生成可序列化和可优化的模型 |
| <a href="https://pytorch.org/docs/stable/nn.html"><strong>torch.nn</strong></a> | 与 autograd 深度集成的神经网络库，设计极为灵活 |
| <a href="https://pytorch.org/docs/stable/multiprocessing.html"><strong>torch.multiprocessing</strong></a> | Python 多进程，但可实现进程间 torch 张量的内存共享。适用于数据加载和 Hogwild 训练 |
| <a href="https://pytorch.org/docs/stable/data.html"><strong>torch.utils</strong></a> | DataLoader 及其他便捷的工具函数 |</p>
<p>通常，PyTorch 可用作：</p>
<ul>
<li>NumPy 的替代品，以利用 GPU 的强大算力。</li>
<li>提供极致灵活性与速度的深度学习研究平台。</li>
</ul>
<p>进一步说明：</p>
<h3>GPU 就绪的张量库</h3>
<p>如果你用过 NumPy，你就用过张量（即 ndarray）。</p>
<p><img src="./docs/source/_static/img/tensor_illustration.png" alt="张量示意图" /></p>
<p>PyTorch 提供的张量可以驻留在 CPU 或 GPU 上，并极大加速计算。</p>
<p>我们提供了丰富的张量操作例程，以加速并满足你的科学计算需求，
如切片、索引、数学运算、线性代数、归约等。
而且它们都非常快！</p>
<h3>动态图神经网络：基于 tape 的自动微分</h3>
<p>PyTorch 构建神经网络有一种独特方式：使用并重放一个“录音带”。</p>
<p>大多数框架如 TensorFlow、Theano、Caffe 和 CNTK 都采用静态方式。
你必须先构建一个神经网络结构，然后反复使用同一个结构。
如果想改变网络行为，就必须从头再来。</p>
<p>而在 PyTorch 中，我们使用了一种称为反向模式自动微分的技术，它允许你
随意更改网络行为，且零延迟、零开销。我们的灵感来自多篇相关研究论文，以及
<a href="https://github.com/twitter/torch-autograd">torch-autograd</a>、
<a href="https://github.com/HIPS/autograd">autograd</a>、
<a href="https://chainer.org">Chainer</a> 等当前及以往的相关工作。</p>
<p>尽管这种技术并非 PyTorch 独有，但我们拥有目前最快的实现之一。
你可以同时获得极致的速度与灵活性，助力你的前沿研究。</p>
<p><img src="https://github.com/pytorch/pytorch/raw/main/docs/source/_static/img/dynamic_graph.gif" alt="动态图" /></p>
<h3>Python 优先</h3>
<p>PyTorch 并不是一个巨大的 C++ 框架的 Python 绑定。
它被设计为深度集成于 Python。
你可以像使用 <a href="https://www.numpy.org/">NumPy</a> / <a href="https://www.scipy.org/">SciPy</a> / <a href="https://scikit-learn.org">scikit-learn</a> 那样自然地使用它。
你可以用自己喜欢的库在 Python 中编写新的神经网络层，
并借助 <a href="https://cython.org/">Cython</a> 和 <a href="http://numba.pydata.org/">Numba</a> 等工具包。
我们的目标是在合适的地方不重复造轮子。</p>
<h3>命令式体验</h3>
<p>PyTorch 设计直观、逻辑线性、易于使用。
你写一行代码，就会立刻执行。没有异步世界的概念。
调试或遇到错误时，堆栈跟踪清晰指向代码定义位置。
我们希望你不必因为糟糕的堆栈跟踪或异步、晦涩的执行引擎而花费数小时调试代码。</p>
<h3>快速且精简</h3>
<p>PyTorch 框架开销极小。我们集成了
<a href="https://software.intel.com/mkl">Intel MKL</a> 以及 NVIDIA（<a href="https://developer.nvidia.com/cudnn">cuDNN</a>、<a href="https://developer.nvidia.com/nccl">NCCL</a>）等加速库以提升速度。
底层的 CPU/GPU 张量与神经网络后端
成熟且历经多年测试。</p>
<p>因此，无论是小型还是大型神经网络，PyTorch 都非常快。</p>
<p>PyTorch 的内存使用极为高效，相较于 Torch 或其他替代品。
我们为 GPU 编写了自定义内存分配器，确保
你的深度学习模型具备极致内存效率。
这让你能训练比以往更大的深度学习模型。</p>
<h3>无痛扩展</h3>
<p>编写新的神经网络模块或对接 PyTorch 的张量 API 都非常直接，
且抽象最小。</p>
<p>你可以用 torch API 直接在 Python 中编写新神经网络层，
<a href="https://pytorch.org/tutorials/advanced/numpy_extensions_tutorial.html">或用你喜欢的基于 NumPy 的库（如 SciPy）</a>。</p>
<p>如果你想用 C/C++ 编写层，我们也提供高效且样板代码极少的扩展 API。
无需编写包装代码。你可以参考<a href="https://pytorch.org/tutorials/advanced/cpp_extension.html">此教程</a>及<a href="https://github.com/pytorch/extension-cpp">此示例</a>。</p>
<h2>安装</h2>
<h3>二进制包</h3>
<p>通过 Conda 或 pip wheels 安装二进制包的命令请见我们的官网：<a href="https://pytorch.org/get-started/locally/">https://pytorch.org/get-started/locally/</a></p>
<h4>NVIDIA Jetson 平台</h4>
<p>NVIDIA Jetson Nano、Jetson TX1/TX2、Jetson Xavier NX/AGX 和 Jetson AGX Orin 的 Python wheel 包在<a href="https://forums.developer.nvidia.com/t/pytorch-for-jetson-version-1-10-now-available/72048">这里</a>提供，L4T 容器发布在<a href="https://catalog.ngc.nvidia.com/orgs/nvidia/containers/l4t-pytorch">这里</a>。</p>
<p>它们需要 JetPack 4.2 及以上版本，<a href="https://github.com/dusty-nv"> @dusty-nv </a> 和 <a href="https://github.com/ptrblck"> @ptrblck </a> 负责维护。</p>
<h3>源码编译</h3>
<h4>先决条件</h4>
<p>如果你打算源码安装，你需要：</p>
<ul>
<li>Python 3.9 或更高版本</li>
<li>完全支持 C++17 的编译器，如 clang 或 gcc（Linux 上需 gcc 9.4.0 或更高版本）</li>
<li>Visual Studio 或 Visual Studio Build Tool（仅限 Windows）</li>
</ul>
<p>* PyTorch CI 使用 Visual C++ BuildTools，可通过 Visual Studio Enterprise、Professional 或 Community 版本获得。也可从 https://visualstudio.microsoft.com/visual-cpp-build-tools/ 单独安装。<em>Visual Studio Code</em> 默认不包含这些构建工具。</p>
<p>环境设置示例：</p>
<ul>
<li>Linux:</li>
</ul>
<pre><code class="language-bash">$ source &lt;CONDA_INSTALL_DIR&gt;/bin/activate
$ conda create -y -n &lt;CONDA_NAME&gt;
$ conda activate &lt;CONDA_NAME&gt;
</code></pre>
<ul>
<li>Windows:</li>
</ul>
<pre><code class="language-bash">$ source &lt;CONDA_INSTALL_DIR&gt;\Scripts\activate.bat
$ conda create -y -n &lt;CONDA_NAME&gt;
$ conda activate &lt;CONDA_NAME&gt;
$ call &quot;C:\Program Files\Microsoft Visual Studio\&lt;VERSION&gt;\Community\VC\Auxiliary\Build\vcvarsall.bat&quot; x64
</code></pre>
<h5>NVIDIA CUDA 支持</h5>
<p>若需编译 CUDA 支持，请<a href="https://pytorch.org/get-started/locally/">从支持矩阵中选择支持的 CUDA 版本</a>，然后安装以下组件：</p>
<ul>
<li><a href="https://developer.nvidia.com/cuda-downloads">NVIDIA CUDA</a></li>
<li><a href="https://developer.nvidia.com/cudnn">NVIDIA cuDNN</a> v8.5 或更高</li>
<li><a href="https://gist.github.com/ax3l/9489132">兼容 CUDA 的编译器</a></li>
</ul>
<p>注意：可参考 <a href="https://docs.nvidia.com/deeplearning/cudnn/backend/latest/reference/support-matrix.html">cuDNN 支持矩阵</a> 查看 cuDNN 与各 CUDA、驱动及硬件的兼容性。</p>
<p>若要禁用 CUDA 支持，导出环境变量 <code>USE_CUDA=0</code>。
更多有用的环境变量见 <code>setup.py</code>。</p>
<p>若为 NVIDIA Jetson 平台（Jetson Nano、TX1、TX2、AGX Xavier）编译，Jetson Nano 的安装说明见<a href="https://devtalk.nvidia.com/default/topic/1049071/jetson-nano/pytorch-for-jetson-nano/">此处</a>。</p>
<h5>AMD ROCm 支持</h5>
<p>若需编译 ROCm 支持，安装</p>
<ul>
<li><a href="https://rocm.docs.amd.com/en/latest/deploy/linux/quick_start.html">AMD ROCm</a> 4.0 或更高</li>
<li>ROCm 目前仅支持 Linux 系统。</li>
</ul>
<p>默认情况下构建系统期望 ROCm 安装在 <code>/opt/rocm</code>。如在其他目录，请设定 <code>ROCM_PATH</code> 环境变量。构建系统会自动检测 AMD GPU 架构，也可用 <code>PYTORCH_ROCM_ARCH</code> 显式指定<a href="https://rocm.docs.amd.com/projects/install-on-linux/en/latest/reference/system-requirements.html#supported-gpus">AMD GPU 架构</a>。</p>
<p>若要禁用 ROCm 支持，导出环境变量 <code>USE_ROCM=0</code>。
更多有用的环境变量见 <code>setup.py</code>。</p>
<h5>Intel GPU 支持</h5>
<p>如需编译 Intel GPU 支持，请参考</p>
<ul>
<li><a href="https://www.intel.com/content/www/us/en/developer/articles/tool/pytorch-prerequisites-for-intel-gpus.html">Intel GPU 的 PyTorch 先决条件</a>。</li>
<li>Intel GPU 支持 Linux 和 Windows。</li>
</ul>
<p>若要禁用 Intel GPU 支持，导出环境变量 <code>USE_XPU=0</code>。
更多有用的环境变量见 <code>setup.py</code>。</p>
<h4>获取 PyTorch 源码</h4>
<pre><code class="language-bash">git clone https://github.com/pytorch/pytorch
cd pytorch
# 如需更新已克隆仓库
git submodule sync
git submodule update --init --recursive
</code></pre>
<h4>安装依赖</h4>
<p><strong>通用</strong></p>
<pre><code class="language-bash">conda install cmake ninja
# 克隆源码后，在 PyTorch 目录下运行
pip install -r requirements.txt
</code></pre>
<p><strong>Linux 下</strong></p>
<pre><code class="language-bash">pip install mkl-static mkl-include
# 仅 CUDA：如需为 GPU 添加 LAPACK 支持
# 安装 magma：需激活 conda 环境并指定 CUDA 版本
.ci/docker/common/install_magma_conda.sh 12.4

# （可选）如使用 torch.compile 的 inductor/triton，需安装匹配 triton 版本
# 在 pytorch 目录下运行
# 对于 Intel GPU 支持，请在运行前显式 `export USE_XPU=1`
make triton
</code></pre>
<p><strong>MacOS 下</strong></p>
<pre><code class="language-bash"># 仅在 Intel x86 处理器机器添加此包
pip install mkl-static mkl-include
# 如需 torch.distributed，添加以下包
conda install pkg-config libuv
</code></pre>
<p><strong>Windows 下</strong></p>
<pre><code class="language-bash">pip install mkl-static mkl-include
# 如需 torch.distributed，添加以下包
# Windows 上分布式包支持为原型功能，可能有变动
conda install -c conda-forge libuv=1.39
</code></pre>
<h4>安装 PyTorch</h4>
<p><strong>Linux 下</strong></p>
<p>如为 AMD ROCm 编译，先运行：</p>
<pre><code class="language-bash"># 仅 ROCm 编译时运行
python tools/amd_build/build_amd.py
</code></pre>
<p>安装 PyTorch</p>
<pre><code class="language-bash">export CMAKE_PREFIX_PATH=&quot;${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}&quot;
python setup.py develop
</code></pre>
<p><strong>macOS 下</strong></p>
<pre><code class="language-bash">python3 setup.py develop
</code></pre>
<p><strong>Windows 下</strong></p>
<p>如需构建旧版 Python 代码，请参考<a href="https://github.com/pytorch/pytorch/blob/main/CONTRIBUTING.md#building-on-legacy-code-and-cuda">旧代码和 CUDA 构建说明</a></p>
<p><strong>仅 CPU 构建</strong></p>
<p>此模式下，PyTorch 计算将仅在 CPU 上运行。</p>
<pre><code class="language-cmd">python setup.py develop
</code></pre>
<p>OpenMP 说明：推荐使用 Intel OpenMP (iomp)。如需链接 iomp，需手动下载库并通过设置 <code>CMAKE_INCLUDE_PATH</code> 和 <code>LIB</code> 配置构建环境。详细说明可参考<a href="https://github.com/pytorch/pytorch/blob/main/docs/source/notes/windows.rst#building-from-source">此处</a>。如未做此配置，则会使用 Microsoft Visual C 的 OpenMP 运行时 (vcomp)。</p>
<p><strong>CUDA 构建</strong></p>
<p>此模式下，PyTorch 计算将通过 CUDA 利用 GPU 加速。</p>
<p>编译 PyTorch CUDA 需 <a href="https://docs.nvidia.com/gameworks/content/gameworkslibrary/nvtx/nvidia_tools_extension_library_nvtx.htm">NVTX</a>，
NVTX 属于 CUDA 套件（名称为 &quot;Nsight Compute&quot;）。如需安装到已装 CUDA 上，请重新运行安装程序并勾选相应选项。
确保在 Visual Studio 安装后再安装包含 Nsight Compute 的 CUDA。</p>
<p>当前支持 VS 2017/2019 及 Ninja 作为 CMake 生成器。如果 <code>PATH</code> 中检测到 <code>ninja.exe</code>，则默认使用 Ninja，否则用 VS 2017/2019。
<br/> 若选用 Ninja，底层工具链会选用最新 MSVC。</p>
<p>还常需安装
<a href="https://developer.nvidia.com/magma">Magma</a>、<a href="https://github.com/oneapi-src/oneDNN">oneDNN（又名 MKLDNN 或 DNNL）</a>、<a href="https://github.com/mozilla/sccache">Sccache</a> 等库。请参考<a href="https://github.com/pytorch/pytorch/tree/main/.ci/pytorch/win-test-helpers/installation-helpers">安装助手</a>。</p>
<p>更多环境变量设置可参考 <a href="https://github.com/pytorch/pytorch/blob/main/.ci/pytorch/win-test-helpers/build_pytorch.bat">build_pytorch.bat</a> 脚本。</p>
<pre><code class="language-cmd">cmd

:: 下载并解压 mkl 包后设置环境变量，否则 CMake 会报找不到 OpenMP 错。
set CMAKE_INCLUDE_PATH={Your directory}\mkl\include
set LIB={Your directory}\mkl\lib;%LIB%

:: 阅读前述内容后操作。
:: [可选] 如需覆盖 Ninja 和 Visual Studio 下 CUDA 的工具链，请运行以下脚本块。
:: 将自动运行 &quot;Visual Studio 2019 Developer Command Prompt&quot;。
:: 如使用 Visual Studio 生成器，请确保 CMake &gt;= 3.12。
set CMAKE_GENERATOR_TOOLSET_VERSION=14.27
set DISTUTILS_USE_SDK=1
for /f &quot;usebackq tokens=*&quot; %i in (`&quot;%ProgramFiles(x86)%\Microsoft Visual Studio\Installer\vswhere.exe&quot; -version [15^,17^) -products * -latest -property installationPath`) do call &quot;%i\VC\Auxiliary\Build\vcvarsall.bat&quot; x64 -vcvars_ver=%CMAKE_GENERATOR_TOOLSET_VERSION%

:: [可选] 如需覆盖 CUDA host 编译器
set CUDAHOSTCXX=C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.27.29110\bin\HostX64\x64\cl.exe

python setup.py develop

</code></pre>
<p><strong>Intel GPU 构建</strong></p>
<p>此模式下将构建支持 Intel GPU 的 PyTorch。</p>
<p>请确保<a href="#prerequisites">通用先决条件</a>及<a href="#intel-gpu-support">Intel GPU 先决条件</a>均已正确安装，并配置好环境变量。工具链需 <code>Visual Studio 2022</code>。</p>
<p>构建命令如下：</p>
<pre><code class="language-cmd">:: CMD 命令：
:: 设置 CMAKE_PREFIX_PATH 以便找到相关包
:: %CONDA_PREFIX% 仅在 `conda activate custom_env` 后有效

if defined CMAKE_PREFIX_PATH (
    set &quot;CMAKE_PREFIX_PATH=%CONDA_PREFIX%\Library;%CMAKE_PREFIX_PATH%&quot;
) else (
    set &quot;CMAKE_PREFIX_PATH=%CONDA_PREFIX%\Library&quot;
)

python setup.py develop
</code></pre>
<h5>调整构建选项（可选）</h5>
<p>可选地（无需先构建），你可以调整 cmake 变量配置。例如，调整 CuDNN 或 BLAS 的目录可在此步骤完成。</p>
<p>Linux 下</p>
<pre><code class="language-bash">export CMAKE_PREFIX_PATH=&quot;${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}&quot;
python setup.py build --cmake-only
ccmake build  # 或 cmake-gui build
</code></pre>
<p>macOS 下</p>
<pre><code class="language-bash">export CMAKE_PREFIX_PATH=&quot;${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}&quot;
MACOSX_DEPLOYMENT_TARGET=10.9 CC=clang CXX=clang++ python setup.py build --cmake-only
ccmake build  # 或 cmake-gui build
</code></pre>
<h3>Docker 镜像</h3>
<h4>使用预构建镜像</h4>
<p>你也可以从 Docker Hub 拉取预构建镜像并用 docker v19.03+ 运行</p>
<pre><code class="language-bash">docker run --gpus all --rm -ti --ipc=host pytorch/pytorch:latest
</code></pre>
<p>请注意，PyTorch 使用共享内存在进程间共享数据，因此如使用 torch 多进程（如多线程数据加载器），
容器默认的共享内存段大小可能不足，建议在运行时用 <code>--ipc=host</code> 或 <code>--shm-size</code> 选项调整。</p>
<h4>自行构建镜像</h4>
<p><strong>注意：</strong> 必须使用 docker 18.06 以上版本构建</p>
<p><code>Dockerfile</code> 提供了带 CUDA 11.1 和 cuDNN v8 支持的镜像构建方案。
你可通过 <code>PYTHON_VERSION=x.y</code> 变量指定 Miniconda 使用的 Python 版本，未设置则用默认值。</p>
<pre><code class="language-bash">make -f docker.Makefile
# 镜像标签为 docker.io/${your_docker_username}/pytorch
</code></pre>
<p>你还可以通过 <code>CMAKE_VARS=&quot;...&quot;</code> 环境变量传递额外 CMake 变量。
详情见 <a href="./setup.py">setup.py</a>。</p>
<pre><code class="language-bash">make -f docker.Makefile
</code></pre>
<h3>构建文档</h3>
<p>要以多种格式构建文档，你需安装 <a href="http://www.sphinx-doc.org">Sphinx</a>
和 pytorch_sphinx_theme2。</p>
<p>本地构建前，请确保你的环境已安装 <code>torch</code>。如仅做小修可安装夜间版，方法见<a href="https://pytorch.org/get-started/locally/">快速入门</a>。</p>
<p>如需更复杂的修复（如添加新模块及文档字符串），可能需<a href="#from-source">源码安装 torch</a>。
文档字符串规范见<a href="https://github.com/pytorch/pytorch/wiki/Docstring-Guidelines">Docstring Guidelines</a>。</p>
<pre><code class="language-bash">cd docs/
pip install -r requirements.txt
make html
make serve
</code></pre>
<p>运行 <code>make</code> 可查看所有可用输出格式。</p>
<p>如遇 katex 错误，运行 <code>npm install katex</code>。若仍报错，尝试
<code>npm install -g katex</code></p>
<blockquote>
<p>[!NOTE]
若你用其他包管理器（如 <code>conda</code>）安装了 <code>nodejs</code>，<code>npm</code> 可能安装了与你 nodejs 版本不兼容的 katex，导致文档构建失败。
已知可用版本组合为 <code>node@6.13.1</code> 和 <code>katex@0.13.18</code>。用 <code>npm</code> 安装后者命令如下：
<code>npm install -g katex@0.13.18</code></p>
</blockquote>
<blockquote>
<p>[!NOTE]
如遇 numpy 不兼容错误，运行：</p>
<pre><code>pip install 'numpy&lt;2'
</code></pre>
</blockquote>
<p>如修改了 CI 依赖，请编辑 <code>.ci/docker/requirements-docs.txt</code> 文件。</p>
<h4>构建 PDF</h4>
<p>要编译 PyTorch 全部文档为 PDF，需安装 <code>texlive</code> 和 LaTeX。macOS 可用：</p>
<pre><code>brew install --cask mactex
</code></pre>
<p>生成 PDF 步骤：</p>
<ol>
<li><p>运行：</p>
<pre><code>make latexpdf
</code></pre>
<p>这会在 <code>build/latex</code> 目录生成所需文件。</p>
</li>
<li><p>进入该目录并执行：</p>
<pre><code>make LATEXOPTS=&quot;-interaction=nonstopmode&quot;
</code></pre>
<p>将生成 <code>pytorch.pdf</code>。再运行一次以正确生成目录和索引。</p>
</li>
</ol>
<blockquote>
<p>[!NOTE]
若需查看目录，请在 PDF 阅读器中切换到<strong>目录</strong>视图。</p>
</blockquote>
<h3>历史版本</h3>
<p>以往 PyTorch 版本的安装说明和二进制包见
<a href="https://pytorch.org/get-started/previous-versions">官网</a>。</p>
<h2>快速入门</h2>
<p>三步助你上手：</p>
<ul>
<li><a href="https://pytorch.org/tutorials/">教程：了解并使用 PyTorch</a></li>
<li><a href="https://github.com/pytorch/examples">示例：各领域易懂的 PyTorch 代码</a></li>
<li><a href="https://pytorch.org/docs/">API 参考手册</a></li>
<li><a href="https://github.com/pytorch/pytorch/blob/main/GLOSSARY.md">术语表</a></li>
</ul>
<h2>资源</h2>
<ul>
<li><a href="https://pytorch.org/">PyTorch.org</a></li>
<li><a href="https://pytorch.org/tutorials/">PyTorch 教程</a></li>
<li><a href="https://github.com/pytorch/examples">PyTorch 示例</a></li>
<li><a href="https://pytorch.org/hub/">PyTorch 模型</a></li>
<li><a href="https://www.udacity.com/course/deep-learning-pytorch--ud188">Udacity 深度学习 PyTorch 入门</a></li>
<li><a href="https://www.udacity.com/course/intro-to-machine-learning-nanodegree--nd229">Udacity PyTorch 机器学习入门</a></li>
<li><a href="https://www.coursera.org/learn/deep-neural-networks-with-pytorch">Coursera PyTorch 深度神经网络</a></li>
<li><a href="https://twitter.com/PyTorch">PyTorch Twitter</a></li>
<li><a href="https://pytorch.org/blog/">PyTorch 博客</a></li>
<li><a href="https://www.youtube.com/channel/UCWXI5YeOsh03QvJ59PMaXFw">PyTorch YouTube</a></li>
</ul>
<h2>交流</h2>
<ul>
<li>论坛：实现、研究等讨论 https://discuss.pytorch.org</li>
<li>GitHub Issues：Bug 报告、特性请求、安装问题、RFC、建议等</li>
<li>Slack：<a href="https://pytorch.slack.com/">PyTorch Slack</a> 主要面向中高级 PyTorch 用户和开发者，适于一般讨论、协作等。如为初学者，建议优先用 <a href="https://discuss.pytorch.org">PyTorch 论坛</a>。如需 Slack 邀请，请填写此表：https://goo.gl/forms/PP1AGvNHpSaJP8to1</li>
<li>邮件简报：一条通道，推送 PyTorch 重要公告。可在此注册：https://eepurl.com/cbG0rv</li>
<li>Facebook 页面：PyTorch 重要公告 https://www.facebook.com/pytorch</li>
<li>品牌规范请见<a href="https://pytorch.org/">官网</a></li>
</ul>
<h2>版本与贡献</h2>
<p>PyTorch 通常每年有三个小版本发布。如遇 Bug，请<a href="https://github.com/pytorch/pytorch/issues">提交 Issue</a>。</p>
<p>欢迎所有贡献。若你计划贡献 Bug 修复，直接提交即可，无需进一步讨论。</p>
<p>如计划贡献新特性、实用函数或核心扩展，请先提交 Issue 与我们讨论，
直接提交 PR 可能会因方向不符而被拒。</p>
<p>了解更多 PyTorch 贡献方式，请见<a href="CONTRIBUTING.md">贡献页面</a>。了解 PyTorch 版本信息请见<a href="RELEASE.md">版本说明</a>。</p>
<h2>团队</h2>
<p>PyTorch 是一个由社区驱动的项目，众多出色工程师和研究人员共同贡献。</p>
<p>当前主要由 <a href="http://soumith.ch">Soumith Chintala</a>、<a href="https://github.com/gchanan">Gregory Chanan</a>、<a href="https://github.com/dzhulgakov">Dmytro Dzhulgakov</a>、<a href="https://github.com/ezyang">Edward Yang</a> 和 <a href="https://github.com/malfet">Nikita Shulga</a> 维护，数百名才华横溢的个人以各种方式做出贡献。
部分主要贡献者（不完全名单）：<a href="https://github.com/killeent">Trevor Killeen</a>、<a href="https://github.com/chsasank">Sasank Chilamkurthy</a>、<a href="https://github.com/szagoruyko">Sergey Zagoruyko</a>、<a href="https://github.com/adamlerer">Adam Lerer</a>、<a href="https://github.com/fmassa">Francisco Massa</a>、<a href="https://github.com/alykhantejani">Alykhan Tejani</a>、<a href="https://github.com/lantiga">Luca Antiga</a>、<a href="https://github.com/albanD">Alban Desmaison</a>、<a href="https://github.com/andreaskoepf">Andreas Koepf</a>、<a href="https://github.com/jekbradbury">James Bradbury</a>、<a href="https://github.com/ebetica">Zeming Lin</a>、<a href="https://github.com/yuandong-tian">Yuandong Tian</a>、<a href="https://github.com/glample">Guillaume Lample</a>、<a href="https://github.com/Maratyszcza">Marat Dukhan</a>、<a href="https://github.com/ngimel">Natalia Gimelshein</a>、<a href="https://github.com/csarofeen">Christian Sarofeen</a>、<a href="https://github.com/martinraison">Martin Raison</a>、<a href="https://github.com/ezyang">Edward Yang</a>、<a href="https://github.com/zdevito">Zachary Devito</a>。</p>
<p>注意：本项目与同名的 <a href="https://github.com/hughperkins/pytorch">hughperkins/pytorch</a> 无关。Hugh 是 Torch 社区的宝贵贡献者，为 Torch 和 PyTorch 做出了许多贡献。</p>
<h2>许可证</h2>
<p>PyTorch 采用 BSD 风格许可证，详见 <a href="LICENSE">LICENSE</a> 文件。</p>
<hr />
<p><a href="https://github.com/OpenAiTx/OpenAiTx">Powered By OpenAiTx</a></p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
</body>
</html>