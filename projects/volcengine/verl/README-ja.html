<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>verl - volcengine/verl ja</title>
    <meta name="title" content="verl - volcengine/verl ja | 👋 こんにちは、みなさん！ verlはByteDance Seedチームが発起し、verlコミュニティによってメンテナンスされているRLトレーニングライブラリです。 verl: Volcano Engine Reinforcement Learning for LLMs verlは、大規模言語モデル（LLM）向けの柔...">
    <meta name="description" content="volcengine/verl - GitHub repository ja documentation and information | 👋 こんにちは、みなさん！ verlはByteDance Seedチームが発起し、verlコミュニティによってメンテナンスされているRLトレーニングライブラリです。 verl: Volcano Engine Reinforcement Learning for LLMs verlは、大規模言語モデル（LLM）向けの柔...">
    <meta name="keywords" content="volcengine, verl, GitHub, repository, ja documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/volcengine/verl/README-ja.html">
    <meta property="og:title" content="verl - volcengine/verl ja | 👋 こんにちは、みなさん！ verlはByteDance Seedチームが発起し、verlコミュニティによってメンテナンスされているRLトレーニングライブラリです。 verl: Volcano Engine Reinforcement Learning for LLMs verlは、大規模言語モデル（LLM）向けの柔...">
    <meta property="og:description" content="volcengine/verl - GitHub repository ja documentation and information | 👋 こんにちは、みなさん！ verlはByteDance Seedチームが発起し、verlコミュニティによってメンテナンスされているRLトレーニングライブラリです。 verl: Volcano Engine Reinforcement Learning for LLMs verlは、大規模言語モデル（LLM）向けの柔...">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div style="position: fixed; top: 2px; left: 2px; z-index: 2000; background: rgba(255,255,255,0.95); border-radius: 6px; box-shadow: 0 2px 8px rgba(0,0,0,0.06); padding: 4px 14px; font-size: 15px; color: #222; font-family: 'Segoe UI', Arial, sans-serif; font-weight: 500; letter-spacing: 0.5px;">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" style="color: #0366d6; text-decoration: none; font-weight: 600;">Open AI Tx</a>
    </div>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/volcengine/verl" id="githubRepoLink" target="_blank">volcengine/verl</a>
<h1 style="display: none;">👋 こんにちは、みなさん！ verlはByteDance Seedチームが発起し、verlコミュニティによってメンテナンスされているRLトレーニングライブラリです。 verl: Volcano Engine Reinforcement Learning for LLMs verlは、大規模言語モデル（LLM）向けの柔...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <div align="center">
 👋 こんにちは、みなさん！
    verlは<b>ByteDance Seedチーム</b>が発起し、verlコミュニティによってメンテナンスされているRLトレーニングライブラリです。
    <br>
    <br>
</div>
<div align="center">
<p><a href="https://deepwiki.com/volcengine/verl"><img src="https://devin.ai/assets/deepwiki-badge.png" alt="Ask DeepWiki.com" height="20"/></a>
<a href="https://github.com/volcengine/verl/stargazers"><img src="https://img.shields.io/github/stars/volcengine/verl" alt="GitHub Repo stars" /></a>
<a href="https://twitter.com/verl_project"><img src="https://img.shields.io/twitter/follow/verl_project" alt="Twitter" /></a>
<a href="https://join.slack.com/t/verlgroup/shared_invite/zt-2w5p9o4c3-yy0x2Q56s_VlGLsJ93A6vA"><img src="https://img.shields.io/badge/Slack-verl-blueviolet?logo=slack&amp"></a>
<a href="https://arxiv.org/pdf/2409.19256"><img src="https://img.shields.io/static/v1?label=EuroSys&message=Paper&color=red"></a>
<a href="https://verl.readthedocs.io/en/latest/"><img src="https://img.shields.io/badge/documentation-blue" alt="Documentation" /></a>
<a href="https://raw.githubusercontent.com/eric-haibin-lin/verl-community/refs/heads/main/WeChat.JPG"><img src="https://img.shields.io/badge/微信-green?logo=wechat&amp"></a></p>
</div>
<p><img src="https://github.com/user-attachments/assets/c42e675e-497c-4508-8bb9-093ad4d1f216" alt="seed logo" /></p>
<h1 style="text-align: center;">verl: Volcano Engine Reinforcement Learning for LLMs</h1>
<p>verlは、大規模言語モデル（LLM）向けの柔軟で高効率かつプロダクションレディなRLトレーニングライブラリです。</p>
<p>verlは、<strong><a href="https://arxiv.org/abs/2409.19256v2">HybridFlow: A Flexible and Efficient RLHF Framework</a></strong> 論文のオープンソースバージョンです。</p>
<p>verlは以下の特徴で柔軟かつ使いやすい設計となっています：</p>
<ul>
<li><p><strong>多様なRLアルゴリズムの容易な拡張</strong>：ハイブリッドコントローラプログラミングモデルにより、複雑な後処理データフローを柔軟かつ効率的に表現・実行可能。GRPOやPPOなどのRLデータフローを数行のコードで構築できます。</p>
</li>
<li><p><strong>モジュラーAPIによる既存LLMインフラとのシームレス統合</strong>：計算とデータ依存性を分離し、FSDP、Megatron-LM、vLLM、SGLangなど既存LLMフレームワークとのシームレスな統合を実現。</p>
</li>
<li><p><strong>柔軟なデバイスマッピング</strong>：さまざまなGPUセットへのモデル配置をサポートし、効率的なリソース活用とクラスター規模に応じたスケーラビリティを提供。</p>
</li>
<li><p>HuggingFaceの人気モデルとの即時統合</p>
</li>
</ul>
<p>verlは高速です：</p>
<ul>
<li><p><strong>最先端のスループット</strong>：SOTA LLMトレーニング・推論エンジン統合およびSOTA RLスループットを実現。</p>
</li>
<li><p><strong>3D-HybridEngineによる効率的なアクターモデル再シャーディング</strong>：トレーニングと生成フェーズの遷移時にメモリの冗長性を解消し、通信オーバーヘッドを大幅に削減。</p>
</li>
</ul>
</p>
<h2>ニュース</h2>
<ul>
<li>[2025/06] verlはMegatronバックエンドで<a href="https://verl.readthedocs.io/en/latest/perf/dpsk.html">DeepSeek-671bおよびQwen3-236b</a>などの大規模MoEモデルをサポート。</li>
<li>[2025/06] verlチームが<a href="https://www.lfasiallc.com/pytorch-day-china/">PyTorch Day China</a>（6月7日開催）で最新プロジェクトアップデートを発表予定。北京でお会いしましょう！</li>
<li>[2025/05] <a href="https://arxiv.org/abs/2409.06957">PF-PPO</a>がICML 2025に採択され、verlでサポート開始！PF-PPOはリプレイバッファによる高品質経験の再利用とノイズリワード信号のフィルタリングで方策学習効率と堅牢性を強化します。</li>
<li>[2025/04] <a href="https://iclr.cc/virtual/2025/calendar?filter_events=Expo+Talk+Panel&amp;filter_rooms=">ICLR 2025 Expo</a>、<a href="https://open-foundation-model.github.io/">SCI-FMワークショップ</a>、<a href="https://lu.ma/d23nyynm">LMSys afterparty</a>でverlの最新後処理技術とプログラミングガイドのチュートリアルを行います。資料は<a href="https://github.com/eric-haibin-lin/verl-community/tree/main/iclr25">こちら</a>。</li>
<li>[2025/04] <a href="https://github.com/ByteDance-Seed/Seed-Thinking-v1.5/blob/main/seed-thinking-v1.5.pdf">Seed-Thinking-v1.5</a>技術レポート公開！verlでトレーニングされ、Seed-Thinking-v1.5はAIME 2024で86.7、Codeforcesで55.0、GPQAで77.3を達成。STEMやコーディング領域で優れた推論能力と幅広い汎化性能を示します。</li>
<li>[2025/04] <a href="https://arxiv.org/pdf/2504.05118">VAPO</a>（価値ベース拡張PPO）論文で最新RL手法を公開。Qwen-32B-baseモデルから学習しAIME 2024で60.4を達成、DAPO-32Bを上回ります。</li>
<li>[2025/03] verl v0.3.0.post1リリース！詳細は<a href="https://github.com/volcengine/verl/releases/">リリースノート</a>参照。前バージョン比で<a href="https://tongyx361.github.io/blogs/posts/verl-intro/#/verl-flexible-and-efficient-rl-for-llms">~1.4倍高速化</a>。</li>
<li>[2025/03] <a href="https://dapo-sia.github.io/">DAPO</a>はQwen2.5-32B事前学習モデルでAIME 2024で50点を達成し、DeepSeekのGRPO（DeepSeek-R1-Zero-Qwen-32B）を超えるSOTA RLアルゴリズム。verlで完全トレーニングされ、<code>recipe/dapo</code>で再現コード公開中。</li>
</ul>
<details><summary> さらに表示... </summary>
<ul>
  <li>[2025/05] [A2M Shanghai](https://a2m.msup.com.cn/home/?aid=4488&city=shanghai)（5/16-5/17）でverlを発表。</li>
  <li>[2025/05] [GOSIM x PyTorch Day 2025](https://paris2025.gosim.org/)でverlを発表。パリで会いましょう！</li>
  <li>[2025/03] [vLLM Beijing Meetup](https://mp.weixin.qq.com/s/n77GibL2corAtQHtVEAzfg)、[SGLang-LMSYS Org Meetup](https://lu.ma/ntjrr7ig)でverlのプログラミングモデルを紹介。[発表資料](https://github.com/eric-haibin-lin/verl-community/blob/main/slides/verl-lmsys-meetup.pdf)。</li>
  <li>[2025/03] EuroSys 2025でverl(HybridFlow)を発表予定。ロッテルダムで会いましょう！</li>
  <li>[2025/02] verl v0.2.0.post2リリース！</li>
  <li>[2025/02] <a href="https://lu.ma/ji7atxux">Bytedance/NVIDIA/Anyscale Ray Meetup</a>でverlを発表。サンノゼで会いましょう！</li>
  <li>[2025/01] [Doubao-1.5-pro](https://team.doubao.com/zh/special/doubao_1_5_pro)がLLM & VLMでSOTA級性能で公開。verlでRLスケーリングプレビューモデルがトレーニングされ、AIMEでOpenAI O1級性能（pass@1: 70.0）を達成。</li>
  <li>[2024/12] Ray Forward 2024でverlを発表。[資料はこちら](https://github.com/eric-haibin-lin/verl-community/blob/main/slides/Ray_Forward_2024_%E5%B7%AB%E9%94%A1%E6%96%8C.pdf)</li>
  <li>[2024/12] NeurIPS 2024で<a href="https://neurips.cc/Expo/Conferences/2024/workshop/100677">Post-training LLMs: From Algorithms to Infrastructure</a>を発表。[スライド](https://github.com/eric-haibin-lin/verl-data/tree/neurips)、[ビデオ](https://neurips.cc/Expo/Conferences/2024/workshop/100677)公開中。</li>
  <li>[2024/10] Ray Summitでverlを発表。[Youtube動画](https://www.youtube.com/watch?v=MrhMcXkXvJU&list=PLzTswPQNepXntmT8jr9WaNfqQ60QwW7-U&index=37)</li>
  <li>[2024/08] HybridFlow (verl)がEuroSys 2025に採択。</li>
</ul>   
</details>
<h2>主な特徴</h2>
<ul>
<li>トレーニング用に<strong>FSDP</strong>、<strong>FSDP2</strong>、<strong>Megatron-LM</strong>をサポート</li>
<li>ロールアウト生成に<strong>vLLM</strong>、<strong>SGLang</strong>、<strong>HF Transformers</strong>をサポート</li>
<li>Hugging Face TransformersおよびModelscope Hubと互換：<a href="https://github.com/volcengine/verl/blob/main/examples/grpo_trainer/run_qwen3-8b.sh">Qwen-3</a>、Qwen-2.5、Llama3.1、Gemma2、DeepSeek-LLMなど</li>
<li>教師ありファインチューニング</li>
<li>強化学習：<a href="https://raw.githubusercontent.com/volcengine/verl/main/examples/ppo_trainer/">PPO</a>、<a href="https://raw.githubusercontent.com/volcengine/verl/main/examples/grpo_trainer/">GRPO</a>、<a href="https://raw.githubusercontent.com/volcengine/verl/main/examples/remax_trainer/">ReMax</a>、<a href="https://verl.readthedocs.io/en/latest/examples/config.html#algorithm">REINFORCE++</a>、<a href="https://raw.githubusercontent.com/volcengine/verl/main/examples/rloo_trainer/">RLOO</a>、<a href="https://raw.githubusercontent.com/volcengine/verl/main/recipe/prime/">PRIME</a>、<a href="https://raw.githubusercontent.com/volcengine/verl/main/recipe/dapo/">DAPO</a>、<a href="https://raw.githubusercontent.com/volcengine/verl/main/recipe/drgrpo">DrGRPO</a>など
<ul>
<li>数学や<a href="https://github.com/volcengine/verl/tree/main/recipe/dapo">コーディング</a>等に対してモデルベースリワード・関数ベースリワード（検証可能リワード）をサポート</li>
<li>VLMsや<a href="https://raw.githubusercontent.com/volcengine/verl/main/examples/grpo_trainer/run_qwen2_5_vl-7b.sh">マルチモーダルRL</a>をQwen2.5-vl、Kimi-VLでサポート</li>
<li><a href="https://github.com/volcengine/verl/tree/main/examples/sglang_multiturn">ツールコールによるマルチターン</a></li>
</ul>
</li>
<li>LLMアライメントレシピ（<a href="https://github.com/volcengine/verl/tree/main/recipe/sppo">Self-play preference optimization (SPPO)</a>など）</li>
<li>Flash attention 2、<a href="https://raw.githubusercontent.com/volcengine/verl/main/examples/ppo_trainer/run_qwen2-7b_seq_balance.sh">シーケンスパッキング</a>、<a href="https://raw.githubusercontent.com/volcengine/verl/main/examples/ppo_trainer/run_deepseek7b_llm_sp2.sh">シーケンス並列</a>をDeepSpeed Ulysses経由でサポート、<a href="https://raw.githubusercontent.com/volcengine/verl/main/examples/sft/gsm8k/run_qwen_05_peft.sh">LoRA</a>、<a href="https://raw.githubusercontent.com/volcengine/verl/main/examples/sft/gsm8k/run_qwen_05_sp2_liger.sh">Liger-kernel</a>も</li>
<li><a href="https://github.com/volcengine/verl/pull/1467">エキスパート並列</a>で671Bモデル・数百GPU規模へ拡張可能</li>
<li>マルチGPU <a href="https://verl.readthedocs.io/en/latest/advance/ppo_lora.html">LoRA RL</a>で省メモリ化</li>
<li>wandb, swanlab, mlflow, tensorboard等で実験トラッキング</li>
</ul>
<h2>今後の機能・変更点</h2>
<ul>
<li>ロードマップ https://github.com/volcengine/verl/issues/710</li>
<li>Megatron v0.11によるDeepSeek 671b最適化 https://github.com/volcengine/verl/issues/708</li>
<li>マルチターンロールアウト・ツール統合最適化 https://github.com/volcengine/verl/issues/1882</li>
<li>環境インタラクション https://github.com/volcengine/verl/issues/1172</li>
<li>v0.3以降のブレイキングチェンジ一覧 https://github.com/volcengine/verl/discussions/943、entropy_coeffはデフォルト0</li>
<li>RL用Lora https://github.com/volcengine/verl/pull/1127</li>
</ul>
<h2>はじめに</h2>
<p><a href="https://verl.readthedocs.io/en/latest/index.html"><b>ドキュメント</b></a></p>
<p><strong>クイックスタート：</strong></p>
<ul>
<li><a href="https://verl.readthedocs.io/en/latest/start/install.html">インストール</a></li>
<li><a href="https://verl.readthedocs.io/en/latest/start/quickstart.html">クイックスタート</a></li>
<li><a href="https://verl.readthedocs.io/en/latest/hybrid_flow.html">プログラミングガイド</a></li>
<li><a href="https://verl.readthedocs.io/en/latest/algo/ppo.html">verlでのPPO</a></li>
<li><a href="https://verl.readthedocs.io/en/latest/algo/grpo.html">verlでのGRPO</a></li>
</ul>
<p><strong>PPOの例をステップバイステップで実行：</strong></p>
<ul>
<li><a href="https://verl.readthedocs.io/en/latest/preparation/prepare_data.html">後処理用データ準備</a></li>
<li><a href="https://verl.readthedocs.io/en/latest/preparation/reward_function.html">データセット用リワード関数実装</a></li>
<li><a href="https://verl.readthedocs.io/en/latest/examples/ppo_code_architecture.html">PPO例のアーキテクチャ解説</a></li>
<li><a href="https://verl.readthedocs.io/en/latest/examples/config.html">設定ファイル解説</a></li>
</ul>
<p><strong>再現性のあるアルゴリズムベースライン：</strong></p>
<ul>
<li><a href="https://verl.readthedocs.io/en/latest/algo/baseline.html">コーディング・数学でのRL性能</a></li>
</ul>
<p><strong>コード解説・高度な利用（拡張）：</strong></p>
<ul>
<li><p>PPOトレーナーとワーカー</p>
<ul>
<li><a href="https://verl.readthedocs.io/en/latest/workers/ray_trainer.html">PPO Rayトレーナー</a></li>
<li><a href="https://verl.readthedocs.io/en/latest/workers/fsdp_workers.html">PyTorch FSDPバックエンド</a></li>
<li><a href="https://verl.readthedocs.io/en/latest/index.html">Megatron-LMバックエンド</a></li>
</ul>
</li>
<li><p>高度な利用・拡張</p>
<ul>
<li><a href="https://verl.readthedocs.io/en/latest/advance/fsdp_extension.html">FSDPバックエンドでのモデル追加</a></li>
<li><a href="https://verl.readthedocs.io/en/latest/advance/megatron_extension.html">Megatron-LMバックエンドでのモデル追加</a></li>
<li><a href="https://verl.readthedocs.io/en/latest/sglang_multiturn/multiturn.html">マルチターンロールアウト対応</a></li>
<li><a href="https://verl.readthedocs.io/en/latest/sglang_multiturn/search_tool_example.html">検索ツール統合</a></li>
<li><a href="https://verl.readthedocs.io/en/latest/examples/sandbox_fusion_example.html">Sandbox Fusion統合</a></li>
<li><a href="https://github.com/volcengine/verl/tree/main/examples/split_placement">GPUリソース分割によるデプロイ</a></li>
<li><a href="https://verl.readthedocs.io/en/latest/advance/dpo_extension.html">他のRL(HF)アルゴリズム拡張</a></li>
<li><a href="https://verl.readthedocs.io/en/latest/advance/placement.html">Ray API設計チュートリアル</a></li>
</ul>
</li>
</ul>
<p><strong>コミュニティのブログ</strong></p>
<ul>
<li><a href="https://github.com/zhaochenyang20/Awesome-ML-SYS-Tutorial/blob/main/rlhf/verl/multi-turn/verl-multiturn-rollout-Release.md">SGLang, verl, OpenBMB, 清華大学：エンドツーエンド多ターンRLHFの開拓</a></li>
<li><a href="https://rocm.blogs.amd.com/artificial-intelligence/verl-large-scale/README.html">verlとROCm統合によるAMD GPUでの人間フィードバック強化学習</a></li>
<li><a href="https://mp.weixin.qq.com/s/7nbqxk4knMGd-hQE9ls2tA">veMLP x verl ：強化学習トレーニング活用</a></li>
<li><a href="https://www.volcengine.com/docs/6459/1463942">verlによるGRPO分散強化学習ベストプラクティス</a></li>
<li><a href="https://github.com/zhaochenyang20/Awesome-ML-SYS-Tutorial/blob/main/rlhf/verl/readme.md">HybridFlow verl原文浅析</a></li>
<li><a href="https://team.doubao.com/en/blog/%E6%9C%80%E9%AB%98%E6%8F%90%E5%8D%8720%E5%80%8D%E5%90%9E%E5%90%90%E9%87%8F-%E8%B1%86%E5%8C%85%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9B%A3%E9%98%9F%E5%8F%91%E5%B8%83%E5%85%A8%E6%96%B0-rlhf-%E6%A1%86%E6%9E%B6-%E7%8E%B0%E5%B7%B2%E5%BC%80%E6%BA%90">最大20倍スループット向上！豆包大模型チーム、新RLHFフレームワーク公開</a></li>
</ul>
<h2>性能チューニングガイド</h2>
<p>オンポリシーRLアルゴリズムの性能は極めて重要です。最適化のための詳細な<a href="https://verl.readthedocs.io/en/latest/perf/perf_tuning.html">性能チューニングガイド</a>を用意しています。</p>
<h2>vLLM &gt;= v0.8.2へのアップグレード</h2>
<p>verlはFSDPをトレーニングバックエンドとして利用時、vLLM&gt;=0.8.2をサポートします。<a href="https://github.com/volcengine/verl/blob/main/docs/README_vllm0.8.md">こちらのドキュメント</a>をご参照ください。vllm 0.7.xはOOMや予期せぬエラーの原因となるバグを含むため避けてください。</p>
<h2>最新SGLangの利用</h2>
<p>SGLangはverlと完全統合されています。SGLang RLグループはマルチターンエージェントRL、VLM RLHF、サーバーベースRL、部分ロールアウトなどユニークな機能に積極的に取り組んでいます。<a href="https://verl.readthedocs.io/en/latest/workers/sglang_worker.html">こちら</a>を参照してください。</p>
<h2>FSDP2へのアップグレード</h2>
<p>verlはFSDP2を全面的にサポートします！FSDP2はtorch distributedチーム推奨で、より高いスループットとメモリ効率、他の機能との組み合わせが可能です（例：torch.compile）。FSDP2有効化は下記設定で可能です：</p>
<pre><code>actor_rollout_ref.ref.strategy=fsdp2
actor_rollout_ref.actor.strategy=fsdp2
critic.strategy=fsdp2 
reward_model.strategy=fsdp2 
</code></pre>
<p>さらに、FSDP2のCPUオフロードは勾配蓄積と互換があり、<code>actor_rollout_ref.actor.offload_policy=True</code>で省メモリ化できます。詳細は https://github.com/volcengine/verl/pull/1026</p>
<h2>AMDサポート（ROCmカーネル）</h2>
<p>verlはFSDPをトレーニングエンジンとしてサポート（Megatronは近日対応予定）、推論エンジンとしてvLLM・SGLang統合済みです。<a href="https://github.com/volcengine/verl/blob/main/docs/amd_tutorial/amd_build_dockerfile_page.rst">インストールガイドはこちら</a>、<a href="https://github.com/volcengine/verl/blob/main/docs/amd_tutorial/amd_vllm_page.rst">vLLMのROCmチューニングはこちら</a>。</p>
<h2>引用・謝辞</h2>
<p>本プロジェクトが有用な場合、以下を引用してください：</p>
<ul>
<li><a href="https://arxiv.org/abs/2409.19256v2">HybridFlow: A Flexible and Efficient RLHF Framework</a></li>
<li><a href="https://i.cs.hku.hk/%7Ecwu/papers/gmsheng-NL2Code24.pdf">A Framework for Training Large Language Models for Code Generation via Proximal Policy Optimization</a></li>
</ul>
<pre><code class="language-bibtex">@article{sheng2024hybridflow,
  title   = {HybridFlow: A Flexible and Efficient RLHF Framework},
  author  = {Guangming Sheng and Chi Zhang and Zilingfeng Ye and Xibin Wu and Wang Zhang and Ru Zhang and Yanghua Peng and Haibin Lin and Chuan Wu},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2409.19256}
}
</code></pre>
<p>verlはNemo-Aligner、Deepspeed-chat、OpenRLHFの設計にインスパイアされています。Bytedance、Anyscale、LMSys.org、<a href="https://github.com/QwenLM/">Alibaba Qwenチーム</a>、上海AI Lab、清華大学、UC Berkeley、UCLA、UIUC、香港大学、ke.com、<a href="https://www.all-hands.dev/">All Hands AI</a>、<a href="http://modelbest.cn/">ModelBest</a>、OpenPipe、JD AI Lab、Microsoft Research、<a href="https://www.stepfun.com/">StepFun</a>、Amazon、Linkedin、美団、<a href="https://www.camel-ai.org/">Camel-AI</a>、<a href="https://github.com/OpenManus">OpenManus</a>、Xiaomi、Prime Intellect、NVIDIA研究所、<a href="https://www.baichuan-ai.com/home">Baichuan</a>、<a href="https://www.xiaohongshu.com/">RedNote</a>、<a href="https://www.swiss-ai.org/">SwissAI</a>、<a href="https://www.moonshot-ai.com/">Moonshot AI (Kimi)</a>、Baidu、Snowflake等、多くの団体に採用・貢献されています。</p>
<h2>verlを活用した素晴らしいプロジェクト</h2>
<ul>
<li><a href="https://github.com/Jiayi-Pan/TinyZero">TinyZero</a>：<strong>DeepSeek R1 Zero</strong>の推論タスク再現 <img src="https://img.shields.io/github/stars/Jiayi-Pan/TinyZero" alt="GitHub Repo stars" /></li>
<li><a href="https://github.com/NovaSky-AI/SkyThought">SkyThought</a>：NovaSky AIチームによるSky-T1-7B RLトレーニング <img src="https://img.shields.io/github/stars/NovaSky-AI/SkyThought" alt="GitHub Repo stars" /></li>
<li><a href="https://github.com/hkust-nlp/simpleRL-reason">simpleRL-reason</a>：SimpleRL-Zoo: ゼロRLの検証と制御 <img src="https://img.shields.io/github/stars/hkust-nlp/simpleRL-reason" alt="GitHub Repo stars" /></li>
<li><a href="https://github.com/hiyouga/EasyR1">Easy-R1</a>：<strong>マルチモーダル</strong>RLトレーニングフレームワーク <img src="https://img.shields.io/github/stars/hiyouga/EasyR1" alt="GitHub Repo stars" /></li>
<li><a href="https://github.com/OpenManus/OpenManus-RL">OpenManus-RL</a>：マルチエージェント環境向けLLMエージェントRLチューニングフレームワーク <img src="https://img.shields.io/github/stars/OpenManus/OpenManus-RL" alt="GitHub Repo stars" /></li>
<li><a href="https://github.com/agentica-project/rllm">rllm</a>：<a href="https://github.com/agentica-project/verl-pipeline">verl-pipeline</a>による非同期RLトレーニング <img src="https://img.shields.io/github/stars/agentica-project/rllm" alt="GitHub Repo stars" /></li>
<li><a href="https://github.com/PRIME-RL/PRIME">PRIME</a>：暗黙的リワードによるプロセス強化学習 <img src="https://img.shields.io/github/stars/PRIME-RL/PRIME" alt="GitHub Repo stars" /></li>
<li><a href="https://github.com/ZihanWang314/ragen">RAGEN</a>：汎用推論<strong>エージェント</strong>トレーニングフレームワーク <img src="https://img.shields.io/github/stars/ZihanWang314/ragen" alt="GitHub Repo stars" /></li>
<li><a href="https://github.com/PeterGriffinJin/Search-R1">Search-R1</a>：推論と**検索（ツールコール）**を組み合わせたRL <img src="https://img.shields.io/github/stars/PeterGriffinJin/Search-R1" alt="GitHub Repo stars" /></li>
<li><a href="https://github.com/pat-jj/DeepRetrieval">DeepRetrieval</a>：<strong>検索エージェント</strong>のRLトレーニング <img src="https://img.shields.io/github/stars/pat-jj/DeepRetrieval" alt="GitHub Repo stars" /></li>
<li><a href="https://github.com/Agent-RL/ReSearch">ReSearch</a>：LLMによる<strong>検索付き推論</strong>の強化学習 <img src="https://img.shields.io/github/stars/Agent-RL/ReSearch" alt="GitHub Repo stars" /></li>
<li><a href="https://github.com/ganler/code-r1">Code-R1</a>：<strong>コード</strong>用R1再現と信頼できるリワード <img src="https://img.shields.io/github/stars/ganler/code-r1" alt="GitHub Repo stars" /></li>
<li><a href="https://github.com/SkyworkAI/Skywork-OR1">Skywork-OR1</a>：Skyworkオープンリアゾナーシリーズ <img src="https://img.shields.io/github/stars/SkyworkAI/Skywork-OR1" alt="GitHub Repo stars" /></li>
<li><a href="https://github.com/GAIR-NLP/ToRL">ToRL</a>：ツール統合RLのスケーリング <img src="https://img.shields.io/github/stars/GAIR-NLP/ToRL" alt="GitHub Repo stars" /></li>
<li><a href="https://github.com/langfengQ/verl-agent">verl-agent</a>：<strong>長期LLM/VLMエージェント</strong>用スケーラブルトレーニングフレームワーク &amp; 新アルゴリズム<strong>GiGPO</strong> <img src="https://img.shields.io/github/stars/langfengQ/verl-agent" alt="GitHub Repo stars" /></li>
<li><a href="https://arxiv.org/abs/2409.06957">PF-PPO</a>：リワード信号信頼性に基づくPPO方策フィルタリングで効率的かつ堅牢なRLHF</li>
<li><a href="https://github.com/ritzz-ai/GUI-R1">GUI-R1</a>：<strong>GUI-R1</strong>: GUIエージェント用R1型VLMアクションモデル <img src="https://img.shields.io/github/stars/ritzz-ai/GUI-R1" alt="GitHub Repo stars" /></li>
<li><a href="https://github.com/GAIR-NLP/DeepResearcher">DeepResearcher</a>：実環境での強化学習による深層研究のスケーリング <img src="https://img.shields.io/github/stars/GAIR-NLP/DeepResearcher" alt="GitHub Repo stars" /></li>
<li><a href="https://github.com/RAGEN-AI/VAGEN">VAGEN</a>：マルチターン強化学習でVLMエージェントをトレーニング <img src="https://img.shields.io/github/stars/RAGEN-AI/VAGEN" alt="GitHub Repo stars" /></li>
<li><a href="https://retool-rl.github.io/">ReTool</a>：LLMの戦略的ツール利用に対する強化学習。コードは近日公開予定...</li>
<li><a href="https://arxiv.org/abs/2505.02387">RM-R1</a>：推論リワードモデルのRLトレーニング <img src="https://img.shields.io/github/stars/RM-R1-UIUC/RM-R1" alt="GitHub Repo stars" /></li>
<li><a href="https://arxiv.org/abs/2505.03335">Absolute Zero Reasoner</a>：人間ラベルなし自己対戦推論フレームワーク <img src="https://img.shields.io/github/stars/LeapLabTHU/Absolute-Zero-Reasoner" alt="GitHub Repo stars" /></li>
<li><a href="https://arxiv.org/pdf/2504.14945">LUFFY</a>：オフポリシーガイダンス下での推論学習 <img src="https://img.shields.io/github/stars/ElliottYan/LUFFY" alt="GitHub Repo stars" /></li>
<li><a href="https://github.com/TIGER-AI-Lab/verl-tool">verl-tool</a>：verlベースの統一的・拡張容易なツールエージェント学習フレームワーク <img src="https://img.shields.io/github/stars/TIGER-AI-Lab/verl-tool" alt="GitHub Repo stars" /></li>
<li><a href="https://github.com/zwhe99/DeepMath">DeepMath</a>：DeepMath-103Kデータ・数理推論モデル群 <img src="https://img.shields.io/github/stars/zwhe99/DeepMath" alt="GitHub Repo stars" /></li>
</ul>
<p>他にも多くの事例が<a href="https://raw.githubusercontent.com/volcengine/verl/main/recipe/README.md">recipe</a>に掲載されています。</p>
<h2>貢献ガイド</h2>
<p>コミュニティからの貢献を歓迎しています！<a href="https://github.com/volcengine/verl/issues/710">プロジェクトロードマップ</a>、<a href="https://github.com/volcengine/verl/issues?q=is%3Aissue%20state%3Aopen%20label%3A%22good%20first%20issue%22">good first issues</a>を確認し、ぜひご参加ください。</p>
<h3>コードリント・整形</h3>
<p>pre-commitを利用しコード品質を向上させています。初期化は：</p>
<pre><code class="language-bash">pip install pre-commit
pre-commit install
</code></pre>
<p>CIエラーのローカル解消は：</p>
<pre><code class="language-bash">pre-commit run
</code></pre>
<h3>CIテストの追加</h3>
<p>可能な場合、新機能にはCIテストを追加してください：</p>
<ol>
<li>最も関連するworkflow ymlファイルを探し、通常<code>hydra</code>デフォルト構成（例：<code>ppo_trainer</code>、<code>ppo_megatron_trainer</code>、<code>sft_trainer</code>など）に対応します。</li>
<li>関連パスパターンを<code>paths</code>セクションに追加（未登録の場合）。</li>
<li>テストスクリプトの負荷を最小化（既存スクリプト例を参照）。</li>
</ol>
<h2><a href="https://team.doubao.com/">ByteDance Seed Team</a>について</h2>
<p>2023年設立のByteDance Seed Teamは、業界最先端のAI基盤モデルの構築に注力しています。世界レベルの研究チームを目指し、科学と社会の進歩に大きく貢献することを目標としています。以下のチャネルからSeedチームについてさらに知ることができます👇</p>
<div>
  <a href="https://team.doubao.com/">
    <img src="https://img.shields.io/badge/Website-%231e37ff?style=for-the-badge&logo=bytedance&logoColor=white"></a>
  <a href="https://github.com/user-attachments/assets/469535a8-42f2-4797-acdf-4f7a1d4a0c3e">
    <img src="https://img.shields.io/badge/WeChat-07C160?style=for-the-badge&logo=wechat&logoColor=white"></a>
 <a href="https://www.xiaohongshu.com/user/profile/668e7e15000000000303157d?xsec_token=ABl2-aqekpytY6A8TuxjrwnZskU-6BsMRE_ufQQaSAvjc%3D&xsec_source=pc_search">
    <img src="https://img.shields.io/badge/Xiaohongshu-%23FF2442?style=for-the-badge&logo=xiaohongshu&logoColor=white"></a>
  <a href="https://www.zhihu.com/org/dou-bao-da-mo-xing-tuan-dui/">
    <img src="https://img.shields.io/badge/zhihu-%230084FF?style=for-the-badge&logo=zhihu&logoColor=white"></a>
</div>
---
<p>採用中！RLエージェント分野のインターン・FTEにご興味ある方は<a href="mailto:haibin.lin@bytedance.com">email</a>までご連絡ください。</p>
<hr />
<p>Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx">Open Ai Tx</a> | Last indexed: 2025-06-07</p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
</body>
</html>