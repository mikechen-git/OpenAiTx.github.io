<!DOCTYPE html>
<html lang="tr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>verl - volcengine/verl tr</title>
    <meta name="title" content="verl - volcengine/verl tr | 👋 Merhaba, herkese! verl, ByteDance Seed ekibi tarafından başlatılan ve verl topluluğu tarafından sürdürülen bir RL eğitim kütüphanesidir. verl: LLM'ler için V...">
    <meta name="description" content="volcengine/verl - GitHub repository tr documentation and information | 👋 Merhaba, herkese! verl, ByteDance Seed ekibi tarafından başlatılan ve verl topluluğu tarafından sürdürülen bir RL eğitim kütüphanesidir. verl: LLM'ler için V...">
    <meta name="keywords" content="volcengine, verl, GitHub, repository, tr documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/volcengine/verl/README-tr.html">
    <meta property="og:title" content="verl - volcengine/verl tr | 👋 Merhaba, herkese! verl, ByteDance Seed ekibi tarafından başlatılan ve verl topluluğu tarafından sürdürülen bir RL eğitim kütüphanesidir. verl: LLM'ler için V...">
    <meta property="og:description" content="volcengine/verl - GitHub repository tr documentation and information | 👋 Merhaba, herkese! verl, ByteDance Seed ekibi tarafından başlatılan ve verl topluluğu tarafından sürdürülen bir RL eğitim kütüphanesidir. verl: LLM'ler için V...">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/volcengine/verl" id="githubRepoLink" target="_blank">volcengine/verl</a>
<h1 style="display: none;">👋 Merhaba, herkese! verl, ByteDance Seed ekibi tarafından başlatılan ve verl topluluğu tarafından sürdürülen bir RL eğitim kütüphanesidir. verl: LLM'ler için V...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <div align="center">
 👋 Merhaba, herkese! 
    verl, <b>ByteDance Seed ekibi</b> tarafından başlatılan ve verl topluluğu tarafından sürdürülen bir RL eğitim kütüphanesidir.
    <br>
    <br>
</div>
<div align="center">
<p><a href="https://deepwiki.com/volcengine/verl"><img src="https://devin.ai/assets/deepwiki-badge.png" alt="Ask DeepWiki.com" height="20"/></a>
<a href="https://github.com/volcengine/verl/stargazers"><img src="https://img.shields.io/github/stars/volcengine/verl" alt="GitHub Repo stars" /></a>
<a href="https://twitter.com/verl_project"><img src="https://img.shields.io/twitter/follow/verl_project" alt="Twitter" /></a>
<a href="https://join.slack.com/t/verlgroup/shared_invite/zt-2w5p9o4c3-yy0x2Q56s_VlGLsJ93A6vA"><img src="https://img.shields.io/badge/Slack-verl-blueviolet?logo=slack&amp"></a>
<a href="https://arxiv.org/pdf/2409.19256"><img src="https://img.shields.io/static/v1?label=EuroSys&message=Paper&color=red"></a>
<a href="https://verl.readthedocs.io/en/latest/"><img src="https://img.shields.io/badge/documentation-blue" alt="Documentation" /></a>
<a href="https://raw.githubusercontent.com/eric-haibin-lin/verl-community/refs/heads/main/WeChat.JPG"><img src="https://img.shields.io/badge/微信-green?logo=wechat&amp"></a></p>
</div>
<p><img src="https://github.com/user-attachments/assets/c42e675e-497c-4508-8bb9-093ad4d1f216" alt="seed logo" /></p>
<h1 style="text-align: center;">verl: LLM'ler için Volcano Engine Takviyeli Öğrenme (Reinforcement Learning)</h1>
<p>verl, büyük dil modelleri (LLM'ler) için esnek, verimli ve üretime hazır bir RL eğitim kütüphanesidir.</p>
<p>verl, <strong><a href="https://arxiv.org/abs/2409.19256v2">HybridFlow: A Flexible and Efficient RLHF Framework</a></strong> makalesinin açık kaynaklı versiyonudur.</p>
<p>verl, aşağıdaki özellikleriyle esnek ve kullanımı kolaydır:</p>
<ul>
<li><p><strong>Çeşitli RL algoritmalarının kolayca genişletilmesi:</strong> Hibrid-kontrolcü programlama modeli, karmaşık eğitim sonrası veri akışlarının esnek şekilde temsil edilmesini ve verimli şekilde yürütülmesini sağlar. GRPO, PPO gibi RL veri akışlarını birkaç satır kod ile oluşturun.</p>
</li>
<li><p><strong>Mevcut LLM altyapısı ile modüler API'ler ile sorunsuz entegrasyon:</strong> Hesaplama ve veri bağımlılıklarını ayırır, mevcut LLM framework'leriyle (FSDP, Megatron-LM, vLLM, SGLang vb.) sorunsuz entegrasyona olanak tanır.</p>
</li>
<li><p><strong>Esnek cihaz haritalama:</strong> Modellerin farklı GPU kümelerine yerleştirilmesini destekler; kaynakların verimli kullanımı ve farklı küme boyutları arasında ölçeklenebilirlik sağlar.</p>
</li>
<li><p>Popüler HuggingFace modelleriyle hazır entegrasyon</p>
</li>
</ul>
<p>verl hızlıdır çünkü:</p>
<ul>
<li><p><strong>En güncel (SOTA) aktarım oranı:</strong> SOTA LLM eğitim ve çıkarım motoru entegrasyonları ve SOTA RL aktarım hızı.</p>
</li>
<li><p><strong>3D-HybridEngine ile verimli aktör modeli yeniden bölütleme (resharding):</strong> Eğitim ve üretim aşamaları arasındaki geçişlerde bellek fazlalığını ortadan kaldırır ve iletişim yükünü önemli ölçüde azaltır.</p>
</li>
</ul>
</p>
<h2>Haberler</h2>
<ul>
<li>[2025/06] Megatron backend ile verl, <a href="https://verl.readthedocs.io/en/latest/perf/dpsk.html">DeepSeek-671b ve Qwen3-236b</a> gibi büyük MoE modellerini destekliyor.</li>
<li>[2025/06] verl ekibi <a href="https://www.lfasiallc.com/pytorch-day-china/">PyTorch Day China</a> etkinliğinde 7 Haziran'da son proje güncellemelerini sunacak. Pekin'de geliştirme ekibimizle tanışın!</li>
<li>[2025/05] <a href="https://arxiv.org/abs/2409.06957">PF-PPO</a>, ICML 2025'e kabul edildi ve artık verl'de destekleniyor! PF-PPO, potansiyel olarak gürültülü ödül sinyallerini filtreleyerek ve yüksek kaliteli deneyimleri tekrar kullanarak politika öğrenme verimliliğini ve sağlamlığını artırır.</li>
<li>[2025/04] <a href="https://iclr.cc/virtual/2025/calendar?filter_events=Expo+Talk+Panel&amp;filter_rooms=">ICLR 2025 Expo</a>, <a href="https://open-foundation-model.github.io/">SCI-FM workshop</a> ve <a href="https://lu.ma/d23nyynm">LMSys afterparty</a> etkinliklerinde verl ile ilgili en yeni eğitim sonrası teknikler ve programlama rehberi hakkında bir eğitim vereceğiz. Sunum materyallerine <a href="https://github.com/eric-haibin-lin/verl-community/tree/main/iclr25">buradan</a> ulaşabilirsiniz.</li>
<li>[2025/04] <a href="https://github.com/ByteDance-Seed/Seed-Thinking-v1.5/blob/main/seed-thinking-v1.5.pdf">Seed-Thinking-v1.5</a> teknik raporu yayımlandı! verl ile eğitilen Seed-Thinking-v1.5, AIME 2024'te 86.7, Codeforces'da 55.0, GPQA'da 77.3 puan alarak STEM ve kodlama alanlarında mükemmel akıl yürütme yetenekleri sergilemektedir. Yöntem ayrıca, çeşitli alanlarda dikkate değer genelleme kabiliyeti göstermektedir.</li>
<li>[2025/04] <a href="https://arxiv.org/pdf/2504.05118">VAPO</a> (değer tabanlı geliştirilmiş PPO) makalesi, akıl yürütme modelleri için en yeni RL metodumuzu kapsar. Qwen-32B-base modelinden eğitilen VAPO, AIME 2024'te 60.4 skoruna ulaşarak DAPO-32B'yi geride bırakmıştır.</li>
<li>[2025/03] verl v0.3.0.post1 yayımlandı! Ayrıntılar için <a href="https://github.com/volcengine/verl/releases/">sürüm notuna</a> bakın. Önceki sürümlere kıyasla <a href="https://tongyx361.github.io/blogs/posts/verl-intro/#/verl-flexible-and-efficient-rl-for-llms">~1.4x hız artışı</a> elde edilmiştir.</li>
<li>[2025/03] <a href="https://dapo-sia.github.io/">DAPO</a> açık kaynak SOTA RL algoritmasıdır ve Qwen2.5-32B ön-eğitimli modeli ile AIME 2024'te 50 puan elde ederek DeepSeek'in GRPO'sunu (DeepSeek-R1-Zero-Qwen-32B) geçmiştir. DAPO'nun eğitimi tamamen verl ile yapılmaktadır ve yeniden üretim kodu artık <code>recipe/dapo</code> dizininde mevcuttur.</li>
</ul>
<details><summary> daha fazla... </summary>
<ul>
  <li>[2025/05] verl, [A2M Shanghai](https://a2m.msup.com.cn/home/?aid=4488&city=shanghai) etkinliğinde 16-17 Mayıs'ta sunulacaktır.</li>
  <li>[2025/05] verl, [GOSIM x PyTorch Day 2025](https://paris2025.gosim.org/) etkinliğinde sunulacak. Paris'te görüşmek üzere!</li>
  <li>[2025/03] verl'in programlama modelini [vLLM Beijing Meetup](https://mp.weixin.qq.com/s/n77GibL2corAtQHtVEAzfg) ve [SGLang-LMSYS Org Meetup](https://lu.ma/ntjrr7ig) etkinliklerinde tanıttık, ayrıntılar için [verl intro and updates](https://github.com/eric-haibin-lin/verl-community/blob/main/slides/verl-lmsys-meetup.pdf).</li>
  <li>[2025/03] verl(HybridFlow) EuroSys 2025'te sunulacak. Rotterdam'da görüşmek üzere!</li>
  <li>[2025/02] verl v0.2.0.post2 yayımlandı!</li>
  <li>[2025/02] verl'i <a href="https://lu.ma/ji7atxux">Bytedance/NVIDIA/Anyscale Ray Meetup</a>'ta sunduk. San Jose'de görüşmek üzere!</li>
  <li>[2025/01] [Doubao-1.5-pro](https://team.doubao.com/zh/special/doubao_1_5_pro), LLM & VLM'de SOTA seviyesinde performans ile yayımlandı. RL ölçekleme önizleme modeli verl kullanılarak eğitildi ve matematik benchmarklarında OpenAI O1 seviyesine ulaştı (AIME'de 70.0 pass@1).</li>
  <li>[2024/12] verl, Ray Forward 2024'te sunuldu. Sunum dosyasına <a href="https://github.com/eric-haibin-lin/verl-community/blob/main/slides/Ray_Forward_2024_%E5%B7%AB%E9%94%A1%E6%96%8C.pdf">buradan</a> ulaşabilirsiniz.</li>
  <li>[2024/12] Ekip, NeurIPS 2024'te <a href="https://neurips.cc/Expo/Conferences/2024/workshop/100677">Post-training LLMs: From Algorithms to Infrastructure</a> başlıklı sunumu gerçekleştirdi. <a href="https://github.com/eric-haibin-lin/verl-data/tree/neurips">Sunumlar</a> ve <a href="https://neurips.cc/Expo/Conferences/2024/workshop/100677">video</a> mevcut.</li>
  <li>[2024/10] verl, Ray Summit'te sunuldu. <a href="https://www.youtube.com/watch?v=MrhMcXkXvJU&list=PLzTswPQNepXntmT8jr9WaNfqQ60QwW7-U&index=37">Youtube videosu</a> mevcut.</li>
  <li>[2024/08] HybridFlow (verl), EuroSys 2025'e kabul edildi.</li>
</ul>   
</details>
<h2>Temel Özellikler</h2>
<ul>
<li>Eğitim için <strong>FSDP</strong>, <strong>FSDP2</strong> ve <strong>Megatron-LM</strong>.</li>
<li>Rollout üretimi için <strong>vLLM</strong>, <strong>SGLang</strong> ve <strong>HF Transformers</strong>.</li>
<li>Hugging Face Transformers ve Modelscope Hub ile uyumlu: <a href="https://raw.githubusercontent.com/volcengine/verl/main/examples/grpo_trainer/run_qwen3-8b.sh">Qwen-3</a>, Qwen-2.5, Llama3.1, Gemma2, DeepSeek-LLM vb.</li>
<li>Denetimli ince ayar (supervised fine-tuning).</li>
<li><a href="https://raw.githubusercontent.com/volcengine/verl/main/examples/ppo_trainer/">PPO</a>, <a href="https://raw.githubusercontent.com/volcengine/verl/main/examples/grpo_trainer/">GRPO</a>, <a href="https://raw.githubusercontent.com/volcengine/verl/main/examples/remax_trainer/">ReMax</a>, <a href="https://verl.readthedocs.io/en/latest/examples/config.html#algorithm">REINFORCE++</a>, <a href="https://raw.githubusercontent.com/volcengine/verl/main/examples/rloo_trainer/">RLOO</a>, <a href="https://raw.githubusercontent.com/volcengine/verl/main/recipe/prime/">PRIME</a>, <a href="https://raw.githubusercontent.com/volcengine/verl/main/recipe/dapo/">DAPO</a>, <a href="https://raw.githubusercontent.com/volcengine/verl/main/recipe/drgrpo/">DrGRPO</a> gibi takviyeli öğrenme algoritmaları.
<ul>
<li>Matematik, <a href="https://raw.githubusercontent.com/volcengine/verl/main/recipe/dapo/">kodlama</a> vb. için model tabanlı ödül ve fonksiyon tabanlı ödül (doğrulanabilir ödül) desteği</li>
<li>Görüntü-dil modelleri (VLM'ler) ve <a href="https://raw.githubusercontent.com/volcengine/verl/main/examples/grpo_trainer/run_qwen2_5_vl-7b.sh">çok modlu RL</a> için destek (Qwen2.5-vl, Kimi-VL)</li>
<li><a href="https://raw.githubusercontent.com/volcengine/verl/main/examples/sglang_multiturn/">Araç çağrısı ile çoklu tur</a></li>
</ul>
</li>
<li><a href="https://raw.githubusercontent.com/volcengine/verl/main/recipe/sppo/">Kendi kendine oyun tercih optimizasyonu (SPPO)</a> gibi LLM hizalama tarifleri</li>
<li>Flash attention 2, <a href="https://raw.githubusercontent.com/volcengine/verl/main/examples/ppo_trainer/run_qwen2-7b_seq_balance.sh">dizi paketleme (sequence packing)</a>, <a href="https://raw.githubusercontent.com/volcengine/verl/main/examples/ppo_trainer/run_deepseek7b_llm_sp2.sh">dizi paralelliği (sequence parallelism)</a> desteği (DeepSpeed Ulysses ile), <a href="https://raw.githubusercontent.com/volcengine/verl/main/examples/sft/gsm8k/run_qwen_05_peft.sh">LoRA</a>, <a href="https://raw.githubusercontent.com/volcengine/verl/main/examples/sft/gsm8k/run_qwen_05_sp2_liger.sh">Liger-kernel</a></li>
<li><a href="https://github.com/volcengine/verl/pull/1467">Uzman paralelliği</a> ile 671B modele ve yüzlerce GPU'ya ölçeklenebilirlik</li>
<li>Bellekten tasarruf için çoklu GPU ile <a href="https://verl.readthedocs.io/en/latest/advance/ppo_lora.html">LoRA RL</a> desteği</li>
<li>wandb, swanlab, mlflow ve tensorboard ile deney takibi</li>
</ul>
<h2>Yaklaşan Özellikler ve Değişiklikler</h2>
<ul>
<li>Yol haritası: https://github.com/volcengine/verl/issues/710</li>
<li>Megatron v0.11 ile DeepSeek 671b optimizasyonları: https://github.com/volcengine/verl/issues/708</li>
<li>Çoklu tur rollout ve araç kullanımı optimizasyonları: https://github.com/volcengine/verl/issues/1882</li>
<li>Ortam etkileşimleri: https://github.com/volcengine/verl/issues/1172</li>
<li>v0.3'ten bu yana yapılan yıkıcı değişiklikler: https://github.com/volcengine/verl/discussions/943, entropy_coeff varsayılan olarak 0</li>
<li>RL için Lora: https://github.com/volcengine/verl/pull/1127</li>
</ul>
<h2>Başlarken</h2>
<p><a href="https://verl.readthedocs.io/en/latest/index.html"><b>Dokümantasyon</b></a></p>
<p><strong>Hızlı Başlangıç:</strong></p>
<ul>
<li><a href="https://verl.readthedocs.io/en/latest/start/install.html">Kurulum</a></li>
<li><a href="https://verl.readthedocs.io/en/latest/start/quickstart.html">Hızlı Başlangıç</a></li>
<li><a href="https://verl.readthedocs.io/en/latest/hybrid_flow.html">Programlama Rehberi</a></li>
<li><a href="https://verl.readthedocs.io/en/latest/algo/ppo.html">verl'de PPO</a></li>
<li><a href="https://verl.readthedocs.io/en/latest/algo/grpo.html">verl'de GRPO</a></li>
</ul>
<p><strong>Adım adım bir PPO örneği çalıştırmak:</strong></p>
<ul>
<li><a href="https://verl.readthedocs.io/en/latest/preparation/prepare_data.html">Eğitim Sonrası için Veri Hazırlama</a></li>
<li><a href="https://verl.readthedocs.io/en/latest/preparation/reward_function.html">Veri Seti için Ödül Fonksiyonu Uygulama</a></li>
<li><a href="https://verl.readthedocs.io/en/latest/examples/ppo_code_architecture.html">PPO Örneği Mimarisi</a></li>
<li><a href="https://verl.readthedocs.io/en/latest/examples/config.html">Yapılandırma Açıklaması</a></li>
</ul>
<p><strong>Tekrarlanabilir algoritma taban çizgileri:</strong></p>
<ul>
<li><a href="https://verl.readthedocs.io/en/latest/algo/baseline.html">Kodlama, matematikte RL performansı</a></li>
</ul>
<p><strong>Kod açıklaması ve ileri seviye kullanım (genişletme) için:</strong></p>
<ul>
<li><p>PPO Eğitici ve Çalışanlar</p>
<ul>
<li><a href="https://verl.readthedocs.io/en/latest/workers/ray_trainer.html">PPO Ray Eğitici</a></li>
<li><a href="https://verl.readthedocs.io/en/latest/workers/fsdp_workers.html">PyTorch FSDP Backend</a></li>
<li><a href="https://verl.readthedocs.io/en/latest/index.html">Megatron-LM Backend</a></li>
</ul>
</li>
<li><p>İleri Düzey Kullanım ve Genişletme</p>
<ul>
<li><a href="https://verl.readthedocs.io/en/latest/advance/fsdp_extension.html">FSDP Backend ile Model Ekleme</a></li>
<li><a href="https://verl.readthedocs.io/en/latest/advance/megatron_extension.html">Megatron-LM Backend ile Model Ekleme</a></li>
<li><a href="https://verl.readthedocs.io/en/latest/sglang_multiturn/multiturn.html">Çoklu Tur Rollout Desteği</a></li>
<li><a href="https://verl.readthedocs.io/en/latest/sglang_multiturn/search_tool_example.html">Arama Aracı Entegrasyonu</a></li>
<li><a href="https://verl.readthedocs.io/en/latest/examples/sandbox_fusion_example.html">Sandbox Fusion Entegrasyonu</a></li>
<li><a href="https://raw.githubusercontent.com/volcengine/verl/main/examples/split_placement/">Ayrı GPU Kaynakları ile Dağıtım</a></li>
<li><a href="https://verl.readthedocs.io/en/latest/advance/dpo_extension.html">Diğer RL(HF) algoritmalarına genişletme</a></li>
<li><a href="https://verl.readthedocs.io/en/latest/advance/placement.html">Ray API tasarım eğitimi</a></li>
</ul>
</li>
</ul>
<p><strong>Topluluktan Bloglar</strong></p>
<ul>
<li><a href="https://github.com/zhaochenyang20/Awesome-ML-SYS-Tutorial/blob/main/rlhf/verl/multi-turn/verl-multiturn-rollout-Release.md">SGLang, verl, OpenBMB ve Tsinghua Üniversitesi: Uçtan Uca Çoklu Tur RLHF'de Öncülük</a></li>
<li><a href="https://rocm.blogs.amd.com/artificial-intelligence/verl-large-scale/README.html">verl ve ROCm Entegrasyonu ile AMD GPU'larda İnsan Geri Bildirimli Takviyeli Öğrenme</a></li>
<li><a href="https://mp.weixin.qq.com/s/7nbqxk4knMGd-hQE9ls2tA">veMLP x verl ：Takviyeli Öğrenme Eğitiminde Ustalık</a></li>
<li><a href="https://www.volcengine.com/docs/6459/1463942">verl ile GRPO Dağıtık Takviyeli Öğrenme En İyi Uygulamaları</a></li>
<li><a href="https://github.com/zhaochenyang20/Awesome-ML-SYS-Tutorial/blob/main/rlhf/verl/readme.md">HybridFlow verl Orijinal Metin Analizi</a></li>
<li><a href="https://team.doubao.com/en/blog/%E6%9C%80%E9%AB%98%E6%8F%90%E5%8D%8720%E5%80%8D%E5%90%9E%E5%90%90%E9%87%8F-%E8%B1%86%E5%8C%85%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9B%A2%E9%98%9F%E5%8F%91%E5%B8%83%E5%85%A8%E6%96%B0-rlhf-%E6%A1%86%E6%9E%B6-%E7%8E%B0%E5%B7%B2%E5%BC%80%E6%BA%90">Maksimum 20 Kat Artış! Doubao Büyük Model Ekibi Yeni RLHF Çerçevesini Yayınladı, Şimdi Açık Kaynak!</a></li>
</ul>
<h2>Performans Ayarlama Rehberi</h2>
<p>On-policy RL algoritması için performans kritiktir. Performansı optimize etmenize yardımcı olmak için ayrıntılı bir <a href="https://verl.readthedocs.io/en/latest/perf/perf_tuning.html">performans ayarlama rehberi</a> yazdık.</p>
<h2>vLLM &gt;= v0.8.2'ye Yükseltme</h2>
<p>verl, eğitim backend'i olarak FSDP kullanıldığında artık vLLM&gt;=0.8.2'yi destekliyor. Kurulum rehberi ve daha fazla bilgi için <a href="https://raw.githubusercontent.com/volcengine/verl/main/docs/README_vllm0.8.md">bu dokümana</a> bakabilirsiniz. OOM ve beklenmeyen hatalara yol açabileceği için vllm 0.7.x kullanmaktan kaçının.</p>
<h2>En Güncel SGLang'i Kullanın</h2>
<p>SGLang, verl ile tamamen uyumludur ve SGLang RL Grubu çoklu tur ajan RL, VLM RLHF, sunucu tabanlı RL ve kısmi rollout gibi özellikler üzerinde yoğun şekilde çalışmaktadır. Kurulum rehberi ve daha fazla bilgi için <a href="https://verl.readthedocs.io/en/latest/workers/sglang_worker.html">bu dokümana</a> bakabilirsiniz.</p>
<h2>FSDP2'ye Yükseltme</h2>
<p>verl, FSDP2'yi tamamen benimsiyor! FSDP2, torch distributed ekibi tarafından önerilmekte olup daha iyi aktarım hızı ve bellek kullanımı sağlar ve diğer özelliklerle (örn. torch.compile) birlikte kullanılabilir. FSDP2'yi etkinleştirmek için, verl main'i kullanın ve aşağıdaki seçenekleri ayarlayın:</p>
<pre><code>actor_rollout_ref.ref.strategy=fsdp2
actor_rollout_ref.actor.strategy=fsdp2
critic.strategy=fsdp2 
reward_model.strategy=fsdp2 
</code></pre>
<p>Ayrıca, FSDP2 cpu offload, gradient accumulation ile uyumludur. Bellekten tasarruf etmek için <code>actor_rollout_ref.actor.offload_policy=True</code> olarak ayarlayabilirsiniz. Daha fazla detay için: https://github.com/volcengine/verl/pull/1026</p>
<h2>AMD Desteği (ROCm Kernel)</h2>
<p>verl, eğitim motoru olarak FSDP'yi (yakında Megatron desteği de gelecek) ve çıkarım motoru olarak vLLM ve SGLang entegrasyonlarını desteklemektedir. Kurulum rehberi ve daha fazla bilgi için <a href="https://raw.githubusercontent.com/volcengine/verl/main/docs/amd_tutorial/amd_build_dockerfile_page.rst">bu dokümana</a> ve ROCm için vLLM performans ayarlama için <a href="https://raw.githubusercontent.com/volcengine/verl/main/docs/amd_tutorial/amd_vllm_page.rst">bu dokümana</a> bakabilirsiniz.</p>
<h2>Atıf ve Teşekkür</h2>
<p>Projeyi faydalı bulursanız, lütfen şu makaleleri atıf gösterin:</p>
<ul>
<li><a href="https://arxiv.org/abs/2409.19256v2">HybridFlow: A Flexible and Efficient RLHF Framework</a></li>
<li><a href="https://i.cs.hku.hk/%7Ecwu/papers/gmsheng-NL2Code24.pdf">A Framework for Training Large Language Models for Code Generation via Proximal Policy Optimization</a></li>
</ul>
<pre><code class="language-bibtex">@article{sheng2024hybridflow,
  title   = {HybridFlow: A Flexible and Efficient RLHF Framework},
  author  = {Guangming Sheng and Chi Zhang and Zilingfeng Ye and Xibin Wu and Wang Zhang and Ru Zhang and Yanghua Peng and Haibin Lin and Chuan Wu},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2409.19256}
}
</code></pre>
<p>verl, Nemo-Aligner, Deepspeed-chat ve OpenRLHF tasarımından ilham alınarak geliştirilmiştir. Projeye Bytedance, Anyscale, LMSys.org, <a href="https://github.com/QwenLM/">Alibaba Qwen ekibi</a>, Shanghai AI Lab, Tsinghua Üniversitesi, UC Berkeley, UCLA, UIUC, Hong Kong Üniversitesi, ke.com, <a href="https://www.all-hands.dev/">All Hands AI</a>, <a href="http://modelbest.cn/">ModelBest</a>, OpenPipe, JD AI Lab, Microsoft Research, <a href="https://www.stepfun.com/">StepFun</a>, Amazon, Linkedin, Meituan, <a href="https://www.camel-ai.org/">Camel-AI</a>, <a href="https://github.com/OpenManus">OpenManus</a>, Xiaomi, Prime Intellect, NVIDIA research, <a href="https://www.baichuan-ai.com/home">Baichuan</a>, <a href="https://www.xiaohongshu.com/">RedNote</a>, <a href="https://www.swiss-ai.org/">SwissAI</a>, <a href="https://www.moonshot-ai.com/">Moonshot AI (Kimi)</a>, Baidu, Snowflake ve daha birçok kurum katkıda bulunmuştur.</p>
<h2>verl kullanan muhteşem çalışmalar</h2>
<ul>
<li><a href="https://github.com/Jiayi-Pan/TinyZero">TinyZero</a>: <strong>DeepSeek R1 Zero</strong> tarifinin akıl yürütme görevleri için yeniden üretimi <img src="https://img.shields.io/github/stars/Jiayi-Pan/TinyZero" alt="GitHub Repo stars" /></li>
<li><a href="https://github.com/NovaSky-AI/SkyThought">SkyThought</a>: NovaSky AI ekibi tarafından Sky-T1-7B için RL eğitimi <img src="https://img.shields.io/github/stars/NovaSky-AI/SkyThought" alt="GitHub Repo stars" /></li>
<li><a href="https://github.com/hkust-nlp/simpleRL-reason">simpleRL-reason</a>: SimpleRL-Zoo: Açık temel modellerde Sıfır Takviyeli Öğrenmeyi inceleme ve yönetme <img src="https://img.shields.io/github/stars/hkust-nlp/simpleRL-reason" alt="GitHub Repo stars" /></li>
<li><a href="https://github.com/hiyouga/EasyR1">Easy-R1</a>: <strong>Çok modlu</strong> RL eğitim çerçevesi <img src="https://img.shields.io/github/stars/hiyouga/EasyR1" alt="GitHub Repo stars" /></li>
<li><a href="https://github.com/OpenManus/OpenManus-RL">OpenManus-RL</a>: Birden fazla ajan ortamı için LLM ajan RL ince ayar çerçevesi <img src="https://img.shields.io/github/stars/OpenManus/OpenManus-RL" alt="GitHub Repo stars" /></li>
<li><a href="https://github.com/agentica-project/rllm">rllm</a>: <a href="https://github.com/agentica-project/verl-pipeline">verl-pipeline</a> ile asenkron RL eğitimi <img src="https://img.shields.io/github/stars/agentica-project/rllm" alt="GitHub Repo stars" /></li>
<li><a href="https://github.com/PRIME-RL/PRIME">PRIME</a>: Dolaylı ödüllerle süreç takviyelendirme <img src="https://img.shields.io/github/stars/PRIME-RL/PRIME" alt="GitHub Repo stars" /></li>
<li><a href="https://github.com/ZihanWang314/ragen">RAGEN</a>: Genel amaçlı akıl yürütme <strong>ajanı</strong> eğitim çerçevesi <img src="https://img.shields.io/github/stars/ZihanWang314/ragen" alt="GitHub Repo stars" /></li>
<li><a href="https://github.com/PeterGriffinJin/Search-R1">Search-R1</a>: Akıl yürütme ve <strong>arama (araç çağrısı)</strong> iç içe geçmiş LLM'ler ile RL <img src="https://img.shields.io/github/stars/PeterGriffinJin/Search-R1" alt="GitHub Repo stars" /></li>
<li><a href="https://github.com/pat-jj/DeepRetrieval">DeepRetrieval</a>: <strong>Arama/Araştırma Sonuçları</strong> ile <strong>Arama Ajanı</strong>'nın RL Eğitimi <img src="https://img.shields.io/github/stars/pat-jj/DeepRetrieval" alt="GitHub Repo stars" /></li>
<li><a href="https://github.com/Agent-RL/ReSearch">ReSearch</a>: Takviyeli öğrenme ile LLM'lerde <strong>Arama ile Akıl Yürütme</strong>yi Öğrenmek <img src="https://img.shields.io/github/stars/Agent-RL/ReSearch" alt="GitHub Repo stars" /></li>
<li><a href="https://github.com/ganler/code-r1">Code-R1</a>: <strong>Kod</strong> için R1'in güvenilir ödüllerle yeniden üretimi <img src="https://img.shields.io/github/stars/ganler/code-r1" alt="GitHub Repo stars" /></li>
<li><a href="https://github.com/SkyworkAI/Skywork-OR1">Skywork-OR1</a>: Skywork açık akıl yürütücü serisi <img src="https://img.shields.io/github/stars/SkyworkAI/Skywork-OR1" alt="GitHub Repo stars" /></li>
<li><a href="https://github.com/GAIR-NLP/ToRL">ToRL</a>: Araç entegre RL ölçeklendirme <img src="https://img.shields.io/github/stars/GAIR-NLP/ToRL" alt="GitHub Repo stars" /></li>
<li><a href="https://github.com/langfengQ/verl-agent">verl-agent</a>: <strong>Uzun ufuklu LLM/VLM ajanları</strong> için ölçeklenebilir eğitim çerçevesi ve yeni algoritma <strong>GiGPO</strong> <img src="https://img.shields.io/github/stars/langfengQ/verl-agent" alt="GitHub Repo stars" /></li>
<li><a href="https://arxiv.org/abs/2409.06957">PF-PPO</a>: Daha verimli ve sağlam RLHF için ödül sinyallerinin güvenilirliğine dayalı PPO için Politika Filtrasyonu.</li>
<li><a href="https://github.com/ritzz-ai/GUI-R1">GUI-R1</a>: <strong>GUI-R1</strong>: <strong>GUI Ajanları</strong> için Genelci R1 tarzı Görsel-Dil Eylem Modeli <img src="https://img.shields.io/github/stars/ritzz-ai/GUI-R1" alt="GitHub Repo stars" /></li>
<li><a href="https://github.com/GAIR-NLP/DeepResearcher">DeepResearcher</a>: Gerçek dünya ortamlarında takviyeli öğrenme ile derin araştırmayı ölçeklendirme <img src="https://img.shields.io/github/stars/GAIR-NLP/DeepResearcher" alt="GitHub Repo stars" /></li>
<li><a href="https://github.com/RAGEN-AI/VAGEN">VAGEN</a>: Çoklu tur takviyeli öğrenme ile VLM ajanları eğitimi <img src="https://img.shields.io/github/stars/RAGEN-AI/VAGEN" alt="GitHub Repo stars" /></li>
<li><a href="https://retool-rl.github.io/">ReTool</a>: LLM'lerde stratejik araç kullanımı için takviyeli öğrenme. Kod yakında yayınlanacak...</li>
<li><a href="https://arxiv.org/abs/2505.02387">RM-R1</a>: Akıl yürütme ödül modellerinin RL ile eğitimi <img src="https://img.shields.io/github/stars/RM-R1-UIUC/RM-R1" alt="GitHub Repo stars" /></li>
<li><a href="https://arxiv.org/abs/2505.03335">Absolute Zero Reasoner</a>: Akıl yürütme için insan tarafından hazırlanmış veri gerektirmeyen kendi kendine oyun çerçevesi <img src="https://img.shields.io/github/stars/LeapLabTHU/Absolute-Zero-Reasoner" alt="GitHub Repo stars" /></li>
<li><a href="https://arxiv.org/pdf/2504.14945">LUFFY</a>: Politikaları politika dışı rehberlikle öğrenmek <img src="https://img.shields.io/github/stars/ElliottYan/LUFFY" alt="GitHub Repo stars" /></li>
<li><a href="https://github.com/TIGER-AI-Lab/verl-tool">verl-tool</a>: verl tabanlı birleşik ve kolay genişletilebilir bir araç-ajan eğitim çerçevesi <img src="https://img.shields.io/github/stars/TIGER-AI-Lab/verl-tool" alt="GitHub Repo stars" /></li>
<li><a href="https://github.com/zwhe99/DeepMath">DeepMath</a>: Matematiksel akıl yürütme için DeepMath-103K veri seti ve model serisi <img src="https://img.shields.io/github/stars/zwhe99/DeepMath" alt="GitHub Repo stars" /></li>
</ul>
<p>ve daha fazlası <a href="https://raw.githubusercontent.com/volcengine/verl/main/recipe/README.md">recipe</a> dizininde listelenmiştir.</p>
<h2>Katkı Rehberi</h2>
<p>Topluluktan katkılar memnuniyetle karşılanır! <a href="https://github.com/volcengine/verl/issues/710">Proje yol haritasını</a> ve <a href="https://github.com/volcengine/verl/issues?q=is%3Aissue%20state%3Aopen%20label%3A%22good%20first%20issue%22">iyi ilk sorunlar</a> listesini inceleyerek katkıda bulunabileceğiniz alanları görebilirsiniz.</p>
<h3>Kod Lint ve Biçimlendirme</h3>
<p>Kod kalitesini artırmak için pre-commit kullanıyoruz. Pre-commit'i başlatmak için:</p>
<pre><code class="language-bash">pip install pre-commit
pre-commit install
</code></pre>
<p>CI hatalarını yerelde çözmek için pre-commit'i manuel olarak çalıştırabilirsiniz:</p>
<pre><code class="language-bash">pre-commit run
</code></pre>
<h3>CI Testleri Ekleme</h3>
<p>Mümkünse, yeni özelliğiniz için CI testi ekleyin:</p>
<ol>
<li>En ilgili workflow yml dosyasını bulun, genellikle bir <code>hydra</code> varsayılan yapılandırmasına karşılık gelir (örn. <code>ppo_trainer</code>, <code>ppo_megatron_trainer</code>, <code>sft_trainer</code> vb).</li>
<li>Henüz eklenmemişse ilgili yol desenlerini <code>paths</code> bölümüne ekleyin.</li>
<li>Test betiklerinin iş yükünü minimuma indirin (örnekler için mevcut betiklere bakın).</li>
</ol>
<h2><a href="https://team.doubao.com/">ByteDance Seed Ekibi</a> Hakkında</h2>
<p>2023 yılında kurulan ByteDance Seed Ekibi, sektördeki en ileri AI temel modellerini geliştirmeye kendini adamıştır. Ekip, dünya çapında bir araştırma ekibi olmayı ve bilime ve topluma önemli katkılar sağlamayı hedeflemektedir. Bytedance Seed hakkında daha fazla bilgi için aşağıdaki kanalları ziyaret edebilirsiniz👇</p>
<div>
  <a href="https://team.doubao.com/">
    <img src="https://img.shields.io/badge/Website-%231e37ff?style=for-the-badge&logo=bytedance&logoColor=white"></a>
  <a href="https://github.com/user-attachments/assets/469535a8-42f2-4797-acdf-4f7a1d4a0c3e">
    <img src="https://img.shields.io/badge/WeChat-07C160?style=for-the-badge&logo=wechat&logoColor=white"></a>
 <a href="https://www.xiaohongshu.com/user/profile/668e7e15000000000303157d?xsec_token=ABl2-aqekpytY6A8TuxjrwnZskU-6BsMRE_ufQQaSAvjc%3D&xsec_source=pc_search">
    <img src="https://img.shields.io/badge/Xiaohongshu-%23FF2442?style=for-the-badge&logo=xiaohongshu&logoColor=white"></a>
  <a href="https://www.zhihu.com/org/dou-bao-da-mo-xing-tuan-dui/">
    <img src="https://img.shields.io/badge/zhihu-%230084FF?style=for-the-badge&logo=zhihu&logoColor=white"></a>
</div>
---
<p>İŞE ALIM YAPIYORUZ! RL ile ajanlar konusunda staj/FTE fırsatlarıyla ilgileniyorsanız bize bir <a href="mailto:haibin.lin@bytedance.com">e-posta</a> gönderin.</p>
<hr />
<p>Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx">Open Ai Tx</a> | Last indexed: 2025-06-07</p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
</body>
</html>