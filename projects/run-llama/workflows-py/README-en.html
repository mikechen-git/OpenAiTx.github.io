<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>workflows-py - run-llama/workflows-py en</title>
    <meta name="title" content="workflows-py - run-llama/workflows-py en | LlamaIndex Workflows LlamaIndex Workflows are a framework for orchestrating and chaining together complex systems of steps and events. What can you build with W...">
    <meta name="description" content="run-llama/workflows-py - GitHub repository en documentation and information | LlamaIndex Workflows LlamaIndex Workflows are a framework for orchestrating and chaining together complex systems of steps and events. What can you build with W...">
    <meta name="keywords" content="run-llama, workflows-py, GitHub, repository, en documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/run-llama/workflows-py/README-en.html">
    <meta property="og:title" content="workflows-py - run-llama/workflows-py en | LlamaIndex Workflows LlamaIndex Workflows are a framework for orchestrating and chaining together complex systems of steps and events. What can you build with W...">
    <meta property="og:description" content="run-llama/workflows-py - GitHub repository en documentation and information | LlamaIndex Workflows LlamaIndex Workflows are a framework for orchestrating and chaining together complex systems of steps and events. What can you build with W...">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div style="position: fixed; top: 2px; left: 2px; z-index: 2000; background: rgba(255,255,255,0.95); border-radius: 6px; box-shadow: 0 2px 8px rgba(0,0,0,0.06); padding: 4px 14px; font-size: 15px; color: #222; font-family: 'Segoe UI', Arial, sans-serif; font-weight: 500; letter-spacing: 0.5px;">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" style="color: #0366d6; text-decoration: none; font-weight: 600;">Open AI Tx</a>
    </div>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/run-llama/workflows-py" id="githubRepoLink" target="_blank">run-llama/workflows-py</a>
<h1 style="display: none;">LlamaIndex Workflows LlamaIndex Workflows are a framework for orchestrating and chaining together complex systems of steps and events. What can you build with W...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <h1>LlamaIndex Workflows</h1>
<p><a href="https://github.com/run-llama/workflows/actions/workflows/test.yml"><img src="https://github.com/run-llama/workflows/actions/workflows/test.yml/badge.svg" alt="Unit Testing" /></a>
<a href="https://coveralls.io/github/run-llama/workflows?branch=main"><img src="https://coveralls.io/repos/github/run-llama/workflows/badge.svg?branch=main" alt="Coverage Status" /></a>
<a href="https://github.com/run-llama/llama-index-workflows/graphs/contributors"><img src="https://img.shields.io/github/contributors/run-llama/workflows" alt="GitHub contributors" /></a></p>
<p><a href="https://pypi.org/project/llama-index-workflows/"><img src="https://img.shields.io/pypi/dm/llama-index-workflows" alt="PyPI - Downloads" /></a>
<a href="https://discord.gg/dGcwcsnxhU"><img src="https://img.shields.io/discord/1059199217496772688" alt="Discord" /></a>
<a href="https://x.com/llama_index"><img src="https://img.shields.io/twitter/follow/llama_index" alt="Twitter" /></a>
<a href="https://www.reddit.com/r/LlamaIndex/"><img src="https://img.shields.io/reddit/subreddit-subscribers/LlamaIndex?style=plastic&amp;logo=reddit&amp;label=r%2FLlamaIndex&amp;labelColor=white" alt="Reddit" /></a></p>
<p>LlamaIndex Workflows are a framework for orchestrating and chaining together complex systems of steps and events.</p>
<h2>What can you build with Workflows?</h2>
<p>Workflows shine when you need to orchestrate complex, multi-step processes that involve AI models, APIs, and decision-making. Here are some examples of what you can build:</p>
<ul>
<li><strong>AI Agents</strong> - Create intelligent systems that can reason, make decisions, and take actions across multiple steps</li>
<li><strong>Document Processing Pipelines</strong> - Build systems that ingest, analyze, summarize, and route documents through various processing stages</li>
<li><strong>Multi-Model AI Applications</strong> - Coordinate between different AI models (LLMs, vision models, etc.) to solve complex tasks</li>
<li><strong>Research Assistants</strong> - Develop workflows that can search, analyze, synthesize information, and provide comprehensive answers</li>
<li><strong>Content Generation Systems</strong> - Create pipelines that generate, review, edit, and publish content with human-in-the-loop approval</li>
<li><strong>Customer Support Automation</strong> - Build intelligent routing systems that can understand, categorize, and respond to customer inquiries</li>
</ul>
<p>The async-first, event-driven architecture makes it easy to build workflows that can route between different capabilities, implement parallel processing patterns, loop over complex sequences, and maintain state across multiple steps - all the features you need to make your AI applications production-ready.</p>
<h2>Key Features</h2>
<ul>
<li><strong>async-first</strong> - workflows are built around Python's async functionality. Steps are async functions that process incoming events from an asyncio queue and emit new events to other queues. This also means that workflows work best in your async apps like FastAPI, Jupyter Notebooks, etc.</li>
<li><strong>event-driven</strong> - workflows consist of steps and events. Organizing your code around events and steps makes it easier to reason about and test.</li>
<li><strong>state management</strong> - each run of a workflow is self-contained, meaning you can launch a workflow, save information within it, serialize the state of a workflow and resume it later.</li>
<li><strong>observability</strong> - workflows are automatically instrumented for observability, meaning you can use tools like <code>Arize Phoenix</code> and <code>OpenTelemetry</code> right out of the box.</li>
</ul>
<h2>Quick Start</h2>
<p>Install the package:</p>
<pre><code class="language-bash">pip install llama-index-workflows
</code></pre>
<p>And create your first workflow:</p>
<pre><code class="language-python">import asyncio
from pydantic import BaseModel, Field
from workflows import Context, Workflow, step
from workflows.events import Event, StartEvent, StopEvent

class MyEvent(Event):
    msg: list[str]

class RunState(BaseModel):
    num_runs: int = Field(default=0)

class MyWorkflow(Workflow):
    @step
    async def start(self, ctx: Context[RunState], ev: StartEvent) -&gt; MyEvent:
        async with ctx.store.edit_state() as state:
            state.num_runs += 1

            return MyEvent(msg=[ev.input_msg] * state.num_runs)

    @step
    async def process(self, ctx: Context[RunState], ev: MyEvent) -&gt; StopEvent:
        data_length = len(&quot;&quot;.join(ev.msg))
        new_msg = f&quot;Processed {len(ev.msg)} times, data length: {data_length}&quot;
        return StopEvent(result=new_msg)

async def main():
    workflow = MyWorkflow()
</code></pre>
<h1>[optional] provide a context object to the workflow</h1>
<p>ctx = Context(workflow)
result = await workflow.run(input_msg=&quot;Hello, world!&quot;, ctx=ctx)
print(&quot;Workflow result:&quot;, result)</p>
<h1>re-running with the same context will retain the state</h1>
<p>result = await workflow.run(input_msg=&quot;Hello, world!&quot;, ctx=ctx)
print(&quot;Workflow result:&quot;, result)</p>
<p>if <strong>name</strong> == &quot;<strong>main</strong>&quot;:
asyncio.run(main())</p>
<pre><code>
In the example above
- Steps that accept a `StartEvent` will be run first.
- Steps that return a `StopEvent` will end the workflow.
- Intermediate events are user defined and can be used to pass information between steps.
- The `Context` object is also used to share information between steps.

Visit the [complete documentation](https://docs.llamaindex.ai/en/stable/understanding/workflows/) for more examples using `llama-index`!

## More examples

- [Basic Feature Run-Through](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/feature_walkthrough.ipynb)
- [Building a Function Calling Agent with `llama-index`](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/agent.ipynb)
- [Human-in-the-loop Iterative Document Extraction](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/document_processing.ipynb)
- Observability
  - [OpenTelemetry + Instrumentation Primer](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observability_pt1.ipynb)
  - [OpenTelemetry + LlamaIndex](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observability_pt2.ipynb)
  - [Arize Phoenix + LlamaIndex](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observablitiy_arize_phoenix.ipynb)
  - [Langfuse + LlamaIndex](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observablitiy_langfuse.ipynb)

## Related Packages

- [Typescript Workflows](https://github.com/run-llama/workflows-ts)



---


Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-07-09


---
</code></pre>

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
</body>
</html>