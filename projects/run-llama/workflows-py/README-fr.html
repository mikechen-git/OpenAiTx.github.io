<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>workflows-py - run-llama/workflows-py fr</title>
    <meta name="title" content="workflows-py - run-llama/workflows-py fr | LlamaIndex Workflows LlamaIndex Workflows est un framework pour orchestrer et enchaîner des systèmes complexes d'étapes et d'événements. Que pouvez-vous constru...">
    <meta name="description" content="run-llama/workflows-py - GitHub repository fr documentation and information | LlamaIndex Workflows LlamaIndex Workflows est un framework pour orchestrer et enchaîner des systèmes complexes d'étapes et d'événements. Que pouvez-vous constru...">
    <meta name="keywords" content="run-llama, workflows-py, GitHub, repository, fr documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/run-llama/workflows-py/README-fr.html">
    <meta property="og:title" content="workflows-py - run-llama/workflows-py fr | LlamaIndex Workflows LlamaIndex Workflows est un framework pour orchestrer et enchaîner des systèmes complexes d'étapes et d'événements. Que pouvez-vous constru...">
    <meta property="og:description" content="run-llama/workflows-py - GitHub repository fr documentation and information | LlamaIndex Workflows LlamaIndex Workflows est un framework pour orchestrer et enchaîner des systèmes complexes d'étapes et d'événements. Que pouvez-vous constru...">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div style="position: fixed; top: 2px; left: 2px; z-index: 2000; background: rgba(255,255,255,0.95); border-radius: 6px; box-shadow: 0 2px 8px rgba(0,0,0,0.06); padding: 4px 14px; font-size: 15px; color: #222; font-family: 'Segoe UI', Arial, sans-serif; font-weight: 500; letter-spacing: 0.5px;">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" style="color: #0366d6; text-decoration: none; font-weight: 600;">Open AI Tx</a>
    </div>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/run-llama/workflows-py" id="githubRepoLink" target="_blank">run-llama/workflows-py</a>
<h1 style="display: none;">LlamaIndex Workflows LlamaIndex Workflows est un framework pour orchestrer et enchaîner des systèmes complexes d'étapes et d'événements. Que pouvez-vous constru...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <h1>LlamaIndex Workflows</h1>
<p><a href="https://github.com/run-llama/workflows/actions/workflows/test.yml"><img src="https://github.com/run-llama/workflows/actions/workflows/test.yml/badge.svg" alt="Tests unitaires" /></a>
<a href="https://coveralls.io/github/run-llama/workflows?branch=main"><img src="https://coveralls.io/repos/github/run-llama/workflows/badge.svg?branch=main" alt="Statut de la couverture" /></a>
<a href="https://github.com/run-llama/llama-index-workflows/graphs/contributors"><img src="https://img.shields.io/github/contributors/run-llama/workflows" alt="Contributeurs GitHub" /></a></p>
<p><a href="https://pypi.org/project/llama-index-workflows/"><img src="https://img.shields.io/pypi/dm/llama-index-workflows" alt="PyPI - Téléchargements" /></a>
<a href="https://discord.gg/dGcwcsnxhU"><img src="https://img.shields.io/discord/1059199217496772688" alt="Discord" /></a>
<a href="https://x.com/llama_index"><img src="https://img.shields.io/twitter/follow/llama_index" alt="Twitter" /></a>
<a href="https://www.reddit.com/r/LlamaIndex/"><img src="https://img.shields.io/reddit/subreddit-subscribers/LlamaIndex?style=plastic&amp;logo=reddit&amp;label=r%2FLlamaIndex&amp;labelColor=white" alt="Reddit" /></a></p>
<p>LlamaIndex Workflows est un framework pour orchestrer et enchaîner des systèmes complexes d'étapes et d'événements.</p>
<h2>Que pouvez-vous construire avec Workflows ?</h2>
<p>Workflows brillent lorsque vous avez besoin d'orchestrer des processus complexes en plusieurs étapes impliquant des modèles d'IA, des API et de la prise de décision. Voici quelques exemples de ce que vous pouvez construire :</p>
<ul>
<li><strong>Agents IA</strong> - Créez des systèmes intelligents capables de raisonner, prendre des décisions et effectuer des actions sur plusieurs étapes</li>
<li><strong>Pipelines de traitement de documents</strong> - Construisez des systèmes qui ingèrent, analysent, résument et dirigent les documents à travers différentes étapes de traitement</li>
<li><strong>Applications IA multi-modèles</strong> - Coordonnez différents modèles d'IA (LLM, modèles de vision, etc.) pour résoudre des tâches complexes</li>
<li><strong>Assistants de recherche</strong> - Développez des workflows capables de rechercher, analyser, synthétiser l'information et fournir des réponses complètes</li>
<li><strong>Systèmes de génération de contenu</strong> - Créez des pipelines qui génèrent, relisent, éditent et publient du contenu avec une validation humaine</li>
<li><strong>Automatisation du support client</strong> - Construisez des systèmes de routage intelligents capables de comprendre, catégoriser et répondre aux demandes des clients</li>
</ul>
<p>L'architecture orientée événements et asynchrone facilite la création de workflows capables de s'orienter entre différentes capacités, d'implémenter des modèles de traitement parallèle, de boucler sur des séquences complexes et de maintenir un état sur plusieurs étapes – toutes les fonctionnalités dont vous avez besoin pour rendre vos applications IA prêtes pour la production.</p>
<h2>Fonctionnalités Clés</h2>
<ul>
<li><strong>async-first</strong> - les workflows sont conçus autour de la fonctionnalité async de Python : les étapes sont des fonctions asynchrones qui traitent les événements entrants depuis une file asyncio et émettent de nouveaux événements vers d'autres files. Cela signifie également que les workflows fonctionnent au mieux dans vos applications async comme FastAPI, Jupyter Notebooks, etc.</li>
<li><strong>orienté événement</strong> - les workflows sont constitués d'étapes et d'événements. Organiser votre code autour des événements et des étapes facilite la compréhension et les tests.</li>
<li><strong>gestion d'état</strong> - chaque exécution d'un workflow est autonome, ce qui signifie que vous pouvez lancer un workflow, sauvegarder des informations à l'intérieur, sérialiser l'état d'un workflow et le reprendre plus tard.</li>
<li><strong>observabilité</strong> - les workflows sont automatiquement instrumentés pour l'observabilité, ce qui signifie que vous pouvez utiliser des outils comme <code>Arize Phoenix</code> et <code>OpenTelemetry</code> dès l'installation.</li>
</ul>
<h2>Démarrage Rapide</h2>
<p>Installez le package :</p>
<pre><code class="language-bash">pip install llama-index-workflows
</code></pre>
<p>Et créez votre premier workflow :</p>
<pre><code class="language-python">import asyncio
from pydantic import BaseModel, Field
from workflows import Context, Workflow, step
from workflows.events import Event, StartEvent, StopEvent

class MyEvent(Event):
    msg: list[str]

class RunState(BaseModel):
    num_runs: int = Field(default=0)

class MyWorkflow(Workflow):
    @step
    async def start(self, ctx: Context[RunState], ev: StartEvent) -&gt; MyEvent:
        async with ctx.store.edit_state() as state:
            state.num_runs += 1

            return MyEvent(msg=[ev.input_msg] * state.num_runs)

    @step
    async def process(self, ctx: Context[RunState], ev: MyEvent) -&gt; StopEvent:
        data_length = len(&quot;&quot;.join(ev.msg))
        new_msg = f&quot;Processed {len(ev.msg)} times, data length: {data_length}&quot;
        return StopEvent(result=new_msg)

async def main():
    workflow = MyWorkflow()
</code></pre>
<pre><code class="language-python">    # [optionnel] fournir un objet contexte au workflow
    ctx = Context(workflow)
    result = await workflow.run(input_msg=&quot;Hello, world!&quot;, ctx=ctx)
    print(&quot;Résultat du workflow :&quot;, result)

    # relancer avec le même contexte conservera l'état
    result = await workflow.run(input_msg=&quot;Hello, world!&quot;, ctx=ctx)
    print(&quot;Résultat du workflow :&quot;, result)

if __name__ == &quot;__main__&quot;:
    asyncio.run(main())
</code></pre>
<p>Dans l'exemple ci-dessus :</p>
<ul>
<li>Les étapes qui acceptent un <code>StartEvent</code> seront exécutées en premier.</li>
<li>Les étapes qui renvoient un <code>StopEvent</code> termineront le workflow.</li>
<li>Les événements intermédiaires sont définis par l'utilisateur et peuvent être utilisés pour transmettre des informations entre les étapes.</li>
<li>L'objet <code>Context</code> est également utilisé pour partager des informations entre les étapes.</li>
</ul>
<p>Consultez la <a href="https://docs.llamaindex.ai/en/stable/understanding/workflows/">documentation complète</a> pour plus d'exemples utilisant <code>llama-index</code> !</p>
<h2>Plus d'exemples</h2>
<ul>
<li><a href="https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/feature_walkthrough.ipynb">Présentation des fonctionnalités de base</a></li>
<li><a href="https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/agent.ipynb">Créer un agent d'appel de fonction avec <code>llama-index</code></a></li>
<li><a href="https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/document_processing.ipynb">Extraction de documents itérative avec intervention humaine</a></li>
<li>Observabilité
<ul>
<li><a href="https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observability_pt1.ipynb">Introduction à OpenTelemetry + Instrumentation</a></li>
<li><a href="https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observability_pt2.ipynb">OpenTelemetry + LlamaIndex</a></li>
<li><a href="https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observablitiy_arize_phoenix.ipynb">Arize Phoenix + LlamaIndex</a></li>
<li><a href="https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observablitiy_langfuse.ipynb">Langfuse + LlamaIndex</a></li>
</ul>
</li>
</ul>
<h2>Packages associés</h2>
<ul>
<li><a href="https://github.com/run-llama/workflows-ts">Workflows Typescript</a></li>
</ul>
<hr />
<p>Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx">Open Ai Tx</a> | Last indexed: 2025-07-09</p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
</body>
</html>