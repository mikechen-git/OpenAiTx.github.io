<!DOCTYPE html>
<html lang="pt">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>tome - runebookai/tome pt</title>
    <meta name="title" content="tome - runebookai/tome pt | Tome - Grimório Mágico de IA um aplicativo mágico de desktop que coloca o poder de LLMs e MCP nas mãos de todos 🔮 Baixe o aplicativo Tome Desktop: Windows | Ma...">
    <meta name="description" content="runebookai/tome - GitHub repository pt documentation and information | Tome - Grimório Mágico de IA um aplicativo mágico de desktop que coloca o poder de LLMs e MCP nas mãos de todos 🔮 Baixe o aplicativo Tome Desktop: Windows | Ma...">
    <meta name="keywords" content="runebookai, tome, GitHub, repository, pt documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/runebookai/tome/README-pt.html">
    <meta property="og:title" content="tome - runebookai/tome pt | Tome - Grimório Mágico de IA um aplicativo mágico de desktop que coloca o poder de LLMs e MCP nas mãos de todos 🔮 Baixe o aplicativo Tome Desktop: Windows | Ma...">
    <meta property="og:description" content="runebookai/tome - GitHub repository pt documentation and information | Tome - Grimório Mágico de IA um aplicativo mágico de desktop que coloca o poder de LLMs e MCP nas mãos de todos 🔮 Baixe o aplicativo Tome Desktop: Windows | Ma...">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div style="position: fixed; top: 2px; left: 2px; z-index: 2000; background: rgba(255,255,255,0.95); border-radius: 6px; box-shadow: 0 2px 8px rgba(0,0,0,0.06); padding: 4px 14px; font-size: 15px; color: #222; font-family: 'Segoe UI', Arial, sans-serif; font-weight: 500; letter-spacing: 0.5px;">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" style="color: #0366d6; text-decoration: none; font-weight: 600;">Open AI Tx</a>
    </div>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/runebookai/tome" id="githubRepoLink" target="_blank">runebookai/tome</a>
<h1 style="display: none;">Tome - Grimório Mágico de IA um aplicativo mágico de desktop que coloca o poder de LLMs e MCP nas mãos de todos 🔮 Baixe o aplicativo Tome Desktop: Windows | Ma...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <h1>Tome - Grimório Mágico de IA</h1>
<img src="https://raw.githubusercontent.com/runebookai/tome/main/static/images/repo-header.png" alt="Tome" />
<p align="center">
    <code>um aplicativo mágico de desktop que coloca o poder de LLMs e MCP nas mãos de todos</code>
</p>
<p align="center">
    <a href="https://discord.gg/9CH6us29YA" target="_blank"><img src="https://img.shields.io/discord/1365100902561742868?logo=discord&logoColor=fff&label=Join%20Us!&color=9D7CD8" alt="Junte-se a nós no Discord" /></a>
    <a href="https://opensource.org/licenses/Apache-2.0" target="_blank"><img src="https://img.shields.io/badge/License-Apache_2.0-blue.svg" alt="Licença: Apache 2.0" /></a>
    <a href="https://github.com/runebookai/tome/releases" target="_blank"><img src="https://img.shields.io/github/v/release/runebookai/tome" alt="Lançamento no GitHub" /></a>
</p>
<p align="center">
    🔮 Baixe o aplicativo Tome Desktop: <a href="https://github.com/runebookai/tome/releases/download/0.6.0/Tome_0.6.0_x64-setup.exe">Windows</a> | <a href="https://github.com/runebookai/tome/releases/download/0.6.0/Tome_0.6.0_aarch64.dmg">MacOS</a>
</p>
<h1>Tome</h1>
<p>O Tome é um aplicativo de desktop que permite que <strong>qualquer pessoa</strong> aproveite a magia dos LLMs e MCP. Baixe o Tome, conecte qualquer LLM local ou remoto e ligue-o a milhares de servidores MCP para criar seu próprio grimório mágico alimentado por IA.</p>
<p>🫥 Quer que seja 100% local, 100% privado? Use Ollama e Qwen3 apenas com servidores MCP locais para lançar feitiços em seu próprio universo de bolso. ⚡ Quer modelos de nuvem de ponta com os servidores MCP remotos mais recentes? Você também pode ter isso. A escolha é toda sua!</p>
<p>🏗️ Esta é uma Visualização Técnica, então lembre-se de que as coisas podem estar inacabadas. <a href="https://discord.gg/9CH6us29YA">Junte-se a nós no Discord</a> para compartilhar dicas, truques e problemas encontrados. Dê uma estrela neste repositório para ficar por dentro das novidades e lançamentos de funcionalidades!</p>
<h2>🪄 Funcionalidades</h2>
<ul>
<li>🧙 <strong>Experiência Facilitada para Iniciantes</strong>
<ul>
<li>Basta baixar e instalar o Tome e conectar o LLM de sua escolha</li>
<li>Sem complicações com JSON, Docker, python ou node</li>
</ul>
</li>
<li>🤖 <strong>Suporte a Modelos de IA</strong>
<ul>
<li><strong>Remoto</strong>: Google Gemini, OpenAI, qualquer endpoint compatível com API OpenAI</li>
<li><strong>Local</strong>: Ollama, LM Studio, Cortex, qualquer endpoint compatível com API OpenAI</li>
</ul>
</li>
<li>🔮 <strong>Suporte Aprimorado a MCP</strong>
<ul>
<li>Interface para instalar, remover, ligar/desligar servidores MCP</li>
<li>Servidores MCP npm, uvx, node, python todos suportados nativamente</li>
</ul>
</li>
<li>🏪 <strong>Integração com o registro <a href="https://smithery.ai">Smithery.ai</a></strong>
<ul>
<li>Milhares de servidores MCP disponíveis via instalação com um clique</li>
</ul>
</li>
<li>✏️ <strong>Personalização de janelas de contexto e temperatura</strong></li>
<li>🧰 <strong>Suporte nativo a chamadas de ferramentas e modelos de raciocínio</strong>
<ul>
<li>Melhorias na interface que destacam claramente chamadas de ferramentas e mensagens de pensamento</li>
</ul>
</li>
</ul>
<h2>Demonstração</h2>
<p>https://github.com/user-attachments/assets/0775d100-3eba-4219-9e2f-360a01f28cce</p>
<h1>Primeiros Passos</h1>
<h2>Requisitos</h2>
<ul>
<li>MacOS ou Windows (Linux em breve!)</li>
<li>Provedor de LLM de sua escolha: <a href="https://ollama.com/">Ollama</a> ou <a href="https://aistudio.google.com/app/apikey">chave da API Gemini</a> são fáceis/grátis</li>
<li><a href="https://github.com/runebookai/tome/releases">Baixe a versão mais recente do Tome</a></li>
</ul>
<h2>Início Rápido</h2>
<ol>
<li>Instale o <a href="https://github.com/runebookai/tome/releases">Tome</a></li>
<li>Conecte seu provedor de LLM preferido - OpenAI, Ollama e Gemini já vêm pré-configurados, mas você também pode adicionar provedores como o LM Studio usando http://localhost:1234/v1 como URL</li>
<li>Abra a aba MCP no Tome e instale seu primeiro <a href="https://github.com/modelcontextprotocol/servers">servidor MCP</a> (Fetch é um fácil para começar, basta colar <code>uvx mcp-server-fetch</code> no campo do servidor).</li>
<li>Converse com seu modelo alimentado por MCP! Peça para buscar a principal notícia do Hacker News.</li>
</ol>
<h1>Visão</h1>
<p>Queremos tornar os LLMs locais e MCP acessíveis para todos. Estamos construindo uma ferramenta que permite que você seja criativo com LLMs, independentemente
de ser engenheiro, entusiasta, hobbyista ou qualquer pessoa entre eles.</p>
<h2>Princípios Fundamentais</h2>
<ul>
<li><strong>Tome é local primeiro:</strong> Você está no controle de para onde seus dados vão.</li>
<li><strong>Tome é para todos:</strong> Você não deve precisar gerenciar linguagens de programação, gerenciadores de pacotes ou arquivos de configuração json.</li>
</ul>
<h2>O que vem a seguir</h2>
<p>Recebemos muitos feedbacks incríveis nas últimas semanas desde o lançamento do Tome, mas temos grandes planos para o futuro. Queremos libertar os LLMs da sua caixa de chat, e temos muitos recursos chegando para ajudar você a fazer isso.</p>
<ul>
<li>Tarefas agendadas: LLMs devem realizar tarefas úteis mesmo quando você não está na frente do computador.</li>
<li>Integrações nativas: Servidores MCP são uma ótima maneira de acessar ferramentas e informações, mas queremos adicionar integrações ainda mais poderosas para interagir com os LLMs de maneiras únicas.</li>
<li>Construtor de aplicativos: acreditamos que, a longo prazo, as melhores experiências não estarão em uma interface de chat. Temos planos para adicionar ferramentas adicionais que permitirão criar aplicativos e fluxos de trabalho poderosos.</li>
<li>??? Conte-nos o que você gostaria de ver! Participe da nossa comunidade pelos links abaixo, adoraríamos ouvir você.</li>
</ul>
<h1>Comunidade</h1>
<p><a href="https://discord.gg/9CH6us29YA">Discord</a> <a href="https://blog.runebook.ai">Blog</a> <a href="https://bsky.app/profile/gettome.app">Bluesky</a> <a href="https://twitter.com/get_tome">Twitter</a></p>
<hr />
<p>Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx">Open Ai Tx</a> | Last indexed: 2025-07-03</p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
</body>
</html>