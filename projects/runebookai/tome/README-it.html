<!DOCTYPE html>
<html lang="it">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>tome - runebookai/tome it</title>
    <meta name="title" content="tome - runebookai/tome it | Tome - Libro degli Incantesimi Magico con IA un'app desktop magica che mette il potere degli LLM e MCP nelle mani di tutti 🔮 Scarica l'app desktop Tome: Window...">
    <meta name="description" content="runebookai/tome - GitHub repository it documentation and information | Tome - Libro degli Incantesimi Magico con IA un'app desktop magica che mette il potere degli LLM e MCP nelle mani di tutti 🔮 Scarica l'app desktop Tome: Window...">
    <meta name="keywords" content="runebookai, tome, GitHub, repository, it documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/runebookai/tome/README-it.html">
    <meta property="og:title" content="tome - runebookai/tome it | Tome - Libro degli Incantesimi Magico con IA un'app desktop magica che mette il potere degli LLM e MCP nelle mani di tutti 🔮 Scarica l'app desktop Tome: Window...">
    <meta property="og:description" content="runebookai/tome - GitHub repository it documentation and information | Tome - Libro degli Incantesimi Magico con IA un'app desktop magica che mette il potere degli LLM e MCP nelle mani di tutti 🔮 Scarica l'app desktop Tome: Window...">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div style="position: fixed; top: 2px; left: 2px; z-index: 2000; background: rgba(255,255,255,0.95); border-radius: 6px; box-shadow: 0 2px 8px rgba(0,0,0,0.06); padding: 4px 14px; font-size: 15px; color: #222; font-family: 'Segoe UI', Arial, sans-serif; font-weight: 500; letter-spacing: 0.5px;">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" style="color: #0366d6; text-decoration: none; font-weight: 600;">Open AI Tx</a>
    </div>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/runebookai/tome" id="githubRepoLink" target="_blank">runebookai/tome</a>
<h1 style="display: none;">Tome - Libro degli Incantesimi Magico con IA un'app desktop magica che mette il potere degli LLM e MCP nelle mani di tutti 🔮 Scarica l'app desktop Tome: Window...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <h1>Tome - Libro degli Incantesimi Magico con IA</h1>
<img src="https://raw.githubusercontent.com/runebookai/tome/main/static/images/repo-header.png" alt="Tome" />
<p align="center">
    <code>un'app desktop magica che mette il potere degli LLM e MCP nelle mani di tutti</code>
</p>
<p align="center">
    <a href="https://discord.gg/9CH6us29YA" target="_blank"><img src="https://img.shields.io/discord/1365100902561742868?logo=discord&logoColor=fff&label=Join%20Us!&color=9D7CD8" alt="Join Us on Discord" /></a>
    <a href="https://opensource.org/licenses/Apache-2.0" target="_blank"><img src="https://img.shields.io/badge/License-Apache_2.0-blue.svg" alt="License: Apache 2.0" /></a>
    <a href="https://github.com/runebookai/tome/releases" target="_blank"><img src="https://img.shields.io/github/v/release/runebookai/tome" alt="GitHub Release" /></a>
</p>
<p align="center">
    🔮 Scarica l'app desktop Tome: <a href="https://github.com/runebookai/tome/releases/download/0.6.0/Tome_0.6.0_x64-setup.exe">Windows</a> | <a href="https://github.com/runebookai/tome/releases/download/0.6.0/Tome_0.6.0_aarch64.dmg">MacOS</a>
</p>
<h1>Tome</h1>
<p>Tome è un'app desktop che permette a <strong>chiunque</strong> di sfruttare la magia degli LLM e MCP. Scarica Tome, collega qualsiasi LLM locale o remoto e connettilo a migliaia di server MCP per creare il tuo magico libro degli incantesimi alimentato dall'IA.</p>
<p>🫥 Vuoi che sia al 100% locale, al 100% privato? Usa Ollama e Qwen3 solo con server MCP locali per lanciare incantesimi nel tuo universo tascabile. ⚡ Vuoi modelli cloud all'avanguardia con gli ultimi server MCP remoti? Puoi avere anche questo. Dipende tutto da te!</p>
<p>🏗️ Questa è un'Anteprima Tecnica, quindi tieni presente che alcune cose potrebbero essere grezze. <a href="https://discord.gg/9CH6us29YA">Unisciti a noi su Discord</a> per condividere suggerimenti, trucchi e problemi che incontri. Metti una stella a questo repo per rimanere aggiornato su novità e nuove funzionalità!</p>
<h2>🪄 Funzionalità</h2>
<ul>
<li>🧙 <strong>Esperienza Semplificata per Principianti</strong>
<ul>
<li>Basta scaricare e installare Tome e collegare l'LLM che preferisci</li>
<li>Niente complicazioni con JSON, Docker, python o node</li>
</ul>
</li>
<li>🤖 <strong>Supporto Modelli AI</strong>
<ul>
<li><strong>Remoti</strong>: Google Gemini, OpenAI, qualsiasi endpoint compatibile con OpenAI API</li>
<li><strong>Locali</strong>: Ollama, LM Studio, Cortex, qualsiasi endpoint compatibile con OpenAI API</li>
</ul>
</li>
<li>🔮 <strong>Supporto MCP Avanzato</strong>
<ul>
<li>Interfaccia per installare, rimuovere, accendere/spegnere server MCP</li>
<li>Server MCP npm, uvx, node, python tutti supportati nativamente</li>
</ul>
</li>
<li>🏪 <strong>Integrazione nel registro <a href="https://smithery.ai">Smithery.ai</a></strong>
<ul>
<li>Migliaia di server MCP disponibili tramite installazione con un clic</li>
</ul>
</li>
<li>✏️ <strong>Personalizzazione delle finestre di contesto e della temperatura</strong></li>
<li>🧰 <strong>Supporto nativo per chiamate a strumenti e modelli di ragionamento</strong>
<ul>
<li>Migliorie UI che distinguono chiaramente tra chiamate a strumenti e messaggi di pensiero</li>
</ul>
</li>
</ul>
<h2>Demo</h2>
<p>https://github.com/user-attachments/assets/0775d100-3eba-4219-9e2f-360a01f28cce</p>
<h1>Per Iniziare</h1>
<h2>Requisiti</h2>
<ul>
<li>MacOS o Windows (Linux in arrivo!)</li>
<li>Un provider LLM a scelta: <a href="https://ollama.com/">Ollama</a> o <a href="https://aistudio.google.com/app/apikey">chiave API Gemini</a> sono semplici/gratuiti</li>
<li><a href="https://github.com/runebookai/tome/releases">Scarica l'ultima versione di Tome</a></li>
</ul>
<h2>Avvio Rapido</h2>
<ol>
<li>Installa <a href="https://github.com/runebookai/tome/releases">Tome</a></li>
<li>Collega il tuo provider LLM preferito - OpenAI, Ollama e Gemini sono preimpostati ma puoi anche aggiungere provider come LM Studio utilizzando http://localhost:1234/v1 come URL</li>
<li>Apri la scheda MCP in Tome e installa il tuo primo <a href="https://github.com/modelcontextprotocol/servers">server MCP</a> (Fetch è uno semplice per iniziare, basta incollare <code>uvx mcp-server-fetch</code> nel campo del server).</li>
<li>Chatta con il tuo modello potenziato da MCP! Chiedigli di recuperare la notizia principale su Hacker News.</li>
</ol>
<h1>Visione</h1>
<p>Vogliamo rendere gli LLM locali e MCP accessibili a tutti. Stiamo costruendo uno strumento che ti permette di essere creativo con gli LLM, indipendentemente dal fatto che tu sia un ingegnere, un maker, un hobbista o chiunque altro.</p>
<h2>Principi Fondamentali</h2>
<ul>
<li><strong>Tome è locale prima di tutto:</strong> Hai il controllo su dove vanno i tuoi dati.</li>
<li><strong>Tome è per tutti:</strong> Non dovresti dover gestire linguaggi di programmazione, package manager o file di configurazione json.</li>
</ul>
<h2>Cosa ci aspetta</h2>
<p>Abbiamo ricevuto molti feedback fantastici nelle ultime settimane dal rilascio di Tome ma abbiamo grandi progetti per il futuro. Vogliamo liberare gli LLM dalla loro chatbox, e abbiamo in arrivo molte funzionalità per aiutarti a farlo.</p>
<ul>
<li>Attività programmate: gli LLM dovrebbero fare cose utili anche quando non sei davanti al computer.</li>
<li>Integrazioni native: i server MCP sono un ottimo modo per accedere a strumenti e informazioni, ma vogliamo aggiungere integrazioni ancora più potenti per interagire con gli LLM in modi unici.</li>
<li>Costruttore di app: crediamo che, a lungo termine, le migliori esperienze non saranno in un'interfaccia di chat. Abbiamo in programma di aggiungere ulteriori strumenti che ti permetteranno di creare potenti applicazioni e flussi di lavoro.</li>
<li>??? Facci sapere cosa vorresti vedere! Unisciti alla nostra community tramite i link qui sotto, ci piacerebbe sentirti.</li>
</ul>
<h1>Community</h1>
<p><a href="https://discord.gg/9CH6us29YA">Discord</a> <a href="https://blog.runebook.ai">Blog</a> <a href="https://bsky.app/profile/gettome.app">Bluesky</a> <a href="https://twitter.com/get_tome">Twitter</a></p>
<hr />
<p>Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx">Open Ai Tx</a> | Last indexed: 2025-07-03</p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
</body>
</html>