<!DOCTYPE html>
<html lang="de">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>tome - German Documentation</title>
    <meta name="description" content="Read tome documentation in German. This project has 292 stars on GitHub.">
    <meta name="keywords" content="tome, German, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "tome",
  "description": "Documentation for tome in German",
  "author": {
    "@type": "Person",
    "name": "runebookai"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 292
  },
  "url": "https://OpenAiTx.github.io/projects/runebookai/tome/README-de.html",
  "sameAs": "https://raw.githubusercontent.com/runebookai/tome/main/README.md",
  "datePublished": "2025-07-03",
  "dateModified": "2025-07-03"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            color: #24292e;
            margin-bottom: 8px;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">tome</h1>
            <div class="project-meta">
                <span class="stars">⭐ 292 stars</span>
                <span class="language">German</span>
                <span>by runebookai</span>
            </div>
        </div>
        
        <div class="content">
            <h1>Tome - Magisches KI-Zauberbuch</h1></p><p><img src="https://raw.githubusercontent.com/runebookai/tome/main/static/images/repo-header.png" alt="Tome" /></p><p><p align="center">
    <code>eine magische Desktop-App, die die Kraft von LLMs und MCP in die Hände aller legt</code>
</p></p><p><p align="center">
    <a href="https://discord.gg/9CH6us29YA" target="_blank"><img src="https://img.shields.io/discord/1365100902561742868?logo=discord&logoColor=fff&label=Join%20Us!&color=9D7CD8" alt="Join Us on Discord" /></a>
    <a href="https://opensource.org/licenses/Apache-2.0" target="_blank"><img src="https://img.shields.io/badge/License-Apache_2.0-blue.svg" alt="License: Apache 2.0" /></a>
    <a href="https://github.com/runebookai/tome/releases" target="_blank"><img src="https://img.shields.io/github/v/release/runebookai/tome" alt="GitHub Release" /></a>
</p></p><p><p align="center">
    🔮 Lade die Tome Desktop-App herunter: <a href="https://github.com/runebookai/tome/releases/download/0.6.0/Tome_0.6.0_x64-setup.exe">Windows</a> | <a href="https://github.com/runebookai/tome/releases/download/0.6.0/Tome_0.6.0_aarch64.dmg">MacOS</a>
</p></p><h1>Tome</h1></p><p>Tome ist eine Desktop-App, die <strong>jedem</strong> ermöglicht, die Magie von LLMs und MCP zu nutzen. Lade Tome herunter, verbinde ein beliebiges lokales oder entferntes LLM und schließe es an Tausende von MCP-Servern an, um dein eigenes magisches, KI-gestütztes Zauberbuch zu erschaffen.</p><p>🫥 Willst du, dass alles 100% lokal und 100% privat bleibt? Nutze Ollama und Qwen3 ausschließlich mit lokalen MCP-Servern, um Zaubersprüche in deinem eigenen Pocket-Universum zu wirken. ⚡ Willst du modernste Cloud-Modelle mit den neuesten entfernten MCP-Servern? Auch das ist möglich. Die Wahl liegt ganz bei dir!</p><p>🏗️ Dies ist eine technische Vorschau, daher kann es an einigen Stellen noch holprig sein. <a href="https://discord.gg/9CH6us29YA" target="_blank" rel="noopener noreferrer">Tritt unserem Discord bei</a>, um Tipps, Tricks und aufgetretene Probleme zu teilen. Setze einen Stern auf dieses Repo, um immer über Updates und neue Funktionen informiert zu bleiben!</p><h2>🪄 Funktionen</h2></p><ul><li>🧙 <strong>Vereinfachtes, anfängerfreundliches Erlebnis</strong></li>
  <li>Einfach Tome herunterladen, installieren und das gewünschte LLM anschließen</li>
  <li>Kein Herumhantieren mit JSON, Docker, Python oder Node notwendig</li>
<li>🤖 <strong>KI-Modellunterstützung</strong></li>
  <li><strong>Remote:</strong> Google Gemini, OpenAI, jeder OpenAI-API-kompatible Endpunkt</li>
  <li><strong>Lokal:</strong> Ollama, LM Studio, Cortex, jeder OpenAI-API-kompatible Endpunkt</li>
<li>🔮 <strong>Erweiterte MCP-Unterstützung</strong></li>
  <li>Benutzeroberfläche zum Installieren, Entfernen, Ein- und Ausschalten von MCP-Servern</li>
  <li>npm, uvx, node, python MCP-Server werden direkt unterstützt</li>
<li>🏪 <strong>Integration in das <a href="https://smithery.ai" target="_blank" rel="noopener noreferrer">Smithery.ai</a>-Register</strong></li>
  <li>Tausende MCP-Server per Ein-Klick-Installation verfügbar</li>
<li>✏️ <strong>Anpassung der Kontextfenster und Temperatur</strong></li>
<li>🧰 <strong>Native Unterstützung für Tool-Calls und Reasoning-Modelle</strong></li>
  <li>UI-Verbesserungen, die Tool-Calls und Denk-Nachrichten klar kennzeichnen</li></p><p></ul><h2>Demo</h2></p><p>https://github.com/user-attachments/assets/0775d100-3eba-4219-9e2f-360a01f28cce</p><h1>Erste Schritte</h1></p><h2>Voraussetzungen</h2></p><ul><li>MacOS oder Windows (Linux kommt bald!)</li>
<li>LLM-Anbieter deiner Wahl: <a href="https://ollama.com/" target="_blank" rel="noopener noreferrer">Ollama</a> oder <a href="https://aistudio.google.com/app/apikey" target="_blank" rel="noopener noreferrer">Gemini API-Schlüssel</a> sind einfach/kostenlos</li>
<li><a href="https://github.com/runebookai/tome/releases" target="_blank" rel="noopener noreferrer">Lade die neueste Version von Tome herunter</a></li></p><p></ul><h2>Schnellstart</h2></p><ul><li>Installiere <a href="https://github.com/runebookai/tome/releases" target="_blank" rel="noopener noreferrer">Tome</a></li>
<li>Verbinde deinen bevorzugten LLM-Anbieter – OpenAI, Ollama und Gemini sind voreingestellt, aber du kannst auch Anbieter wie LM Studio hinzufügen, indem du http://localhost:1234/v1 als URL verwendest</li>
<li>Öffne den MCP-Tab in Tome und installiere deinen ersten <a href="https://github.com/modelcontextprotocol/servers" target="_blank" rel="noopener noreferrer">MCP-Server</a> (Fetch ist ein einfacher Einstieg, kopiere einfach <code>uvx mcp-server-fetch</code> in das Serverfeld).</li>
<li>Chatte mit deinem MCP-gestützten Modell! Bitte es, die Top-Story auf Hacker News zu holen.</li></p><p></ul><h1>Vision</h1></p><p>Wir möchten lokale LLMs und MCP für alle zugänglich machen. Wir bauen ein Tool, das dir ermöglicht, kreativ mit LLMs zu arbeiten, egal ob du Entwickler, Bastler, Hobbyist oder irgendetwas dazwischen bist.</p><h2>Grundprinzipien</h2></p><ul><li><strong>Tome ist lokal zuerst:</strong> Du kontrollierst, wohin deine Daten gehen.</li>
<li><strong>Tome ist für alle:</strong> Du solltest dich nicht mit Programmiersprachen, Paketmanagern oder JSON-Konfigurationsdateien herumschlagen müssen.</li></p><p></ul><h2>Wie geht es weiter</h2></p><p>Wir haben seit der Veröffentlichung von Tome in den letzten Wochen viel tolles Feedback erhalten, aber wir haben große Pläne für die Zukunft. Wir wollen LLMs aus ihrer Chatbox befreien und haben viele neue Funktionen in Arbeit, die euch dabei unterstützen.</p><ul><li>Geplante Aufgaben: LLMs sollten hilfreiche Dinge erledigen, auch wenn du nicht am Computer bist.</li>
<li>Native Integrationen: MCP-Server sind ein großartiger Weg, um auf Tools und Informationen zuzugreifen, aber wir wollen noch mächtigere Integrationen hinzufügen, um auf einzigartige Weise mit LLMs zu interagieren.</li>
<li>App-Builder: Wir glauben langfristig, dass die besten Erfahrungen nicht in einer Chat-Oberfläche stattfinden. Wir planen, zusätzliche Tools bereitzustellen, mit denen du leistungsstarke Anwendungen und Workflows erstellen kannst.</li>
<li>??? Sag uns, was du dir wünschst! Tritt über die untenstehenden Links unserer Community bei, wir freuen uns auf dein Feedback.</li></p><p></ul><h1>Community</h1></p><p><a href="https://discord.gg/9CH6us29YA" target="_blank" rel="noopener noreferrer">Discord</a> <a href="https://blog.runebook.ai" target="_blank" rel="noopener noreferrer">Blog</a> <a href="https://bsky.app/profile/gettome.app" target="_blank" rel="noopener noreferrer">Bluesky</a> <a href="https://twitter.com/get_tome" target="_blank" rel="noopener noreferrer">Twitter</a> </p><p>
---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-07-03

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/runebookai/tome/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-07-03 
    </div>
    
</body>
</html>