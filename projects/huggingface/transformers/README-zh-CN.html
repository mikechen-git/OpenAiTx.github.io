<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>transformers - huggingface/transformers zh-CN</title>
    <meta name="title" content="transformers - huggingface/transformers zh-CN | English | 简体中文 | 繁體中文 | 한국어 | Español | 日本語 | हिन्दी | Русский | Рortuguês | తెలుగు | Français | Deutsch | Tiếng Việt | العربية | اردو | 最先进的预训练模型，适用于推理和训练 Tran...">
    <meta name="description" content="huggingface/transformers - GitHub repository zh-CN documentation and information | English | 简体中文 | 繁體中文 | 한국어 | Español | 日本語 | हिन्दी | Русский | Рortuguês | తెలుగు | Français | Deutsch | Tiếng Việt | العربية | اردو | 最先进的预训练模型，适用于推理和训练 Tran...">
    <meta name="keywords" content="huggingface, transformers, GitHub, repository, zh-CN documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/huggingface/transformers/README-zh-CN.html">
    <meta property="og:title" content="transformers - huggingface/transformers zh-CN | English | 简体中文 | 繁體中文 | 한국어 | Español | 日本語 | हिन्दी | Русский | Рortuguês | తెలుగు | Français | Deutsch | Tiếng Việt | العربية | اردو | 最先进的预训练模型，适用于推理和训练 Tran...">
    <meta property="og:description" content="huggingface/transformers - GitHub repository zh-CN documentation and information | English | 简体中文 | 繁體中文 | 한국어 | Español | 日本語 | हिन्दी | Русский | Рortuguês | తెలుగు | Français | Deutsch | Tiếng Việt | العربية | اردو | 最先进的预训练模型，适用于推理和训练 Tran...">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div style="position: fixed; top: 2px; left: 2px; z-index: 2000; background: rgba(255,255,255,0.95); border-radius: 6px; box-shadow: 0 2px 8px rgba(0,0,0,0.06); padding: 4px 14px; font-size: 15px; color: #222; font-family: 'Segoe UI', Arial, sans-serif; font-weight: 500; letter-spacing: 0.5px;">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" style="color: #0366d6; text-decoration: none; font-weight: 600;">Open AI Tx</a>
    </div>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/huggingface/transformers" id="githubRepoLink" target="_blank">huggingface/transformers</a>
<h1 style="display: none;">English | 简体中文 | 繁體中文 | 한국어 | Español | 日本語 | हिन्दी | Русский | Рortuguês | తెలుగు | Français | Deutsch | Tiếng Việt | العربية | اردو | 最先进的预训练模型，适用于推理和训练 Tran...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <!---
Copyright 2020 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
<p align="center">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-dark.svg">
    <source media="(prefers-color-scheme: light)" srcset="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-light.svg">
    <img alt="Hugging Face Transformers Library" src="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-light.svg" width="352" height="59" style="max-width: 100%;">
  </picture>
  <br/>
  <br/>
</p>
<p align="center">
    <a href="https://huggingface.com/models"><img alt="Checkpoints on Hub" src="https://img.shields.io/endpoint?url=https://huggingface.co/api/shields/models&color=brightgreen"></a>
    <a href="https://circleci.com/gh/huggingface/transformers"><img alt="Build" src="https://img.shields.io/circleci/build/github/huggingface/transformers/main"></a>
    <a href="https://github.com/huggingface/transformers/blob/main/LICENSE"><img alt="GitHub" src="https://img.shields.io/github/license/huggingface/transformers.svg?color=blue"></a>
    <a href="https://huggingface.co/docs/transformers/index"><img alt="Documentation" src="https://img.shields.io/website/http/huggingface.co/docs/transformers/index.svg?down_color=red&down_message=offline&up_message=online"></a>
    <a href="https://github.com/huggingface/transformers/releases"><img alt="GitHub release" src="https://img.shields.io/github/release/huggingface/transformers.svg"></a>
    <a href="https://github.com/huggingface/transformers/blob/main/CODE_OF_CONDUCT.md"><img alt="Contributor Covenant" src="https://img.shields.io/badge/Contributor%20Covenant-v2.0%20adopted-ff69b4.svg"></a>
    <a href="https://zenodo.org/badge/latestdoi/155220641"><img src="https://zenodo.org/badge/155220641.svg" alt="DOI"></a>
</p>
<h4 align="center">
    <p>
        <b>English</b> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_zh-hans.md">简体中文</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_zh-hant.md">繁體中文</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ko.md">한국어</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_es.md">Español</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ja.md">日本語</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_hd.md">हिन्दी</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ru.md">Русский</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_pt-br.md">Рortuguês</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_te.md">తెలుగు</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_fr.md">Français</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_de.md">Deutsch</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_vi.md">Tiếng Việt</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ar.md">العربية</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ur.md">اردو</a> |
    </p>
</h4>
<h3 align="center">
    <p>最先进的预训练模型，适用于推理和训练</p>
</h3>
<h3 align="center">
    <a href="https://hf.co/course"><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/course_banner.png"></a>
</h3>
<p>Transformers 是一个包含预训练文本、计算机视觉、音频、视频及多模态模型的库，可用于推理和训练。使用 Transformers 可以在你的数据上微调模型，构建推理应用，并支持多模态生成式 AI 应用场景。</p>
<p>在 <a href="https://huggingface.com/models">Hugging Face Hub</a> 上有超过 50 万个 Transformers <a href="https://huggingface.co/models?library=transformers&amp;sort=trending">模型检查点</a> 可供使用。</p>
<p>立即探索 <a href="https://huggingface.com/">Hub</a>，查找合适的模型，用 Transformers 帮助你立刻开始。</p>
<h2>安装</h2>
<p>Transformers 支持 Python 3.9+，<a href="https://pytorch.org/get-started/locally/">PyTorch</a> 2.1+，<a href="https://www.tensorflow.org/install/pip">TensorFlow</a> 2.6+，以及 <a href="https://flax.readthedocs.io/en/latest/">Flax</a> 0.4.1+。</p>
<p>推荐使用 <a href="https://docs.python.org/3/library/venv.html">venv</a> 或 <a href="https://docs.astral.sh/uv/">uv</a>，即基于 Rust 的快速 Python 包和项目管理器，创建并激活虚拟环境。</p>
<pre><code class="language-py"># venv
python -m venv .my-env
source .my-env/bin/activate
# uv
uv venv .my-env
source .my-env/bin/activate
</code></pre>
<p>在你的虚拟环境中安装 Transformers。</p>
<pre><code class="language-py"># pip
pip install &quot;transformers[torch]&quot;

# uv
uv pip install &quot;transformers[torch]&quot;
</code></pre>
<p>如果你希望体验库中最新的更改或者有意参与贡献，可以从源码安装 Transformers。但<em>最新</em>版本可能不稳定。如果遇到错误，欢迎提交 <a href="https://github.com/huggingface/transformers/issues">issue</a>。</p>
<pre><code class="language-shell">git clone https://github.com/huggingface/transformers.git
cd transformers

# pip
pip install .[torch]

# uv
uv pip install .[torch]
</code></pre>
<h2>快速开始</h2>
<p>通过 <a href="https://huggingface.co/docs/transformers/pipeline_tutorial">Pipeline</a> API 立即开始使用 Transformers。<code>Pipeline</code> 是一个高级推理类，支持文本、音频、视觉和多模态任务。它自动处理输入的预处理并返回相应的输出。</p>
<p>实例化一个 pipeline，并指定用于文本生成的模型。模型会被下载并缓存，方便你后续重复使用。最后，传入一些文本以提示模型。</p>
<pre><code class="language-py">from transformers import pipeline

pipeline = pipeline(task=&quot;text-generation&quot;, model=&quot;Qwen/Qwen2.5-1.5B&quot;)
pipeline(&quot;the secret to baking a really good cake is &quot;)
[{'generated_text': 'the secret to baking a really good cake is 1) to use the right ingredients and 2) to follow the recipe exactly. the recipe for the cake is as follows: 1 cup of sugar, 1 cup of flour, 1 cup of milk, 1 cup of butter, 1 cup of eggs, 1 cup of chocolate chips. if you want to make 2 cakes, how much sugar do you need? To make 2 cakes, you will need 2 cups of sugar.'}]
</code></pre>
<p>与模型进行对话的用法也是一样的。唯一的区别是你需要构建一段对话历史（即 <code>Pipeline</code> 的输入），包括你和系统之间的对话。</p>
<blockquote>
<p>[!TIP]
你也可以直接从命令行与模型对话。</p>
<pre><code class="language-shell">transformers chat Qwen/Qwen2.5-0.5B-Instruct
</code></pre>
</blockquote>
<pre><code class="language-py">import torch
from transformers import pipeline

chat = [
    {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;你是一个好斗、机智、爱吐槽的机器人，风格如 1986 年好莱坞电影中的形象。&quot;},
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;嘿，你能告诉我在纽约有什么有趣的事情可以做吗？&quot;}
]

pipeline = pipeline(task=&quot;text-generation&quot;, model=&quot;meta-llama/Meta-Llama-3-8B-Instruct&quot;, torch_dtype=torch.bfloat16, device_map=&quot;auto&quot;)
response = pipeline(chat, max_new_tokens=512)
print(response[0][&quot;generated_text&quot;][-1][&quot;content&quot;])
</code></pre>
<p>展开下方示例，了解 <code>Pipeline</code> 在不同模态和任务下的使用方式。</p>
<details>
<summary>自动语音识别</summary>
<pre><code class="language-py">from transformers import pipeline

pipeline = pipeline(task=&quot;automatic-speech-recognition&quot;, model=&quot;openai/whisper-large-v3&quot;)
pipeline(&quot;https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac&quot;)
{'text': ' I have a dream that one day this nation will rise up and live out the true meaning of its creed.'}
</code></pre>
</details>
<details>
<summary>图像分类</summary>
<h3 align="center">
    <a><img src="https://huggingface.co/datasets/Narsil/image_dummy/raw/main/parrots.png"></a>
</h3>
<pre><code class="language-py">from transformers import pipeline

pipeline = pipeline(task=&quot;image-classification&quot;, model=&quot;facebook/dinov2-small-imagenet1k-1-layer&quot;)
pipeline(&quot;https://huggingface.co/datasets/Narsil/image_dummy/raw/main/parrots.png&quot;)
[{'label': 'macaw', 'score': 0.997848391532898},
 {'label': 'sulphur-crested cockatoo, Kakatoe galerita, Cacatua galerita',
  'score': 0.0016551691805943847},
 {'label': 'lorikeet', 'score': 0.00018523589824326336},
 {'label': 'African grey, African gray, Psittacus erithacus',
  'score': 7.85409429227002e-05},
 {'label': 'quail', 'score': 5.502637941390276e-05}]
</code></pre>
</details>
<details>
<summary>视觉问答</summary>
<h3 align="center">
    <a><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/idefics-few-shot.jpg"></a>
</h3>
<pre><code class="language-py">from transformers import pipeline

pipeline = pipeline(task=&quot;visual-question-answering&quot;, model=&quot;Salesforce/blip-vqa-base&quot;)
pipeline(
    image=&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/idefics-few-shot.jpg&quot;,
    question=&quot;图片里是什么？&quot;,
)
[{'answer': 'statue of liberty'}]
</code></pre>
</details>
<h2>为什么要使用 Transformers？</h2>
<ol>
<li><p>易于使用的最先进模型：</p>
<ul>
<li>在自然语言理解与生成、计算机视觉、音频、视频和多模态任务上表现优异。</li>
<li>研究人员、工程师和开发者易于上手。</li>
<li>仅需学习三个用户相关的抽象类。</li>
<li>提供统一的 API 使用所有预训练模型。</li>
</ul>
</li>
<li><p>降低计算成本，减少碳足迹：</p>
<ul>
<li>共享训练好的模型，无需从零开始训练。</li>
<li>减少计算时间和生产成本。</li>
<li>数十种模型架构，跨所有模态有超过 100 万个预训练检查点。</li>
</ul>
</li>
<li><p>为模型生命周期的每一步选择合适的框架：</p>
<ul>
<li>用三行代码训练最先进的模型。</li>
<li>可随意在 PyTorch/JAX/TF2.0 框架之间迁移同一个模型。</li>
<li>针对训练、评估和生产选择合适的框架。</li>
</ul>
</li>
<li><p>轻松定制模型或示例以满足你的需求：</p>
<ul>
<li>我们为每个架构提供示例，帮助你复现原作者发布的结果。</li>
<li>尽可能保持模型内部结构一致性开放。</li>
<li>模型文件可独立于库使用，便于快速实验。</li>
</ul>
</li>
</ol>
<a target="_blank" href="https://huggingface.co/enterprise">
    <img alt="Hugging Face Enterprise Hub" src="https://github.com/user-attachments/assets/247fb16d-d251-4583-96c4-d3d76dda4925">
</a><br>
<h2>为什么不应该使用 Transformers？</h2>
<ul>
<li>本库不是神经网络的模块化构建工具箱。模型文件中的代码故意未引入额外抽象，便于研究人员直接迭代每个模型，无需深入额外抽象/文件。</li>
<li>训练 API 针对 Transformers 提供的 PyTorch 模型进行了优化。如需通用的机器学习循环，建议使用 <a href="https://huggingface.co/docs/accelerate">Accelerate</a> 等其他库。</li>
<li><a href="(https://github.com/huggingface/transformers/tree/main/examples)">示例脚本</a> 仅为<em>示例</em>。它们未必能直接应用于你的具体场景，你需要自行调整代码以适配。</li>
</ul>
<h2>100 个基于 Transformers 的项目</h2>
<p>Transformers 不仅仅是一个预训练模型工具包，更是一个围绕 Hugging Face Hub 构建的社区。我们希望 Transformers 能帮助开发者、研究员、学生、教授、工程师及所有人实现他们的理想项目。</p>
<p>为庆祝 Transformers 获得 10 万星，我们特别推出了 <a href="./awesome-transformers.md">awesome-transformers</a> 页面，列出了 100 个用 Transformers 构建的杰出项目。</p>
<p>如果你拥有或使用的项目认为值得上榜，请提交 PR 添加它！</p>
<h2>示例模型</h2>
<p>你可以直接在 <a href="https://huggingface.co/models">Hub 模型页面</a> 测试我们的大多数模型。</p>
<p>展开下方每个模态，查看不同应用场景下的部分示例模型。</p>
<details>
<summary>音频</summary>
<ul>
<li>使用 <a href="https://huggingface.co/openai/whisper-large-v3-turbo">Whisper</a> 进行音频分类</li>
<li>使用 <a href="https://huggingface.co/UsefulSensors/moonshine">Moonshine</a> 进行自动语音识别</li>
<li>使用 <a href="https://huggingface.co/superb/wav2vec2-base-superb-ks">Wav2Vec2</a> 进行关键词检测</li>
<li>使用 <a href="https://huggingface.co/kyutai/moshiko-pytorch-bf16">Moshi</a> 进行语音到语音生成</li>
<li>使用 <a href="https://huggingface.co/facebook/musicgen-large">MusicGen</a> 文本生成音频</li>
<li>使用 <a href="https://huggingface.co/suno/bark">Bark</a> 文本转语音</li>
</ul>
</details>
<details>
<summary>计算机视觉</summary>
<ul>
<li>使用 <a href="https://huggingface.co/facebook/sam-vit-base">SAM</a> 自动生成掩码</li>
<li>使用 <a href="https://huggingface.co/apple/DepthPro-hf">DepthPro</a> 进行深度估计</li>
<li>使用 <a href="https://huggingface.co/facebook/dinov2-base">DINO v2</a> 进行图像分类</li>
<li>使用 <a href="https://huggingface.co/magic-leap-community/superglue_outdoor">SuperGlue</a> 关键点检测</li>
<li>使用 <a href="https://huggingface.co/magic-leap-community/superglue">SuperGlue</a> 关键点匹配</li>
<li>使用 <a href="https://huggingface.co/PekingU/rtdetr_v2_r50vd">RT-DETRv2</a> 目标检测</li>
<li>使用 <a href="https://huggingface.co/usyd-community/vitpose-base-simple">VitPose</a> 姿态估计</li>
<li>使用 <a href="https://huggingface.co/shi-labs/oneformer_ade20k_swin_large">OneFormer</a> 通用分割</li>
<li>使用 <a href="https://huggingface.co/MCG-NJU/videomae-large">VideoMAE</a> 视频分类</li>
</ul>
</details>
<details>
<summary>多模态</summary>
<ul>
<li>使用 <a href="https://huggingface.co/Qwen/Qwen2-Audio-7B">Qwen2-Audio</a> 音频或文本转文本</li>
<li>使用 <a href="https://huggingface.co/microsoft/layoutlmv3-base">LayoutLMv3</a> 文档问答</li>
<li>使用 <a href="https://huggingface.co/Qwen/Qwen2.5-VL-3B-Instruct">Qwen-VL</a> 图像或文本转文本</li>
<li>使用 <a href="https://huggingface.co/Salesforce/blip2-opt-2.7b">BLIP-2</a> 图像描述生成</li>
<li>使用 <a href="https://huggingface.co/stepfun-ai/GOT-OCR-2.0-hf">GOT-OCR2</a> 基于 OCR 的文档理解</li>
<li>使用 <a href="https://huggingface.co/google/tapas-base">TAPAS</a> 表格问答</li>
<li>使用 <a href="https://huggingface.co/BAAI/Emu3-Gen">Emu3</a> 统一多模态理解与生成</li>
<li>使用 <a href="https://huggingface.co/llava-hf/llava-onevision-qwen2-0.5b-ov-hf">Llava-OneVision</a> 视觉转文本</li>
<li>使用 <a href="https://huggingface.co/llava-hf/llava-1.5-7b-hf">Llava</a> 视觉问答</li>
<li>使用 <a href="https://huggingface.co/microsoft/kosmos-2-patch14-224">Kosmos-2</a> 视觉指表达分割</li>
</ul>
</details>
<details>
<summary>NLP</summary>
<ul>
<li>使用 <a href="https://huggingface.co/answerdotai/ModernBERT-base">ModernBERT</a> 掩码词填充</li>
<li>使用 <a href="https://huggingface.co/google/gemma-2-2b">Gemma</a> 命名实体识别</li>
<li>使用 <a href="https://huggingface.co/mistralai/Mixtral-8x7B-v0.1">Mixtral</a> 问答</li>
<li>使用 <a href="https://huggingface.co/facebook/bart-large-cnn">BART</a> 摘要生成</li>
<li>使用 <a href="https://huggingface.co/google-t5/t5-base">T5</a> 翻译</li>
<li>使用 <a href="https://huggingface.co/meta-llama/Llama-3.2-1B">Llama</a> 文本生成</li>
<li>使用 <a href="https://huggingface.co/Qwen/Qwen2.5-0.5B">Qwen</a> 文本分类</li>
</ul>
</details>
<h2>引用</h2>
<p>我们现在有一篇可用于引用 🤗 Transformers 库的 <a href="https://www.aclweb.org/anthology/2020.emnlp-demos.6/">论文</a>：</p>
<pre><code class="language-bibtex">@inproceedings{wolf-etal-2020-transformers,
    title = &quot;Transformers: State-of-the-Art Natural Language Processing&quot;,
    author = &quot;Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush&quot;,
    booktitle = &quot;Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations&quot;,
    month = oct,
    year = &quot;2020&quot;,
    address = &quot;Online&quot;,
    publisher = &quot;Association for Computational Linguistics&quot;,
    url = &quot;https://www.aclweb.org/anthology/2020.emnlp-demos.6&quot;,
    pages = &quot;38--45&quot;
}
</code></pre>
<hr />
<p><a href="https://github.com/OpenAiTx/OpenAiTx">Powered By OpenAiTx</a></p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
</body>
</html>