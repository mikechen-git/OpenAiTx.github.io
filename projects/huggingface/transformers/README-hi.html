<!DOCTYPE html>
<html lang="hi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>transformers - huggingface/transformers</title>
    <meta name="title" content="transformers - huggingface/transformers">
    <meta name="description" content="huggingface/transformers - GitHub repository hi documentation and informationEnglish | 简体中文 | 繁體中文 | 한국어 | Español | 日本語 | हिन्दी | Русский | Рortuguês | తెలుగు | Français | Deutsch | Tiếng Việt | العربية | اردو | इन्फरेंस और ट्रेनिंग के...">
    <meta name="keywords" content="huggingface, transformers, GitHub, repository, hi documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/huggingface/transformers/README-hi.html">
    <meta property="og:title" content="transformers - huggingface/transformers">
    <meta property="og:description" content="huggingface/transformers - GitHub repository hi documentation and information">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/huggingface/transformers" id="githubRepoLink" target="_blank">huggingface/transformers</a>
<h1 style="display: none;">English | 简体中文 | 繁體中文 | 한국어 | Español | 日本語 | हिन्दी | Русский | Рortuguês | తెలుగు | Français | Deutsch | Tiếng Việt | العربية | اردو | इन्फरेंस और ट्रेनिंग के...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <!---
Copyright 2020 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
<p align="center">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-dark.svg">
    <source media="(prefers-color-scheme: light)" srcset="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-light.svg">
    <img alt="Hugging Face Transformers Library" src="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-light.svg" width="352" height="59" style="max-width: 100%;">
  </picture>
  <br/>
  <br/>
</p>
<p align="center">
    <a href="https://huggingface.com/models"><img alt="Checkpoints on Hub" src="https://img.shields.io/endpoint?url=https://huggingface.co/api/shields/models&color=brightgreen"></a>
    <a href="https://circleci.com/gh/huggingface/transformers"><img alt="Build" src="https://img.shields.io/circleci/build/github/huggingface/transformers/main"></a>
    <a href="https://github.com/huggingface/transformers/blob/main/LICENSE"><img alt="GitHub" src="https://img.shields.io/github/license/huggingface/transformers.svg?color=blue"></a>
    <a href="https://huggingface.co/docs/transformers/index"><img alt="Documentation" src="https://img.shields.io/website/http/huggingface.co/docs/transformers/index.svg?down_color=red&down_message=offline&up_message=online"></a>
    <a href="https://github.com/huggingface/transformers/releases"><img alt="GitHub release" src="https://img.shields.io/github/release/huggingface/transformers.svg"></a>
    <a href="https://github.com/huggingface/transformers/blob/main/CODE_OF_CONDUCT.md"><img alt="Contributor Covenant" src="https://img.shields.io/badge/Contributor%20Covenant-v2.0%20adopted-ff69b4.svg"></a>
    <a href="https://zenodo.org/badge/latestdoi/155220641"><img src="https://zenodo.org/badge/155220641.svg" alt="DOI"></a>
</p>
<h4 align="center">
    <p>
        <b>English</b> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_zh-hans.md">简体中文</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_zh-hant.md">繁體中文</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ko.md">한국어</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_es.md">Español</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ja.md">日本語</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_hd.md">हिन्दी</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ru.md">Русский</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_pt-br.md">Рortuguês</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_te.md">తెలుగు</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_fr.md">Français</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_de.md">Deutsch</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_vi.md">Tiếng Việt</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ar.md">العربية</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ur.md">اردو</a> |
    </p>
</h4>
<h3 align="center">
    <p>इन्फरेंस और ट्रेनिंग के लिए अत्याधुनिक प्रीट्रेंड मॉडल</p>
</h3>
<h3 align="center">
    <a href="https://hf.co/course"><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/course_banner.png"></a>
</h3>
<p>Transformers एक प्रीट्रेंड टेक्स्ट, कंप्यूटर विज़न, ऑडियो, वीडियो, और मल्टीमोडल मॉडल्स की लाइब्रेरी है, जिसका उपयोग इन्फरेंस और ट्रेनिंग के लिए किया जाता है। Transformers का उपयोग अपने डेटा पर मॉडल्स को फाइन-ट्यून करने, इन्फरेंस एप्लिकेशन बनाने, और मल्टीपल मोडैलिटी में जनरेटिव एआई उपयोग मामलों के लिए करें।</p>
<p><a href="https://huggingface.com/models">Hugging Face Hub</a> पर 500K+ से अधिक Transformers <a href="https://huggingface.co/models?library=transformers&amp;sort=trending">मॉडल चेकपॉइंट्स</a> उपलब्ध हैं, जिनका आप उपयोग कर सकते हैं।</p>
<p>आज ही <a href="https://huggingface.com/">Hub</a> को एक्सप्लोर करें, कोई मॉडल खोजें और Transformers का उपयोग करके तुरंत शुरुआत करें।</p>
<h2>इंस्टॉलेशन</h2>
<p>Transformers, Python 3.9+ <a href="https://pytorch.org/get-started/locally/">PyTorch</a> 2.1+, <a href="https://www.tensorflow.org/install/pip">TensorFlow</a> 2.6+, और <a href="https://flax.readthedocs.io/en/latest/">Flax</a> 0.4.1+ के साथ काम करता है।</p>
<p><a href="https://docs.python.org/3/library/venv.html">venv</a> या <a href="https://docs.astral.sh/uv/">uv</a> (एक तेज़ Rust-आधारित Python पैकेज और प्रोजेक्ट मैनेजर) से एक वर्चुअल एनवायरनमेंट बनाएँ और सक्रिय करें।</p>
<pre><code class="language-py"># venv
python -m venv .my-env
source .my-env/bin/activate
# uv
uv venv .my-env
source .my-env/bin/activate
</code></pre>
<p>अपने वर्चुअल एनवायरनमेंट में Transformers इंस्टॉल करें।</p>
<pre><code class="language-py"># pip
pip install &quot;transformers[torch]&quot;

# uv
uv pip install &quot;transformers[torch]&quot;
</code></pre>
<p>यदि आप लाइब्रेरी में नवीनतम बदलाव चाहते हैं या योगदान देने में रुचि रखते हैं तो स्रोत से Transformers इंस्टॉल करें। हालाँकि, <em>नवीनतम</em> संस्करण स्थिर नहीं हो सकता है। यदि आपको कोई त्रुटि मिलती है तो बेझिझक <a href="https://github.com/huggingface/transformers/issues">issue</a> खोलें।</p>
<pre><code class="language-shell">git clone https://github.com/huggingface/transformers.git
cd transformers

# pip
pip install .[torch]

# uv
uv pip install .[torch]
</code></pre>
<h2>क्विकस्टार्ट</h2>
<p><a href="https://huggingface.co/docs/transformers/pipeline_tutorial">Pipeline</a> API के साथ तुरंत Transformers का उपयोग शुरू करें। <code>Pipeline</code> एक उच्च स्तरीय इन्फरेंस क्लास है जो टेक्स्ट, ऑडियो, विज़न, और मल्टीमोडल टास्क्स को सपोर्ट करती है। यह इनपुट का प्रीप्रोसेसिंग संभालता है और उचित आउटपुट लौटाता है।</p>
<p>पाइपलाइन इंस्टैंसिएट करें और टेक्स्ट जनरेशन के लिए उपयोग होने वाला मॉडल स्पेसिफाई करें। मॉडल डाउनलोड और कैश हो जाता है ताकि आप इसे आसानी से फिर से उपयोग कर सकें। अंत में, मॉडल को प्रॉम्प्ट करने के लिए कुछ टेक्स्ट पास करें।</p>
<pre><code class="language-py">from transformers import pipeline

pipeline = pipeline(task=&quot;text-generation&quot;, model=&quot;Qwen/Qwen2.5-1.5B&quot;)
pipeline(&quot;the secret to baking a really good cake is &quot;)
[{'generated_text': 'the secret to baking a really good cake is 1) to use the right ingredients and 2) to follow the recipe exactly. the recipe for the cake is as follows: 1 cup of sugar, 1 cup of flour, 1 cup of milk, 1 cup of butter, 1 cup of eggs, 1 cup of chocolate chips. if you want to make 2 cakes, how much sugar do you need? To make 2 cakes, you will need 2 cups of sugar.'}]
</code></pre>
<p>किसी मॉडल के साथ चैट करने के लिए, उपयोग पैटर्न वही है। फर्क सिर्फ इतना है कि आपको अपने और सिस्टम के बीच एक चैट हिस्ट्री (जो <code>Pipeline</code> को इनपुट दी जाती है) बनानी होगी।</p>
<blockquote>
<p>[!TIP]
आप कमांड लाइन से भी सीधे किसी मॉडल के साथ चैट कर सकते हैं।</p>
<pre><code class="language-shell">transformers chat Qwen/Qwen2.5-0.5B-Instruct
</code></pre>
</blockquote>
<pre><code class="language-py">import torch
from transformers import pipeline

chat = [
    {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are a sassy, wise-cracking robot as imagined by Hollywood circa 1986.&quot;},
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hey, can you tell me any fun things to do in New York?&quot;}
]

pipeline = pipeline(task=&quot;text-generation&quot;, model=&quot;meta-llama/Meta-Llama-3-8B-Instruct&quot;, torch_dtype=torch.bfloat16, device_map=&quot;auto&quot;)
response = pipeline(chat, max_new_tokens=512)
print(response[0][&quot;generated_text&quot;][-1][&quot;content&quot;])
</code></pre>
<p>नीचे दिए गए उदाहरणों का विस्तार करें यह देखने के लिए कि <code>Pipeline</code> विभिन्न मोडैलिटी और कार्यों के लिए कैसे काम करता है।</p>
<details>
<summary>स्वचालित स्पीच रिकग्निशन</summary>
<pre><code class="language-py">from transformers import pipeline

pipeline = pipeline(task=&quot;automatic-speech-recognition&quot;, model=&quot;openai/whisper-large-v3&quot;)
pipeline(&quot;https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac&quot;)
{'text': ' I have a dream that one day this nation will rise up and live out the true meaning of its creed.'}
</code></pre>
</details>
<details>
<summary>इमेज क्लासिफिकेशन</summary>
<h3 align="center">
    <a><img src="https://huggingface.co/datasets/Narsil/image_dummy/raw/main/parrots.png"></a>
</h3>
<pre><code class="language-py">from transformers import pipeline

pipeline = pipeline(task=&quot;image-classification&quot;, model=&quot;facebook/dinov2-small-imagenet1k-1-layer&quot;)
pipeline(&quot;https://huggingface.co/datasets/Narsil/image_dummy/raw/main/parrots.png&quot;)
[{'label': 'macaw', 'score': 0.997848391532898},
 {'label': 'sulphur-crested cockatoo, Kakatoe galerita, Cacatua galerita',
  'score': 0.0016551691805943847},
 {'label': 'lorikeet', 'score': 0.00018523589824326336},
 {'label': 'African grey, African gray, Psittacus erithacus',
  'score': 7.85409429227002e-05},
 {'label': 'quail', 'score': 5.502637941390276e-05}]
</code></pre>
</details>
<details>
<summary>विज़ुअल क्वेश्चन आंसरिंग</summary>
<h3 align="center">
    <a><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/idefics-few-shot.jpg"></a>
</h3>
<pre><code class="language-py">from transformers import pipeline

pipeline = pipeline(task=&quot;visual-question-answering&quot;, model=&quot;Salesforce/blip-vqa-base&quot;)
pipeline(
    image=&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/idefics-few-shot.jpg&quot;,
    question=&quot;What is in the image?&quot;,
)
[{'answer': 'statue of liberty'}]
</code></pre>
</details>
<h2>मुझे Transformers का उपयोग क्यों करना चाहिए?</h2>
<ol>
<li><p>उपयोग में आसान अत्याधुनिक मॉडल्स:</p>
<ul>
<li>नेचुरल लैंग्वेज अंडरस्टैंडिंग और जनरेशन, कंप्यूटर विज़न, ऑडियो, वीडियो, और मल्टीमोडल टास्क्स में उच्च प्रदर्शन।</li>
<li>शोधकर्ताओं, इंजीनियरों और डेवलपर्स के लिए कम बाधाएं।</li>
<li>केवल तीन क्लासेस के साथ कम यूज़र-फेसिंग एब्स्ट्रैक्शन्स।</li>
<li>हमारे सभी प्रीट्रेंड मॉडल्स के लिए एकीकृत API।</li>
</ul>
</li>
<li><p>कम कंप्यूट लागत, छोटा कार्बन फुटप्रिंट:</p>
<ul>
<li>शुरुआत से ट्रेनिंग करने के बजाय ट्रेंड मॉडल्स साझा करें।</li>
<li>कंप्यूट समय और प्रोडक्शन लागत कम करें।</li>
<li>सभी मोडैलिटी में 1M+ प्रीट्रेंड चेकपॉइंट्स के साथ दर्जनों मॉडल आर्किटेक्चर।</li>
</ul>
</li>
<li><p>मॉडल के जीवनकाल के हर हिस्से के लिए सही फ्रेमवर्क चुनें:</p>
<ul>
<li>3 लाइनों के कोड में अत्याधुनिक मॉडल्स को ट्रेन करें।</li>
<li>एक ही मॉडल को PyTorch/JAX/TF2.0 फ्रेमवर्क्स के बीच इच्छानुसार मूव करें।</li>
<li>ट्रेनिंग, मूल्यांकन और उत्पादन के लिए सही फ्रेमवर्क चुनें।</li>
</ul>
</li>
<li><p>आसानी से किसी मॉडल या उदाहरण को अपनी आवश्यकता के अनुसार अनुकूलित करें:</p>
<ul>
<li>हम प्रत्येक आर्किटेक्चर के लिए ऐसे उदाहरण प्रदान करते हैं, जिससे आप मूल लेखकों द्वारा प्रकाशित परिणामों को पुन: उत्पन्न कर सकें।</li>
<li>मॉडल इंटरनल्स को यथासंभव सुसंगत रूप से एक्सपोज़ किया गया है।</li>
<li>त्वरित प्रयोगों के लिए मॉडल फाइल्स को लाइब्रेरी से स्वतंत्र रूप से उपयोग किया जा सकता है।</li>
</ul>
</li>
</ol>
<a target="_blank" href="https://huggingface.co/enterprise">
    <img alt="Hugging Face Enterprise Hub" src="https://github.com/user-attachments/assets/247fb16d-d251-4583-96c4-d3d76dda4925">
</a><br>
<h2>मुझे Transformers का उपयोग क्यों नहीं करना चाहिए?</h2>
<ul>
<li>यह लाइब्रेरी न्यूरल नेट्स के लिए बिल्डिंग ब्लॉक्स का एक मॉड्यूलर टूलबॉक्स नहीं है। मॉडल फाइल्स में कोड को जानबूझकर अतिरिक्त एब्स्ट्रैक्शन्स के साथ रिफैक्टर नहीं किया गया है, ताकि शोधकर्ता प्रत्येक मॉडल पर जल्दी से काम कर सकें।</li>
<li>ट्रेनिंग API को विशेष रूप से Transformers द्वारा प्रदान किए गए PyTorch मॉडल्स के साथ काम करने के लिए ऑप्टिमाइज़ किया गया है। सामान्य मशीन लर्निंग लूप्स के लिए, आपको <a href="https://huggingface.co/docs/accelerate">Accelerate</a> जैसी अन्य लाइब्रेरी का उपयोग करना चाहिए।</li>
<li><a href="(https://github.com/huggingface/transformers/tree/main/examples)">उदाहरण स्क्रिप्ट्स</a> केवल <em>उदाहरण</em> हैं। वे जरूरी नहीं कि आपके विशिष्ट उपयोग मामले पर तुरंत काम करें, और आपको इसे काम करने के लिए कोड को अनुकूलित करना होगा।</li>
</ul>
<h2>Transformers का उपयोग करने वाले 100 प्रोजेक्ट्स</h2>
<p>Transformers केवल प्रीट्रेंड मॉडल्स का टूलकिट नहीं है, बल्कि यह इसके चारों ओर बने प्रोजेक्ट्स और Hugging Face Hub की एक कम्युनिटी है। हम चाहते हैं कि Transformers डेवलपर्स, शोधकर्ताओं, छात्रों, प्रोफेसरों, इंजीनियरों और अन्य सभी को उनके ड्रीम प्रोजेक्ट्स बनाने में सक्षम बनाए।</p>
<p>Transformers के 100,000 स्टार्स सेलिब्रेट करने के लिए, हम कम्युनिटी के <a href="./awesome-transformers.md">awesome-transformers</a> पेज पर बने 100 अद्भुत प्रोजेक्ट्स को उजागर करना चाहते हैं।</p>
<p>यदि आप किसी ऐसे प्रोजेक्ट के मालिक हैं या उपयोग करते हैं, जिसे आपको लगता है कि इस सूची का हिस्सा होना चाहिए, तो कृपया इसे जोड़ने के लिए PR खोलें!</p>
<h2>उदाहरण मॉडल्स</h2>
<p>आप हमारे अधिकांश मॉडल्स को सीधे उनके <a href="https://huggingface.co/models">Hub मॉडल पेजेज़</a> पर टेस्ट कर सकते हैं।</p>
<p>नीचे प्रत्येक मोडैलिटी का विस्तार करें और विभिन्न उपयोग मामलों के लिए कुछ उदाहरण मॉडल्स देखें।</p>
<details>
<summary>ऑडियो</summary>
<ul>
<li><a href="https://huggingface.co/openai/whisper-large-v3-turbo">Whisper</a> के साथ ऑडियो क्लासिफिकेशन</li>
<li><a href="https://huggingface.co/UsefulSensors/moonshine">Moonshine</a> के साथ स्वचालित स्पीच रिकग्निशन</li>
<li><a href="https://huggingface.co/superb/wav2vec2-base-superb-ks">Wav2Vec2</a> के साथ कीवर्ड स्पॉटिंग</li>
<li><a href="https://huggingface.co/kyutai/moshiko-pytorch-bf16">Moshi</a> के साथ स्पीच टू स्पीच जनरेशन</li>
<li><a href="https://huggingface.co/facebook/musicgen-large">MusicGen</a> के साथ टेक्स्ट टू ऑडियो</li>
<li><a href="https://huggingface.co/suno/bark">Bark</a> के साथ टेक्स्ट टू स्पीच</li>
</ul>
</details>
<details>
<summary>कंप्यूटर विज़न</summary>
<ul>
<li><a href="https://huggingface.co/facebook/sam-vit-base">SAM</a> के साथ स्वचालित मास्क जनरेशन</li>
<li><a href="https://huggingface.co/apple/DepthPro-hf">DepthPro</a> के साथ डेप्थ एस्टीमेशन</li>
<li><a href="https://huggingface.co/facebook/dinov2-base">DINO v2</a> के साथ इमेज क्लासिफिकेशन</li>
<li><a href="https://huggingface.co/magic-leap-community/superglue_outdoor">SuperGlue</a> के साथ कीपॉइंट डिटेक्शन</li>
<li><a href="https://huggingface.co/magic-leap-community/superglue">SuperGlue</a> के साथ कीपॉइंट मैचिंग</li>
<li><a href="https://huggingface.co/PekingU/rtdetr_v2_r50vd">RT-DETRv2</a> के साथ ऑब्जेक्ट डिटेक्शन</li>
<li><a href="https://huggingface.co/usyd-community/vitpose-base-simple">VitPose</a> के साथ पोज़ एस्टीमेशन</li>
<li><a href="https://huggingface.co/shi-labs/oneformer_ade20k_swin_large">OneFormer</a> के साथ यूनिवर्सल सेगमेंटेशन</li>
<li><a href="https://huggingface.co/MCG-NJU/videomae-large">VideoMAE</a> के साथ वीडियो क्लासिफिकेशन</li>
</ul>
</details>
<details>
<summary>मल्टीमोडल</summary>
<ul>
<li><a href="https://huggingface.co/Qwen/Qwen2-Audio-7B">Qwen2-Audio</a> के साथ ऑडियो या टेक्स्ट टू टेक्स्ट</li>
<li><a href="https://huggingface.co/microsoft/layoutlmv3-base">LayoutLMv3</a> के साथ डॉक्युमेंट क्वेश्चन आंसरिंग</li>
<li><a href="https://huggingface.co/Qwen/Qwen2.5-VL-3B-Instruct">Qwen-VL</a> के साथ इमेज या टेक्स्ट टू टेक्स्ट</li>
<li><a href="https://huggingface.co/Salesforce/blip2-opt-2.7b">BLIP-2</a> के साथ इमेज कैप्शनिंग</li>
<li><a href="https://huggingface.co/stepfun-ai/GOT-OCR-2.0-hf">GOT-OCR2</a> के साथ OCR-आधारित डॉक्युमेंट समझ</li>
<li><a href="https://huggingface.co/google/tapas-base">TAPAS</a> के साथ टेबल क्वेश्चन आंसरिंग</li>
<li><a href="https://huggingface.co/BAAI/Emu3-Gen">Emu3</a> के साथ एकीकृत मल्टीमोडल समझ और जनरेशन</li>
<li><a href="https://huggingface.co/llava-hf/llava-onevision-qwen2-0.5b-ov-hf">Llava-OneVision</a> के साथ विज़न टू टेक्स्ट</li>
<li><a href="https://huggingface.co/llava-hf/llava-1.5-7b-hf">Llava</a> के साथ विज़ुअल क्वेश्चन आंसरिंग</li>
<li><a href="https://huggingface.co/microsoft/kosmos-2-patch14-224">Kosmos-2</a> के साथ विज़ुअल रेफरिंग एक्सप्रेशन सेगमेंटेशन</li>
</ul>
</details>
<details>
<summary>NLP</summary>
<ul>
<li><a href="https://huggingface.co/answerdotai/ModernBERT-base">ModernBERT</a> के साथ मास्क्ड वर्ड कंप्लीशन</li>
<li><a href="https://huggingface.co/google/gemma-2-2b">Gemma</a> के साथ नामित इकाई पहचान</li>
<li><a href="https://huggingface.co/mistralai/Mixtral-8x7B-v0.1">Mixtral</a> के साथ क्वेश्चन आंसरिंग</li>
<li><a href="https://huggingface.co/facebook/bart-large-cnn">BART</a> के साथ समरीकरण</li>
<li><a href="https://huggingface.co/google-t5/t5-base">T5</a> के साथ अनुवाद</li>
<li><a href="https://huggingface.co/meta-llama/Llama-3.2-1B">Llama</a> के साथ टेक्स्ट जनरेशन</li>
<li><a href="https://huggingface.co/Qwen/Qwen2.5-0.5B">Qwen</a> के साथ टेक्स्ट क्लासिफिकेशन</li>
</ul>
</details>
<h2>संदर्भ</h2>
<p>अब हमारे पास 🤗 Transformers लाइब्रेरी के लिए एक <a href="https://www.aclweb.org/anthology/2020.emnlp-demos.6/">पेपर</a> है, जिसे आप संदर्भित कर सकते हैं:</p>
<pre><code class="language-bibtex">@inproceedings{wolf-etal-2020-transformers,
    title = &quot;Transformers: State-of-the-Art Natural Language Processing&quot;,
    author = &quot;Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush&quot;,
    booktitle = &quot;Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations&quot;,
    month = oct,
    year = &quot;2020&quot;,
    address = &quot;Online&quot;,
    publisher = &quot;Association for Computational Linguistics&quot;,
    url = &quot;https://www.aclweb.org/anthology/2020.emnlp-demos.6&quot;,
    pages = &quot;38--45&quot;
}
</code></pre>
<hr />
<p><a href="https://github.com/OpenAiTx/OpenAiTx">Powered By OpenAiTx</a></p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
</body>
</html>