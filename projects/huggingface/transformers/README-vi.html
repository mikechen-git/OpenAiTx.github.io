<!DOCTYPE html>
<html lang="vi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>transformers - huggingface/transformers vi</title>
    <meta name="title" content="transformers - huggingface/transformers vi | English | 简体中文 | 繁體中文 | 한국어 | Español | 日本語 | हिन्दी | Русский | Рortuguês | తెలుగు | Français | Deutsch | Tiếng Việt | العربية | اردو | Mô hình pretrained tiên...">
    <meta name="description" content="huggingface/transformers - GitHub repository vi documentation and information | English | 简体中文 | 繁體中文 | 한국어 | Español | 日本語 | हिन्दी | Русский | Рortuguês | తెలుగు | Français | Deutsch | Tiếng Việt | العربية | اردو | Mô hình pretrained tiên...">
    <meta name="keywords" content="huggingface, transformers, GitHub, repository, vi documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/huggingface/transformers/README-vi.html">
    <meta property="og:title" content="transformers - huggingface/transformers vi | English | 简体中文 | 繁體中文 | 한국어 | Español | 日本語 | हिन्दी | Русский | Рortuguês | తెలుగు | Français | Deutsch | Tiếng Việt | العربية | اردو | Mô hình pretrained tiên...">
    <meta property="og:description" content="huggingface/transformers - GitHub repository vi documentation and information | English | 简体中文 | 繁體中文 | 한국어 | Español | 日本語 | हिन्दी | Русский | Рortuguês | తెలుగు | Français | Deutsch | Tiếng Việt | العربية | اردو | Mô hình pretrained tiên...">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/huggingface/transformers" id="githubRepoLink" target="_blank">huggingface/transformers</a>
<h1 style="display: none;">English | 简体中文 | 繁體中文 | 한국어 | Español | 日本語 | हिन्दी | Русский | Рortuguês | తెలుగు | Français | Deutsch | Tiếng Việt | العربية | اردو | Mô hình pretrained tiên...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <!---
Bản quyền 2020 Nhóm HuggingFace. Đã đăng ký mọi quyền.

Được cấp phép theo Giấy phép Apache, Phiên bản 2.0 ("Giấy phép");
bạn không được sử dụng tệp này ngoại trừ tuân thủ Giấy phép.
Bạn có thể lấy một bản sao của Giấy phép tại

    http://www.apache.org/licenses/LICENSE-2.0

Trừ khi luật pháp yêu cầu hoặc được đồng ý bằng văn bản, phần mềm
phân phối theo Giấy phép này được phân phối "NGUYÊN TRẠNG",
KHÔNG CÓ BẤT KỲ BẢO ĐẢM NÀO, cả rõ ràng lẫn ngụ ý.
Xem Giấy phép để biết các quy định về quyền hạn và
giới hạn theo Giấy phép.
-->
<p align="center">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-dark.svg">
    <source media="(prefers-color-scheme: light)" srcset="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-light.svg">
    <img alt="Thư viện Hugging Face Transformers" src="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-light.svg" width="352" height="59" style="max-width: 100%;">
  </picture>
  <br/>
  <br/>
</p>
<p align="center">
    <a href="https://huggingface.com/models"><img alt="Checkpoints trên Hub" src="https://img.shields.io/endpoint?url=https://huggingface.co/api/shields/models&color=brightgreen"></a>
    <a href="https://circleci.com/gh/huggingface/transformers"><img alt="Build" src="https://img.shields.io/circleci/build/github/huggingface/transformers/main"></a>
    <a href="https://github.com/huggingface/transformers/blob/main/LICENSE"><img alt="GitHub" src="https://img.shields.io/github/license/huggingface/transformers.svg?color=blue"></a>
    <a href="https://huggingface.co/docs/transformers/index"><img alt="Tài liệu" src="https://img.shields.io/website/http/huggingface.co/docs/transformers/index.svg?down_color=red&down_message=offline&up_message=online"></a>
    <a href="https://github.com/huggingface/transformers/releases"><img alt="Phát hành trên GitHub" src="https://img.shields.io/github/release/huggingface/transformers.svg"></a>
    <a href="https://github.com/huggingface/transformers/blob/main/CODE_OF_CONDUCT.md"><img alt="Contributor Covenant" src="https://img.shields.io/badge/Contributor%20Covenant-v2.0%20adopted-ff69b4.svg"></a>
    <a href="https://zenodo.org/badge/latestdoi/155220641"><img src="https://zenodo.org/badge/155220641.svg" alt="DOI"></a>
</p>
<h4 align="center">
    <p>
        <b>English</b> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_zh-hans.md">简体中文</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_zh-hant.md">繁體中文</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ko.md">한국어</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_es.md">Español</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ja.md">日本語</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_hd.md">हिन्दी</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ru.md">Русский</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_pt-br.md">Рortuguês</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_te.md">తెలుగు</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_fr.md">Français</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_de.md">Deutsch</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_vi.md">Tiếng Việt</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ar.md">العربية</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ur.md">اردو</a> |
    </p>
</h4>
<h3 align="center">
    <p>Mô hình pretrained tiên tiến nhất cho suy luận và huấn luyện</p>
</h3>
<h3 align="center">
    <a href="https://hf.co/course"><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/course_banner.png"></a>
</h3>
<p>Transformers là một thư viện các mô hình văn bản, thị giác máy tính, âm thanh, video và đa phương thức đã được huấn luyện sẵn cho mục đích suy luận và huấn luyện. Sử dụng Transformers để tinh chỉnh mô hình trên dữ liệu của bạn, xây dựng các ứng dụng suy luận và cho các trường hợp sử dụng AI tạo sinh trên nhiều phương thức khác nhau.</p>
<p>Có hơn 500.000+ <a href="https://huggingface.co/models?library=transformers&amp;sort=trending">checkpoint mô hình</a> Transformers trên <a href="https://huggingface.com/models">Hugging Face Hub</a> mà bạn có thể sử dụng.</p>
<p>Khám phá <a href="https://huggingface.com/">Hub</a> ngay hôm nay để tìm một mô hình và sử dụng Transformers để bắt đầu ngay lập tức.</p>
<h2>Cài đặt</h2>
<p>Transformers làm việc với Python 3.9+ <a href="https://pytorch.org/get-started/locally/">PyTorch</a> 2.1+, <a href="https://www.tensorflow.org/install/pip">TensorFlow</a> 2.6+, và <a href="https://flax.readthedocs.io/en/latest/">Flax</a> 0.4.1+.</p>
<p>Tạo và kích hoạt một môi trường ảo với <a href="https://docs.python.org/3/library/venv.html">venv</a> hoặc <a href="https://docs.astral.sh/uv/">uv</a>, một trình quản lý gói và dự án Python nhanh dựa trên Rust.</p>
<pre><code class="language-py"># venv
python -m venv .my-env
source .my-env/bin/activate
# uv
uv venv .my-env
source .my-env/bin/activate
</code></pre>
<p>Cài đặt Transformers trong môi trường ảo của bạn.</p>
<pre><code class="language-py"># pip
pip install &quot;transformers[torch]&quot;

# uv
uv pip install &quot;transformers[torch]&quot;
</code></pre>
<p>Cài đặt Transformers từ mã nguồn nếu bạn muốn cập nhật những thay đổi mới nhất của thư viện hoặc có ý định đóng góp phát triển. Tuy nhiên, phiên bản <em>mới nhất</em> có thể không ổn định. Hãy mở <a href="https://github.com/huggingface/transformers/issues">issue</a> nếu bạn gặp lỗi.</p>
<pre><code class="language-shell">git clone https://github.com/huggingface/transformers.git
cd transformers

# pip
pip install .[torch]

# uv
uv pip install .[torch]
</code></pre>
<h2>Khởi động nhanh</h2>
<p>Bắt đầu với Transformers ngay lập tức với API <a href="https://huggingface.co/docs/transformers/pipeline_tutorial">Pipeline</a>. <code>Pipeline</code> là một lớp suy luận cấp cao hỗ trợ các tác vụ văn bản, âm thanh, thị giác và đa phương thức. Nó xử lý tiền xử lý đầu vào và trả về đầu ra phù hợp.</p>
<p>Khởi tạo một pipeline và chỉ định mô hình sử dụng cho sinh văn bản. Mô hình sẽ được tải về và lưu vào bộ nhớ đệm để có thể sử dụng lại dễ dàng. Cuối cùng, truyền vào một đoạn văn bản để mô hình sinh kết quả.</p>
<pre><code class="language-py">from transformers import pipeline

pipeline = pipeline(task=&quot;text-generation&quot;, model=&quot;Qwen/Qwen2.5-1.5B&quot;)
pipeline(&quot;the secret to baking a really good cake is &quot;)
[{'generated_text': 'the secret to baking a really good cake is 1) to use the right ingredients and 2) to follow the recipe exactly. the recipe for the cake is as follows: 1 cup of sugar, 1 cup of flour, 1 cup of milk, 1 cup of butter, 1 cup of eggs, 1 cup of chocolate chips. if you want to make 2 cakes, how much sugar do you need? To make 2 cakes, you will need 2 cups of sugar.'}]
</code></pre>
<p>Để trò chuyện với một mô hình, cách sử dụng cũng tương tự. Sự khác biệt duy nhất là bạn cần xây dựng lịch sử hội thoại (đầu vào cho <code>Pipeline</code>) giữa bạn và hệ thống.</p>
<blockquote>
<p>[!TIP]
Bạn cũng có thể trò chuyện với mô hình trực tiếp từ dòng lệnh.</p>
<pre><code class="language-shell">transformers chat Qwen/Qwen2.5-0.5B-Instruct
</code></pre>
</blockquote>
<pre><code class="language-py">import torch
from transformers import pipeline

chat = [
    {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;Bạn là một robot hài hước, trả treo như tưởng tượng của Hollywood năm 1986.&quot;},
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Này, bạn có thể gợi ý vài điều thú vị để làm ở New York không?&quot;}
]

pipeline = pipeline(task=&quot;text-generation&quot;, model=&quot;meta-llama/Meta-Llama-3-8B-Instruct&quot;, torch_dtype=torch.bfloat16, device_map=&quot;auto&quot;)
response = pipeline(chat, max_new_tokens=512)
print(response[0][&quot;generated_text&quot;][-1][&quot;content&quot;])
</code></pre>
<p>Mở rộng các ví dụ bên dưới để xem <code>Pipeline</code> hoạt động với các phương thức và tác vụ khác nhau như thế nào.</p>
<details>
<summary>Nhận diện giọng nói tự động</summary>
<pre><code class="language-py">from transformers import pipeline

pipeline = pipeline(task=&quot;automatic-speech-recognition&quot;, model=&quot;openai/whisper-large-v3&quot;)
pipeline(&quot;https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac&quot;)
{'text': ' I have a dream that one day this nation will rise up and live out the true meaning of its creed.'}
</code></pre>
</details>
<details>
<summary>Phân loại hình ảnh</summary>
<h3 align="center">
    <a><img src="https://huggingface.co/datasets/Narsil/image_dummy/raw/main/parrots.png"></a>
</h3>
<pre><code class="language-py">from transformers import pipeline

pipeline = pipeline(task=&quot;image-classification&quot;, model=&quot;facebook/dinov2-small-imagenet1k-1-layer&quot;)
pipeline(&quot;https://huggingface.co/datasets/Narsil/image_dummy/raw/main/parrots.png&quot;)
[{'label': 'macaw', 'score': 0.997848391532898},
 {'label': 'sulphur-crested cockatoo, Kakatoe galerita, Cacatua galerita',
  'score': 0.0016551691805943847},
 {'label': 'lorikeet', 'score': 0.00018523589824326336},
 {'label': 'African grey, African gray, Psittacus erithacus',
  'score': 7.85409429227002e-05},
 {'label': 'quail', 'score': 5.502637941390276e-05}]
</code></pre>
</details>
<details>
<summary>Hỏi đáp hình ảnh</summary>
<h3 align="center">
    <a><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/idefics-few-shot.jpg"></a>
</h3>
<pre><code class="language-py">from transformers import pipeline

pipeline = pipeline(task=&quot;visual-question-answering&quot;, model=&quot;Salesforce/blip-vqa-base&quot;)
pipeline(
    image=&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/idefics-few-shot.jpg&quot;,
    question=&quot;What is in the image?&quot;,
)
[{'answer': 'statue of liberty'}]
</code></pre>
</details>
<h2>Tại sao nên sử dụng Transformers?</h2>
<ol>
<li><p>Mô hình tiên tiến dễ sử dụng:</p>
<ul>
<li>Hiệu năng cao đối với các tác vụ hiểu &amp; sinh ngôn ngữ tự nhiên, thị giác máy tính, âm thanh, video và đa phương thức.</li>
<li>Giảm rào cản cho các nhà nghiên cứu, kỹ sư và lập trình viên.</li>
<li>Chỉ cần học ba lớp trừu tượng hướng người dùng.</li>
<li>API thống nhất cho tất cả các mô hình đã huấn luyện sẵn.</li>
</ul>
</li>
<li><p>Giảm chi phí tính toán, giảm dấu chân carbon:</p>
<ul>
<li>Chia sẻ mô hình đã huấn luyện thay vì huấn luyện lại từ đầu.</li>
<li>Giảm thời gian tính toán và chi phí sản xuất.</li>
<li>Hàng chục kiến trúc mô hình với hơn 1 triệu checkpoint pretrained trên mọi phương thức.</li>
</ul>
</li>
<li><p>Tự do chọn framework phù hợp cho mọi giai đoạn vòng đời mô hình:</p>
<ul>
<li>Huấn luyện mô hình tiên tiến chỉ với 3 dòng lệnh.</li>
<li>Dễ dàng chuyển mô hình giữa PyTorch/JAX/TF2.0.</li>
<li>Chọn framework phù hợp cho huấn luyện, đánh giá và sản xuất.</li>
</ul>
</li>
<li><p>Dễ dàng tùy chỉnh mô hình hoặc ví dụ cho nhu cầu của bạn:</p>
<ul>
<li>Cung cấp ví dụ cho từng kiến trúc để tái tạo kết quả đã công bố.</li>
<li>Lõi mô hình được lộ ra một cách nhất quán.</li>
<li>File mô hình có thể dùng độc lập với thư viện để thử nghiệm nhanh.</li>
</ul>
</li>
</ol>
<a target="_blank" href="https://huggingface.co/enterprise">
    <img alt="Hugging Face Enterprise Hub" src="https://github.com/user-attachments/assets/247fb16d-d251-4583-96c4-d3d76dda4925">
</a><br>
<h2>Khi nào KHÔNG nên sử dụng Transformers?</h2>
<ul>
<li>Thư viện này không phải là một bộ công cụ mô-đun các khối xây dựng mạng nơ-ron. Mã nguồn trong file mô hình không được tái cấu trúc với các trừu tượng bổ sung, nhằm giúp các nhà nghiên cứu có thể thử nghiệm nhanh trên từng mô hình mà không cần đi sâu vào nhiều lớp trừu tượng/file khác.</li>
<li>API huấn luyện được tối ưu để làm việc với mô hình PyTorch mà Transformers cung cấp. Nếu cần vòng lặp máy học tổng quát, bạn nên dùng thư viện khác như <a href="https://huggingface.co/docs/accelerate">Accelerate</a>.</li>
<li><a href="https://github.com/huggingface/transformers/tree/main/examples">Các script ví dụ</a> chỉ là <em>ví dụ</em>. Chúng có thể không hoạt động ngay với trường hợp sử dụng của bạn và bạn cần điều chỉnh lại mã nguồn.</li>
</ul>
<h2>100 dự án sử dụng Transformers</h2>
<p>Transformers không chỉ là một bộ công cụ sử dụng mô hình pretrained, mà còn là một cộng đồng các dự án xây dựng xung quanh nó và
Hugging Face Hub. Chúng tôi muốn Transformers giúp các lập trình viên, nhà nghiên cứu, sinh viên, giảng viên, kỹ sư, và bất kỳ ai khác xây dựng dự án mơ ước của họ.</p>
<p>Để kỷ niệm Transformers đạt 100.000 stars, chúng tôi muốn tôn vinh cộng đồng với trang <a href="./awesome-transformers.md">awesome-transformers</a> liệt kê 100 dự án tuyệt vời xây dựng bằng Transformers.</p>
<p>Nếu bạn sở hữu hoặc sử dụng một dự án xứng đáng nằm trong danh sách này, hãy mở PR để bổ sung nhé!</p>
<h2>Một số mô hình ví dụ</h2>
<p>Bạn có thể thử hầu hết các mô hình trực tiếp trên <a href="https://huggingface.co/models">trang mô hình trên Hub</a>.</p>
<p>Mở rộng từng phương thức bên dưới để xem một số mô hình ví dụ cho các trường hợp sử dụng khác nhau.</p>
<details>
<summary>Âm thanh</summary>
<ul>
<li>Phân loại âm thanh với <a href="https://huggingface.co/openai/whisper-large-v3-turbo">Whisper</a></li>
<li>Nhận diện giọng nói tự động với <a href="https://huggingface.co/UsefulSensors/moonshine">Moonshine</a></li>
<li>Phát hiện từ khóa với <a href="https://huggingface.co/superb/wav2vec2-base-superb-ks">Wav2Vec2</a></li>
<li>Chuyển đổi lời nói sang lời nói với <a href="https://huggingface.co/kyutai/moshiko-pytorch-bf16">Moshi</a></li>
<li>Văn bản sang âm thanh với <a href="https://huggingface.co/facebook/musicgen-large">MusicGen</a></li>
<li>Văn bản sang giọng nói với <a href="https://huggingface.co/suno/bark">Bark</a></li>
</ul>
</details>
<details>
<summary>Thị giác máy tính</summary>
<ul>
<li>Sinh mặt nạ tự động với <a href="https://huggingface.co/facebook/sam-vit-base">SAM</a></li>
<li>Ước lượng độ sâu với <a href="https://huggingface.co/apple/DepthPro-hf">DepthPro</a></li>
<li>Phân loại hình ảnh với <a href="https://huggingface.co/facebook/dinov2-base">DINO v2</a></li>
<li>Phát hiện keypoint với <a href="https://huggingface.co/magic-leap-community/superglue_outdoor">SuperGlue</a></li>
<li>Ghép keypoint với <a href="https://huggingface.co/magic-leap-community/superglue">SuperGlue</a></li>
<li>Phát hiện vật thể với <a href="https://huggingface.co/PekingU/rtdetr_v2_r50vd">RT-DETRv2</a></li>
<li>Ước lượng tư thế với <a href="https://huggingface.co/usyd-community/vitpose-base-simple">VitPose</a></li>
<li>Phân đoạn đa năng với <a href="https://huggingface.co/shi-labs/oneformer_ade20k_swin_large">OneFormer</a></li>
<li>Phân loại video với <a href="https://huggingface.co/MCG-NJU/videomae-large">VideoMAE</a></li>
</ul>
</details>
<details>
<summary>Đa phương thức</summary>
<ul>
<li>Âm thanh hoặc văn bản sang văn bản với <a href="https://huggingface.co/Qwen/Qwen2-Audio-7B">Qwen2-Audio</a></li>
<li>Hỏi đáp tài liệu với <a href="https://huggingface.co/microsoft/layoutlmv3-base">LayoutLMv3</a></li>
<li>Hình ảnh hoặc văn bản sang văn bản với <a href="https://huggingface.co/Qwen/Qwen2.5-VL-3B-Instruct">Qwen-VL</a></li>
<li>Sinh chú thích hình ảnh với <a href="https://huggingface.co/Salesforce/blip2-opt-2.7b">BLIP-2</a></li>
<li>Hiểu tài liệu dựa trên OCR với <a href="https://huggingface.co/stepfun-ai/GOT-OCR-2.0-hf">GOT-OCR2</a></li>
<li>Hỏi đáp bảng với <a href="https://huggingface.co/google/tapas-base">TAPAS</a></li>
<li>Hiểu và sinh đa phương thức thống nhất với <a href="https://huggingface.co/BAAI/Emu3-Gen">Emu3</a></li>
<li>Thị giác sang văn bản với <a href="https://huggingface.co/llava-hf/llava-onevision-qwen2-0.5b-ov-hf">Llava-OneVision</a></li>
<li>Hỏi đáp hình ảnh với <a href="https://huggingface.co/llava-hf/llava-1.5-7b-hf">Llava</a></li>
<li>Phân đoạn biểu thức tham chiếu hình ảnh với <a href="https://huggingface.co/microsoft/kosmos-2-patch14-224">Kosmos-2</a></li>
</ul>
</details>
<details>
<summary>Xử lý ngôn ngữ tự nhiên (NLP)</summary>
<ul>
<li>Điền từ thiếu với <a href="https://huggingface.co/answerdotai/ModernBERT-base">ModernBERT</a></li>
<li>Nhận diện thực thể có tên với <a href="https://huggingface.co/google/gemma-2-2b">Gemma</a></li>
<li>Hỏi đáp với <a href="https://huggingface.co/mistralai/Mixtral-8x7B-v0.1">Mixtral</a></li>
<li>Tóm tắt với <a href="https://huggingface.co/facebook/bart-large-cnn">BART</a></li>
<li>Dịch với <a href="https://huggingface.co/google-t5/t5-base">T5</a></li>
<li>Sinh văn bản với <a href="https://huggingface.co/meta-llama/Llama-3.2-1B">Llama</a></li>
<li>Phân loại văn bản với <a href="https://huggingface.co/Qwen/Qwen2.5-0.5B">Qwen</a></li>
</ul>
</details>
<h2>Trích dẫn</h2>
<p>Chúng tôi hiện đã có <a href="https://www.aclweb.org/anthology/2020.emnlp-demos.6/">bài báo</a> bạn có thể trích dẫn cho thư viện 🤗 Transformers:</p>
<pre><code class="language-bibtex">@inproceedings{wolf-etal-2020-transformers,
    title = &quot;Transformers: State-of-the-Art Natural Language Processing&quot;,
    author = &quot;Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush&quot;,
    booktitle = &quot;Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations&quot;,
    month = oct,
    year = &quot;2020&quot;,
    address = &quot;Online&quot;,
    publisher = &quot;Association for Computational Linguistics&quot;,
    url = &quot;https://www.aclweb.org/anthology/2020.emnlp-demos.6&quot;,
    pages = &quot;38--45&quot;
}
</code></pre>
<hr />
<p><a href="https://github.com/OpenAiTx/OpenAiTx">Powered By OpenAiTx</a></p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
</body>
</html>