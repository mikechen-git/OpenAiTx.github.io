<!DOCTYPE html>
<html lang="de">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>memvid - Olow304/memvid</title>
    <meta name="title" content="memvid - Olow304/memvid">
    <meta name="description" content="Olow304/memvid - GitHub repository de documentation and informationMemvid - Video-basierte KI-Erinnerung 🧠📹 Die leichte, bahnbrechende Lösung für KI-Erinnerungen im großen Maßstab Memvid revolutioniert das KI-Gedächtnis-Management, indem es Textdaten in Videos kodiert. So wird eine blitzschnelle semantische Suche über Millionen von Textausschnitten mit Abrufzeiten unter einer Sekunde ermöglicht. Anders als traditionelle Vektor-Datenbanken, die enorme Mengen an RAM und Speicher benötigen, komprimiert Memvid Ihre Wissensbasis in kompakte Videodateien und ermöglicht dennoch den sofortigen Zugriff auf jede Information. 🎥 Demo https://github.com/user-attachments/assets/ec550e93-e9c4-459f-a8a1-46e122b5851e ✨ Hauptfunktionen 🎥 Video-als-Datenbank: Speichern Sie Millionen von Textausschnitten in einer einzigen MP4-Datei 🔍 Semantische Suche: Finden Sie relevante Inhalte mit natürlichen Sprachabfragen 💬 Integrierter Chat: Konversationsschnittstelle mit kontextbezogenen Antworten 📚 PDF-Unterstützung: Direkter Import und Indexierung von PDF-Dokumenten 🚀 Schneller Abruf: Suchzeiten unter einer Sekunde bei riesigen Datenmengen 💾 Effiziente Speicherung: 10-fache Komprimierung im Vergleich zu herkömmlichen Datenbanken 🔌 Pluggable LLMs: Funktioniert mit OpenAI, Anthropic oder lokalen Modellen 🌐 Offline-First: Nach der Videoerstellung kein Internet erforderlich 🔧 Einfache API:...">
    <meta name="keywords" content="Olow304, memvid, GitHub, repository, de documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/Olow304/memvid/README-de.html">
    <meta property="og:title" content="memvid - Olow304/memvid">
    <meta property="og:description" content="Olow304/memvid - GitHub repository de documentation and information">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/Olow304/memvid" id="githubRepoLink" target="_blank">Olow304/memvid</a>
<br>
<h1 style="display: none;">Memvid - Video-basierte KI-Erinnerung 🧠📹 Die leichte, bahnbrechende Lösung für KI-Erinnerungen im großen Maßstab Memvid revolutioniert das KI-Gedächtnis-Management, indem es Textdaten in Videos kodiert. So wird eine blitzschnelle semantische Suche über Millionen von Textausschnitten mit Abrufzeiten unter einer Sekunde ermöglicht. Anders als traditionelle Vektor-Datenbanken, die enorme Mengen an RAM und Speicher benötigen, komprimiert Memvid Ihre Wissensbasis in kompakte Videodateien und ermöglicht dennoch den sofortigen Zugriff auf jede Information. 🎥 Demo https://github.com/user-attachments/assets/ec550e93-e9c4-459f-a8a1-46e122b5851e ✨ Hauptfunktionen 🎥 Video-als-Datenbank: Speichern Sie Millionen von Textausschnitten in einer einzigen MP4-Datei 🔍 Semantische Suche: Finden Sie relevante Inhalte mit natürlichen Sprachabfragen 💬 Integrierter Chat: Konversationsschnittstelle mit kontextbezogenen Antworten 📚 PDF-Unterstützung: Direkter Import und Indexierung von PDF-Dokumenten 🚀 Schneller Abruf: Suchzeiten unter einer Sekunde bei riesigen Datenmengen 💾 Effiziente Speicherung: 10-fache Komprimierung im Vergleich zu herkömmlichen Datenbanken 🔌 Pluggable LLMs: Funktioniert mit OpenAI, Anthropic oder lokalen Modellen 🌐 Offline-First: Nach der Videoerstellung kein Internet erforderlich 🔧 Einfache API:...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <h1>Memvid - Video-basierte KI-Erinnerung 🧠📹</h1>
<p><strong>Die leichte, bahnbrechende Lösung für KI-Erinnerungen im großen Maßstab</strong></p>
<p><a href="https://pypi.org/project/memvid/"><img src="https://badge.fury.io/py/memvid.svg" alt="PyPI version" /></a>
<a href="https://opensource.org/licenses/MIT"><img src="https://img.shields.io/badge/License-MIT-yellow.svg" alt="License: MIT" /></a>
<a href="https://www.python.org/downloads/"><img src="https://img.shields.io/badge/python-3.8+-blue.svg" alt="Python 3.8+" /></a>
<a href="https://github.com/psf/black"><img src="https://img.shields.io/badge/code%20style-black-000000.svg" alt="Code style: black" /></a></p>
<p>Memvid revolutioniert das KI-Gedächtnis-Management, indem es Textdaten in Videos kodiert. So wird eine <strong>blitzschnelle semantische Suche</strong> über Millionen von Textausschnitten mit <strong>Abrufzeiten unter einer Sekunde</strong> ermöglicht. Anders als traditionelle Vektor-Datenbanken, die enorme Mengen an RAM und Speicher benötigen, komprimiert Memvid Ihre Wissensbasis in kompakte Videodateien und ermöglicht dennoch den sofortigen Zugriff auf jede Information.</p>
<h2>🎥 Demo</h2>
<p>https://github.com/user-attachments/assets/ec550e93-e9c4-459f-a8a1-46e122b5851e</p>
<h2>✨ Hauptfunktionen</h2>
<ul>
<li>🎥 <strong>Video-als-Datenbank</strong>: Speichern Sie Millionen von Textausschnitten in einer einzigen MP4-Datei</li>
<li>🔍 <strong>Semantische Suche</strong>: Finden Sie relevante Inhalte mit natürlichen Sprachabfragen</li>
<li>💬 <strong>Integrierter Chat</strong>: Konversationsschnittstelle mit kontextbezogenen Antworten</li>
<li>📚 <strong>PDF-Unterstützung</strong>: Direkter Import und Indexierung von PDF-Dokumenten</li>
<li>🚀 <strong>Schneller Abruf</strong>: Suchzeiten unter einer Sekunde bei riesigen Datenmengen</li>
<li>💾 <strong>Effiziente Speicherung</strong>: 10-fache Komprimierung im Vergleich zu herkömmlichen Datenbanken</li>
<li>🔌 <strong>Pluggable LLMs</strong>: Funktioniert mit OpenAI, Anthropic oder lokalen Modellen</li>
<li>🌐 <strong>Offline-First</strong>: Nach der Videoerstellung kein Internet erforderlich</li>
<li>🔧 <strong>Einfache API</strong>: Starten Sie mit nur 3 Codezeilen</li>
</ul>
<h2>🎯 Anwendungsfälle</h2>
<ul>
<li><strong>📖 Digitale Bibliotheken</strong>: Indizieren Sie Tausende von Büchern in einer einzigen Videodatei</li>
<li><strong>🎓 Lerninhalte</strong>: Erstellen Sie durchsuchbare Videomemories von Kursmaterialien</li>
<li><strong>📰 Nachrichtenarchive</strong>: Komprimieren Sie jahrelange Artikel in handhabbare Videodatenbanken</li>
<li><strong>💼 Unternehmenswissen</strong>: Bauen Sie unternehmensweite, durchsuchbare Wissensbasen auf</li>
<li><strong>🔬 Wissenschaftliche Arbeiten</strong>: Schnelle semantische Suche in wissenschaftlicher Literatur</li>
<li><strong>📝 Persönliche Notizen</strong>: Verwandeln Sie Ihre Notizen in einen durchsuchbaren KI-Assistenten</li>
</ul>
<h2>🚀 Warum Memvid?</h2>
<h3>Bahnbrechende Innovation</h3>
<ul>
<li><strong>Video als Datenbank</strong>: Speichern Sie Millionen von Textausschnitten in einer einzigen MP4-Datei</li>
<li><strong>Sofortiger Abruf</strong>: Semantische Suche unter einer Sekunde in riesigen Datensätzen</li>
<li><strong>10x Speicher-Effizienz</strong>: Videokomprimierung reduziert den Speicherbedarf drastisch</li>
<li><strong>Null Infrastruktur</strong>: Keine Datenbankserver, nur Dateien, die Sie überallhin kopieren können</li>
<li><strong>Offline-First</strong>: Funktioniert komplett offline, sobald die Videos erstellt wurden</li>
</ul>
<h3>Leichtgewichtige Architektur</h3>
<ul>
<li><strong>Minimale Abhängigkeiten</strong>: Kernfunktionalität in ca. 1000 Zeilen Python</li>
<li><strong>CPU-freundlich</strong>: Läuft effizient ohne GPU-Anforderungen</li>
<li><strong>Portabel</strong>: Eine einzige Videodatei enthält Ihre gesamte Wissensbasis</li>
<li><strong>Streambar</strong>: Videos können aus Cloud-Speichern gestreamt werden</li>
</ul>
<h2>📦 Installation</h2>
<h3>Schnellinstallation</h3>
<pre><code class="language-bash">pip install memvid
</code></pre>
<h3>Für PDF-Unterstützung</h3>
<pre><code class="language-bash">pip install memvid PyPDF2
</code></pre>
<h3>Empfohlene Einrichtung (Virtuelle Umgebung)</h3>
<pre><code class="language-bash"># Neues Projektverzeichnis erstellen
mkdir my-memvid-project
cd my-memvid-project

# Virtuelle Umgebung erstellen
python -m venv venv

# Aktivieren
# Auf macOS/Linux:
source venv/bin/activate
# Auf Windows:
venv\Scripts\activate

# Memvid installieren
pip install memvid

# Für PDF-Unterstützung:
pip install PyPDF2
</code></pre>
<h2>🎯 Schnellstart</h2>
<h3>Grundlegende Nutzung</h3>
<pre><code class="language-python">from memvid import MemvidEncoder, MemvidChat

# Videogedächtnis aus Textausschnitten erstellen
chunks = [&quot;Wichtige Tatsache 1&quot;, &quot;Wichtige Tatsache 2&quot;, &quot;Details zu historischen Ereignissen&quot;]
encoder = MemvidEncoder()
encoder.add_chunks(chunks)
encoder.build_video(&quot;memory.mp4&quot;, &quot;memory_index.json&quot;)

# Mit Ihrem Gedächtnis chatten
chat = MemvidChat(&quot;memory.mp4&quot;, &quot;memory_index.json&quot;)
chat.start_session()
response = chat.chat(&quot;Was weißt du über historische Ereignisse?&quot;)
print(response)
</code></pre>
<h3>Gedächtnis aus Dokumenten aufbauen</h3>
<pre><code class="language-python">from memvid import MemvidEncoder
import os

# Dokumente laden
encoder = MemvidEncoder(chunk_size=512, overlap=50)

# Textdateien hinzufügen
for file in os.listdir(&quot;documents&quot;):
    with open(f&quot;documents/{file}&quot;, &quot;r&quot;) as f:
        encoder.add_text(f.read(), metadata={&quot;source&quot;: file})

# Optimiertes Video erstellen
encoder.build_video(
    &quot;knowledge_base.mp4&quot;,
    &quot;knowledge_index.json&quot;,
    fps=30,  # Höhere FPS = mehr Chunks pro Sekunde
    frame_size=512  # Größere Frames = mehr Daten pro Frame
)
</code></pre>
<h3>Erweiterte Suche &amp; Abruf</h3>
<pre><code class="language-python">from memvid import MemvidRetriever

# Retriever initialisieren
retriever = MemvidRetriever(&quot;knowledge_base.mp4&quot;, &quot;knowledge_index.json&quot;)

# Semantische Suche
results = retriever.search(&quot;machine learning algorithms&quot;, top_k=5)
for chunk, score in results:
    print(f&quot;Score: {score:.3f} | {chunk[:100]}...&quot;)

# Kontextfenster erhalten
context = retriever.get_context(&quot;explain neural networks&quot;, max_tokens=2000)
print(context)
</code></pre>
<h3>Interaktive Chat-Oberfläche</h3>
<pre><code class="language-python">from memvid import MemvidInteractive

# Interaktive Chat-UI starten
interactive = MemvidInteractive(&quot;knowledge_base.mp4&quot;, &quot;knowledge_index.json&quot;)
interactive.run()  # Öffnet Weboberfläche unter http://localhost:7860
</code></pre>
<h3>Testen mit file_chat.py</h3>
<p>Das Skript <code>examples/file_chat.py</code> bietet eine umfassende Möglichkeit, Memvid mit eigenen Dokumenten zu testen:</p>
<pre><code class="language-bash"># Ein Verzeichnis mit Dokumenten verarbeiten
python examples/file_chat.py --input-dir /path/to/documents --provider google

# Bestimmte Dateien verarbeiten
python examples/file_chat.py --files doc1.txt doc2.pdf --provider openai

# H.265-Komprimierung verwenden (erfordert Docker)
python examples/file_chat.py --input-dir docs/ --codec h265 --provider google

# Benutzerdefiniertes Chunking für große Dokumente
python examples/file_chat.py --files large.pdf --chunk-size 2048 --overlap 32 --provider google

# Bestehendes Gedächtnis laden
python examples/file_chat.py --load-existing output/my_memory --provider google
</code></pre>
<h3>Komplettes Beispiel: Chat mit einem PDF-Buch</h3>
<pre><code class="language-bash"># 1. Neues Verzeichnis erstellen und Umgebung einrichten
mkdir book-chat-demo
cd book-chat-demo
python -m venv venv
source venv/bin/activate  # Unter Windows: venv\Scripts\activate

# 2. Abhängigkeiten installieren
pip install memvid PyPDF2

# 3. book_chat.py erstellen
cat &gt; book_chat.py &lt;&lt; 'EOF'
from memvid import MemvidEncoder, chat_with_memory
import os

# Ihre PDF-Datei
book_pdf = &quot;book.pdf&quot;  # Ersetzen Sie dies durch den Pfad zu Ihrem PDF

# Videogedächtnis aufbauen
encoder = MemvidEncoder()
encoder.add_pdf(book_pdf)
encoder.build_video(&quot;book_memory.mp4&quot;, &quot;book_index.json&quot;)

# Mit dem Buch chatten
api_key = os.getenv(&quot;OPENAI_API_KEY&quot;)  # Optional: für KI-Antworten
```markdown
chat_with_memory(&quot;book_memory.mp4&quot;, &quot;book_index.json&quot;, api_key=api_key)
EOF

# 4. Ausführen
export OPENAI_API_KEY=&quot;dein-api-key&quot;  # Optional
python book_chat.py
</code></pre>
<h2>🛠️ Erweiterte Konfiguration</h2>
<h3>Eigene Embeddings</h3>
<pre><code class="language-python">from sentence_transformers import SentenceTransformer

# Eigenes Embedding-Modell verwenden
custom_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')
encoder = MemvidEncoder(embedding_model=custom_model)
</code></pre>
<h3>Video-Optimierung</h3>
<pre><code class="language-python"># Für maximale Kompression
encoder.build_video(
    &quot;compressed.mp4&quot;,
    &quot;index.json&quot;,
    fps=60,  # Mehr Bilder pro Sekunde
    frame_size=256,  # Kleinere Bilder
    video_codec='h265',  # Bessere Kompression
    crf=28  # Kompressionsqualität (je niedriger, desto bessere Qualität)
)
</code></pre>
<h3>Verteilte Verarbeitung</h3>
<pre><code class="language-python"># Große Datensätze parallel verarbeiten
encoder = MemvidEncoder(n_workers=8)
encoder.add_chunks_parallel(massive_chunk_list)
</code></pre>
<h2>🐛 Fehlerbehebung</h2>
<h3>Häufige Probleme</h3>
<p><strong>ModuleNotFoundError: No module named 'memvid'</strong></p>
<pre><code class="language-bash"># Stelle sicher, dass du das richtige Python verwendest
which python  # Sollte den Pfad deiner virtuellen Umgebung anzeigen
# Falls nicht, aktiviere deine virtuelle Umgebung:
source venv/bin/activate  # Unter Windows: venv\Scripts\activate
</code></pre>
<p><strong>ImportError: PyPDF2 ist erforderlich für PDF-Unterstützung</strong></p>
<pre><code class="language-bash">pip install PyPDF2
</code></pre>
<p><strong>LLM API-Schlüssel-Probleme</strong></p>
<pre><code class="language-bash"># Setze deinen API-Schlüssel (bekomme einen unter https://platform.openai.com)
export GOOGLE_API_KEY=&quot;AIzaSyB1-...&quot;  # macOS/Linux
# Oder unter Windows:
set GOOGLE_API_KEY=AIzaSyB1-...
</code></pre>
<p><strong>Verarbeitung großer PDFs</strong></p>
<pre><code class="language-python"># Für sehr große PDFs kleinere Chunk-Größen verwenden
encoder = MemvidEncoder()
encoder.add_pdf(&quot;large_book.pdf&quot;, chunk_size=400, overlap=50)
</code></pre>
<h2>🤝 Beitrag leisten</h2>
<p>Beiträge sind willkommen! Weitere Details findest du in unserem <a href="https://raw.githubusercontent.com/Olow304/memvid/main/CONTRIBUTING.md">Beitragsleitfaden</a>.</p>
<pre><code class="language-bash"># Tests ausführen
pytest tests/

# Mit Coverage ausführen
pytest --cov=memvid tests/

# Code formatieren
black memvid/
</code></pre>
<h2>🆚 Vergleich mit traditionellen Lösungen</h2>
<p>| Funktion | Memvid | Vektor-DBs | Traditionelle DBs |
|----------|--------|------------|-------------------|
| Speichereffizienz | ⭐⭐⭐⭐⭐ | ⭐⭐ | ⭐⭐⭐ |
| Setup-Komplexität | Einfach | Komplex | Komplex |
| Semantische Suche | ✅ | ✅ | ❌ |
| Offline-Nutzung | ✅ | ❌ | ✅ |
| Portabilität | Dateibasiert | Serverbasiert | Serverbasiert |
| Skalierbarkeit | Millionen | Millionen | Milliarden |
| Kosten | Kostenlos | $$$$ | $$$ |</p>
<h2>📚 Beispiele</h2>
<p>Siehe das Verzeichnis <a href="https://raw.githubusercontent.com/Olow304/memvid/main/examples/">examples/</a> für:</p>
<ul>
<li>Aufbau von Speicher aus Wikipedia-Dumps</li>
<li>Erstellung einer persönlichen Wissensdatenbank</li>
<li>Mehrsprachige Unterstützung</li>
<li>Echtzeit-Updates des Speichers</li>
<li>Integration mit beliebten LLMs</li>
</ul>
<h2>🆘 Hilfe erhalten</h2>
<ul>
<li>📖 <a href="https://github.com/olow304/memvid/wiki">Dokumentation</a> - Umfassende Anleitungen</li>
<li>💬 <a href="https://github.com/olow304/memvid/discussions">Diskussionen</a> - Fragen stellen</li>
<li>🐛 <a href="https://github.com/olow304/memvid/issues">Issue Tracker</a> - Fehler melden</li>
<li>🌟 <a href="https://github.com/olow304/memvid/discussions/categories/show-and-tell">Show &amp; Tell</a> - Teile deine Projekte</li>
</ul>
<h2>🔗 Links</h2>
<ul>
<li><a href="https://github.com/olow304/memvid">GitHub Repository</a></li>
<li><a href="https://pypi.org/project/memvid">PyPI-Paket</a></li>
<li><a href="https://github.com/olow304/memvid/releases">Changelog</a></li>
</ul>
<h2>📄 Lizenz</h2>
<p>MIT-Lizenz – siehe <a href="https://raw.githubusercontent.com/Olow304/memvid/main/LICENSE">LICENSE</a> Datei für Details.</p>
<h2>🙏 Danksagung</h2>
<p>Erstellt von <a href="https://github.com/olow304">Olow304</a> und der Memvid-Community.</p>
<p>Erstellt mit ❤️ unter Verwendung von:</p>
<ul>
<li><a href="https://www.sbert.net/">sentence-transformers</a> – Modernste Embeddings für semantische Suche</li>
<li><a href="https://opencv.org/">OpenCV</a> – Computer Vision und Videobearbeitung</li>
<li><a href="https://github.com/lincolnloop/python-qrcode">qrcode</a> – QR-Code-Generierung</li>
<li><a href="https://github.com/facebookresearch/faiss">FAISS</a> – Effiziente Ähnlichkeitssuche</li>
<li><a href="https://github.com/py-pdf/pypdf">PyPDF2</a> – PDF-Text-Extraktion</li>
</ul>
<p>Besonderer Dank an alle Mitwirkenden, die Memvid besser machen!</p>
<hr />
<p><strong>Bereit, dein KI-Speichermanagement zu revolutionieren? Installiere Memvid und lege los!</strong> 🚀</p>
<pre><code>

---


Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-06-08


---
</code></pre>

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Statcounter and other scripts can be added here -->
</body>
</html>