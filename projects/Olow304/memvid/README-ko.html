<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>memvid - Olow304/memvid</title>
    <meta name="title" content="memvid - Olow304/memvid">
    <meta name="description" content="Olow304/memvid - GitHub repository ko documentation and informationMemvid - 영상 기반 AI 메모리 🧠📹 AI 메모리를 대규모로 구현하는 경량 혁신 솔루션 Memvid는 텍스트 데이터를 비디오로 인코딩하여, 수백만 개의 텍스트 청크에 대한 번개같이 빠른 의미론적 검색과 1초 미만의 검색 시간을 가능하게 하며 AI 메모리 관리 방식을 혁신합니다...">
    <meta name="keywords" content="Olow304, memvid, GitHub, repository, ko documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/Olow304/memvid/README-ko.html">
    <meta property="og:title" content="memvid - Olow304/memvid">
    <meta property="og:description" content="Olow304/memvid - GitHub repository ko documentation and information">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/Olow304/memvid" id="githubRepoLink" target="_blank">Olow304/memvid</a>
<h1 style="display: none;">Memvid - 영상 기반 AI 메모리 🧠📹 AI 메모리를 대규모로 구현하는 경량 혁신 솔루션 Memvid는 텍스트 데이터를 비디오로 인코딩하여, 수백만 개의 텍스트 청크에 대한 번개같이 빠른 의미론적 검색과 1초 미만의 검색 시간을 가능하게 하며 AI 메모리 관리 방식을 혁신합니다...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <h1>Memvid - 영상 기반 AI 메모리 🧠📹</h1>
<p><strong>AI 메모리를 대규모로 구현하는 경량 혁신 솔루션</strong></p>
<p><a href="https://pypi.org/project/memvid/"><img src="https://badge.fury.io/py/memvid.svg" alt="PyPI version" /></a>
<a href="https://opensource.org/licenses/MIT"><img src="https://img.shields.io/badge/License-MIT-yellow.svg" alt="License: MIT" /></a>
<a href="https://www.python.org/downloads/"><img src="https://img.shields.io/badge/python-3.8+-blue.svg" alt="Python 3.8+" /></a>
<a href="https://github.com/psf/black"><img src="https://img.shields.io/badge/code%20style-black-000000.svg" alt="Code style: black" /></a></p>
<p>Memvid는 텍스트 데이터를 비디오로 인코딩하여, <strong>수백만 개의 텍스트 청크에 대한 번개같이 빠른 의미론적 검색</strong>과 <strong>1초 미만의 검색 시간</strong>을 가능하게 하며 AI 메모리 관리 방식을 혁신합니다. 기존의 벡터 데이터베이스가 대량의 RAM과 저장 공간을 소모하는 것과 달리, Memvid는 지식 베이스를 컴팩트한 비디오 파일로 압축하면서도 언제든지 즉시 정보에 접근할 수 있습니다.</p>
<h2>🎥 데모</h2>
<p>https://github.com/user-attachments/assets/ec550e93-e9c4-459f-a8a1-46e122b5851e</p>
<h2>✨ 주요 기능</h2>
<ul>
<li>🎥 <strong>비디오 기반 데이터베이스</strong>: 수백만 개의 텍스트 청크를 하나의 MP4 파일에 저장</li>
<li>🔍 <strong>의미론적 검색</strong>: 자연어 쿼리를 통한 관련 콘텐츠 검색</li>
<li>💬 <strong>내장 챗봇</strong>: 문맥을 이해하는 대화형 인터페이스</li>
<li>📚 <strong>PDF 지원</strong>: PDF 문서의 직접 가져오기 및 인덱싱</li>
<li>🚀 <strong>빠른 검색</strong>: 대규모 데이터셋에서도 1초 미만의 검색 속도</li>
<li>💾 <strong>효율적 저장</strong>: 기존 데이터베이스 대비 10배 압축률</li>
<li>🔌 <strong>플러그인 LLM 지원</strong>: OpenAI, Anthropic 또는 로컬 모델과 연동</li>
<li>🌐 <strong>오프라인 우선</strong>: 비디오 생성 후 인터넷 불필요</li>
<li>🔧 <strong>간단한 API</strong>: 단 3줄 코드로 시작 가능</li>
</ul>
<h2>🎯 활용 사례</h2>
<ul>
<li><strong>📖 디지털 라이브러리</strong>: 수천 권의 책을 하나의 비디오 파일로 색인화</li>
<li><strong>🎓 교육 자료</strong>: 강의자료의 검색 가능한 비디오 메모리 생성</li>
<li><strong>📰 뉴스 아카이브</strong>: 수년치 기사를 관리 가능한 비디오 데이터베이스로 압축</li>
<li><strong>💼 기업 지식 관리</strong>: 회사 전체의 지식 베이스를 검색 가능하게 구축</li>
<li><strong>🔬 연구 논문</strong>: 과학 문헌에 대한 신속한 의미론적 검색</li>
<li><strong>📝 개인 노트</strong>: 개인 노트를 검색 가능한 AI 어시스턴트로 변환</li>
</ul>
<h2>🚀 왜 Memvid인가?</h2>
<h3>혁신적인 차별성</h3>
<ul>
<li><strong>비디오 기반 데이터베이스</strong>: 수백만 개 텍스트 청크를 하나의 MP4 파일에 저장</li>
<li><strong>즉시 검색</strong>: 대규모 데이터셋에서도 1초 미만의 의미론적 검색</li>
<li><strong>10배 저장 효율</strong>: 비디오 압축으로 메모리 사용량 획기적 절감</li>
<li><strong>인프라 불필요</strong>: 데이터베이스 서버 없이 파일만 복사하면 됨</li>
<li><strong>오프라인 우선</strong>: 비디오 생성 후 완전 오프라인 동작</li>
</ul>
<h3>경량 아키텍처</h3>
<ul>
<li><strong>최소 의존성</strong>: 핵심 기능이 약 1000줄의 Python 코드로 구현</li>
<li><strong>CPU 친화적</strong>: GPU 없이도 효율적으로 실행</li>
<li><strong>휴대성</strong>: 단일 비디오 파일에 전체 지식 베이스 저장</li>
<li><strong>스트리밍 가능</strong>: 클라우드 저장소에서 비디오 스트리밍 지원</li>
</ul>
<h2>📦 설치</h2>
<h3>빠른 설치</h3>
<pre><code class="language-bash">pip install memvid
</code></pre>
<h3>PDF 지원 설치</h3>
<pre><code class="language-bash">pip install memvid PyPDF2
</code></pre>
<h3>권장 환경 (가상환경)</h3>
<pre><code class="language-bash"># 새 프로젝트 디렉터리 생성
mkdir my-memvid-project
cd my-memvid-project

# 가상환경 생성
python -m venv venv

# 활성화
# macOS/Linux:
source venv/bin/activate
# Windows:
venv\Scripts\activate

# memvid 설치
pip install memvid

# PDF 지원 추가:
pip install PyPDF2
</code></pre>
<h2>🎯 빠른 시작</h2>
<h3>기본 사용법</h3>
<pre><code class="language-python">from memvid import MemvidEncoder, MemvidChat

# 텍스트 청크로 비디오 메모리 생성
chunks = [&quot;중요 사실 1&quot;, &quot;중요 사실 2&quot;, &quot;역사적 사건 상세&quot;]
encoder = MemvidEncoder()
encoder.add_chunks(chunks)
encoder.build_video(&quot;memory.mp4&quot;, &quot;memory_index.json&quot;)

# 메모리와 대화
chat = MemvidChat(&quot;memory.mp4&quot;, &quot;memory_index.json&quot;)
chat.start_session()
response = chat.chat(&quot;역사적 사건에 대해 무엇을 알고 있나요?&quot;)
print(response)
</code></pre>
<h3>문서에서 메모리 구축</h3>
<pre><code class="language-python">from memvid import MemvidEncoder
import os

# 문서 로드
encoder = MemvidEncoder(chunk_size=512, overlap=50)

# 텍스트 파일 추가
for file in os.listdir(&quot;documents&quot;):
    with open(f&quot;documents/{file}&quot;, &quot;r&quot;) as f:
        encoder.add_text(f.read(), metadata={&quot;source&quot;: file})

# 최적화된 비디오 생성
encoder.build_video(
    &quot;knowledge_base.mp4&quot;,
    &quot;knowledge_index.json&quot;,
    fps=30,  # FPS가 높을수록 초당 더 많은 청크 저장
    frame_size=512  # 프레임 크기가 클수록 프레임당 데이터 증가
)
</code></pre>
<h3>고급 검색 및 검색</h3>
<pre><code class="language-python">from memvid import MemvidRetriever

# 리트리버 초기화
retriever = MemvidRetriever(&quot;knowledge_base.mp4&quot;, &quot;knowledge_index.json&quot;)

# 의미론적 검색
results = retriever.search(&quot;머신러닝 알고리즘&quot;, top_k=5)
for chunk, score in results:
    print(f&quot;Score: {score:.3f} | {chunk[:100]}...&quot;)

# 컨텍스트 윈도우 가져오기
context = retriever.get_context(&quot;신경망 설명&quot;, max_tokens=2000)
print(context)
</code></pre>
<h3>인터랙티브 챗 인터페이스</h3>
<pre><code class="language-python">from memvid import MemvidInteractive

# 인터랙티브 챗 UI 실행
interactive = MemvidInteractive(&quot;knowledge_base.mp4&quot;, &quot;knowledge_index.json&quot;)
interactive.run()  # http://localhost:7860 웹 인터페이스 오픈
</code></pre>
<h3>file_chat.py로 테스트하기</h3>
<p><code>examples/file_chat.py</code> 스크립트는 본인 문서로 Memvid를 종합적으로 테스트할 수 있는 방법을 제공합니다:</p>
<pre><code class="language-bash"># 문서 디렉토리 처리
python examples/file_chat.py --input-dir /path/to/documents --provider google

# 특정 파일 처리
python examples/file_chat.py --files doc1.txt doc2.pdf --provider openai

# H.265 압축 사용 (Docker 필요)
python examples/file_chat.py --input-dir docs/ --codec h265 --provider google

# 대용량 문서용 커스텀 청킹
python examples/file_chat.py --files large.pdf --chunk-size 2048 --overlap 32 --provider google

# 기존 메모리 로드
python examples/file_chat.py --load-existing output/my_memory --provider google
</code></pre>
<h3>전체 예제: PDF 책과 챗하기</h3>
<pre><code class="language-bash"># 1. 새 디렉터리 생성 및 환경 설정
mkdir book-chat-demo
cd book-chat-demo
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# 2. 의존성 설치
pip install memvid PyPDF2

# 3. book_chat.py 생성
cat &gt; book_chat.py &lt;&lt; 'EOF'
from memvid import MemvidEncoder, chat_with_memory
import os

# PDF 파일 지정
book_pdf = &quot;book.pdf&quot;  # PDF 경로로 교체

# 비디오 메모리 구축
encoder = MemvidEncoder()
encoder.add_pdf(book_pdf)
encoder.build_video(&quot;book_memory.mp4&quot;, &quot;book_index.json&quot;)

# 책과 대화
api_key = os.getenv(&quot;OPENAI_API_KEY&quot;)  # AI 응답을 위한 옵션
chat_with_memory(&quot;book_memory.mp4&quot;, &quot;book_index.json&quot;, api_key=api_key)
EOF

# 4. 실행하기
export OPENAI_API_KEY=&quot;your-api-key&quot;  # 선택 사항
python book_chat.py
</code></pre>
<h2>🛠️ 고급 설정</h2>
<h3>커스텀 임베딩</h3>
<pre><code class="language-python">from sentence_transformers import SentenceTransformer

# 커스텀 임베딩 모델 사용
custom_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')
encoder = MemvidEncoder(embedding_model=custom_model)
</code></pre>
<h3>비디오 최적화</h3>
<pre><code class="language-python"># 최대 압축을 위해
encoder.build_video(
    &quot;compressed.mp4&quot;,
    &quot;index.json&quot;,
    fps=60,  # 초당 프레임 수 증가
    frame_size=256,  # 더 작은 프레임
    video_codec='h265',  # 더 나은 압축
    crf=28  # 압축 품질 (낮을수록 더 좋은 품질)
)
</code></pre>
<h3>분산 처리</h3>
<pre><code class="language-python"># 대용량 데이터셋 병렬 처리
encoder = MemvidEncoder(n_workers=8)
encoder.add_chunks_parallel(massive_chunk_list)
</code></pre>
<h2>🐛 문제 해결</h2>
<h3>일반적인 문제</h3>
<p><strong>ModuleNotFoundError: No module named 'memvid'</strong></p>
<pre><code class="language-bash"># 올바른 Python을 사용 중인지 확인
which python  # 가상환경 경로가 출력되어야 함
# 그렇지 않다면, 가상환경 활성화:
source venv/bin/activate  # Windows에서는: venv\Scripts\activate
</code></pre>
<p><strong>ImportError: PyPDF2 is required for PDF support</strong></p>
<pre><code class="language-bash">pip install PyPDF2
</code></pre>
<p><strong>LLM API 키 문제</strong></p>
<pre><code class="language-bash"># API 키 설정 (https://platform.openai.com 에서 발급)
export GOOGLE_API_KEY=&quot;AIzaSyB1-...&quot;  # macOS/Linux
# 또는 Windows에서:
set GOOGLE_API_KEY=AIzaSyB1-...
</code></pre>
<p><strong>대용량 PDF 처리</strong></p>
<pre><code class="language-python"># 매우 큰 PDF의 경우 더 작은 청크 크기 사용
encoder = MemvidEncoder()
encoder.add_pdf(&quot;large_book.pdf&quot;, chunk_size=400, overlap=50)
</code></pre>
<h2>🤝 기여하기</h2>
<p>기여를 환영합니다! 자세한 내용은 <a href="https://raw.githubusercontent.com/Olow304/memvid/main/CONTRIBUTING.md">기여 가이드</a>를 참고해 주세요.</p>
<pre><code class="language-bash"># 테스트 실행
pytest tests/

# 커버리지와 함께 실행
pytest --cov=memvid tests/

# 코드 포맷팅
black memvid/
</code></pre>
<h2>🆚 기존 솔루션과의 비교</h2>
<p>| 기능 | Memvid | 벡터 DB | 전통적 DB |
|------|--------|---------|-----------|
| 저장 효율성 | ⭐⭐⭐⭐⭐ | ⭐⭐ | ⭐⭐⭐ |
| 구축 복잡성 | 간단 | 복잡 | 복잡 |
| 의미 기반 검색 | ✅ | ✅ | ❌ |
| 오프라인 사용 | ✅ | ❌ | ✅ |
| 이식성 | 파일 기반 | 서버 기반 | 서버 기반 |
| 확장성 | 수백만 | 수백만 | 수십억 |
| 비용 | 무료 | $$$$ | $$$ |</p>
<h2>📚 예제</h2>
<p><a href="https://raw.githubusercontent.com/Olow304/memvid/main/examples/">examples/</a> 디렉터리에서 확인할 수 있습니다:</p>
<ul>
<li>위키피디아 덤프에서 메모리 구축</li>
<li>개인 지식 베이스 생성</li>
<li>다국어 지원</li>
<li>실시간 메모리 업데이트</li>
<li>인기 LLM과의 통합</li>
</ul>
<h2>🆘 도움 받기</h2>
<ul>
<li>📖 <a href="https://github.com/olow304/memvid/wiki">문서</a> - 종합 안내서</li>
<li>💬 <a href="https://github.com/olow304/memvid/discussions">토론</a> - 질문하기</li>
<li>🐛 <a href="https://github.com/olow304/memvid/issues">이슈 트래커</a> - 버그 신고</li>
<li>🌟 <a href="https://github.com/olow304/memvid/discussions/categories/show-and-tell">Show &amp; Tell</a> - 프로젝트 공유</li>
</ul>
<h2>🔗 링크</h2>
<ul>
<li><a href="https://github.com/olow304/memvid">GitHub 저장소</a></li>
<li><a href="https://pypi.org/project/memvid">PyPI 패키지</a></li>
<li><a href="https://github.com/olow304/memvid/releases">Changelog</a></li>
</ul>
<h2>📄 라이선스</h2>
<p>MIT 라이선스 - 자세한 내용은 <a href="https://raw.githubusercontent.com/Olow304/memvid/main/LICENSE">LICENSE</a> 파일을 참조하세요.</p>
<h2>🙏 감사의 말</h2>
<p><a href="https://github.com/olow304">Olow304</a> 및 Memvid 커뮤니티에 의해 제작되었습니다.</p>
<p>다음과 같은 오픈소스 도구로 만들어졌습니다:</p>
<ul>
<li><a href="https://www.sbert.net/">sentence-transformers</a> - 의미 기반 검색용 최신 임베딩</li>
<li><a href="https://opencv.org/">OpenCV</a> - 컴퓨터 비전 및 비디오 처리</li>
<li><a href="https://github.com/lincolnloop/python-qrcode">qrcode</a> - QR 코드 생성</li>
<li><a href="https://github.com/facebookresearch/faiss">FAISS</a> - 효율적인 유사도 검색</li>
<li><a href="https://github.com/py-pdf/pypdf">PyPDF2</a> - PDF 텍스트 추출</li>
</ul>
<p>Memvid를 더 좋게 만들어 주신 모든 기여자분들께 특별히 감사드립니다!</p>
<hr />
<p><strong>AI 메모리 관리의 혁신을 시작할 준비가 되셨나요? Memvid를 설치하고 바로 시작하세요!</strong> 🚀</p>
<hr />
<p>Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx">Open Ai Tx</a> | Last indexed: 2025-06-08</p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Statcounter and other scripts can be added here -->
</body>
</html>