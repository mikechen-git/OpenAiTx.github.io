<!DOCTYPE html><html lang="en"><head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Memvid - Mémoire IA Basée sur la Vidéo 🧠📹 - Olow304/memvid</title>

    <!-- Primary Meta Tags -->
    <meta name="title" content="Memvid - Mémoire IA Basée sur la Vidéo 🧠📹 - Olow304/memvid">
    <meta name="description" content="Olow304/memvid - GitHub repository fr documentation and information">
    <meta name="keywords" content="Olow304, memvid, GitHub, repository, fr documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">

    <!-- Open Graph -->
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/Olow304/memvid/README-fr.html">
    <meta property="og:title" content="Memvid - Mémoire IA Basée sur la Vidéo 🧠📹 - Olow304/memvid">
    <meta property="og:description" content="Olow304/memvid - GitHub repository fr documentation and information">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">

    <!-- Favicon -->
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">

    <!-- Marked.js for Markdown rendering -->
    <script type="text/javascript" async="" src="https://www.statcounter.com/counter/recorder.js"></script><script src="/js/marked.min.js?v=20250613"></script>
    <!-- Highlight.js for code syntax highlighting -->
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <!-- Custom CSS -->
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        /* Layout */
        body {
            display: flex;
            flex-direction: column;
            min-height: 100vh;
        }

        .main-container {
            margin: 0 auto;
            width: 100%;
            max-width: 980px;
            padding: 0 20px;
        }

        @media (max-width: 768px) {
            .main-container {
                padding: 0 15px;
            }
        }

        /* Image size restrictions */
        .markdown-body img {
            max-width: 100%;
            height: auto;
        }

        /* Existing styles */
        .header {
            text-align: center;
            margin-bottom: 30px;
            padding: 20px;
            background-color: #f6f8fa;
            border-bottom: 1px solid #e1e4e8;
            position: relative;
        }

        .back-button {
            position: absolute;
            left: 20px;
            top: 50%;
            transform: translateY(-50%);
            color: #0366d6;
            text-decoration: none;
            display: flex;
            align-items: center;
            font-size: 14px;
            padding: 5px 10px;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            background-color: #fff;
        }

        .back-button:hover {
            background-color: #f6f8fa;
            border-color: #0366d6;
        }

        .back-button::before {
            content: "←";
            margin-right: 5px;
            font-size: 16px;
        }

        .header .links {
            margin-top: 10px;
            font-size: 16px;
        }

        .header .links a {
            color: #0366d6;
            text-decoration: none;
            margin-left: 5px;
        }

        .header .links a:hover {
            text-decoration: underline;
        }
        
        /* Language badges styles */
        .language-badges {
            margin-top: 15px;
            text-align: center;
        }
        .language-badges a {
            display: inline-block;
            margin: 2px;
            text-decoration: none;
        }
        .language-badges img {
            height: 20px;
            border-radius: 3px;
        }
        .language-badges a:hover img {
            opacity: 0.8;
        }
    </style>
</head>

<body>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/Olow304/memvid" id="githubRepoLink" target="_blank">Olow304/memvid</a>
        </div>
        <div class="language-badges" id="languageBadges"><a href="https://openaitx.github.io/view.html?user=Olow304&amp;project=memvid&amp;lang=en"><img src="https://img.shields.io/badge/EN-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Olow304&amp;project=memvid&amp;lang=zh-CN"><img src="https://img.shields.io/badge/简中-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Olow304&amp;project=memvid&amp;lang=zh-TW"><img src="https://img.shields.io/badge/繁中-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Olow304&amp;project=memvid&amp;lang=ja"><img src="https://img.shields.io/badge/日本語-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Olow304&amp;project=memvid&amp;lang=ko"><img src="https://img.shields.io/badge/한국어-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Olow304&amp;project=memvid&amp;lang=th"><img src="https://img.shields.io/badge/ไทย-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Olow304&amp;project=memvid&amp;lang=fr"><img src="https://img.shields.io/badge/Français-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Olow304&amp;project=memvid&amp;lang=de"><img src="https://img.shields.io/badge/Deutsch-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Olow304&amp;project=memvid&amp;lang=es"><img src="https://img.shields.io/badge/Español-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Olow304&amp;project=memvid&amp;lang=it"><img src="https://img.shields.io/badge/Italiano-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Olow304&amp;project=memvid&amp;lang=ru"><img src="https://img.shields.io/badge/Русский-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Olow304&amp;project=memvid&amp;lang=pt"><img src="https://img.shields.io/badge/Português-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Olow304&amp;project=memvid&amp;lang=nl"><img src="https://img.shields.io/badge/Nederlands-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Olow304&amp;project=memvid&amp;lang=pl"><img src="https://img.shields.io/badge/Polski-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Olow304&amp;project=memvid&amp;lang=ar"><img src="https://img.shields.io/badge/العربية-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Olow304&amp;project=memvid&amp;lang=tr"><img src="https://img.shields.io/badge/Türkçe-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Olow304&amp;project=memvid&amp;lang=vi"><img src="https://img.shields.io/badge/Tiếng Việt-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Olow304&amp;project=memvid&amp;lang=hi"><img src="https://img.shields.io/badge/हिंदी-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Olow304&amp;project=memvid&amp;lang=fa"><img src="https://img.shields.io/badge/فارسی-white" alt="version"></a> <a href="https://openaitx.github.io/view.html?user=Olow304&amp;project=memvid&amp;lang=id"><img src="https://img.shields.io/badge/Bahasa Indonesia-white" alt="version"></a></div>
    </div>

    <div class="main-container">
        <div class="markdown-body" id="content"><h1>Memvid - Mémoire IA Basée sur la Vidéo 🧠📹</h1>
<p><strong>La solution légère et révolutionnaire pour la mémoire IA à grande échelle</strong></p>
<p><a href="https://pypi.org/project/memvid/"><img src="https://badge.fury.io/py/memvid.svg" alt="PyPI version"></a><br><a href="https://opensource.org/licenses/MIT"><img src="https://img.shields.io/badge/License-MIT-yellow.svg" alt="License: MIT"></a><br><a href="https://www.python.org/downloads/"><img src="https://img.shields.io/badge/python-3.8+-blue.svg" alt="Python 3.8+"></a><br><a href="https://github.com/psf/black"><img src="https://img.shields.io/badge/code%20style-black-000000.svg" alt="Code style: black"></a></p>
<p>Memvid révolutionne la gestion de la mémoire pour l’IA en encodant les données textuelles en vidéos, permettant une <strong>recherche sémantique ultra-rapide</strong> sur des millions de fragments de texte avec des <strong>temps de récupération inférieurs à la seconde</strong>. Contrairement aux bases de données vectorielles traditionnelles qui consomment énormément de RAM et de stockage, Memvid compresse votre base de connaissance en fichiers vidéo compacts tout en maintenant un accès instantané à toute information.</p>
<h2>🎥 Démonstration</h2>
<p><a href="https://github.com/user-attachments/assets/ec550e93-e9c4-459f-a8a1-46e122b5851e">https://github.com/user-attachments/assets/ec550e93-e9c4-459f-a8a1-46e122b5851e</a></p>
<h2>✨ Principales fonctionnalités</h2>
<ul>
<li>🎥 <strong>Vidéo comme Base de Données</strong> : Stockez des millions de fragments de texte dans un seul fichier MP4</li>
<li>🔍 <strong>Recherche Sémantique</strong> : Trouvez le contenu pertinent avec des requêtes en langage naturel</li>
<li>💬 <strong>Chat Intégré</strong> : Interface conversationnelle avec des réponses contextuelles</li>
<li>📚 <strong>Support PDF</strong> : Import et indexation directe de documents PDF</li>
<li>🚀 <strong>Récupération Rapide</strong> : Recherche en moins d’une seconde sur des ensembles de données massifs</li>
<li>💾 <strong>Stockage Efficace</strong> : Compression 10x par rapport aux bases de données classiques</li>
<li>🔌 <strong>LLMs Modulaire</strong> : Fonctionne avec OpenAI, Anthropic ou des modèles locaux</li>
<li>🌐 <strong>Offline-First</strong> : Aucune connexion Internet nécessaire après la génération des vidéos</li>
<li>🔧 <strong>API Simple</strong> : Commencez en seulement 3 lignes de code</li>
</ul>
<h2>🎯 Cas d’utilisation</h2>
<ul>
<li><strong>📖 Bibliothèques Numériques</strong> : Indexez des milliers de livres dans un seul fichier vidéo</li>
<li><strong>🎓 Contenus Éducatifs</strong> : Créez des mémoires vidéo consultables pour les supports de cours</li>
<li><strong>📰 Archives de Presse</strong> : Compressez des années d’articles dans des bases de données vidéo faciles à gérer</li>
<li><strong>💼 Connaissance d’Entreprise</strong> : Construisez des bases de connaissances consultables à l’échelle de l’entreprise</li>
<li><strong>🔬 Publications Scientifiques</strong> : Recherche sémantique rapide dans la littérature scientifique</li>
<li><strong>📝 Notes Personnelles</strong> : Transformez vos notes en assistant IA consultable</li>
</ul>
<h2>🚀 Pourquoi Memvid ?</h2>
<h3>Innovation Révolutionnaire</h3>
<ul>
<li><strong>Vidéo comme Base de Données</strong> : Stockez des millions de fragments de texte dans un seul fichier MP4</li>
<li><strong>Récupération Instantanée</strong> : Recherche sémantique en moins d’une seconde sur de grands ensembles de données</li>
<li><strong>Efficacité de Stockage 10x</strong> : La compression vidéo réduit considérablement l’empreinte mémoire</li>
<li><strong>Zéro Infrastructure</strong> : Pas de serveur de base de données, juste des fichiers que vous pouvez copier n’importe où</li>
<li><strong>Offline-First</strong> : Fonctionne entièrement hors-ligne une fois les vidéos générées</li>
</ul>
<h3>Architecture Légère</h3>
<ul>
<li><strong>Dépendances Minimales</strong> : Fonctionnalité principale en ~1000 lignes de Python</li>
<li><strong>Optimisé CPU</strong> : Fonctionne efficacement sans nécessiter de GPU</li>
<li><strong>Portable</strong> : Un seul fichier vidéo contient toute votre base de connaissance</li>
<li><strong>Diffusable</strong> : Les vidéos peuvent être diffusées depuis un stockage cloud</li>
</ul>
<h2>📦 Installation</h2>
<h3>Installation Rapide</h3>
<pre><code class="language-bash hljs">pip install memvid
</code></pre>
<h3>Pour le support PDF</h3>
<pre><code class="language-bash hljs">pip install memvid PyPDF2
</code></pre>
<h3>Configuration recommandée (Environnement Virtuel)</h3>
<pre><code class="language-bash hljs"><span class="hljs-comment"># Créer un nouveau dossier de projet</span>
<span class="hljs-built_in">mkdir</span> my-memvid-project
<span class="hljs-built_in">cd</span> my-memvid-project

<span class="hljs-comment"># Créer un environnement virtuel</span>
python -m venv venv

<span class="hljs-comment"># L’activer</span>
<span class="hljs-comment"># Sur macOS/Linux :</span>
<span class="hljs-built_in">source</span> venv/bin/activate
<span class="hljs-comment"># Sur Windows :</span>
venv\Scripts\activate

<span class="hljs-comment"># Installer memvid</span>
pip install memvid

<span class="hljs-comment"># Pour le support PDF :</span>
pip install PyPDF2
</code></pre>
<h2>🎯 Démarrage Rapide</h2>
<h3>Utilisation de Base</h3>
<pre><code class="language-python hljs"><span class="hljs-keyword">from</span> memvid <span class="hljs-keyword">import</span> MemvidEncoder, MemvidChat

<span class="hljs-comment"># Créer une mémoire vidéo à partir de fragments de texte</span>
chunks = [<span class="hljs-string">"Fait important 1"</span>, <span class="hljs-string">"Fait important 2"</span>, <span class="hljs-string">"Détails d’un événement historique"</span>]
encoder = MemvidEncoder()
encoder.add_chunks(chunks)
encoder.build_video(<span class="hljs-string">"memory.mp4"</span>, <span class="hljs-string">"memory_index.json"</span>)

<span class="hljs-comment"># Discuter avec votre mémoire</span>
chat = MemvidChat(<span class="hljs-string">"memory.mp4"</span>, <span class="hljs-string">"memory_index.json"</span>)
chat.start_session()
response = chat.chat(<span class="hljs-string">"Que sais-tu des événements historiques ?"</span>)
<span class="hljs-built_in">print</span>(response)
</code></pre>
<h3>Créer une mémoire à partir de documents</h3>
<pre><code class="language-python hljs"><span class="hljs-keyword">from</span> memvid <span class="hljs-keyword">import</span> MemvidEncoder
<span class="hljs-keyword">import</span> os

<span class="hljs-comment"># Charger des documents</span>
encoder = MemvidEncoder(chunk_size=<span class="hljs-number">512</span>, overlap=<span class="hljs-number">50</span>)

<span class="hljs-comment"># Ajouter des fichiers texte</span>
<span class="hljs-keyword">for</span> file <span class="hljs-keyword">in</span> os.listdir(<span class="hljs-string">"documents"</span>):
    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">f"documents/<span class="hljs-subst">{file}</span>"</span>, <span class="hljs-string">"r"</span>) <span class="hljs-keyword">as</span> f:
        encoder.add_text(f.read(), metadata={<span class="hljs-string">"source"</span>: file})

<span class="hljs-comment"># Générer une vidéo optimisée</span>
encoder.build_video(
    <span class="hljs-string">"knowledge_base.mp4"</span>,
    <span class="hljs-string">"knowledge_index.json"</span>,
    fps=<span class="hljs-number">30</span>,  <span class="hljs-comment"># Plus de FPS = plus de fragments par seconde</span>
    frame_size=<span class="hljs-number">512</span>  <span class="hljs-comment"># Plus grande taille de frame = plus de données par frame</span>
)
</code></pre>
<h3>Recherche &amp; Récupération Avancées</h3>
<pre><code class="language-python hljs"><span class="hljs-keyword">from</span> memvid <span class="hljs-keyword">import</span> MemvidRetriever

<span class="hljs-comment"># Initialiser le récupérateur</span>
retriever = MemvidRetriever(<span class="hljs-string">"knowledge_base.mp4"</span>, <span class="hljs-string">"knowledge_index.json"</span>)

<span class="hljs-comment"># Recherche sémantique</span>
results = retriever.search(<span class="hljs-string">"algorithmes d’apprentissage automatique"</span>, top_k=<span class="hljs-number">5</span>)
<span class="hljs-keyword">for</span> chunk, score <span class="hljs-keyword">in</span> results:
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f"Score : <span class="hljs-subst">{score:<span class="hljs-number">.3</span>f}</span> | <span class="hljs-subst">{chunk[:<span class="hljs-number">100</span>]}</span>..."</span>)

<span class="hljs-comment"># Obtenir une fenêtre de contexte</span>
context = retriever.get_context(<span class="hljs-string">"expliquer les réseaux de neurones"</span>, max_tokens=<span class="hljs-number">2000</span>)
<span class="hljs-built_in">print</span>(context)
</code></pre>
<h3>Interface Chat Interactive</h3>
<pre><code class="language-python hljs"><span class="hljs-keyword">from</span> memvid <span class="hljs-keyword">import</span> MemvidInteractive

<span class="hljs-comment"># Lancer l’interface chat interactive</span>
interactive = MemvidInteractive(<span class="hljs-string">"knowledge_base.mp4"</span>, <span class="hljs-string">"knowledge_index.json"</span>)
interactive.run()  <span class="hljs-comment"># Ouvre l’interface web sur http://localhost:7860</span>
</code></pre>
<h3>Tester avec file_chat.py</h3>
<p>Le script <code>examples/file_chat.py</code> fournit un moyen complet de tester Memvid avec vos propres documents :</p>
<pre><code class="language-bash hljs"><span class="hljs-comment"># Traiter un dossier de documents</span>
python examples/file_chat.py --input-dir /path/to/documents --provider google

<span class="hljs-comment"># Traiter des fichiers spécifiques</span>
python examples/file_chat.py --files doc1.txt doc2.pdf --provider openai

<span class="hljs-comment"># Utiliser la compression H.265 (nécessite Docker)</span>
python examples/file_chat.py --input-dir docs/ --codec h265 --provider google

<span class="hljs-comment"># Fragmentation personnalisée pour les gros documents</span>
python examples/file_chat.py --files large.pdf --chunk-size 2048 --overlap 32 --provider google

<span class="hljs-comment"># Charger une mémoire existante</span>
python examples/file_chat.py --load-existing output/my_memory --provider google
</code></pre>
<h3>Exemple Complet : Discuter avec un livre PDF</h3>
<pre><code class="language-bash hljs"><span class="hljs-comment"># 1. Créer un nouveau dossier et configurer l’environnement</span>
<span class="hljs-built_in">mkdir</span> book-chat-demo
<span class="hljs-built_in">cd</span> book-chat-demo
python -m venv venv
<span class="hljs-built_in">source</span> venv/bin/activate  <span class="hljs-comment"># Sur Windows : venv\Scripts\activate</span>

<span class="hljs-comment"># 2. Installer les dépendances</span>
pip install memvid PyPDF2

<span class="hljs-comment"># 3. Créer book_chat.py</span>
<span class="hljs-built_in">cat</span> &gt; book_chat.py &lt;&lt; <span class="hljs-string">'EOF'</span>
from memvid import MemvidEncoder, chat_with_memory
import os

<span class="hljs-comment"># Votre fichier PDF</span>
book_pdf = <span class="hljs-string">"book.pdf"</span>  <span class="hljs-comment"># Remplacez par le chemin de votre PDF</span>

<span class="hljs-comment"># Construire la mémoire vidéo</span>
encoder = MemvidEncoder()
encoder.add_pdf(book_pdf)
encoder.build_video(<span class="hljs-string">"book_memory.mp4"</span>, <span class="hljs-string">"book_index.json"</span>)

<span class="hljs-comment"># Discuter avec le livre</span>
api_key = os.getenv(<span class="hljs-string">"OPENAI_API_KEY"</span>)  <span class="hljs-comment"># Optionnel : pour les réponses IA</span>
```python
chat_with_memory(<span class="hljs-string">"book_memory.mp4"</span>, <span class="hljs-string">"book_index.json"</span>, api_key=api_key)
EOF

<span class="hljs-comment"># 4. Exécutez-le</span>
<span class="hljs-built_in">export</span> OPENAI_API_KEY=<span class="hljs-string">"votre-clé-api"</span>  <span class="hljs-comment"># Optionnel</span>
python book_chat.py
</code></pre>
<h2>🛠️ Configuration avancée</h2>
<h3>Embeddings personnalisés</h3>
<pre><code class="language-python hljs"><span class="hljs-keyword">from</span> sentence_transformers <span class="hljs-keyword">import</span> SentenceTransformer

<span class="hljs-comment"># Utiliser un modèle d'embedding personnalisé</span>
custom_model = SentenceTransformer(<span class="hljs-string">'sentence-transformers/all-mpnet-base-v2'</span>)
encoder = MemvidEncoder(embedding_model=custom_model)
</code></pre>
<h3>Optimisation vidéo</h3>
<pre><code class="language-python hljs"><span class="hljs-comment"># Pour une compression maximale</span>
encoder.build_video(
    <span class="hljs-string">"compressed.mp4"</span>,
    <span class="hljs-string">"index.json"</span>,
    fps=<span class="hljs-number">60</span>,  <span class="hljs-comment"># Plus d'images par seconde</span>
    frame_size=<span class="hljs-number">256</span>,  <span class="hljs-comment"># Images plus petites</span>
    video_codec=<span class="hljs-string">'h265'</span>,  <span class="hljs-comment"># Meilleure compression</span>
    crf=<span class="hljs-number">28</span>  <span class="hljs-comment"># Qualité de compression (plus bas = meilleure qualité)</span>
)
</code></pre>
<h3>Traitement distribué</h3>
<pre><code class="language-python hljs"><span class="hljs-comment"># Traiter de grands ensembles de données en parallèle</span>
encoder = MemvidEncoder(n_workers=<span class="hljs-number">8</span>)
encoder.add_chunks_parallel(massive_chunk_list)
</code></pre>
<h2>🐛 Dépannage</h2>
<h3>Problèmes courants</h3>
<p><strong>ModuleNotFoundError: No module named 'memvid'</strong></p>
<pre><code class="language-bash hljs"><span class="hljs-comment"># Assurez-vous d'utiliser le bon Python</span>
<span class="hljs-built_in">which</span> python  <span class="hljs-comment"># Doit afficher le chemin de votre environnement virtuel</span>
<span class="hljs-comment"># Sinon, activez votre environnement virtuel :</span>
<span class="hljs-built_in">source</span> venv/bin/activate  <span class="hljs-comment"># Sous Windows : venv\Scripts\activate</span>
</code></pre>
<p><strong>ImportError: PyPDF2 is required for PDF support</strong></p>
<pre><code class="language-bash hljs">pip install PyPDF2
</code></pre>
<p><strong>Problèmes de clé API LLM</strong></p>
<pre><code class="language-bash hljs"><span class="hljs-comment"># Définir votre clé API (à obtenir sur https://platform.openai.com)</span>
<span class="hljs-built_in">export</span> GOOGLE_API_KEY=<span class="hljs-string">"AIzaSyB1-..."</span>  <span class="hljs-comment"># macOS/Linux</span>
<span class="hljs-comment"># Ou sous Windows :</span>
<span class="hljs-built_in">set</span> GOOGLE_API_KEY=AIzaSyB1-...
</code></pre>
<p><strong>Traitement de PDF volumineux</strong></p>
<pre><code class="language-python hljs"><span class="hljs-comment"># Pour les très gros PDF, utilisez des tailles de fragments plus petites</span>
encoder = MemvidEncoder()
encoder.add_pdf(<span class="hljs-string">"large_book.pdf"</span>, chunk_size=<span class="hljs-number">400</span>, overlap=<span class="hljs-number">50</span>)
</code></pre>
<h2>🤝 Contribuer</h2>
<p>Nous accueillons les contributions ! Veuillez consulter notre <a href="https://raw.githubusercontent.com/Olow304/memvid/main/CONTRIBUTING.md">Guide de contribution</a> pour plus de détails.</p>
<pre><code class="language-bash hljs"><span class="hljs-comment"># Exécuter les tests</span>
pytest tests/

<span class="hljs-comment"># Exécuter avec la couverture</span>
pytest --cov=memvid tests/

<span class="hljs-comment"># Formater le code</span>
black memvid/
</code></pre>
<h2>🆚 Comparaison avec les solutions traditionnelles</h2>
<table>
<thead>
<tr>
<th>Fonctionnalité</th>
<th>Memvid</th>
<th>Bases de données vectorielles</th>
<th>Bases de données traditionnelles</th>
</tr>
</thead>
<tbody><tr>
<td>Efficacité de stockage</td>
<td>⭐⭐⭐⭐⭐</td>
<td>⭐⭐</td>
<td>⭐⭐⭐</td>
</tr>
<tr>
<td>Complexité de mise en place</td>
<td>Simple</td>
<td>Complexe</td>
<td>Complexe</td>
</tr>
<tr>
<td>Recherche sémantique</td>
<td>✅</td>
<td>✅</td>
<td>❌</td>
</tr>
<tr>
<td>Utilisation hors ligne</td>
<td>✅</td>
<td>❌</td>
<td>✅</td>
</tr>
<tr>
<td>Portabilité</td>
<td>Basé sur fichier</td>
<td>Basé sur serveur</td>
<td>Basé sur serveur</td>
</tr>
<tr>
<td>Scalabilité</td>
<td>Millions</td>
<td>Millions</td>
<td>Milliards</td>
</tr>
<tr>
<td>Coût</td>
<td>Gratuit</td>
<td>$$$$</td>
<td>$$$</td>
</tr>
</tbody></table>
<h2>📚 Exemples</h2>
<p>Consultez le répertoire <a href="https://raw.githubusercontent.com/Olow304/memvid/main/examples/">examples/</a> pour :</p>
<ul>
<li>Construire une mémoire à partir de dumps Wikipedia</li>
<li>Créer une base de connaissances personnelle</li>
<li>Prise en charge multilingue</li>
<li>Mises à jour mémoire en temps réel</li>
<li>Intégration avec les LLMs populaires</li>
</ul>
<h2>🆘 Obtenir de l'aide</h2>
<ul>
<li>📖 <a href="https://github.com/olow304/memvid/wiki">Documentation</a> - Guides complets</li>
<li>💬 <a href="https://github.com/olow304/memvid/discussions">Discussions</a> - Posez vos questions</li>
<li>🐛 <a href="https://github.com/olow304/memvid/issues">Suivi des problèmes</a> - Signalez des bugs</li>
<li>🌟 <a href="https://github.com/olow304/memvid/discussions/categories/show-and-tell">Show &amp; Tell</a> - Partagez vos projets</li>
</ul>
<h2>🔗 Liens</h2>
<ul>
<li><a href="https://github.com/olow304/memvid">Dépôt GitHub</a></li>
<li><a href="https://pypi.org/project/memvid">Paquet PyPI</a></li>
<li><a href="https://github.com/olow304/memvid/releases">Changelog</a></li>
</ul>
<h2>📄 Licence</h2>
<p>Licence MIT - voir le fichier <a href="https://raw.githubusercontent.com/Olow304/memvid/main/LICENSE">LICENSE</a> pour plus de détails.</p>
<h2>🙏 Remerciements</h2>
<p>Créé par <a href="https://github.com/olow304">Olow304</a> et la communauté Memvid.</p>
<p>Développé avec ❤️ grâce à :</p>
<ul>
<li><a href="https://www.sbert.net/">sentence-transformers</a> - Embeddings de pointe pour la recherche sémantique</li>
<li><a href="https://opencv.org/">OpenCV</a> - Vision par ordinateur et traitement vidéo</li>
<li><a href="https://github.com/lincolnloop/python-qrcode">qrcode</a> - Génération de QR codes</li>
<li><a href="https://github.com/facebookresearch/faiss">FAISS</a> - Recherche de similarité efficace</li>
<li><a href="https://github.com/py-pdf/pypdf">PyPDF2</a> - Extraction de texte PDF</li>
</ul>
<p>Un grand merci à tous les contributeurs qui améliorent Memvid !</p>
<hr>
<p><strong>Prêt à révolutionner la gestion de la mémoire de votre IA ? Installez Memvid et commencez à bâtir !</strong> 🚀</p>
<pre><code class="hljs language-yaml">

<span class="hljs-meta">---

</span>
<span class="hljs-string">Tranlated</span> <span class="hljs-string">By</span> [<span class="hljs-string">Open</span> <span class="hljs-string">Ai</span> <span class="hljs-string">Tx</span>]<span class="hljs-string">(https://github.com/OpenAiTx/OpenAiTx)</span> <span class="hljs-string">|</span> <span class="hljs-attr">Last indexed:</span> <span class="hljs-number">2025-06-08</span>


<span class="hljs-meta">---
</span></code></pre>
</div>
    </div>

    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async=""></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
    


</body></html>