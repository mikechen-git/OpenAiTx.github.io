<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>memvid - Olow304/memvid</title>
    <meta name="title" content="memvid - Olow304/memvid">
    <meta name="description" content="Olow304/memvid - GitHub repository ja documentation and informationMemvid - ビデオベースAIメモリ 🧠📹 AIメモリを大規模に実現する軽量で革新的なソリューション Memvidはテキストデータを動画にエンコードすることでAIメモリ管理を革新し、数百万のテキストチャンクに対して超高速なセマンティック検索とサブセカンドの検索応答を実現します。従来のベクターデータベースのように大量のRAMやストレージを必要とせず、Memvidは知識ベースをコンパクトな動画ファイルに圧縮し、あらゆる情報への即時アクセスを可能にします。 🎥 デモ https://github.com/user-attachments/assets/ec550e93-e9c4-459f-a8a1-46e122b5851e ✨ 主な特徴 🎥 ビデオをデータベースとして利用: 数百万のテキストチャンクを1つのMP4ファイルに保存 🔍 セマンティック検索: 自然言語のクエリで関連コンテンツを検索 💬 内蔵チャット機能: 文脈を理解した会話型インターフェース 📚 PDF対応: PDFドキュメントを直接インポート・インデックス化 🚀 高速検索: 大規模データセットでもサブセカンドで検索 💾 効率的なストレージ: 従来型データベースの10倍の圧縮率 🔌 プラガブルなLLM対応: OpenAI、Anthropic、ローカルモデルに対応 🌐 オフラインファースト: 動画生成後はインターネット不要 🔧 シンプルなAPI: たった3行で利用開始 🎯 利用例 📖 デジタルライブラリ: 数千冊の書籍を1つの動画ファイルでインデックス 🎓 教育コンテンツ: 講義資料を検索可能な動画メモリに 📰 ニュースアーカイブ: 複数年分の記事を管理しやすい動画データベースに圧縮 💼 企業ナレッジ: 会社全体のナレッジベースを検索可能に構築 🔬 論文管理: 科学文献の高速セマンティック検索 📝 個人メモ: 自分のノートを検索可能なAIアシスタントに変換 🚀 Memvidを選ぶ理由 革新的なイノベーション ビデオをデータベースに: 数百万のテキストチャンクを1つのMP4ファイルに保存 瞬時の検索応答: 大規模データセットをサブセカンドでセマンティック検索 10倍のストレージ効率: 動画圧縮でメモリ使用量を劇的に削減 インフラ不要: データベースサーバー不要、どこでもコピー可能なファイルのみ オフラインファースト: 動画生成後は完全オフラインで動作 軽量なアーキテクチャ 最小限の依存関係: コア機能は約1000行のPythonコード CPUフレンドリー: GPU不要で効率的に動作 ポータブル: 1つの動画ファイルに知識ベース全体を格納 ストリーミング対応: 動画はクラウドストレージからストリーミング可能 📦 インストール クイックインストール pip install memvid PDFサポートを利用する場合 pip install memvid PyPDF2 推奨セットアップ（仮想環境） # 新しいプロジェクトディレクトリを作成 mkdir my-memvid-project cd my-memvid-project # 仮想環境を作成 python -m venv venv # 有効化 # macOS/Linuxの場合: source venv/bin/activate # Windowsの場合: venv\Scripts\activate # memvidをインストール pip install memvid # PDFサポートを利用する場合: pip install PyPDF2 🎯 クイックスタート 基本的な使い方 from memvid import MemvidEncoder, MemvidChat # テキストチャンクから動画メモリを作成 chunks = [&quot;重要な事実1&quot;, &quot;重要な事実2&quot;, &quot;歴史的な出来事の詳細&quot;] encoder = MemvidEncoder() encoder.add_chunks(chunks) encoder.build_video(&quot;memory.mp4&quot;, &quot;memory_index.json&quot;) # メモリとチャット chat = MemvidChat(&quot;memory.mp4&quot;, &quot;memory_index.json&quot;)...">
    <meta name="keywords" content="Olow304, memvid, GitHub, repository, ja documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/Olow304/memvid/README-ja.html">
    <meta property="og:title" content="memvid - Olow304/memvid">
    <meta property="og:description" content="Olow304/memvid - GitHub repository ja documentation and information">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/Olow304/memvid" id="githubRepoLink" target="_blank">Olow304/memvid</a>
<br>
<h1 style="display: none;">Memvid - ビデオベースAIメモリ 🧠📹 AIメモリを大規模に実現する軽量で革新的なソリューション Memvidはテキストデータを動画にエンコードすることでAIメモリ管理を革新し、数百万のテキストチャンクに対して超高速なセマンティック検索とサブセカンドの検索応答を実現します。従来のベクターデータベースのように大量のRAMやストレージを必要とせず、Memvidは知識ベースをコンパクトな動画ファイルに圧縮し、あらゆる情報への即時アクセスを可能にします。 🎥 デモ https://github.com/user-attachments/assets/ec550e93-e9c4-459f-a8a1-46e122b5851e ✨ 主な特徴 🎥 ビデオをデータベースとして利用: 数百万のテキストチャンクを1つのMP4ファイルに保存 🔍 セマンティック検索: 自然言語のクエリで関連コンテンツを検索 💬 内蔵チャット機能: 文脈を理解した会話型インターフェース 📚 PDF対応: PDFドキュメントを直接インポート・インデックス化 🚀 高速検索: 大規模データセットでもサブセカンドで検索 💾 効率的なストレージ: 従来型データベースの10倍の圧縮率 🔌 プラガブルなLLM対応: OpenAI、Anthropic、ローカルモデルに対応 🌐 オフラインファースト: 動画生成後はインターネット不要 🔧 シンプルなAPI: たった3行で利用開始 🎯 利用例 📖 デジタルライブラリ: 数千冊の書籍を1つの動画ファイルでインデックス 🎓 教育コンテンツ: 講義資料を検索可能な動画メモリに 📰 ニュースアーカイブ: 複数年分の記事を管理しやすい動画データベースに圧縮 💼 企業ナレッジ: 会社全体のナレッジベースを検索可能に構築 🔬 論文管理: 科学文献の高速セマンティック検索 📝 個人メモ: 自分のノートを検索可能なAIアシスタントに変換 🚀 Memvidを選ぶ理由 革新的なイノベーション ビデオをデータベースに: 数百万のテキストチャンクを1つのMP4ファイルに保存 瞬時の検索応答: 大規模データセットをサブセカンドでセマンティック検索 10倍のストレージ効率: 動画圧縮でメモリ使用量を劇的に削減 インフラ不要: データベースサーバー不要、どこでもコピー可能なファイルのみ オフラインファースト: 動画生成後は完全オフラインで動作 軽量なアーキテクチャ 最小限の依存関係: コア機能は約1000行のPythonコード CPUフレンドリー: GPU不要で効率的に動作 ポータブル: 1つの動画ファイルに知識ベース全体を格納 ストリーミング対応: 動画はクラウドストレージからストリーミング可能 📦 インストール クイックインストール pip install memvid PDFサポートを利用する場合 pip install memvid PyPDF2 推奨セットアップ（仮想環境） # 新しいプロジェクトディレクトリを作成 mkdir my-memvid-project cd my-memvid-project # 仮想環境を作成 python -m venv venv # 有効化 # macOS/Linuxの場合: source venv/bin/activate # Windowsの場合: venv\Scripts\activate # memvidをインストール pip install memvid # PDFサポートを利用する場合: pip install PyPDF2 🎯 クイックスタート 基本的な使い方 from memvid import MemvidEncoder, MemvidChat # テキストチャンクから動画メモリを作成 chunks = [&quot;重要な事実1&quot;, &quot;重要な事実2&quot;, &quot;歴史的な出来事の詳細&quot;] encoder = MemvidEncoder() encoder.add_chunks(chunks) encoder.build_video(&quot;memory.mp4&quot;, &quot;memory_index.json&quot;) # メモリとチャット chat = MemvidChat(&quot;memory.mp4&quot;, &quot;memory_index.json&quot;)...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <h1>Memvid - ビデオベースAIメモリ 🧠📹</h1>
<p><strong>AIメモリを大規模に実現する軽量で革新的なソリューション</strong></p>
<p><a href="https://pypi.org/project/memvid/"><img src="https://badge.fury.io/py/memvid.svg" alt="PyPI version" /></a>
<a href="https://opensource.org/licenses/MIT"><img src="https://img.shields.io/badge/License-MIT-yellow.svg" alt="License: MIT" /></a>
<a href="https://www.python.org/downloads/"><img src="https://img.shields.io/badge/python-3.8+-blue.svg" alt="Python 3.8+" /></a>
<a href="https://github.com/psf/black"><img src="https://img.shields.io/badge/code%20style-black-000000.svg" alt="Code style: black" /></a></p>
<p>Memvidはテキストデータを動画にエンコードすることでAIメモリ管理を革新し、<strong>数百万のテキストチャンクに対して超高速なセマンティック検索</strong>と<strong>サブセカンドの検索応答</strong>を実現します。従来のベクターデータベースのように大量のRAMやストレージを必要とせず、Memvidは知識ベースをコンパクトな動画ファイルに圧縮し、あらゆる情報への即時アクセスを可能にします。</p>
<h2>🎥 デモ</h2>
<p>https://github.com/user-attachments/assets/ec550e93-e9c4-459f-a8a1-46e122b5851e</p>
<h2>✨ 主な特徴</h2>
<ul>
<li>🎥 <strong>ビデオをデータベースとして利用</strong>: 数百万のテキストチャンクを1つのMP4ファイルに保存</li>
<li>🔍 <strong>セマンティック検索</strong>: 自然言語のクエリで関連コンテンツを検索</li>
<li>💬 <strong>内蔵チャット機能</strong>: 文脈を理解した会話型インターフェース</li>
<li>📚 <strong>PDF対応</strong>: PDFドキュメントを直接インポート・インデックス化</li>
<li>🚀 <strong>高速検索</strong>: 大規模データセットでもサブセカンドで検索</li>
<li>💾 <strong>効率的なストレージ</strong>: 従来型データベースの10倍の圧縮率</li>
<li>🔌 <strong>プラガブルなLLM対応</strong>: OpenAI、Anthropic、ローカルモデルに対応</li>
<li>🌐 <strong>オフラインファースト</strong>: 動画生成後はインターネット不要</li>
<li>🔧 <strong>シンプルなAPI</strong>: たった3行で利用開始</li>
</ul>
<h2>🎯 利用例</h2>
<ul>
<li><strong>📖 デジタルライブラリ</strong>: 数千冊の書籍を1つの動画ファイルでインデックス</li>
<li><strong>🎓 教育コンテンツ</strong>: 講義資料を検索可能な動画メモリに</li>
<li><strong>📰 ニュースアーカイブ</strong>: 複数年分の記事を管理しやすい動画データベースに圧縮</li>
<li><strong>💼 企業ナレッジ</strong>: 会社全体のナレッジベースを検索可能に構築</li>
<li><strong>🔬 論文管理</strong>: 科学文献の高速セマンティック検索</li>
<li><strong>📝 個人メモ</strong>: 自分のノートを検索可能なAIアシスタントに変換</li>
</ul>
<h2>🚀 Memvidを選ぶ理由</h2>
<h3>革新的なイノベーション</h3>
<ul>
<li><strong>ビデオをデータベースに</strong>: 数百万のテキストチャンクを1つのMP4ファイルに保存</li>
<li><strong>瞬時の検索応答</strong>: 大規模データセットをサブセカンドでセマンティック検索</li>
<li><strong>10倍のストレージ効率</strong>: 動画圧縮でメモリ使用量を劇的に削減</li>
<li><strong>インフラ不要</strong>: データベースサーバー不要、どこでもコピー可能なファイルのみ</li>
<li><strong>オフラインファースト</strong>: 動画生成後は完全オフラインで動作</li>
</ul>
<h3>軽量なアーキテクチャ</h3>
<ul>
<li><strong>最小限の依存関係</strong>: コア機能は約1000行のPythonコード</li>
<li><strong>CPUフレンドリー</strong>: GPU不要で効率的に動作</li>
<li><strong>ポータブル</strong>: 1つの動画ファイルに知識ベース全体を格納</li>
<li><strong>ストリーミング対応</strong>: 動画はクラウドストレージからストリーミング可能</li>
</ul>
<h2>📦 インストール</h2>
<h3>クイックインストール</h3>
<pre><code class="language-bash">pip install memvid
</code></pre>
<h3>PDFサポートを利用する場合</h3>
<pre><code class="language-bash">pip install memvid PyPDF2
</code></pre>
<h3>推奨セットアップ（仮想環境）</h3>
<pre><code class="language-bash"># 新しいプロジェクトディレクトリを作成
mkdir my-memvid-project
cd my-memvid-project

# 仮想環境を作成
python -m venv venv

# 有効化
# macOS/Linuxの場合:
source venv/bin/activate
# Windowsの場合:
venv\Scripts\activate

# memvidをインストール
pip install memvid

# PDFサポートを利用する場合:
pip install PyPDF2
</code></pre>
<h2>🎯 クイックスタート</h2>
<h3>基本的な使い方</h3>
<pre><code class="language-python">from memvid import MemvidEncoder, MemvidChat

# テキストチャンクから動画メモリを作成
chunks = [&quot;重要な事実1&quot;, &quot;重要な事実2&quot;, &quot;歴史的な出来事の詳細&quot;]
encoder = MemvidEncoder()
encoder.add_chunks(chunks)
encoder.build_video(&quot;memory.mp4&quot;, &quot;memory_index.json&quot;)

# メモリとチャット
chat = MemvidChat(&quot;memory.mp4&quot;, &quot;memory_index.json&quot;)
chat.start_session()
response = chat.chat(&quot;歴史的な出来事について何を知っていますか？&quot;)
print(response)
</code></pre>
<h3>ドキュメントからメモリを構築</h3>
<pre><code class="language-python">from memvid import MemvidEncoder
import os

# ドキュメントの読み込み
encoder = MemvidEncoder(chunk_size=512, overlap=50)

# テキストファイルを追加
for file in os.listdir(&quot;documents&quot;):
    with open(f&quot;documents/{file}&quot;, &quot;r&quot;) as f:
        encoder.add_text(f.read(), metadata={&quot;source&quot;: file})

# 最適化された動画を作成
encoder.build_video(
    &quot;knowledge_base.mp4&quot;,
    &quot;knowledge_index.json&quot;,
    fps=30,  # FPSが高いほど1秒あたりのチャンク数が増加
    frame_size=512  # フレームサイズが大きいほど1フレームあたりのデータ量が増加
)
</code></pre>
<h3>高度な検索・取得</h3>
<pre><code class="language-python">from memvid import MemvidRetriever

# リトリーバの初期化
retriever = MemvidRetriever(&quot;knowledge_base.mp4&quot;, &quot;knowledge_index.json&quot;)

# セマンティック検索
results = retriever.search(&quot;機械学習アルゴリズム&quot;, top_k=5)
for chunk, score in results:
    print(f&quot;Score: {score:.3f} | {chunk[:100]}...&quot;)

# コンテキストウィンドウの取得
context = retriever.get_context(&quot;ニューラルネットワークを説明して&quot;, max_tokens=2000)
print(context)
</code></pre>
<h3>インタラクティブチャットインターフェース</h3>
<pre><code class="language-python">from memvid import MemvidInteractive

# インタラクティブチャットUIを起動
interactive = MemvidInteractive(&quot;knowledge_base.mp4&quot;, &quot;knowledge_index.json&quot;)
interactive.run()  # Webインターフェースが http://localhost:7860 で開きます
</code></pre>
<h3>file_chat.py でのテスト</h3>
<p><code>examples/file_chat.py</code> スクリプトを使うことで、自分のドキュメントでMemvidを包括的にテストできます:</p>
<pre><code class="language-bash"># ドキュメントディレクトリを処理
python examples/file_chat.py --input-dir /path/to/documents --provider google

# 特定ファイルを処理
python examples/file_chat.py --files doc1.txt doc2.pdf --provider openai

# H.265圧縮を利用（Dockerが必要）
python examples/file_chat.py --input-dir docs/ --codec h265 --provider google

# 大きなドキュメント用にカスタムチャンク化
python examples/file_chat.py --files large.pdf --chunk-size 2048 --overlap 32 --provider google

# 既存メモリの読み込み
python examples/file_chat.py --load-existing output/my_memory --provider google
</code></pre>
<h3>完全例: PDF書籍とチャット</h3>
<pre><code class="language-bash"># 1. 新しいディレクトリを作成し環境をセットアップ
mkdir book-chat-demo
cd book-chat-demo
python -m venv venv
source venv/bin/activate  # Windowsの場合: venv\Scripts\activate

# 2. 依存関係をインストール
pip install memvid PyPDF2

# 3. book_chat.pyを作成
cat &gt; book_chat.py &lt;&lt; 'EOF'
from memvid import MemvidEncoder, chat_with_memory
import os

# あなたのPDFファイル
book_pdf = &quot;book.pdf&quot;  # あなたのPDFパスに置き換えてください

# 動画メモリを構築
encoder = MemvidEncoder()
encoder.add_pdf(book_pdf)
encoder.build_video(&quot;book_memory.mp4&quot;, &quot;book_index.json&quot;)

# 書籍とチャット
api_key = os.getenv(&quot;OPENAI_API_KEY&quot;)  # オプション: AI応答用
```markdown
chat_with_memory(&quot;book_memory.mp4&quot;, &quot;book_index.json&quot;, api_key=api_key)
EOF

# 4. 実行する
export OPENAI_API_KEY=&quot;your-api-key&quot;  # オプション
python book_chat.py
</code></pre>
<h2>🛠️ 高度な設定</h2>
<h3>カスタム埋め込み</h3>
<pre><code class="language-python">from sentence_transformers import SentenceTransformer

# カスタム埋め込みモデルを使用
custom_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')
encoder = MemvidEncoder(embedding_model=custom_model)
</code></pre>
<h3>ビデオ最適化</h3>
<pre><code class="language-python"># 最大圧縮のために
encoder.build_video(
    &quot;compressed.mp4&quot;,
    &quot;index.json&quot;,
    fps=60,  # フレームレートを上げる
    frame_size=256,  # フレームサイズを小さく
    video_codec='h265',  # より良い圧縮
    crf=28  # 圧縮品質（値が小さいほど高品質）
)
</code></pre>
<h3>分散処理</h3>
<pre><code class="language-python"># 大規模データセットを並列処理
encoder = MemvidEncoder(n_workers=8)
encoder.add_chunks_parallel(massive_chunk_list)
</code></pre>
<h2>🐛 トラブルシューティング</h2>
<h3>よくある問題</h3>
<p><strong>ModuleNotFoundError: No module named 'memvid'</strong></p>
<pre><code class="language-bash"># 正しいPythonを使っているか確認
which python  # 仮想環境のパスが表示されるはず
# そうでない場合は、仮想環境を有効化:
source venv/bin/activate  # Windowsの場合: venv\Scripts\activate
</code></pre>
<p><strong>ImportError: PyPDF2 is required for PDF support</strong></p>
<pre><code class="language-bash">pip install PyPDF2
</code></pre>
<p><strong>LLM APIキーの問題</strong></p>
<pre><code class="language-bash"># APIキーを設定（https://platform.openai.com で取得可能）
export GOOGLE_API_KEY=&quot;AIzaSyB1-...&quot;  # macOS/Linux
# Windowsの場合:
set GOOGLE_API_KEY=AIzaSyB1-...
</code></pre>
<p><strong>大容量PDFの処理</strong></p>
<pre><code class="language-python"># 非常に大きなPDFの場合、小さいチャンクサイズを使用
encoder = MemvidEncoder()
encoder.add_pdf(&quot;large_book.pdf&quot;, chunk_size=400, overlap=50)
</code></pre>
<h2>🤝 コントリビューション</h2>
<p>貢献を歓迎します！ 詳細は <a href="https://raw.githubusercontent.com/Olow304/memvid/main/CONTRIBUTING.md">CONTRIBUTINGガイド</a> をご覧ください。</p>
<pre><code class="language-bash"># テストを実行
pytest tests/

# カバレッジ付きで実行
pytest --cov=memvid tests/

# コードの整形
black memvid/
</code></pre>
<h2>🆚 従来型ソリューションとの比較</h2>
<p>| 機能 | Memvid | ベクトルDB | 従来型DB |
|---------|--------|------------|-----------------|
| 保存効率 | ⭐⭐⭐⭐⭐ | ⭐⭐ | ⭐⭐⭐ |
| セットアップの複雑さ | シンプル | 複雑 | 複雑 |
| セマンティック検索 | ✅ | ✅ | ❌ |
| オフライン利用 | ✅ | ❌ | ✅ |
| ポータビリティ | ファイルベース | サーバーベース | サーバーベース |
| スケーラビリティ | 数百万 | 数百万 | 数十億 |
| コスト | 無料 | $$$$ | $$$ |</p>
<h2>📚 例</h2>
<p><a href="https://raw.githubusercontent.com/Olow304/memvid/main/examples/">examples/</a> ディレクトリを参照してください:</p>
<ul>
<li>Wikipediaダンプからメモリを構築</li>
<li>個人ナレッジベースの作成</li>
<li>多言語対応</li>
<li>リアルタイムメモリアップデート</li>
<li>人気LLMとの統合</li>
</ul>
<h2>🆘 ヘルプを得るには</h2>
<ul>
<li>📖 <a href="https://github.com/olow304/memvid/wiki">ドキュメント</a> - 包括的なガイド</li>
<li>💬 <a href="https://github.com/olow304/memvid/discussions">ディスカッション</a> - 質問はこちら</li>
<li>🐛 <a href="https://github.com/olow304/memvid/issues">イシュートラッカー</a> - バグ報告</li>
<li>🌟 <a href="https://github.com/olow304/memvid/discussions/categories/show-and-tell">Show &amp; Tell</a> - プロジェクト共有</li>
</ul>
<h2>🔗 リンク</h2>
<ul>
<li><a href="https://github.com/olow304/memvid">GitHubリポジトリ</a></li>
<li><a href="https://pypi.org/project/memvid">PyPIパッケージ</a></li>
<li><a href="https://github.com/olow304/memvid/releases">Changelog</a></li>
</ul>
<h2>📄 ライセンス</h2>
<p>MITライセンス - 詳細は <a href="https://raw.githubusercontent.com/Olow304/memvid/main/LICENSE">LICENSE</a> ファイルを参照してください。</p>
<h2>🙏 謝辞</h2>
<p><a href="https://github.com/olow304">Olow304</a> と Memvid コミュニティによって作成されました。</p>
<p>❤️ を込めて以下を利用して構築:</p>
<ul>
<li><a href="https://www.sbert.net/">sentence-transformers</a> - セマンティック検索のための最先端埋め込み</li>
<li><a href="https://opencv.org/">OpenCV</a> - コンピュータビジョンおよびビデオ処理</li>
<li><a href="https://github.com/lincolnloop/python-qrcode">qrcode</a> - QRコード生成</li>
<li><a href="https://github.com/facebookresearch/faiss">FAISS</a> - 高効率な類似検索</li>
<li><a href="https://github.com/py-pdf/pypdf">PyPDF2</a> - PDFテキスト抽出</li>
</ul>
<p>Memvidをより良くするために貢献してくださった全ての方に感謝します！</p>
<hr />
<p><strong>AIのメモリ管理を革新する準備はできましたか？Memvidをインストールして構築を始めましょう！</strong> 🚀</p>
<pre><code>

---


Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-06-08


---
</code></pre>

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Statcounter and other scripts can be added here -->
</body>
</html>