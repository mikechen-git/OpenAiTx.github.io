<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>memvid - Olow304/memvid en</title>
    <meta name="title" content="memvid - Olow304/memvid en | Memvid - Video-Based AI Memory 🧠📹 The lightweight, game-changing solution for AI memory at scale Memvid revolutionizes AI memory management by encoding text d...">
    <meta name="description" content="Olow304/memvid - GitHub repository en documentation and information | Memvid - Video-Based AI Memory 🧠📹 The lightweight, game-changing solution for AI memory at scale Memvid revolutionizes AI memory management by encoding text d...">
    <meta name="keywords" content="Olow304, memvid, GitHub, repository, en documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/Olow304/memvid/README-en.html">
    <meta property="og:title" content="memvid - Olow304/memvid en | Memvid - Video-Based AI Memory 🧠📹 The lightweight, game-changing solution for AI memory at scale Memvid revolutionizes AI memory management by encoding text d...">
    <meta property="og:description" content="Olow304/memvid - GitHub repository en documentation and information | Memvid - Video-Based AI Memory 🧠📹 The lightweight, game-changing solution for AI memory at scale Memvid revolutionizes AI memory management by encoding text d...">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/Olow304/memvid" id="githubRepoLink" target="_blank">Olow304/memvid</a>
<h1 style="display: none;">Memvid - Video-Based AI Memory 🧠📹 The lightweight, game-changing solution for AI memory at scale Memvid revolutionizes AI memory management by encoding text d...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <h1>Memvid - Video-Based AI Memory 🧠📹</h1>
<p><strong>The lightweight, game-changing solution for AI memory at scale</strong></p>
<p><a href="https://pypi.org/project/memvid/"><img src="https://badge.fury.io/py/memvid.svg" alt="PyPI version" /></a>
<a href="https://opensource.org/licenses/MIT"><img src="https://img.shields.io/badge/License-MIT-yellow.svg" alt="License: MIT" /></a>
<a href="https://www.python.org/downloads/"><img src="https://img.shields.io/badge/python-3.8+-blue.svg" alt="Python 3.8+" /></a>
<a href="https://github.com/psf/black"><img src="https://img.shields.io/badge/code%20style-black-000000.svg" alt="Code style: black" /></a></p>
<p>Memvid revolutionizes AI memory management by encoding text data into videos, enabling <strong>lightning-fast semantic search</strong> across millions of text chunks with <strong>sub-second retrieval times</strong>. Unlike traditional vector databases that consume massive amounts of RAM and storage, Memvid compresses your knowledge base into compact video files while maintaining instant access to any piece of information.</p>
<h2>🎥 Demo</h2>
<p>https://github.com/user-attachments/assets/ec550e93-e9c4-459f-a8a1-46e122b5851e</p>
<h2>✨ Key Features</h2>
<ul>
<li>🎥 <strong>Video-as-Database</strong>: Store millions of text chunks in a single MP4 file</li>
<li>🔍 <strong>Semantic Search</strong>: Find relevant content using natural language queries</li>
<li>💬 <strong>Built-in Chat</strong>: Conversational interface with context-aware responses</li>
<li>📚 <strong>PDF Support</strong>: Direct import and indexing of PDF documents</li>
<li>🚀 <strong>Fast Retrieval</strong>: Sub-second search across massive datasets</li>
<li>💾 <strong>Efficient Storage</strong>: 10x compression compared to traditional databases</li>
<li>🔌 <strong>Pluggable LLMs</strong>: Works with OpenAI, Anthropic, or local models</li>
<li>🌐 <strong>Offline-First</strong>: No internet required after video generation</li>
<li>🔧 <strong>Simple API</strong>: Get started with just 3 lines of code</li>
</ul>
<h2>🎯 Use Cases</h2>
<ul>
<li><strong>📖 Digital Libraries</strong>: Index thousands of books in a single video file</li>
<li><strong>🎓 Educational Content</strong>: Create searchable video memories of course materials</li>
<li><strong>📰 News Archives</strong>: Compress years of articles into manageable video databases</li>
<li><strong>💼 Corporate Knowledge</strong>: Build company-wide searchable knowledge bases</li>
<li><strong>🔬 Research Papers</strong>: Quick semantic search across scientific literature</li>
<li><strong>📝 Personal Notes</strong>: Transform your notes into a searchable AI assistant</li>
</ul>
<h2>🚀 Why Memvid?</h2>
<h3>Game-Changing Innovation</h3>
<ul>
<li><strong>Video as Database</strong>: Store millions of text chunks in a single MP4 file</li>
<li><strong>Instant Retrieval</strong>: Sub-second semantic search across massive datasets</li>
<li><strong>10x Storage Efficiency</strong>: Video compression reduces memory footprint dramatically</li>
<li><strong>Zero Infrastructure</strong>: No database servers, just files you can copy anywhere</li>
<li><strong>Offline-First</strong>: Works completely offline once videos are generated</li>
</ul>
<h3>Lightweight Architecture</h3>
<ul>
<li><strong>Minimal Dependencies</strong>: Core functionality in ~1000 lines of Python</li>
<li><strong>CPU-Friendly</strong>: Runs efficiently without GPU requirements</li>
<li><strong>Portable</strong>: Single video file contains your entire knowledge base</li>
<li><strong>Streamable</strong>: Videos can be streamed from cloud storage</li>
</ul>
<h2>📦 Installation</h2>
<h3>Quick Install</h3>
<pre><code class="language-bash">pip install memvid
</code></pre>
<h3>For PDF Support</h3>
<pre><code class="language-bash">pip install memvid PyPDF2
</code></pre>
<h3>Recommended Setup (Virtual Environment)</h3>
<pre><code class="language-bash"># Create a new project directory
mkdir my-memvid-project
cd my-memvid-project

# Create virtual environment
python -m venv venv

# Activate it
# On macOS/Linux:
source venv/bin/activate
# On Windows:
venv\Scripts\activate

# Install memvid
pip install memvid

# For PDF support:
pip install PyPDF2
</code></pre>
<h2>🎯 Quick Start</h2>
<h3>Basic Usage</h3>
<pre><code class="language-python">from memvid import MemvidEncoder, MemvidChat

# Create video memory from text chunks
chunks = [&quot;Important fact 1&quot;, &quot;Important fact 2&quot;, &quot;Historical event details&quot;]
encoder = MemvidEncoder()
encoder.add_chunks(chunks)
encoder.build_video(&quot;memory.mp4&quot;, &quot;memory_index.json&quot;)

# Chat with your memory
chat = MemvidChat(&quot;memory.mp4&quot;, &quot;memory_index.json&quot;)
chat.start_session()
response = chat.chat(&quot;What do you know about historical events?&quot;)
print(response)
</code></pre>
<h3>Building Memory from Documents</h3>
<pre><code class="language-python">from memvid import MemvidEncoder
import os

# Load documents
encoder = MemvidEncoder(chunk_size=512, overlap=50)

# Add text files
for file in os.listdir(&quot;documents&quot;):
    with open(f&quot;documents/{file}&quot;, &quot;r&quot;) as f:
        encoder.add_text(f.read(), metadata={&quot;source&quot;: file})

# Build optimized video
encoder.build_video(
    &quot;knowledge_base.mp4&quot;,
    &quot;knowledge_index.json&quot;,
    fps=30,  # Higher FPS = more chunks per second
    frame_size=512  # Larger frames = more data per frame
)
</code></pre>
<h3>Advanced Search &amp; Retrieval</h3>
<pre><code class="language-python">from memvid import MemvidRetriever

# Initialize retriever
retriever = MemvidRetriever(&quot;knowledge_base.mp4&quot;, &quot;knowledge_index.json&quot;)

# Semantic search
results = retriever.search(&quot;machine learning algorithms&quot;, top_k=5)
for chunk, score in results:
    print(f&quot;Score: {score:.3f} | {chunk[:100]}...&quot;)

# Get context window
context = retriever.get_context(&quot;explain neural networks&quot;, max_tokens=2000)
print(context)
</code></pre>
<h3>Interactive Chat Interface</h3>
<pre><code class="language-python">from memvid import MemvidInteractive

# Launch interactive chat UI
interactive = MemvidInteractive(&quot;knowledge_base.mp4&quot;, &quot;knowledge_index.json&quot;)
interactive.run()  # Opens web interface at http://localhost:7860
</code></pre>
<h3>Testing with file_chat.py</h3>
<p>The <code>examples/file_chat.py</code> script provides a comprehensive way to test Memvid with your own documents:</p>
<pre><code class="language-bash"># Process a directory of documents
python examples/file_chat.py --input-dir /path/to/documents --provider google

# Process specific files
python examples/file_chat.py --files doc1.txt doc2.pdf --provider openai

# Use H.265 compression (requires Docker)
python examples/file_chat.py --input-dir docs/ --codec h265 --provider google

# Custom chunking for large documents
python examples/file_chat.py --files large.pdf --chunk-size 2048 --overlap 32 --provider google

# Load existing memory
python examples/file_chat.py --load-existing output/my_memory --provider google
</code></pre>
<h3>Complete Example: Chat with a PDF Book</h3>
<pre><code class="language-bash"># 1. Create a new directory and set up environment
mkdir book-chat-demo
cd book-chat-demo
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# 2. Install dependencies
pip install memvid PyPDF2

# 3. Create book_chat.py
cat &gt; book_chat.py &lt;&lt; 'EOF'
from memvid import MemvidEncoder, chat_with_memory
import os

# Your PDF file
book_pdf = &quot;book.pdf&quot;  # Replace with your PDF path

# Build video memory
encoder = MemvidEncoder()
encoder.add_pdf(book_pdf)
encoder.build_video(&quot;book_memory.mp4&quot;, &quot;book_index.json&quot;)

# Chat with the book
api_key = os.getenv(&quot;OPENAI_API_KEY&quot;)  # Optional: for AI responses
</code></pre>
<p>chat_with_memory(&quot;book_memory.mp4&quot;, &quot;book_index.json&quot;, api_key=api_key)
EOF</p>
<h1>4. Run it</h1>
<p>export OPENAI_API_KEY=&quot;your-api-key&quot;  # Optional
python book_chat.py</p>
<pre><code>
## 🛠️ Advanced Configuration

### Custom Embeddings
```python
from sentence_transformers import SentenceTransformer

# Use custom embedding model
custom_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')
encoder = MemvidEncoder(embedding_model=custom_model)
</code></pre>
<h3>Video Optimization</h3>
<pre><code class="language-python"># For maximum compression
encoder.build_video(
    &quot;compressed.mp4&quot;,
    &quot;index.json&quot;,
    fps=60,  # More frames per second
    frame_size=256,  # Smaller frames
    video_codec='h265',  # Better compression
    crf=28  # Compression quality (lower = better quality)
)
</code></pre>
<h3>Distributed Processing</h3>
<pre><code class="language-python"># Process large datasets in parallel
encoder = MemvidEncoder(n_workers=8)
encoder.add_chunks_parallel(massive_chunk_list)
</code></pre>
<h2>🐛 Troubleshooting</h2>
<h3>Common Issues</h3>
<p><strong>ModuleNotFoundError: No module named 'memvid'</strong></p>
<pre><code class="language-bash"># Make sure you're using the right Python
which python  # Should show your virtual environment path
# If not, activate your virtual environment:
source venv/bin/activate  # On Windows: venv\Scripts\activate
</code></pre>
<p><strong>ImportError: PyPDF2 is required for PDF support</strong></p>
<pre><code class="language-bash">pip install PyPDF2
</code></pre>
<p><strong>LLM API Key Issues</strong></p>
<pre><code class="language-bash"># Set your API key (get one at https://platform.openai.com)
export GOOGLE_API_KEY=&quot;AIzaSyB1-...&quot;  # macOS/Linux
# Or on Windows:
set GOOGLE_API_KEY=AIzaSyB1-...
</code></pre>
<p><strong>Large PDF Processing</strong></p>
<pre><code class="language-python"># For very large PDFs, use smaller chunk sizes
encoder = MemvidEncoder()
encoder.add_pdf(&quot;large_book.pdf&quot;, chunk_size=400, overlap=50)
</code></pre>
<h2>🤝 Contributing</h2>
<p>We welcome contributions! Please see our <a href="https://raw.githubusercontent.com/Olow304/memvid/main/CONTRIBUTING.md">Contributing Guide</a> for details.</p>
<pre><code class="language-bash"># Run tests
pytest tests/

# Run with coverage
pytest --cov=memvid tests/

# Format code
black memvid/
</code></pre>
<h2>🆚 Comparison with Traditional Solutions</h2>
<p>| Feature | Memvid | Vector DBs | Traditional DBs |
|---------|--------|------------|-----------------|
| Storage Efficiency | ⭐⭐⭐⭐⭐ | ⭐⭐ | ⭐⭐⭐ |
| Setup Complexity | Simple | Complex | Complex |
| Semantic Search | ✅ | ✅ | ❌ |
| Offline Usage | ✅ | ❌ | ✅ |
| Portability | File-based | Server-based | Server-based |
| Scalability | Millions | Millions | Billions |
| Cost | Free | $$$$ | $$$ |</p>
<h2>📚 Examples</h2>
<p>Check out the <a href="https://raw.githubusercontent.com/Olow304/memvid/main/examples/">examples/</a> directory for:</p>
<ul>
<li>Building memory from Wikipedia dumps</li>
<li>Creating a personal knowledge base</li>
<li>Multi-language support</li>
<li>Real-time memory updates</li>
<li>Integration with popular LLMs</li>
</ul>
<h2>🆘 Getting Help</h2>
<ul>
<li>📖 <a href="https://github.com/olow304/memvid/wiki">Documentation</a> - Comprehensive guides</li>
<li>💬 <a href="https://github.com/olow304/memvid/discussions">Discussions</a> - Ask questions</li>
<li>🐛 <a href="https://github.com/olow304/memvid/issues">Issue Tracker</a> - Report bugs</li>
<li>🌟 <a href="https://github.com/olow304/memvid/discussions/categories/show-and-tell">Show &amp; Tell</a> - Share your projects</li>
</ul>
<h2>🔗 Links</h2>
<ul>
<li><a href="https://github.com/olow304/memvid">GitHub Repository</a></li>
<li><a href="https://pypi.org/project/memvid">PyPI Package</a></li>
<li><a href="https://github.com/olow304/memvid/releases">Changelog</a></li>
</ul>
<h2>📄 License</h2>
<p>MIT License - see <a href="https://raw.githubusercontent.com/Olow304/memvid/main/LICENSE">LICENSE</a> file for details.</p>
<h2>🙏 Acknowledgments</h2>
<p>Created by <a href="https://github.com/olow304">Olow304</a> and the Memvid community.</p>
<p>Built with ❤️ using:</p>
<ul>
<li><a href="https://www.sbert.net/">sentence-transformers</a> - State-of-the-art embeddings for semantic search</li>
<li><a href="https://opencv.org/">OpenCV</a> - Computer vision and video processing</li>
<li><a href="https://github.com/lincolnloop/python-qrcode">qrcode</a> - QR code generation</li>
<li><a href="https://github.com/facebookresearch/faiss">FAISS</a> - Efficient similarity search</li>
<li><a href="https://github.com/py-pdf/pypdf">PyPDF2</a> - PDF text extraction</li>
</ul>
<p>Special thanks to all contributors who help make Memvid better!</p>
<hr />
<p><strong>Ready to revolutionize your AI memory management? Install Memvid and start building!</strong> 🚀</p>
<hr />
<p>Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx">Open Ai Tx</a> | Last indexed: 2025-06-08</p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
</body>
</html>