<!DOCTYPE html>
<html lang="th">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>KAI-Scheduler - NVIDIA/KAI-Scheduler</title>
    <meta name="title" content="KAI-Scheduler - NVIDIA/KAI-Scheduler">
    <meta name="description" content="NVIDIA/KAI-Scheduler - GitHub repository th documentation and informationKAI Scheduler KAI Scheduler เป็น Kubernetes scheduler ที่มีความเสถียร มีประสิทธิภาพ และสามารถขยายขนาดได้ ออกแบบมาเพื่อเพิ่มประสิทธิภาพการจัดสรรทรัพยากร GPU สำหรับงาน AI และ Machine Learning ออกแบบมาเพื่อบริหารจัดการคลัสเตอร์ GPU ขนาดใหญ่ที่มีโหนดนับพัน และรองรับปริมาณงานจำนวนมาก ทำให้ KAI Scheduler เหมาะสำหรับสภาพแวดล้อมขนาดใหญ่และต้องการสมรรถนะสูง KAI Scheduler ช่วยให้ผู้ดูแลระบบ Kubernetes สามารถจัดสรรทรัพยากร GPU ให้กับงานต่าง ๆ ได้แบบไดนามิก KAI Scheduler รองรับวงจรชีวิต AI ทั้งหมด ตั้งแต่งานขนาดเล็กที่ต้องการทรัพยากรน้อยและตอบสนองไว ไปจนถึงการฝึกสอนและทำนายผลขนาดใหญ่ ทั้งหมดในคลัสเตอร์เดียวกัน ช่วยให้มั่นใจว่าทรัพยากรถูกจัดสรรอย่างเหมาะสม พร้อมรักษาความเป็นธรรมระหว่างผู้ใช้งานที่แตกต่างกัน สามารถทำงานร่วมกับ scheduler อื่น ๆ ที่ติดตั้งในคลัสเตอร์ได้ คุณสมบัติเด่น Batch Scheduling: รับประกันว่าพ็อดทั้งหมดในกลุ่มจะถูกจัดสรรพร้อมกันหรือไม่ถูกจัดสรรเลย การบรรจุแบบ Bin Packing &amp; Spread Scheduling: เพิ่มประสิทธิภาพการใช้โหนดโดยลดการกระจัดกระจาย (bin-packing) หรือเพิ่มความทนทานและการกระจายโหลด (spread scheduling) Workload Priority: จัดลำดับความสำคัญของงานในคิวได้อย่างมีประสิทธิภาพ Hierarchical Queues: จัดการงานผ่านคิว 2 ระดับ เพื่อความยืดหยุ่นในการควบคุมขององค์กร Resource distribution: ปรับแต่งโควต้า น้ำหนักเกินโควต้า ขีดจำกัด และลำดับความสำคัญต่อคิว Fairness Policies: รับประกันการจัดสรรทรัพยากรอย่างเป็นธรรมด้วย Dominant Resource Fairness (DRF) และการเรียกคืนทรัพยากรข้ามคิว Workload Consolidation: จัดสรรงานที่กำลังทำงานใหม่อย่างชาญฉลาดเพื่อลดการกระจัดกระจายและเพิ่มการใช้คลัสเตอร์ Elastic Workloads: ปรับขนาดงานแบบไดนามิกภายในจำนวนพ็อดขั้นต่ำและสูงสุดที่กำหนด Dynamic Resource Allocation (DRA): รองรับทรัพยากรฮาร์ดแวร์เฉพาะผู้ผลิตผ่าน Kubernetes ResourceClaims (เช่น GPU จาก NVIDIA หรือ AMD) GPU Sharing: อนุญาตให้งานหลายรายการแชร์ GPU เดียวหรือหลายตัวได้อย่างมีประสิทธิภาพ เพื่อใช้ทรัพยากรอย่างสูงสุด รองรับ Cloud &amp; On-premise: ใช้งานร่วมกับโครงสร้างพื้นฐาน Cloud แบบไดนามิก (รวมถึง auto-scalers เช่น Karpenter) และการติดตั้งแบบ On-premise ข้อกำหนดเบื้องต้น ก่อนติดตั้ง KAI Scheduler ให้ตรวจสอบว่าคุณมี: คลัสเตอร์ Kubernetes ที่กำลังทำงานอยู่ ติดตั้ง Helm CLI แล้ว ติดตั้ง NVIDIA GPU-Operator เพื่อให้สามารถจัดสรรงานที่ขอใช้ทรัพยากร GPU การติดตั้ง KAI Scheduler จะถูกติดตั้งใน namespace kai-scheduler เมื่อส่งงาน ให้ใช้...">
    <meta name="keywords" content="NVIDIA, KAI-Scheduler, GitHub, repository, th documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/NVIDIA/KAI-Scheduler/README-th.html">
    <meta property="og:title" content="KAI-Scheduler - NVIDIA/KAI-Scheduler">
    <meta property="og:description" content="NVIDIA/KAI-Scheduler - GitHub repository th documentation and information">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/NVIDIA/KAI-Scheduler" id="githubRepoLink" target="_blank">NVIDIA/KAI-Scheduler</a>
<br>
<h1 style="display: none;">KAI Scheduler KAI Scheduler เป็น Kubernetes scheduler ที่มีความเสถียร มีประสิทธิภาพ และสามารถขยายขนาดได้ ออกแบบมาเพื่อเพิ่มประสิทธิภาพการจัดสรรทรัพยากร GPU สำหรับงาน AI และ Machine Learning ออกแบบมาเพื่อบริหารจัดการคลัสเตอร์ GPU ขนาดใหญ่ที่มีโหนดนับพัน และรองรับปริมาณงานจำนวนมาก ทำให้ KAI Scheduler เหมาะสำหรับสภาพแวดล้อมขนาดใหญ่และต้องการสมรรถนะสูง KAI Scheduler ช่วยให้ผู้ดูแลระบบ Kubernetes สามารถจัดสรรทรัพยากร GPU ให้กับงานต่าง ๆ ได้แบบไดนามิก KAI Scheduler รองรับวงจรชีวิต AI ทั้งหมด ตั้งแต่งานขนาดเล็กที่ต้องการทรัพยากรน้อยและตอบสนองไว ไปจนถึงการฝึกสอนและทำนายผลขนาดใหญ่ ทั้งหมดในคลัสเตอร์เดียวกัน ช่วยให้มั่นใจว่าทรัพยากรถูกจัดสรรอย่างเหมาะสม พร้อมรักษาความเป็นธรรมระหว่างผู้ใช้งานที่แตกต่างกัน สามารถทำงานร่วมกับ scheduler อื่น ๆ ที่ติดตั้งในคลัสเตอร์ได้ คุณสมบัติเด่น Batch Scheduling: รับประกันว่าพ็อดทั้งหมดในกลุ่มจะถูกจัดสรรพร้อมกันหรือไม่ถูกจัดสรรเลย การบรรจุแบบ Bin Packing &amp; Spread Scheduling: เพิ่มประสิทธิภาพการใช้โหนดโดยลดการกระจัดกระจาย (bin-packing) หรือเพิ่มความทนทานและการกระจายโหลด (spread scheduling) Workload Priority: จัดลำดับความสำคัญของงานในคิวได้อย่างมีประสิทธิภาพ Hierarchical Queues: จัดการงานผ่านคิว 2 ระดับ เพื่อความยืดหยุ่นในการควบคุมขององค์กร Resource distribution: ปรับแต่งโควต้า น้ำหนักเกินโควต้า ขีดจำกัด และลำดับความสำคัญต่อคิว Fairness Policies: รับประกันการจัดสรรทรัพยากรอย่างเป็นธรรมด้วย Dominant Resource Fairness (DRF) และการเรียกคืนทรัพยากรข้ามคิว Workload Consolidation: จัดสรรงานที่กำลังทำงานใหม่อย่างชาญฉลาดเพื่อลดการกระจัดกระจายและเพิ่มการใช้คลัสเตอร์ Elastic Workloads: ปรับขนาดงานแบบไดนามิกภายในจำนวนพ็อดขั้นต่ำและสูงสุดที่กำหนด Dynamic Resource Allocation (DRA): รองรับทรัพยากรฮาร์ดแวร์เฉพาะผู้ผลิตผ่าน Kubernetes ResourceClaims (เช่น GPU จาก NVIDIA หรือ AMD) GPU Sharing: อนุญาตให้งานหลายรายการแชร์ GPU เดียวหรือหลายตัวได้อย่างมีประสิทธิภาพ เพื่อใช้ทรัพยากรอย่างสูงสุด รองรับ Cloud &amp; On-premise: ใช้งานร่วมกับโครงสร้างพื้นฐาน Cloud แบบไดนามิก (รวมถึง auto-scalers เช่น Karpenter) และการติดตั้งแบบ On-premise ข้อกำหนดเบื้องต้น ก่อนติดตั้ง KAI Scheduler ให้ตรวจสอบว่าคุณมี: คลัสเตอร์ Kubernetes ที่กำลังทำงานอยู่ ติดตั้ง Helm CLI แล้ว ติดตั้ง NVIDIA GPU-Operator เพื่อให้สามารถจัดสรรงานที่ขอใช้ทรัพยากร GPU การติดตั้ง KAI Scheduler จะถูกติดตั้งใน namespace kai-scheduler เมื่อส่งงาน ให้ใช้...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <p><a href="LICENSE"><img src="https://img.shields.io/badge/License-Apache_2.0-blue.svg" alt="License" /></a> <a href="https://github.com/NVIDIA/KAI-Scheduler/blob/main/.github/workflows/update-coverage-badge.yaml"><img src="https://github.com/NVIDIA/KAI-Scheduler/raw/coverage-badge/badges/coverage.svg" alt="Coverage" /></a></p>
<h1>KAI Scheduler</h1>
<p>KAI Scheduler เป็น <a href="https://kubernetes.io/docs/concepts/scheduling-eviction/kube-scheduler/">Kubernetes scheduler</a> ที่มีความเสถียร มีประสิทธิภาพ และสามารถขยายขนาดได้ ออกแบบมาเพื่อเพิ่มประสิทธิภาพการจัดสรรทรัพยากร GPU สำหรับงาน AI และ Machine Learning</p>
<p>ออกแบบมาเพื่อบริหารจัดการคลัสเตอร์ GPU ขนาดใหญ่ที่มีโหนดนับพัน และรองรับปริมาณงานจำนวนมาก ทำให้ KAI Scheduler เหมาะสำหรับสภาพแวดล้อมขนาดใหญ่และต้องการสมรรถนะสูง
KAI Scheduler ช่วยให้ผู้ดูแลระบบ Kubernetes สามารถจัดสรรทรัพยากร GPU ให้กับงานต่าง ๆ ได้แบบไดนามิก</p>
<p>KAI Scheduler รองรับวงจรชีวิต AI ทั้งหมด ตั้งแต่งานขนาดเล็กที่ต้องการทรัพยากรน้อยและตอบสนองไว ไปจนถึงการฝึกสอนและทำนายผลขนาดใหญ่ ทั้งหมดในคลัสเตอร์เดียวกัน
ช่วยให้มั่นใจว่าทรัพยากรถูกจัดสรรอย่างเหมาะสม พร้อมรักษาความเป็นธรรมระหว่างผู้ใช้งานที่แตกต่างกัน
สามารถทำงานร่วมกับ scheduler อื่น ๆ ที่ติดตั้งในคลัสเตอร์ได้</p>
<h2>คุณสมบัติเด่น</h2>
<ul>
<li><a href="docs/batch/README.md">Batch Scheduling</a>: รับประกันว่าพ็อดทั้งหมดในกลุ่มจะถูกจัดสรรพร้อมกันหรือไม่ถูกจัดสรรเลย</li>
<li>การบรรจุแบบ Bin Packing &amp; Spread Scheduling: เพิ่มประสิทธิภาพการใช้โหนดโดยลดการกระจัดกระจาย (bin-packing) หรือเพิ่มความทนทานและการกระจายโหลด (spread scheduling)</li>
<li><a href="docs/priority/README.md">Workload Priority</a>: จัดลำดับความสำคัญของงานในคิวได้อย่างมีประสิทธิภาพ</li>
<li><a href="docs/queues/README.md">Hierarchical Queues</a>: จัดการงานผ่านคิว 2 ระดับ เพื่อความยืดหยุ่นในการควบคุมขององค์กร</li>
<li><a href="docs/fairness/README.md#resource-division-algorithm">Resource distribution</a>: ปรับแต่งโควต้า น้ำหนักเกินโควต้า ขีดจำกัด และลำดับความสำคัญต่อคิว</li>
<li><a href="docs/fairness/README.md#reclaim-strategies">Fairness Policies</a>: รับประกันการจัดสรรทรัพยากรอย่างเป็นธรรมด้วย Dominant Resource Fairness (DRF) และการเรียกคืนทรัพยากรข้ามคิว</li>
<li>Workload Consolidation: จัดสรรงานที่กำลังทำงานใหม่อย่างชาญฉลาดเพื่อลดการกระจัดกระจายและเพิ่มการใช้คลัสเตอร์</li>
<li><a href="docs/elastic/README.md">Elastic Workloads</a>: ปรับขนาดงานแบบไดนามิกภายในจำนวนพ็อดขั้นต่ำและสูงสุดที่กำหนด</li>
<li>Dynamic Resource Allocation (DRA): รองรับทรัพยากรฮาร์ดแวร์เฉพาะผู้ผลิตผ่าน Kubernetes ResourceClaims (เช่น GPU จาก NVIDIA หรือ AMD)</li>
<li><a href="docs/gpu-sharing/README.md">GPU Sharing</a>: อนุญาตให้งานหลายรายการแชร์ GPU เดียวหรือหลายตัวได้อย่างมีประสิทธิภาพ เพื่อใช้ทรัพยากรอย่างสูงสุด</li>
<li>รองรับ Cloud &amp; On-premise: ใช้งานร่วมกับโครงสร้างพื้นฐาน Cloud แบบไดนามิก (รวมถึง auto-scalers เช่น Karpenter) และการติดตั้งแบบ On-premise</li>
</ul>
<h2>ข้อกำหนดเบื้องต้น</h2>
<p>ก่อนติดตั้ง KAI Scheduler ให้ตรวจสอบว่าคุณมี:</p>
<ul>
<li>คลัสเตอร์ Kubernetes ที่กำลังทำงานอยู่</li>
<li>ติดตั้ง <a href="https://helm.sh/docs/intro/install">Helm</a> CLI แล้ว</li>
<li>ติดตั้ง <a href="https://github.com/NVIDIA/gpu-operator">NVIDIA GPU-Operator</a> เพื่อให้สามารถจัดสรรงานที่ขอใช้ทรัพยากร GPU</li>
</ul>
<h2>การติดตั้ง</h2>
<p>KAI Scheduler จะถูกติดตั้งใน namespace <code>kai-scheduler</code> เมื่อส่งงาน ให้ใช้ namespace แยกเฉพาะ</p>
<h3>วิธีการติดตั้ง</h3>
<p>KAI Scheduler สามารถติดตั้งได้โดย:</p>
<ul>
<li><strong>จาก Production (แนะนำ)</strong></li>
<li><strong>จาก Source (Build it Yourself)</strong></li>
</ul>
<h4>ติดตั้งจาก Production</h4>
<p>ค้นหาเวอร์ชันล่าสุดที่หน้า <a href="https://github.com/NVIDIA/KAI-Scheduler/releases">releases</a>
รันคำสั่งด้านล่างโดยแทนที่ <code>&lt;VERSION&gt;</code> ด้วยเวอร์ชันที่ต้องการ:</p>
<pre><code class="language-sh">helm upgrade -i kai-scheduler oci://ghcr.io/nvidia/kai-scheduler/kai-scheduler -n kai-scheduler --create-namespace --version &lt;VERSION&gt;
</code></pre>
<h4>Build จาก Source</h4>
<p>ปฏิบัติตามคำแนะนำ <a href="docs/developer/building-from-source.md">ที่นี่</a></p>
<h2>เริ่มต้นอย่างรวดเร็ว</h2>
<p>หากต้องการเริ่มจัดสรรงานด้วย KAI Scheduler โปรดดูตัวอย่าง <a href="docs/quickstart/README.md">Quick Start</a></p>
<h2>แผนการดำเนินงาน</h2>
<h3>ภาพรวมลำดับความสำคัญหลักสำหรับปี 2025</h3>
<ul>
<li>ปรับโครงสร้างโค้ดเพื่อรองรับการใช้งานแบบเป็นกลางทางผู้ผลิต (vendor neutrality)</li>
<li>รองรับ Scheduling Gates https://github.com/NVIDIA/KAI-Scheduler/issues/63</li>
<li>ศึกษาความเป็นไปได้ในการเชื่อมต่อกับ Kueue https://github.com/NVIDIA/KAI-Scheduler/issues/68</li>
<li>เพิ่มการรองรับ Topology Aware Scheduling สำหรับ pod-group https://github.com/NVIDIA/KAI-Scheduler/issues/66</li>
<li>รองรับ Min Run Time ต่อ workload</li>
<li>รองรับ Max Run Time ต่อ workload (พร้อม delayed requeue)</li>
<li>เพิ่ม PriorityClasses หลายรายการเป็นค่าเริ่มต้นในการติดตั้ง KAI</li>
<li>รองรับ JobSet</li>
<li>รองรับ LWS (LeaderWorkerSet)</li>
<li>เพิ่ม metric สำหรับ pod และ pod-group preemptions</li>
<li>แยกการทำงานของ Priority และ Preemption</li>
</ul>
<h3>เป้าหมายระยะยาว</h3>
<ul>
<li>รองรับการ time decay ต่อคิว</li>
<li>ปรับปรุงความสามารถในการขยายขนาด (hyper scale)</li>
<li>รองรับ Consolidation ของ Inference workload เพื่อลดการกระจัดกระจายของคลัสเตอร์</li>
<li>รองรับคิวแบบลำดับชั้น n-levels</li>
<li>Rollout งาน Inference อย่างปลอดภัย (new revision update โดยใช้ queue temporary over-quota)</li>
</ul>
<h2>ชุมชน การพูดคุย และการสนับสนุน</h2>
<p>เรายินดีรับฟังความคิดเห็นจากคุณ! ช่องทางติดต่อที่ดีที่สุดมีดังนี้:</p>
<h3>Slack</h3>
<p>เข้าร่วม <a href="https://communityinviter.com/apps/cloud-native/cncf">CNCF Slack</a> ก่อน และเยี่ยมชมช่อง <a href="https://cloud-native.slack.com/archives/kai-scheduler">#kai-scheduler</a></p>
<h3>ประชุมชุมชนทุกสองสัปดาห์</h3>
<p><strong>เมื่อ:</strong> ทุกวันจันทร์สัปดาห์เว้นสัปดาห์ เวลา 17:00 CEST<br />
<a href="https://dateful.com/time-zone-converter?t=17&amp;tz2=Germany">แปลงเวลาเป็นเขตเวลาของคุณ</a> | <a href="https://calendar.google.com/calendar/event?action=TEMPLATE&amp;tmeid=N2Q2bjhoNXAzMGc0cWpnZTQ4OGtpdXFhanFfMjAyNTA2MDlUMTUwMDAwWiAxZjQ2OTZiOWVlM2JiMWE1ZWIzMTAwODBkNDZiZmMwMDZjNTUxYWFiZmU1YTM3ZGM2YTc0NTFhYmNhMmE1ODk0QGc&amp;tmsrc=1f4696b9ee3bb1a5eb310080d46bfc006c551aabfe5a37dc6a7451abca2a5894%40group.calendar.google.com&amp;scp=ALL">เพิ่มลงในปฏิทินของคุณ</a>  | <a href="https://docs.google.com/document/d/13K7NGdPebOstlrsif1YLjGz1x-aJafMXeIgqbO7WghI/edit?usp=sharing">บันทึกการประชุม &amp; วาระการประชุม</a></p>
<h3>Mailing List</h3>
<p>เข้าร่วม <a href="https://groups.google.com/g/kai-scheduler">kai-scheduler mailing list</a> เพื่อรับข่าวสารอัปเดตการประชุมประจำสัปดาห์</p>
<h3>ปัญหาทางเทคนิค &amp; ขอฟีเจอร์</h3>
<p>โปรดเปิด <a href="https://github.com/NVIDIA/KAI-Scheduler/issues/new/choose">GitHub issue</a> สำหรับแจ้งบั๊ก เสนอฟีเจอร์ หรือขอความช่วยเหลือทางเทคนิค เพื่อให้เราติดตามคำขอและตอบกลับได้อย่างมีประสิทธิภาพ</p>
<hr />
<p>Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx">Open Ai Tx</a> | Last indexed: 2025-06-08</p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Statcounter and other scripts can be added here -->
</body>
</html>