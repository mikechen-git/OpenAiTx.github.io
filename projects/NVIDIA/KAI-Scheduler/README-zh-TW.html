<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>KAI-Scheduler - NVIDIA/KAI-Scheduler</title>
    <meta name="title" content="KAI-Scheduler - NVIDIA/KAI-Scheduler">
    <meta name="description" content="NVIDIA/KAI-Scheduler - GitHub repository zh-TW documentation and informationKAI Scheduler KAI Scheduler 是一個強大、高效且可擴展的 Kubernetes 排程器，專為優化 AI 及機器學習工作負載的 GPU 資源分配而設計。 KAI Scheduler 專為管理大規模 GPU 叢集（包含數千個節點）與高吞吐量工作負載而設計，非常適合龐大且高需求的環境。 KAI Scheduler 允許 Kubernetes 叢集管理員動態分配 GPU 資源給各種工作負載。 KAI Scheduler 支援完整的 AI 生命週期，從需要最小資源的小型互動式作業，到大型訓練與推論工作，都可在同一叢集內運行。 它確保最佳資源分配，同時維持不同消費者之間的資源公平性。 可與叢集上安裝的其他排程器並行運行。 主要功能 批次排程：確保同一群組內所有 pod 要麼同時排程，要麼全部不排程。 資源裝箱與分散排程：通過最小化碎片化（裝箱）或增加彈性與負載平衡（分散排程）來優化節點使用率。 工作負載優先順序：在佇列中有效地設定工作負載優先順序。 階層式佇列：利用二層佇列階層管理工作負載，提供彈性的組織控管。 資源分配：可自訂每個佇列的配額、超額配額權重、限制與優先順序。 公平性策略：利用主導資源公平性（DRF）及資源回收機制，確保跨佇列的資源公平分配。 工作負載整併：智慧地重新分配運行中的工作負載，以減少碎片並提高叢集使用率。 彈性工作負載：可在定義的最小與最大 pod 數量範圍內動態調整工作負載規模。 動態資源分配（DRA）：通過 Kubernetes ResourceClaims 支援廠商專屬硬體資源（如 NVIDIA 或 AMD 的 GPU）。 GPU 共用：允許多個工作負載高效共用單顆或多顆 GPU，最大化資源利用率。 雲端與地端支援：完全相容於動態雲端基礎設施（包含如 Karpenter 的自動擴縮器）及靜態地端部署。 先決條件 安裝 KAI Scheduler 前，請確保您已經具備： 正在運行的 Kubernetes 叢集 已安裝 Helm CLI 已安裝 NVIDIA GPU-Operator，以便排程要求 GPU 資源的工作負載 安裝方式 KAI Scheduler 將安裝於 kai-scheduler 命名空間。提交工作負載時請務必使用專屬命名空間。 安裝方法 KAI Scheduler 可以透過以下方式安裝： 從正式版本安裝（建議） 從原始碼建構（自行編譯） 從正式版本安裝 請至 releases 頁面找到最新發行版本。 將 &lt;VERSION&gt; 替換為所需的發行版本後，執行下列指令： helm upgrade -i kai-scheduler oci://ghcr.io/nvidia/kai-scheduler/kai-scheduler -n kai-scheduler --create-namespace --version &lt;VERSION&gt; 從原始碼建構 請依照這裡的說明進行 快速開始 若要開始使用 KAI Scheduler 排程工作負載，請參考快速開始範例 發展藍圖 2025 年主要優先事項概覽 重構程式碼基礎以提升廠商中立性 支援 Scheduling Gates https://github.com/NVIDIA/KAI-Scheduler/issues/63 研究與 Kueue 的可能整合 https://github.com/NVIDIA/KAI-Scheduler/issues/68 新增 pod-group 的拓撲感知排程支援 https://github.com/NVIDIA/KAI-Scheduler/issues/66 支援每個工作負載的最小運行時間 支援每個工作負載的最大運行時間（含延遲重排隊機制） 預設 KAI 安裝新增更多 PriorityClasses 支援 JobSet 支援 LWS (LeaderWorkerSet) 新增 pod 與 pod-group 搶占相關度量指標 解耦優先順序與搶占機制 長期目標 支援每個佇列的時間衰減 超大規模擴展改進 支援推論型工作負載的整併，以促進叢集碎片化修復 支援 n 層階層佇列...">
    <meta name="keywords" content="NVIDIA, KAI-Scheduler, GitHub, repository, zh-TW documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/NVIDIA/KAI-Scheduler/README-zh-TW.html">
    <meta property="og:title" content="KAI-Scheduler - NVIDIA/KAI-Scheduler">
    <meta property="og:description" content="NVIDIA/KAI-Scheduler - GitHub repository zh-TW documentation and information">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/NVIDIA/KAI-Scheduler" id="githubRepoLink" target="_blank">NVIDIA/KAI-Scheduler</a>
<br>
<h1 style="display: none;">KAI Scheduler KAI Scheduler 是一個強大、高效且可擴展的 Kubernetes 排程器，專為優化 AI 及機器學習工作負載的 GPU 資源分配而設計。 KAI Scheduler 專為管理大規模 GPU 叢集（包含數千個節點）與高吞吐量工作負載而設計，非常適合龐大且高需求的環境。 KAI Scheduler 允許 Kubernetes 叢集管理員動態分配 GPU 資源給各種工作負載。 KAI Scheduler 支援完整的 AI 生命週期，從需要最小資源的小型互動式作業，到大型訓練與推論工作，都可在同一叢集內運行。 它確保最佳資源分配，同時維持不同消費者之間的資源公平性。 可與叢集上安裝的其他排程器並行運行。 主要功能 批次排程：確保同一群組內所有 pod 要麼同時排程，要麼全部不排程。 資源裝箱與分散排程：通過最小化碎片化（裝箱）或增加彈性與負載平衡（分散排程）來優化節點使用率。 工作負載優先順序：在佇列中有效地設定工作負載優先順序。 階層式佇列：利用二層佇列階層管理工作負載，提供彈性的組織控管。 資源分配：可自訂每個佇列的配額、超額配額權重、限制與優先順序。 公平性策略：利用主導資源公平性（DRF）及資源回收機制，確保跨佇列的資源公平分配。 工作負載整併：智慧地重新分配運行中的工作負載，以減少碎片並提高叢集使用率。 彈性工作負載：可在定義的最小與最大 pod 數量範圍內動態調整工作負載規模。 動態資源分配（DRA）：通過 Kubernetes ResourceClaims 支援廠商專屬硬體資源（如 NVIDIA 或 AMD 的 GPU）。 GPU 共用：允許多個工作負載高效共用單顆或多顆 GPU，最大化資源利用率。 雲端與地端支援：完全相容於動態雲端基礎設施（包含如 Karpenter 的自動擴縮器）及靜態地端部署。 先決條件 安裝 KAI Scheduler 前，請確保您已經具備： 正在運行的 Kubernetes 叢集 已安裝 Helm CLI 已安裝 NVIDIA GPU-Operator，以便排程要求 GPU 資源的工作負載 安裝方式 KAI Scheduler 將安裝於 kai-scheduler 命名空間。提交工作負載時請務必使用專屬命名空間。 安裝方法 KAI Scheduler 可以透過以下方式安裝： 從正式版本安裝（建議） 從原始碼建構（自行編譯） 從正式版本安裝 請至 releases 頁面找到最新發行版本。 將 &lt;VERSION&gt; 替換為所需的發行版本後，執行下列指令： helm upgrade -i kai-scheduler oci://ghcr.io/nvidia/kai-scheduler/kai-scheduler -n kai-scheduler --create-namespace --version &lt;VERSION&gt; 從原始碼建構 請依照這裡的說明進行 快速開始 若要開始使用 KAI Scheduler 排程工作負載，請參考快速開始範例 發展藍圖 2025 年主要優先事項概覽 重構程式碼基礎以提升廠商中立性 支援 Scheduling Gates https://github.com/NVIDIA/KAI-Scheduler/issues/63 研究與 Kueue 的可能整合 https://github.com/NVIDIA/KAI-Scheduler/issues/68 新增 pod-group 的拓撲感知排程支援 https://github.com/NVIDIA/KAI-Scheduler/issues/66 支援每個工作負載的最小運行時間 支援每個工作負載的最大運行時間（含延遲重排隊機制） 預設 KAI 安裝新增更多 PriorityClasses 支援 JobSet 支援 LWS (LeaderWorkerSet) 新增 pod 與 pod-group 搶占相關度量指標 解耦優先順序與搶占機制 長期目標 支援每個佇列的時間衰減 超大規模擴展改進 支援推論型工作負載的整併，以促進叢集碎片化修復 支援 n 層階層佇列...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <p><a href="LICENSE"><img src="https://img.shields.io/badge/License-Apache_2.0-blue.svg" alt="License" /></a> <a href="https://github.com/NVIDIA/KAI-Scheduler/blob/main/.github/workflows/update-coverage-badge.yaml"><img src="https://github.com/NVIDIA/KAI-Scheduler/raw/coverage-badge/badges/coverage.svg" alt="Coverage" /></a></p>
<h1>KAI Scheduler</h1>
<p>KAI Scheduler 是一個強大、高效且可擴展的 <a href="https://kubernetes.io/zh/docs/concepts/scheduling-eviction/kube-scheduler/">Kubernetes 排程器</a>，專為優化 AI 及機器學習工作負載的 GPU 資源分配而設計。</p>
<p>KAI Scheduler 專為管理大規模 GPU 叢集（包含數千個節點）與高吞吐量工作負載而設計，非常適合龐大且高需求的環境。
KAI Scheduler 允許 Kubernetes 叢集管理員動態分配 GPU 資源給各種工作負載。</p>
<p>KAI Scheduler 支援完整的 AI 生命週期，從需要最小資源的小型互動式作業，到大型訓練與推論工作，都可在同一叢集內運行。
它確保最佳資源分配，同時維持不同消費者之間的資源公平性。
可與叢集上安裝的其他排程器並行運行。</p>
<h2>主要功能</h2>
<ul>
<li><a href="https://raw.githubusercontent.com/NVIDIA/KAI-Scheduler/main/docs/batch/README.md">批次排程</a>：確保同一群組內所有 pod 要麼同時排程，要麼全部不排程。</li>
<li>資源裝箱與分散排程：通過最小化碎片化（裝箱）或增加彈性與負載平衡（分散排程）來優化節點使用率。</li>
<li><a href="https://raw.githubusercontent.com/NVIDIA/KAI-Scheduler/main/docs/priority/README.md">工作負載優先順序</a>：在佇列中有效地設定工作負載優先順序。</li>
<li><a href="https://raw.githubusercontent.com/NVIDIA/KAI-Scheduler/main/docs/queues/README.md">階層式佇列</a>：利用二層佇列階層管理工作負載，提供彈性的組織控管。</li>
<li><a href="https://raw.githubusercontent.com/NVIDIA/KAI-Scheduler/main/docs/fairness/README.md#resource-division-algorithm">資源分配</a>：可自訂每個佇列的配額、超額配額權重、限制與優先順序。</li>
<li><a href="https://raw.githubusercontent.com/NVIDIA/KAI-Scheduler/main/docs/fairness/README.md#reclaim-strategies">公平性策略</a>：利用主導資源公平性（DRF）及資源回收機制，確保跨佇列的資源公平分配。</li>
<li>工作負載整併：智慧地重新分配運行中的工作負載，以減少碎片並提高叢集使用率。</li>
<li><a href="https://raw.githubusercontent.com/NVIDIA/KAI-Scheduler/main/docs/elastic/README.md">彈性工作負載</a>：可在定義的最小與最大 pod 數量範圍內動態調整工作負載規模。</li>
<li>動態資源分配（DRA）：通過 Kubernetes ResourceClaims 支援廠商專屬硬體資源（如 NVIDIA 或 AMD 的 GPU）。</li>
<li><a href="https://raw.githubusercontent.com/NVIDIA/KAI-Scheduler/main/docs/gpu-sharing/README.md">GPU 共用</a>：允許多個工作負載高效共用單顆或多顆 GPU，最大化資源利用率。</li>
<li>雲端與地端支援：完全相容於動態雲端基礎設施（包含如 Karpenter 的自動擴縮器）及靜態地端部署。</li>
</ul>
<h2>先決條件</h2>
<p>安裝 KAI Scheduler 前，請確保您已經具備：</p>
<ul>
<li>正在運行的 Kubernetes 叢集</li>
<li>已安裝 <a href="https://helm.sh/docs/intro/install">Helm</a> CLI</li>
<li>已安裝 <a href="https://github.com/NVIDIA/gpu-operator">NVIDIA GPU-Operator</a>，以便排程要求 GPU 資源的工作負載</li>
</ul>
<h2>安裝方式</h2>
<p>KAI Scheduler 將安裝於 <code>kai-scheduler</code> 命名空間。提交工作負載時請務必使用專屬命名空間。</p>
<h3>安裝方法</h3>
<p>KAI Scheduler 可以透過以下方式安裝：</p>
<ul>
<li><strong>從正式版本安裝（建議）</strong></li>
<li><strong>從原始碼建構（自行編譯）</strong></li>
</ul>
<h4>從正式版本安裝</h4>
<p>請至 <a href="https://github.com/NVIDIA/KAI-Scheduler/releases">releases</a> 頁面找到最新發行版本。
將 <code>&lt;VERSION&gt;</code> 替換為所需的發行版本後，執行下列指令：</p>
<pre><code class="language-sh">helm upgrade -i kai-scheduler oci://ghcr.io/nvidia/kai-scheduler/kai-scheduler -n kai-scheduler --create-namespace --version &lt;VERSION&gt;
</code></pre>
<h4>從原始碼建構</h4>
<p>請依照<a href="https://raw.githubusercontent.com/NVIDIA/KAI-Scheduler/main/docs/developer/building-from-source.md">這裡</a>的說明進行</p>
<h2>快速開始</h2>
<p>若要開始使用 KAI Scheduler 排程工作負載，請參考<a href="https://raw.githubusercontent.com/NVIDIA/KAI-Scheduler/main/docs/quickstart/README.md">快速開始範例</a></p>
<h2>發展藍圖</h2>
<h3>2025 年主要優先事項概覽</h3>
<ul>
<li>重構程式碼基礎以提升廠商中立性</li>
<li>支援 Scheduling Gates https://github.com/NVIDIA/KAI-Scheduler/issues/63</li>
<li>研究與 Kueue 的可能整合 https://github.com/NVIDIA/KAI-Scheduler/issues/68</li>
<li>新增 pod-group 的拓撲感知排程支援 https://github.com/NVIDIA/KAI-Scheduler/issues/66</li>
<li>支援每個工作負載的最小運行時間</li>
<li>支援每個工作負載的最大運行時間（含延遲重排隊機制）</li>
<li>預設 KAI 安裝新增更多 PriorityClasses</li>
<li>支援 JobSet</li>
<li>支援 LWS (LeaderWorkerSet)</li>
<li>新增 pod 與 pod-group 搶占相關度量指標</li>
<li>解耦優先順序與搶占機制</li>
</ul>
<h3>長期目標</h3>
<ul>
<li>支援每個佇列的時間衰減</li>
<li>超大規模擴展改進</li>
<li>支援推論型工作負載的整併，以促進叢集碎片化修復</li>
<li>支援 n 層階層佇列</li>
<li>優雅地推出推論型工作負載（新修訂版可臨時超額配額）</li>
</ul>
<h2>社群、討論與支援</h2>
<p>我們很樂意聽取您的意見！以下是與我們聯繫的最佳方式：</p>
<h3>Slack</h3>
<p>請先加入 <a href="https://communityinviter.com/apps/cloud-native/cncf">CNCF Slack</a>，再進入 <a href="https://cloud-native.slack.com/archives/kai-scheduler">#kai-scheduler</a> 頻道。</p>
<h3>雙週社群通話</h3>
<p><strong>時間：</strong> 每隔一週的星期一 17:00 CEST<br />
<a href="https://dateful.com/time-zone-converter?t=17&amp;tz2=Germany">轉換為您所在時區</a> | <a href="https://calendar.google.com/calendar/event?action=TEMPLATE&amp;tmeid=N2Q2bjhoNXAzMGc0cWpnZTQ4OGtpdXFhanFfMjAyNTA2MDlUMTUwMDAwWiAxZjQ2OTZiOWVlM2JiMWE1ZWIzMTAwODBkNDZiZmMwMDZjNTUxYWFiZmU1YTM3ZGM2YTc0NTFhYmNhMmE1ODk0QGc&amp;tmsrc=1f4696b9ee3bb1a5eb310080d46bfc006c551aabfe5a37dc6a7451abca2a5894%40group.calendar.google.com&amp;scp=ALL">加入您的行事曆</a>  | <a href="https://docs.google.com/document/d/13K7NGdPebOstlrsif1YLjGz1x-aJafMXeIgqbO7WghI/edit?usp=sharing">會議記錄與議程</a></p>
<h3>郵件列表</h3>
<p>加入 <a href="https://groups.google.com/g/kai-scheduler">kai-scheduler 郵件列表</a>，以獲取雙週會議的最新資訊。</p>
<h3>技術問題與功能請求</h3>
<p>請透過 <a href="https://github.com/NVIDIA/KAI-Scheduler/issues/new/choose">GitHub issue</a> 回報錯誤、功能建議或技術協助。這有助於我們追蹤需求並有效回應。</p>
<hr />
<p>Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx">Open Ai Tx</a> | Last indexed: 2025-06-08</p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Statcounter and other scripts can be added here -->
</body>
</html>