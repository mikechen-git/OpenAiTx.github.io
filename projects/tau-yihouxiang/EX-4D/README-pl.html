<!DOCTYPE html>
<html lang="pl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>EX-4D - tau-yihouxiang/EX-4D pl</title>
    <meta name="title" content="EX-4D - tau-yihouxiang/EX-4D pl | EX-4D: Synteza wideo 4D z ekstremalnych punktów widzenia za pomocą szczelnej siatki głębi 📄 Artykuł | 🎥 Strona domowa | 💻 Kod 🌟 Najważniejsze cechy 🎯 Synte...">
    <meta name="description" content="tau-yihouxiang/EX-4D - GitHub repository pl documentation and information | EX-4D: Synteza wideo 4D z ekstremalnych punktów widzenia za pomocą szczelnej siatki głębi 📄 Artykuł | 🎥 Strona domowa | 💻 Kod 🌟 Najważniejsze cechy 🎯 Synte...">
    <meta name="keywords" content="tau-yihouxiang, EX-4D, GitHub, repository, pl documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/tau-yihouxiang/EX-4D/README-pl.html">
    <meta property="og:title" content="EX-4D - tau-yihouxiang/EX-4D pl | EX-4D: Synteza wideo 4D z ekstremalnych punktów widzenia za pomocą szczelnej siatki głębi 📄 Artykuł | 🎥 Strona domowa | 💻 Kod 🌟 Najważniejsze cechy 🎯 Synte...">
    <meta property="og:description" content="tau-yihouxiang/EX-4D - GitHub repository pl documentation and information | EX-4D: Synteza wideo 4D z ekstremalnych punktów widzenia za pomocą szczelnej siatki głębi 📄 Artykuł | 🎥 Strona domowa | 💻 Kod 🌟 Najważniejsze cechy 🎯 Synte...">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div style="position: fixed; top: 2px; left: 2px; z-index: 2000; background: rgba(255,255,255,0.95); border-radius: 6px; box-shadow: 0 2px 8px rgba(0,0,0,0.06); padding: 4px 14px; font-size: 15px; color: #222; font-family: 'Segoe UI', Arial, sans-serif; font-weight: 500; letter-spacing: 0.5px;">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" style="color: #0366d6; text-decoration: none; font-weight: 600;">Open AI Tx</a>
    </div>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/tau-yihouxiang/EX-4D" id="githubRepoLink" target="_blank">tau-yihouxiang/EX-4D</a>
<h1 style="display: none;">EX-4D: Synteza wideo 4D z ekstremalnych punktów widzenia za pomocą szczelnej siatki głębi 📄 Artykuł | 🎥 Strona domowa | 💻 Kod 🌟 Najważniejsze cechy 🎯 Synte...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <h1>EX-4D: Synteza wideo 4D z ekstremalnych punktów widzenia za pomocą szczelnej siatki głębi</h1>
<div align="center">
<img src="https://raw.githubusercontent.com/tau-yihouxiang/EX-4D/main/docs/Logo.png" alt="EX-4D Logo" width="250">
<p><a href="https://arxiv.org/abs/2506.05554">📄 Artykuł</a>  |  <a href="https://tau-yihouxiang.github.io/projects/EX-4D/EX-4D.html">🎥 Strona domowa</a>  |  <a href="https://github.com/tau-yihouxiang/EX-4D">💻 Kod</a></p>
</div>
<h2>🌟 Najważniejsze cechy</h2>
<ul>
<li><strong>🎯 Synteza z ekstremalnych punktów widzenia</strong>: Generowanie wysokiej jakości wideo 4D z ruchem kamery od -90° do 90°</li>
<li><strong>🔧 Szczelna siatka głębi</strong>: Nowatorska reprezentacja geometryczna modelująca zarówno widoczne, jak i zasłonięte obszary</li>
<li><strong>⚡ Lekka architektura</strong>: Tylko 1% parametrów uczących się (140M) w stosunku do 14B głównego modelu dyfuzji wideo</li>
<li><strong>🎭 Bez treningu na wielu widokach</strong>: Innowacyjna strategia maskowania eliminuje potrzebę kosztownych zestawów danych z wielu kamer</li>
<li><strong>🏆 Najwyższa jakość</strong>: Przewyższa istniejące metody, szczególnie przy ekstremalnych kątach kamery</li>
</ul>
<h2>🎬 Wyniki demonstracyjne</h2>
<div align="center">
<img src="https://raw.githubusercontent.com/tau-yihouxiang/EX-4D/main/docs/teaser.png" alt="EX-4D Demo Results" width="800">
</div>
<p><em>EX-4D przekształca filmy monokularne w doświadczenia 4D sterowane kamerą, zapewniając fizycznie spójne wyniki pod ekstremalnymi kątami widzenia.</em></p>
<h2>🏗️ Przegląd frameworku</h2>
<div align="center">
<img src="https://raw.githubusercontent.com/tau-yihouxiang/EX-4D/main/docs/overview.png" alt="EX-4D Architecture">
</div>
<p>Nasz framework składa się z trzech kluczowych komponentów:</p>
<ol>
<li><strong>🔺 Konstrukcja szczelnej siatki głębi (Depth Watertight Mesh)</strong>: Tworzy solidny priorytet geometryczny, który jawnie modeluje zarówno widoczne, jak i ukryte obszary</li>
<li><strong>🎭 Symulowana strategia maskowania</strong>: Generuje skuteczne dane treningowe z filmów monokularnych bez użycia zestawów danych z wielu widoków</li>
<li><strong>⚙️ Lekki adapter LoRA</strong>: Efektywnie integruje informacje geometryczne z wytrenowanymi modelami dyfuzji wideo</li>
</ol>
<h2>🚀 Szybki start</h2>
<h3>Instalacja</h3>
<pre><code class="language-bash"># Sklonuj repozytorium
git clone https://github.com/tau-yihouxiang/EX-4D.git
cd EX-4D

# Utwórz środowisko conda
conda create -n ex4d python=3.10
conda activate ex4d
# Zainstaluj PyTorch (zalecana wersja 2.x)
pip install torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1 --index-url https://download.pytorch.org/whl/cu124
# Zainstaluj Nvdiffrast
pip install git+https://github.com/NVlabs/nvdiffrast.git
# Zainstaluj zależności oraz diffsynth
pip install -e .
# Zainstaluj depthcrafter do estymacji głębi. (Postępuj zgodnie z instrukcją DepthCrafter dotyczącą przygotowania punktów kontrolnych.)
git clone https://github.com/Tencent/DepthCrafter.git
</code></pre>
<h3>Pobierz wytrenowany model</h3>
<pre><code class="language-bash">huggingface-cli download Wan-AI/Wan2.1-I2V-14B-480P --local-dir ./models/Wan-AI
huggingface-cli download yihouxiang/EX-4D --local-dir ./models/EX-4D
</code></pre>
<h3>Przykład użycia</h3>
<h4>1. Rekonstrukcja DW-Mesh</h4>
<pre><code class="language-bash"># --cam 180 (30 / 60 / 90 / zoom_in / zoom_out )
python recon.py --input_video examples/flower/input.mp4 --cam 180 --output_dir outputs/flower --save_mesh
</code></pre>
<h4>2. Generowanie EX-4D (wymagane 48GB VRAM)</h4>
<pre><code class="language-bash">python generate.py --color_video outputs/flower/color_180.mp4 --mask_video outputs/flower/mask_180.mp4 --output_video outputs/flower/output.mp4
</code></pre>
<table>
<tr>
<td width="45%" align="center">
<img src="https://raw.githubusercontent.com/tau-yihouxiang/EX-4D/main/examples/flower/input.gif" width="100%">
<br><b>Wideo wejściowe</b>
</td>
<td align="center">
<div style="font-size: 2em; color: #4A90E2; padding: 0 0px;">
  ➜
</div>
</td>
<td width="45%" align="center">
<img src="https://raw.githubusercontent.com/tau-yihouxiang/EX-4D/main/examples/flower/output.gif" width="100%">
<br><b>Wideo wyjściowe</b>
</td>
</tr> 
</table>
<!-- ## 📊 Performance

### Quantitative Results
| Metoda | FID (Ekstremalny) ↓ | FVD (Ekstremalny) ↓ | Wynik VBench ↑ |
|--------|---------------------|---------------------|----------------|
| ReCamMaster | 64.68 | 943.45 | 0.434 |
| TrajectoryCrafter | 65.33 | 893.80 | 0.447 |
| TrajectoryAttention | 62.49 | 912.14 | 0.389 |
| **EX-4D (Nasza metoda)** | **55.42** | **823.61** | **0.450** | -->
<h3>Wyniki badań użytkowników</h3>
<ul>
<li><strong>70,7%</strong> uczestników preferowało EX-4D względem metod bazowych</li>
<li>Lepsza spójność fizyczna i jakość przy ekstremalnych kątach widzenia</li>
<li>Znacząca poprawa wraz ze wzrostem ekstremalności kątów kamery</li>
</ul>
<h2>🎯 Zastosowania</h2>
<ul>
<li><strong>🎮 Gry</strong>: Tworzenie immersyjnych filmowych scen 3D na podstawie materiału 2D</li>
<li><strong>🎬 Produkcja filmowa</strong>: Generowanie nowych ujęć kamery do postprodukcji</li>
<li><strong>🥽 VR/AR</strong>: Tworzenie doświadczeń wideo z dowolnego punktu widzenia</li>
<li><strong>📱 Media społecznościowe</strong>: Generowanie dynamicznych ruchów kamery do tworzenia treści</li>
<li><strong>🏢 Architektura</strong>: Wizualizacja przestrzeni z wielu punktów widzenia</li>
</ul>
<!-- ## 📈 Benchmarki -->
<!-- ### Ocena zakresu punktów widzenia

| Zakres | Mały (0°→30°) | Duży (0°→60°) | Ekstremalny (0°→90°) | Pełny (-90°→90°) |
|--------|---------------|---------------|----------------------|------------------|
| Wynik FID | 44.19 | 50.30 | 55.42 | - |
| Różnica wydajności | +9,1% lepiej | +8,9% lepiej | +11,3% lepiej | +15,5% lepiej | -->
<!-- *Różnica wydajności względem drugiej najlepszej metody w każdej kategorii.* -->
<h2>⚠️ Ograniczenia</h2>
<ul>
<li><strong>Zależność od głębi</strong>: Wydajność zależy od jakości estymacji głębi z jednego obrazu</li>
<li><strong>Koszt obliczeniowy</strong>: Wymaga dużej mocy obliczeniowej dla filmów w wysokiej rozdzielczości</li>
<li><strong>Powierzchnie refleksyjne</strong>: Trudności z materiałami odblaskowymi lub przezroczystymi</li>
</ul>
<h2>🔮 Przyszłe prace</h2>
<ul>
<li>[ ] Optymalizacja wnioskowania w czasie rzeczywistym (3DGS / 4DGS)</li>
<li>[ ] Wsparcie dla wyższych rozdzielczości (1K, 2K)</li>
<li>[ ] Techniki neuronowego udoskonalania siatek (mesh refinement)</li>
</ul>
<h2>🙏 Podziękowania</h2>
<p>Chcielibyśmy podziękować projektowi <a href="https://github.com/modelscope/DiffSynth-Studio/tree/v1.1.1">DiffSynth-Studio v1.1.1</a> za udostępnienie podstawowego frameworka dyfuzyjnego.</p>
<h2>📚 Cytowanie</h2>
<p>Jeśli nasza praca okazała się przydatna, prosimy o cytowanie:</p>
<pre><code class="language-bibtex">@misc{hu2025ex4dextremeviewpoint4d,
      title={EX-4D: EXtreme Viewpoint 4D Video Synthesis via Depth Watertight Mesh}, 
      author={Tao Hu and Haoyang Peng and Xiao Liu and Yuewen Ma},
      year={2025},
      eprint={2506.05554},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2506.05554}, 
}
</code></pre>
<hr />
<p>Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx">Open Ai Tx</a> | Last indexed: 2025-07-08</p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
</body>
</html>