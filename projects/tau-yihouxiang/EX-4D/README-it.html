<!DOCTYPE html>
<html lang="it">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>EX-4D - tau-yihouxiang/EX-4D it</title>
    <meta name="title" content="EX-4D - tau-yihouxiang/EX-4D it | EX-4D: Sintesi Video 4D da Punti di Vista Estremi tramite Depth Watertight Mesh 📄 Paper | 🎥 Homepage | 💻 Codice 🌟 Punti Salienti 🎯 Sintesi da Punti di Vist...">
    <meta name="description" content="tau-yihouxiang/EX-4D - GitHub repository it documentation and information | EX-4D: Sintesi Video 4D da Punti di Vista Estremi tramite Depth Watertight Mesh 📄 Paper | 🎥 Homepage | 💻 Codice 🌟 Punti Salienti 🎯 Sintesi da Punti di Vist...">
    <meta name="keywords" content="tau-yihouxiang, EX-4D, GitHub, repository, it documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/tau-yihouxiang/EX-4D/README-it.html">
    <meta property="og:title" content="EX-4D - tau-yihouxiang/EX-4D it | EX-4D: Sintesi Video 4D da Punti di Vista Estremi tramite Depth Watertight Mesh 📄 Paper | 🎥 Homepage | 💻 Codice 🌟 Punti Salienti 🎯 Sintesi da Punti di Vist...">
    <meta property="og:description" content="tau-yihouxiang/EX-4D - GitHub repository it documentation and information | EX-4D: Sintesi Video 4D da Punti di Vista Estremi tramite Depth Watertight Mesh 📄 Paper | 🎥 Homepage | 💻 Codice 🌟 Punti Salienti 🎯 Sintesi da Punti di Vist...">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div style="position: fixed; top: 2px; left: 2px; z-index: 2000; background: rgba(255,255,255,0.95); border-radius: 6px; box-shadow: 0 2px 8px rgba(0,0,0,0.06); padding: 4px 14px; font-size: 15px; color: #222; font-family: 'Segoe UI', Arial, sans-serif; font-weight: 500; letter-spacing: 0.5px;">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" style="color: #0366d6; text-decoration: none; font-weight: 600;">Open AI Tx</a>
    </div>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/tau-yihouxiang/EX-4D" id="githubRepoLink" target="_blank">tau-yihouxiang/EX-4D</a>
<h1 style="display: none;">EX-4D: Sintesi Video 4D da Punti di Vista Estremi tramite Depth Watertight Mesh 📄 Paper | 🎥 Homepage | 💻 Codice 🌟 Punti Salienti 🎯 Sintesi da Punti di Vist...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <h1>EX-4D: Sintesi Video 4D da Punti di Vista Estremi tramite Depth Watertight Mesh</h1>
<div align="center">
<img src="https://raw.githubusercontent.com/tau-yihouxiang/EX-4D/main/docs/Logo.png" alt="EX-4D Logo" width="250">
<p><a href="https://arxiv.org/abs/2506.05554">📄 Paper</a>  |  <a href="https://tau-yihouxiang.github.io/projects/EX-4D/EX-4D.html">🎥 Homepage</a>  |  <a href="https://github.com/tau-yihouxiang/EX-4D">💻 Codice</a></p>
</div>
<h2>🌟 Punti Salienti</h2>
<ul>
<li><strong>🎯 Sintesi da Punti di Vista Estremi</strong>: Genera video 4D di alta qualità con movimenti di camera da -90° a 90°</li>
<li><strong>🔧 Depth Watertight Mesh</strong>: Nuova rappresentazione geometrica che modella sia le regioni visibili che quelle occluse</li>
<li><strong>⚡ Architettura Leggera</strong>: Solo l'1% dei parametri addestrabili (140M) rispetto alla backbone di diffusione video da 14B</li>
<li><strong>🎭 Nessun Addestramento Multi-view</strong>: Innovativa strategia di mascheramento che elimina la necessità di costosi dataset multi-view</li>
<li><strong>🏆 Prestazioni all'Avanguardia</strong>: Supera i metodi esistenti, soprattutto su angoli di ripresa estremi</li>
</ul>
<h2>🎬 Risultati Demo</h2>
<div align="center">
<img src="https://raw.githubusercontent.com/tau-yihouxiang/EX-4D/main/docs/teaser.png" alt="EX-4D Demo Results" width="800">
</div>
<p><em>EX-4D trasforma video monoculari in esperienze 4D controllabili dalla camera con risultati fisicamente coerenti anche da punti di vista estremi.</em></p>
<h2>🏗️ Panoramica del Framework</h2>
<div align="center">
<img src="https://raw.githubusercontent.com/tau-yihouxiang/EX-4D/main/docs/overview.png" alt="EX-4D Architecture">
</div>
<p>Il nostro framework è composto da tre componenti chiave:</p>
<ol>
<li><strong>🔺 Costruzione Depth Watertight Mesh</strong>: Crea un robusto prior geometrico che modella esplicitamente sia le regioni visibili che quelle occluse</li>
<li><strong>🎭 Strategia di Mascheramento Simulato</strong>: Genera dati di addestramento efficaci da video monoculari senza dataset multi-view</li>
<li><strong>⚙️ Lightweight LoRA Adapter</strong>: Integra in modo efficiente le informazioni geometriche con modelli pre-addestrati di video diffusion</li>
</ol>
<h2>🚀 Quick Start</h2>
<h3>Installazione</h3>
<pre><code class="language-bash"># Clona il repository
git clone https://github.com/tau-yihouxiang/EX-4D.git
cd EX-4D

# Crea un ambiente conda
conda create -n ex4d python=3.10
conda activate ex4d
# Installa PyTorch (consigliato 2.x)
pip install torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1 --index-url https://download.pytorch.org/whl/cu124
# Installa Nvdiffrast
pip install git+https://github.com/NVlabs/nvdiffrast.git
# Installa le dipendenze e diffsynth
pip install -e .
# Installa depthcrafter per la stima della profondità. (Segui le istruzioni di DepthCrafter per la preparazione dei checkpoint.)
git clone https://github.com/Tencent/DepthCrafter.git
</code></pre>
<h3>Scarica il Modello Preaddestrato</h3>
<pre><code class="language-bash">huggingface-cli download Wan-AI/Wan2.1-I2V-14B-480P --local-dir ./models/Wan-AI
huggingface-cli download yihouxiang/EX-4D --local-dir ./models/EX-4D
</code></pre>
<h3>Esempio di Utilizzo</h3>
<h4>1. Ricostruzione DW-Mesh</h4>
<pre><code class="language-bash"># --cam 180 (30 / 60 / 90 / zoom_in / zoom_out )
python recon.py --input_video examples/flower/input.mp4 --cam 180 --output_dir outputs/flower --save_mesh
</code></pre>
<h4>2. Generazione EX-4D (richiesti 48GB VRAM)</h4>
<pre><code class="language-bash">python generate.py --color_video outputs/flower/color_180.mp4 --mask_video outputs/flower/mask_180.mp4 --output_video outputs/flower/output.mp4
</code></pre>
<table>
<tr>
<td width="45%" align="center">
<img src="https://raw.githubusercontent.com/tau-yihouxiang/EX-4D/main/examples/flower/input.gif" width="100%">
<br><b>Video di Input</b>
</td>
<td align="center">
<div style="font-size: 2em; color: #4A90E2; padding: 0 0px;">
  ➜
</div>
</td>
<td width="45%" align="center">
<img src="https://raw.githubusercontent.com/tau-yihouxiang/EX-4D/main/examples/flower/output.gif" width="100%">
<br><b>Video di Output</b>
</td>
</tr> 
</table>
<!-- ## 📊 Performance

### Quantitative Results
| Metodo | FID (Estremo) ↓ | FVD (Estremo) ↓ | VBench Score ↑ |
|--------|-----------------|-----------------|----------------|
| ReCamMaster | 64.68 | 943.45 | 0.434 |
| TrajectoryCrafter | 65.33 | 893.80 | 0.447 |
| TrajectoryAttention | 62.49 | 912.14 | 0.389 |
| **EX-4D (Nostro)** | **55.42** | **823.61** | **0.450** | -->
<h3>Risultati dello Studio Utente</h3>
<ul>
<li><strong>70.7%</strong> dei partecipanti ha preferito EX-4D rispetto ai metodi di base</li>
<li>Prestazioni superiori in coerenza fisica e qualità da punti di vista estremi</li>
<li>Miglioramento significativo man mano che gli angoli di ripresa diventano più estremi</li>
</ul>
<h2>🎯 Applicazioni</h2>
<ul>
<li><strong>🎮 Gaming</strong>: Creazione di cinematiche di gioco 3D immersive da filmati 2D</li>
<li><strong>🎬 Produzione Cinematografica</strong>: Generazione di angolazioni di camera innovative per la post-produzione</li>
<li><strong>🥽 VR/AR</strong>: Creazione di esperienze video a punto di vista libero</li>
<li><strong>📱 Social Media</strong>: Generazione di movimenti dinamici di camera per la creazione di contenuti</li>
<li><strong>🏢 Architettura</strong>: Visualizzazione di spazi da molteplici punti di vista</li>
</ul>
<!-- ## 📈 Benchmark -->
<!-- ### Valutazione Intervallo Angolazione

| Intervallo | Piccolo (0°→30°) | Grande (0°→60°) | Estremo (0°→90°) | Completo (-90°→90°) |
|------------|------------------|------------------|------------------|---------------------|
| FID Score | 44.19 | 50.30 | 55.42 | - |
| Vantaggio Prestazionale | +9.1% meglio | +8.9% meglio | +11.3% meglio | +15.5% meglio | -->
<!-- *Vantaggio prestazionale rispetto al secondo miglior metodo in ciascuna categoria.* -->
<h2>⚠️ Limitazioni</h2>
<ul>
<li><strong>Dipendenza dalla Profondità</strong>: Le prestazioni dipendono dalla qualità della stima di profondità monoculare</li>
<li><strong>Costo Computazionale</strong>: Richiede notevoli risorse computazionali per video ad alta risoluzione</li>
<li><strong>Superfici Riflettenti</strong>: Difficoltà con materiali riflettenti o trasparenti</li>
</ul>
<h2>🔮 Lavori Futuri</h2>
<ul>
<li>[ ] Ottimizzazione per inferenza in tempo reale (3DGS / 4DGS)</li>
<li>[ ] Supporto per risoluzioni più elevate (1K, 2K)</li>
<li>[ ] Tecniche di raffinamento di mesh neurali</li>
</ul>
<h2>🙏 Ringraziamenti</h2>
<p>Desideriamo ringraziare il progetto <a href="https://github.com/modelscope/DiffSynth-Studio/tree/v1.1.1">DiffSynth-Studio v1.1.1</a> per aver fornito il framework di diffusione di base.</p>
<h2>📚 Citazione</h2>
<p>Se trovi utile il nostro lavoro, considera di citarlo:</p>
<pre><code class="language-bibtex">@misc{hu2025ex4dextremeviewpoint4d,
      title={EX-4D: EXtreme Viewpoint 4D Video Synthesis via Depth Watertight Mesh}, 
      author={Tao Hu and Haoyang Peng and Xiao Liu and Yuewen Ma},
      year={2025},
      eprint={2506.05554},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2506.05554}, 
}
</code></pre>
<hr />
<p>Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx">Open Ai Tx</a> | Last indexed: 2025-07-08</p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
</body>
</html>