<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>EX-4D - tau-yihouxiang/EX-4D zh-CN</title>
    <meta name="title" content="EX-4D - tau-yihouxiang/EX-4D zh-CN | EX-4D: 基于深度水密网格的极端视角4D视频合成 📄 论文 | 🎥 主页 | 💻 代码 🌟 亮点 🎯 极端视角合成：生成高质量4D视频，支持相机从-90°到90°的广泛运动 🔧 深度水密网格：新颖的几何表示，同时建模可见与遮挡区域 ⚡ 轻量级架构：仅为14B视频扩散主干1%的可训练参数（140M） 🎭...">
    <meta name="description" content="tau-yihouxiang/EX-4D - GitHub repository zh-CN documentation and information | EX-4D: 基于深度水密网格的极端视角4D视频合成 📄 论文 | 🎥 主页 | 💻 代码 🌟 亮点 🎯 极端视角合成：生成高质量4D视频，支持相机从-90°到90°的广泛运动 🔧 深度水密网格：新颖的几何表示，同时建模可见与遮挡区域 ⚡ 轻量级架构：仅为14B视频扩散主干1%的可训练参数（140M） 🎭...">
    <meta name="keywords" content="tau-yihouxiang, EX-4D, GitHub, repository, zh-CN documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/tau-yihouxiang/EX-4D/README-zh-CN.html">
    <meta property="og:title" content="EX-4D - tau-yihouxiang/EX-4D zh-CN | EX-4D: 基于深度水密网格的极端视角4D视频合成 📄 论文 | 🎥 主页 | 💻 代码 🌟 亮点 🎯 极端视角合成：生成高质量4D视频，支持相机从-90°到90°的广泛运动 🔧 深度水密网格：新颖的几何表示，同时建模可见与遮挡区域 ⚡ 轻量级架构：仅为14B视频扩散主干1%的可训练参数（140M） 🎭...">
    <meta property="og:description" content="tau-yihouxiang/EX-4D - GitHub repository zh-CN documentation and information | EX-4D: 基于深度水密网格的极端视角4D视频合成 📄 论文 | 🎥 主页 | 💻 代码 🌟 亮点 🎯 极端视角合成：生成高质量4D视频，支持相机从-90°到90°的广泛运动 🔧 深度水密网格：新颖的几何表示，同时建模可见与遮挡区域 ⚡ 轻量级架构：仅为14B视频扩散主干1%的可训练参数（140M） 🎭...">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div style="position: fixed; top: 2px; left: 2px; z-index: 2000; background: rgba(255,255,255,0.95); border-radius: 6px; box-shadow: 0 2px 8px rgba(0,0,0,0.06); padding: 4px 14px; font-size: 15px; color: #222; font-family: 'Segoe UI', Arial, sans-serif; font-weight: 500; letter-spacing: 0.5px;">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" style="color: #0366d6; text-decoration: none; font-weight: 600;">Open AI Tx</a>
    </div>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/tau-yihouxiang/EX-4D" id="githubRepoLink" target="_blank">tau-yihouxiang/EX-4D</a>
<h1 style="display: none;">EX-4D: 基于深度水密网格的极端视角4D视频合成 📄 论文 | 🎥 主页 | 💻 代码 🌟 亮点 🎯 极端视角合成：生成高质量4D视频，支持相机从-90°到90°的广泛运动 🔧 深度水密网格：新颖的几何表示，同时建模可见与遮挡区域 ⚡ 轻量级架构：仅为14B视频扩散主干1%的可训练参数（140M） 🎭...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <h1>EX-4D: 基于深度水密网格的极端视角4D视频合成</h1>
<div align="center">
<img src="https://raw.githubusercontent.com/tau-yihouxiang/EX-4D/main/docs/Logo.png" alt="EX-4D Logo" width="250">
<p><a href="https://arxiv.org/abs/2506.05554">📄 论文</a>  |  <a href="https://tau-yihouxiang.github.io/projects/EX-4D/EX-4D.html">🎥 主页</a>  |  <a href="https://github.com/tau-yihouxiang/EX-4D">💻 代码</a></p>
</div>
<h2>🌟 亮点</h2>
<ul>
<li><strong>🎯 极端视角合成</strong>：生成高质量4D视频，支持相机从-90°到90°的广泛运动</li>
<li><strong>🔧 深度水密网格</strong>：新颖的几何表示，同时建模可见与遮挡区域</li>
<li><strong>⚡ 轻量级架构</strong>：仅为14B视频扩散主干1%的可训练参数（140M）</li>
<li><strong>🎭 无需多视角训练</strong>：创新的遮罩策略，无需昂贵的多视角数据集</li>
<li><strong>🏆 最先进性能</strong>：在极端相机角度下优于现有方法</li>
</ul>
<h2>🎬 演示结果</h2>
<div align="center">
<img src="https://raw.githubusercontent.com/tau-yihouxiang/EX-4D/main/docs/teaser.png" alt="EX-4D Demo Results" width="800">
</div>
<p><em>EX-4D将单目视频转变为可控相机的4D体验，在极端视角下也能实现物理一致的结果。</em></p>
<h2>🏗️ 框架概览</h2>
<div align="center">
<img src="https://raw.githubusercontent.com/tau-yihouxiang/EX-4D/main/docs/overview.png" alt="EX-4D Architecture">
</div>
<p>我们的框架包含三个关键组件：</p>
<ol>
<li><strong>🔺 深度水密网格构建</strong>：创建鲁棒的几何先验，显式建模可见与遮挡区域</li>
<li><strong>🎭 模拟遮罩策略</strong>：利用单目视频，无需多视角数据集生成有效训练数据</li>
<li><strong>⚙️ 轻量级LoRA适配器</strong>：高效融合几何信息与预训练视频扩散模型</li>
</ol>
<h2>🚀 快速开始</h2>
<h3>安装</h3>
<pre><code class="language-bash"># 克隆仓库
git clone https://github.com/tau-yihouxiang/EX-4D.git
cd EX-4D

# 创建conda环境
conda create -n ex4d python=3.10
conda activate ex4d
# 安装PyTorch（推荐2.x版本）
pip install torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1 --index-url https://download.pytorch.org/whl/cu124
# 安装Nvdiffrast
pip install git+https://github.com/NVlabs/nvdiffrast.git
# 安装依赖和diffsynth
pip install -e .
# 安装depthcrafter用于深度估计。（按照DepthCrafter的安装说明准备检查点文件。）
git clone https://github.com/Tencent/DepthCrafter.git
</code></pre>
<h3>下载预训练模型</h3>
<pre><code class="language-bash">huggingface-cli download Wan-AI/Wan2.1-I2V-14B-480P --local-dir ./models/Wan-AI
huggingface-cli download yihouxiang/EX-4D --local-dir ./models/EX-4D
</code></pre>
<h3>示例用法</h3>
<h4>1. DW-Mesh重建</h4>
<pre><code class="language-bash"># --cam 180 (30 / 60 / 90 / zoom_in / zoom_out )
python recon.py --input_video examples/flower/input.mp4 --cam 180 --output_dir outputs/flower --save_mesh
</code></pre>
<h4>2. EX-4D生成（需要48GB显存）</h4>
<pre><code class="language-bash">python generate.py --color_video outputs/flower/color_180.mp4 --mask_video outputs/flower/mask_180.mp4 --output_video outputs/flower/output.mp4
</code></pre>
<table>
<tr>
<td width="45%" align="center">
<img src="https://raw.githubusercontent.com/tau-yihouxiang/EX-4D/main/examples/flower/input.gif" width="100%">
<br><b>输入视频</b>
</td>
<td align="center">
<div style="font-size: 2em; color: #4A90E2; padding: 0 0px;">
  ➜
</div>
</td>
<td width="45%" align="center">
<img src="https://raw.githubusercontent.com/tau-yihouxiang/EX-4D/main/examples/flower/output.gif" width="100%">
<br><b>输出视频</b>
</td>
</tr> 
</table>
<!-- ## 📊 Performance

### Quantitative Results
| 方法 | FID (极端) ↓ | FVD (极端) ↓ | VBench 得分 ↑ |
|--------|-----------------|-----------------|----------------|
| ReCamMaster | 64.68 | 943.45 | 0.434 |
| TrajectoryCrafter | 65.33 | 893.80 | 0.447 |
| TrajectoryAttention | 62.49 | 912.14 | 0.389 |
| **EX-4D (本方法)** | **55.42** | **823.61** | **0.450** | -->
<h3>用户研究结果</h3>
<ul>
<li><strong>70.7%</strong> 的参与者更喜欢 EX-4D 而非基线方法</li>
<li>在物理一致性和极端视角质量方面表现优异</li>
<li>随着摄像机角度变得更极端，表现显著提升</li>
</ul>
<h2>🎯 应用场景</h2>
<ul>
<li><strong>🎮 游戏</strong>：从 2D 画面生成沉浸式 3D 游戏电影</li>
<li><strong>🎬 影视制作</strong>：为后期制作生成新颖的摄像机角度</li>
<li><strong>🥽 VR/AR</strong>：打造自由视点视频体验</li>
<li><strong>📱 社交媒体</strong>：为内容创作生成动态镜头运动</li>
<li><strong>🏢 建筑</strong>：从多个视角可视化空间</li>
</ul>
<!-- ## 📈 基准测试 -->
<!-- ### 视角范围评估

| 范围 | 小 (0°→30°) | 大 (0°→60°) | 极端 (0°→90°) | 全部 (-90°→90°) |
|-------|----------------|----------------|------------------|-----------------|
| FID 得分 | 44.19 | 50.30 | 55.42 | - |
| 表现差距 | 优于第二名 +9.1% | 优于第二名 +8.9% | 优于第二名 +11.3% | 优于第二名 +15.5% | -->
<!-- *与各类别下第二优方法的表现差距。* -->
<h2>⚠️ 局限性</h2>
<ul>
<li><strong>深度依赖</strong>：表现依赖于单目深度估计的质量</li>
<li><strong>计算成本</strong>：高分辨率视频需要较大的计算量</li>
<li><strong>反光表面</strong>：对反光或透明材质存在挑战</li>
</ul>
<h2>🔮 未来工作</h2>
<ul>
<li>[ ] 实时推理优化（3DGS / 4DGS）</li>
<li>[ ] 支持更高分辨率（1K, 2K）</li>
<li>[ ] 神经网格细化技术</li>
</ul>
<h2>🙏 鸣谢</h2>
<p>我们感谢 <a href="https://github.com/modelscope/DiffSynth-Studio/tree/v1.1.1">DiffSynth-Studio v1.1.1</a> 项目，提供了基础扩散框架。</p>
<h2>📚 引用</h2>
<p>如果您觉得我们的工作有用，请引用：</p>
<pre><code class="language-bibtex">@misc{hu2025ex4dextremeviewpoint4d,
      title={EX-4D: EXtreme Viewpoint 4D Video Synthesis via Depth Watertight Mesh}, 
      author={Tao Hu and Haoyang Peng and Xiao Liu and Yuewen Ma},
      year={2025},
      eprint={2506.05554},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2506.05554}, 
}
</code></pre>
<hr />
<p>Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx">Open Ai Tx</a> | Last indexed: 2025-07-08</p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
</body>
</html>