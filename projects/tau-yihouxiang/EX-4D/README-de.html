<!DOCTYPE html>
<html lang="de">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>EX-4D - tau-yihouxiang/EX-4D de</title>
    <meta name="title" content="EX-4D - tau-yihouxiang/EX-4D de | EX-4D: EXtreme Viewpoint 4D Video Synthesis via Depth Watertight Mesh 📄 Paper | 🎥 Homepage | 💻 Code 🌟 Highlights 🎯 Extreme Viewpoint Synthesis: Erzeuge hoc...">
    <meta name="description" content="tau-yihouxiang/EX-4D - GitHub repository de documentation and information | EX-4D: EXtreme Viewpoint 4D Video Synthesis via Depth Watertight Mesh 📄 Paper | 🎥 Homepage | 💻 Code 🌟 Highlights 🎯 Extreme Viewpoint Synthesis: Erzeuge hoc...">
    <meta name="keywords" content="tau-yihouxiang, EX-4D, GitHub, repository, de documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/tau-yihouxiang/EX-4D/README-de.html">
    <meta property="og:title" content="EX-4D - tau-yihouxiang/EX-4D de | EX-4D: EXtreme Viewpoint 4D Video Synthesis via Depth Watertight Mesh 📄 Paper | 🎥 Homepage | 💻 Code 🌟 Highlights 🎯 Extreme Viewpoint Synthesis: Erzeuge hoc...">
    <meta property="og:description" content="tau-yihouxiang/EX-4D - GitHub repository de documentation and information | EX-4D: EXtreme Viewpoint 4D Video Synthesis via Depth Watertight Mesh 📄 Paper | 🎥 Homepage | 💻 Code 🌟 Highlights 🎯 Extreme Viewpoint Synthesis: Erzeuge hoc...">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div style="position: fixed; top: 2px; left: 2px; z-index: 2000; background: rgba(255,255,255,0.95); border-radius: 6px; box-shadow: 0 2px 8px rgba(0,0,0,0.06); padding: 4px 14px; font-size: 15px; color: #222; font-family: 'Segoe UI', Arial, sans-serif; font-weight: 500; letter-spacing: 0.5px;">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" style="color: #0366d6; text-decoration: none; font-weight: 600;">Open AI Tx</a>
    </div>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/tau-yihouxiang/EX-4D" id="githubRepoLink" target="_blank">tau-yihouxiang/EX-4D</a>
<h1 style="display: none;">EX-4D: EXtreme Viewpoint 4D Video Synthesis via Depth Watertight Mesh 📄 Paper | 🎥 Homepage | 💻 Code 🌟 Highlights 🎯 Extreme Viewpoint Synthesis: Erzeuge hoc...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <h1>EX-4D: EXtreme Viewpoint 4D Video Synthesis via Depth Watertight Mesh</h1>
<div align="center">
<img src="https://raw.githubusercontent.com/tau-yihouxiang/EX-4D/main/docs/Logo.png" alt="EX-4D Logo" width="250">
<p><a href="https://arxiv.org/abs/2506.05554">📄 Paper</a>  |  <a href="https://tau-yihouxiang.github.io/projects/EX-4D/EX-4D.html">🎥 Homepage</a>  |  <a href="https://github.com/tau-yihouxiang/EX-4D">💻 Code</a></p>
</div>
<h2>🌟 Highlights</h2>
<ul>
<li><strong>🎯 Extreme Viewpoint Synthesis</strong>: Erzeuge hochwertige 4D-Videos mit Kamerabewegungen von -90° bis 90°</li>
<li><strong>🔧 Depth Watertight Mesh</strong>: Neue geometrische Repräsentation, die sowohl sichtbare als auch verdeckte Bereiche modelliert</li>
<li><strong>⚡ Leichtgewichtige Architektur</strong>: Nur 1 % trainierbare Parameter (140M) des 14B Video-Diffusions-Backbones</li>
<li><strong>🎭 Kein Multi-View-Training</strong>: Innovative Maskierungsstrategie eliminiert die Notwendigkeit teurer Multi-View-Datensätze</li>
<li><strong>🏆 State-of-the-art Performance</strong>: Übertrifft bestehende Methoden, insbesondere bei extremen Kamerawinkeln</li>
</ul>
<h2>🎬 Demo-Ergebnisse</h2>
<div align="center">
<img src="https://raw.githubusercontent.com/tau-yihouxiang/EX-4D/main/docs/teaser.png" alt="EX-4D Demo Results" width="800">
</div>
<p><em>EX-4D verwandelt monokulare Videos in kamerasteuerbare 4D-Erlebnisse mit physikalisch konsistenten Ergebnissen bei extremen Blickwinkeln.</em></p>
<h2>🏗️ Rahmenüberblick</h2>
<div align="center">
<img src="https://raw.githubusercontent.com/tau-yihouxiang/EX-4D/main/docs/overview.png" alt="EX-4D Architecture">
</div>
<p>Unser Framework besteht aus drei Schlüsselelementen:</p>
<ol>
<li><strong>🔺 Depth Watertight Mesh Construction</strong>: Erzeugt ein robustes geometrisches Vorwissen, das explizit sowohl sichtbare als auch verdeckte Bereiche modelliert</li>
<li><strong>🎭 Simulierte Maskierungsstrategie</strong>: Generiert effektive Trainingsdaten aus monokularen Videos ohne Multi-View-Datensätze</li>
<li><strong>⚙️ Leichtgewichtiger LoRA-Adapter</strong>: Integriert geometrische Informationen effizient in vortrainierte Video-Diffusionsmodelle</li>
</ol>
<h2>🚀 Schnellstart</h2>
<h3>Installation</h3>
<pre><code class="language-bash"># Repository klonen
git clone https://github.com/tau-yihouxiang/EX-4D.git
cd EX-4D

# Conda-Umgebung erstellen
conda create -n ex4d python=3.10
conda activate ex4d
# PyTorch installieren (2.x empfohlen)
pip install torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1 --index-url https://download.pytorch.org/whl/cu124
# Nvdiffrast installieren
pip install git+https://github.com/NVlabs/nvdiffrast.git
# Abhängigkeiten und diffsynth installieren
pip install -e .
# depthcrafter für Tiefenschätzung installieren. (Folge DepthCrafters Installationsanleitung für die Vorbereitung der Checkpoints.)
git clone https://github.com/Tencent/DepthCrafter.git
</code></pre>
<h3>Vorgefertigtes Modell herunterladen</h3>
<pre><code class="language-bash">huggingface-cli download Wan-AI/Wan2.1-I2V-14B-480P --local-dir ./models/Wan-AI
huggingface-cli download yihouxiang/EX-4D --local-dir ./models/EX-4D
</code></pre>
<h3>Beispielanwendung</h3>
<h4>1. DW-Mesh Rekonstruktion</h4>
<pre><code class="language-bash"># --cam 180 (30 / 60 / 90 / zoom_in / zoom_out )
python recon.py --input_video examples/flower/input.mp4 --cam 180 --output_dir outputs/flower --save_mesh
</code></pre>
<h4>2. EX-4D Generierung (48GB VRAM erforderlich)</h4>
<pre><code class="language-bash">python generate.py --color_video outputs/flower/color_180.mp4 --mask_video outputs/flower/mask_180.mp4 --output_video outputs/flower/output.mp4
</code></pre>
<table>
<tr>
<td width="45%" align="center">
<img src="https://raw.githubusercontent.com/tau-yihouxiang/EX-4D/main/examples/flower/input.gif" width="100%">
<br><b>Eingabevideo</b>
</td>
<td align="center">
<div style="font-size: 2em; color: #4A90E2; padding: 0 0px;">
  ➜
</div>
</td>
<td width="45%" align="center">
<img src="https://raw.githubusercontent.com/tau-yihouxiang/EX-4D/main/examples/flower/output.gif" width="100%">
<br><b>Ausgabevideo</b>
</td>
</tr> 
</table>
<!-- ## 📊 Performance

### Quantitative Results
| Methode | FID (Extreme) ↓ | FVD (Extreme) ↓ | VBench Score ↑ |
|---------|-----------------|-----------------|----------------|
| ReCamMaster | 64.68 | 943.45 | 0.434 |
| TrajectoryCrafter | 65.33 | 893.80 | 0.447 |
| TrajectoryAttention | 62.49 | 912.14 | 0.389 |
| **EX-4D (Unseres)** | **55.42** | **823.61** | **0.450** | -->
<h3>Ergebnisse der Benutzerstudie</h3>
<ul>
<li><strong>70,7%</strong> der Teilnehmer bevorzugten EX-4D gegenüber den Basismethoden</li>
<li>Überlegene Leistung bei physikalischer Konsistenz und Qualität aus extremen Blickwinkeln</li>
<li>Deutliche Verbesserung, wenn die Kamerawinkel extremer werden</li>
</ul>
<h2>🎯 Anwendungen</h2>
<ul>
<li><strong>🎮 Gaming</strong>: Immersive 3D-Spielkinematiken aus 2D-Material erstellen</li>
<li><strong>🎬 Filmproduktion</strong>: Neue Kamerawinkel für die Postproduktion generieren</li>
<li><strong>🥽 VR/AR</strong>: Free-Viewpoint-Videoerlebnisse erstellen</li>
<li><strong>📱 Soziale Medien</strong>: Dynamische Kamerabewegungen für die Content-Erstellung erzeugen</li>
<li><strong>🏢 Architektur</strong>: Räume aus mehreren Blickwinkeln visualisieren</li>
</ul>
<!-- ## 📈 Benchmarks -->
<!-- ### Auswertung des Blickwinkelbereichs

| Bereich | Klein (0°→30°) | Groß (0°→60°) | Extrem (0°→90°) | Voll (-90°→90°) |
|---------|----------------|---------------|-----------------|-----------------|
| FID Score | 44.19 | 50.30 | 55.42 | - |
| Leistungsabstand | +9,1% besser | +8,9% besser | +11,3% besser | +15,5% besser | -->
<!-- *Leistungsabstand im Vergleich zur zweitbesten Methode in jeder Kategorie.* -->
<h2>⚠️ Einschränkungen</h2>
<ul>
<li><strong>Abhängigkeit von Tiefe</strong>: Die Leistung hängt von der Qualität der monokularen Tiefenschätzung ab</li>
<li><strong>Rechenaufwand</strong>: Benötigt erhebliche Rechenleistung für hochauflösende Videos</li>
<li><strong>Reflektierende Oberflächen</strong>: Herausforderungen bei reflektierenden oder transparenten Materialien</li>
</ul>
<h2>🔮 Zukünftige Arbeiten</h2>
<ul>
<li>[ ] Echtzeit-Inferenz-Optimierung (3DGS / 4DGS)</li>
<li>[ ] Unterstützung für höhere Auflösungen (1K, 2K)</li>
<li>[ ] Techniken zur neuronalen Mesh-Verfeinerung</li>
</ul>
<h2>🙏 Danksagung</h2>
<p>Wir danken dem <a href="https://github.com/modelscope/DiffSynth-Studio/tree/v1.1.1">DiffSynth-Studio v1.1.1</a>-Projekt für die Bereitstellung des grundlegenden Diffusions-Frameworks.</p>
<h2>📚 Zitation</h2>
<p>Wenn Sie unsere Arbeit nützlich finden, zitieren Sie bitte:</p>
<pre><code class="language-bibtex">@misc{hu2025ex4dextremeviewpoint4d,
      title={EX-4D: EXtreme Viewpoint 4D Video Synthesis via Depth Watertight Mesh}, 
      author={Tao Hu and Haoyang Peng und Xiao Liu und Yuewen Ma},
      year={2025},
      eprint={2506.05554},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2506.05554}, 
}
</code></pre>
<hr />
<p>Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx">Open Ai Tx</a> | Last indexed: 2025-07-08</p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
</body>
</html>