<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>tensorzero - tensorzero/tensorzero</title>
    <meta name="title" content="tensorzero - tensorzero/tensorzero">
    <meta name="description" content="tensorzero/tensorzero - GitHub repository ru documentation and informationTensorZero TensorZero создает цикл обратной связи для оптимизации LLM-приложений — превращая производственные данные в более умные, быстрые и дешевые модели. Ин...">
    <meta name="keywords" content="tensorzero, tensorzero, GitHub, repository, ru documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/tensorzero/tensorzero/README-ru.html">
    <meta property="og:title" content="tensorzero - tensorzero/tensorzero">
    <meta property="og:description" content="tensorzero/tensorzero - GitHub repository ru documentation and information">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/tensorzero/tensorzero" id="githubRepoLink" target="_blank">tensorzero/tensorzero</a>
<h1 style="display: none;">TensorZero TensorZero создает цикл обратной связи для оптимизации LLM-приложений — превращая производственные данные в более умные, быстрые и дешевые модели. Ин...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <img src="https://github.com/user-attachments/assets/47d67430-386d-4675-82ad-d4734d3262d9" width=128 height=128>
<h1>TensorZero</h1>
<p><strong>TensorZero создает цикл обратной связи для оптимизации LLM-приложений — превращая производственные данные в более умные, быстрые и дешевые модели.</strong></p>
<ol>
<li>Интегрируйте наш шлюз моделей</li>
<li>Отправляйте метрики или обратную связь</li>
<li>Оптимизируйте промпты, модели и стратегии инференса</li>
<li>Наблюдайте, как ваши LLM улучшаются со временем</li>
</ol>
<p>Это обеспечивает <strong>циклическое обучение и работу с данными для LLM</strong>, объединяя:</p>
<ul>
<li>[x] <strong>Инференс:</strong> единый API для всех LLM, с задержкой &lt;1 мс (P99)</li>
<li>[x] <strong>Наблюдаемость:</strong> инференс и обратная связь → в вашу базу данных</li>
<li>[x] <strong>Оптимизация:</strong> от промптов до дообучения и RL</li>
<li>[x] <strong>Оценки:</strong> сравнение промптов, моделей, стратегий инференса</li>
<li>[x] <strong>Эксперименты:</strong> встроенное A/B тестирование, маршрутизация, фолбэки</li>
</ul>
<hr />
<p align="center">
  <b><a href="https://www.tensorzero.com/" target="_blank">Веб-сайт</a></b>
  ·
  <b><a href="https://www.tensorzero.com/docs" target="_blank">Документация</a></b>
  ·
  <b><a href="https://www.x.com/tensorzero" target="_blank">Twitter</a></b>
  ·
  <b><a href="https://www.tensorzero.com/slack" target="_blank">Slack</a></b>
  ·
  <b><a href="https://www.tensorzero.com/discord" target="_blank">Discord</a></b>
  <br>
  <br>
  <b><a href="https://www.tensorzero.com/docs/quickstart" target="_blank">Быстрый старт (5 минут)</a></b>
  ·
  <b><a href="https://www.tensorzero.com/docs/gateway/tutorial" target="_blank">Полный туториал</a></b>
  ·
  <b><a href="https://www.tensorzero.com/docs/gateway/deployment" target="_blank">Руководство по развертыванию</a></b>
  ·
  <b><a href="https://www.tensorzero.com/docs/gateway/api-reference" target="_blank">API Reference</a></b>
  ·
  <b><a href="https://www.tensorzero.com/docs/gateway/deployment" target="_blank">Configuration Reference</a></b>
</p>
<hr />
<table>
  <tr>
    <td width="30%" valign="top"><b>Что такое TensorZero?</b></td>
    <td width="70%" valign="top">TensorZero — это open-source фреймворк для создания LLM-приложений промышленного уровня. Он объединяет шлюз LLM, наблюдаемость, оптимизацию, оценки и проведение экспериментов.</td>
  </tr>
  <tr>
    <td width="30%" valign="top"><b>Чем TensorZero отличается от других LLM-фреймворков?</b></td>
    <td width="70%" valign="top">
      1. TensorZero позволяет оптимизировать сложные LLM-приложения на основе производственных метрик и обратной связи от пользователей.<br>
      2. TensorZero поддерживает требования промышленных LLM-приложений: низкая задержка, высокая пропускная способность, строгая типизация, самостоятельное размещение, GitOps, настраиваемость и др.<br>
      3. TensorZero объединяет весь стек LLMOps, создавая кумулятивные преимущества. Например, LLM-оценки могут использоваться для дообучения моделей вместе с AI-судьями.
    </td>
  </tr>
  <tr>
    <td width="30%" valign="top"><b>Могу ли я использовать TensorZero с ___?</b></td>
    <td width="70%" valign="top">Да. Поддерживаются все основные языки программирования. Вы можете использовать TensorZero с нашим Python-клиентом, любым OpenAI SDK или нашим HTTP API.</td>
  </tr>
  <tr>
    <td width="30%" valign="top"><b>Готов ли TensorZero к промышленному использованию?</b></td>
    <td width="70%" valign="top">Да. Вот кейс: <b><a href="https://www.tensorzero.com/blog/case-study-automating-code-changelogs-at-a-large-bank-with-llms">Автоматизация changelog’ов кода в крупном банке с помощью LLM</a></b></td>
  </tr>
  <tr>
    <td width="30%" valign="top"><b>Сколько стоит TensorZero?</b></td>
    <td width="70%" valign="top">Ничего. TensorZero полностью open-source и для самостоятельного размещения. Нет платных функций.</td>
  </tr>
  <tr>
    <td width="30%" valign="top"><b>Кто разрабатывает TensorZero?</b></td>
    <td width="70%" valign="top">В нашей технической команде есть бывший мейнтейнер компилятора Rust, исследователи машинного обучения (Stanford, CMU, Oxford, Columbia) с тысячами цитирований, и директор по продукту стартапа-декакорна. Нас поддерживают те же инвесторы, что и ведущие open-source проекты (например, ClickHouse, CockroachDB) и AI-лаборатории (например, OpenAI, Anthropic).</td>
  </tr>
  <tr>
    <td width="30%" valign="top"><b>Как начать пользоваться?</b></td>
    <td width="70%" valign="top">Вы можете внедрять TensorZero поэтапно. Наш <b><a href="https://www.tensorzero.com/docs/quickstart">Быстрый старт</a></b> показывает путь от обычного OpenAI-обертки до промышленного LLM-приложения с наблюдаемостью и дообучением всего за 5 минут.</td>
  </tr>
</table>
<hr />
<h2>Возможности</h2>
<h3>🌐 Шлюз LLM</h3>
<blockquote>
<p><strong>Интегрируйтесь с TensorZero один раз и получите доступ ко всем основным LLM-провайдерам.</strong></p>
</blockquote>
<table>
  <tr></tr> <!-- flip highlight order -->
  <tr>
    <td width="50%" align="center" valign="middle"><b>Провайдеры моделей</b></td>
    <td width="50%" align="center" valign="middle"><b>Возможности</b></td>
  </tr>
  <tr>
    <td width="50%" align="left" valign="top">
      <p>
        Шлюз TensorZero нативно поддерживает:
      </p>
      <ul>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/anthropic">Anthropic</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/aws-bedrock">AWS Bedrock</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/aws-sagemaker">AWS SageMaker</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/azure">Azure OpenAI Service</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/deepseek">DeepSeek</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/fireworks">Fireworks</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/gcp-vertex-ai-anthropic">GCP Vertex AI Anthropic</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/gcp-vertex-ai-gemini">GCP Vertex AI Gemini</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/google-ai-studio-gemini">Google AI Studio (Gemini API)</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/hyperbolic">Hyperbolic</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/mistral">Mistral</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/openai">OpenAI</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/together">Together</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/vllm">vLLM</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/xai">xAI</a></b></li>
      </ul>
      <p>
        <em>
          Нужен другой провайдер?
          Скорее всего, он поддерживается, потому что TensorZero интегрируется с <b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/openai-compatible">любым OpenAI-совместимым API (например, Ollama)</a></b>.
        </em>
      </p>
    </td>
    <td width="50%" align="left" valign="top">
      <p>
        Шлюз TensorZero поддерживает продвинутые возможности, такие как:
      </p>
      <ul>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/retries-fallbacks">Повторы и фолбэки</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations">Оптимизации времени инференса</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/prompt-templates-schemas">Шаблоны и схемы промптов</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/tutorial#experimentation">Эксперименты (A/B тестирование)</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/configuration-reference">Конфигурация как код (GitOps)</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/batch-inference">Пакетный инференс</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/multimodal-inference">Мультимодальный инференс (VLMs)</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/inference-caching">Кэширование инференса</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/metrics-feedback">Метрики и обратная связь</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/episodes">Многошаговые LLM-процессы (эпизоды)</a></b></li>
        <li><em>и многое другое…</em></li>
      </ul>
      <p>
        Шлюз TensorZero написан на Rust 🦀 с учетом <b>производительности</b> (&lt;1 мс p99 задержки при 10k QPS).
        См. <b><a href="https://www.tensorzero.com/docs/gateway/benchmarks">Бенчмарки</a></b>.<br>
      </p>
      <p>
        Вы можете запускать инференс с помощью <b>клиента TensorZero</b> (рекомендуется), <b>клиента OpenAI</b> или <b>HTTP API</b>.
      </p>
    </td>
  </tr>
</table>
<br>
<details open>
<summary><b>Использование: Python &mdash; Клиент TensorZero (рекомендуется)</b></summary>
<p>Вы можете получить доступ к любому провайдеру через Python-клиент TensorZero.</p>
<ol>
<li><code>pip install tensorzero</code></li>
<li>Опционально: настройте конфигурацию TensorZero.</li>
<li>Запустите инференс:</li>
</ol>
<pre><code class="language-python">from tensorzero import TensorZeroGateway  # или AsyncTensorZeroGateway


with TensorZeroGateway.build_embedded(clickhouse_url=&quot;...&quot;, config_file=&quot;...&quot;) as client:
    response = client.inference(
        model_name=&quot;openai::gpt-4o-mini&quot;,
        # Можно легко попробовать других провайдеров: &quot;anthropic::claude-3-7-sonnet-20250219&quot;
        input={
            &quot;messages&quot;: [
                {
                    &quot;role&quot;: &quot;user&quot;,
                    &quot;content&quot;: &quot;Напиши хайку об искусственном интеллекте.&quot;,
                }
            ]
        },
    )
</code></pre>
<p>Смотрите <strong><a href="https://www.tensorzero.com/docs/quickstart">Быстрый старт</a></strong> для получения дополнительной информации.</p>
</details>
<details>
<summary><b>Использование: Python &mdash; Клиент OpenAI</b></summary>
<p>Вы можете получить доступ к любому провайдеру через Python-клиент OpenAI с TensorZero.</p>
<ol>
<li><code>pip install tensorzero</code></li>
<li>Опционально: настройте конфигурацию TensorZero.</li>
<li>Запустите инференс:</li>
</ol>
<pre><code class="language-python">from openai import OpenAI  # или AsyncOpenAI
from tensorzero import patch_openai_client

client = OpenAI()
patch_openai_client(
    client,
    clickhouse_url=&quot;http://chuser:chpassword@localhost:8123/tensorzero&quot;,
    config_file=&quot;config/tensorzero.toml&quot;,
    async_setup=False,
)

response = client.chat.completions.create(
    model=&quot;tensorzero::model_name::openai::gpt-4o-mini&quot;,
    # Легко попробуйте других провайдеров: &quot;tensorzero::model_name::anthropic::claude-3-7-sonnet-20250219&quot;
    messages=[
        {
            &quot;role&quot;: &quot;user&quot;,
            &quot;content&quot;: &quot;Напиши хайку об искусственном интеллекте.&quot;,
        }
    ],
)
</code></pre>
<p>Смотрите <strong><a href="https://www.tensorzero.com/docs/quickstart">Быстрый старт</a></strong> для получения дополнительной информации.</p>
</details>
<details>
<summary><b>Использование: JavaScript / TypeScript (Node) &mdash; OpenAI Client</b></summary>
<p>Вы можете получить доступ к любому провайдеру, используя OpenAI Node client с TensorZero.</p>
<ol>
<li>Разверните <code>tensorzero/gateway</code> с помощью Docker.
<strong><a href="https://www.tensorzero.com/docs/gateway/deployment">Подробная инструкция →</a></strong></li>
<li>Настройте конфигурацию TensorZero.</li>
<li>Запустите инференс:</li>
</ol>
<pre><code class="language-ts">import OpenAI from &quot;openai&quot;;

const client = new OpenAI({
  baseURL: &quot;http://localhost:3000/openai/v1&quot;,
});

const response = await client.chat.completions.create({
  model: &quot;tensorzero::model_name::openai::gpt-4o-mini&quot;,
  // Легко попробуйте других провайдеров: &quot;tensorzero::model_name::anthropic::claude-3-7-sonnet-20250219&quot;
  messages: [
    {
      role: &quot;user&quot;,
      content: &quot;Напиши хайку об искусственном интеллекте.&quot;,
    },
  ],
});
</code></pre>
<p>Смотрите <strong><a href="https://www.tensorzero.com/docs/quickstart">Быстрый старт</a></strong> для получения дополнительной информации.</p>
</details>
<details>
<summary><b>Использование: Другие языки и платформы &mdash; HTTP API</b></summary>
<p>TensorZero поддерживает практически любой язык программирования или платформу через HTTP API.</p>
<ol>
<li>Разверните <code>tensorzero/gateway</code> с помощью Docker.
<strong><a href="https://www.tensorzero.com/docs/gateway/deployment">Подробная инструкция →</a></strong></li>
<li>Необязательно: настройте конфигурацию TensorZero.</li>
<li>Запустите инференс:</li>
</ol>
<pre><code class="language-bash">curl -X POST &quot;http://localhost:3000/inference&quot; \
  -H &quot;Content-Type: application/json&quot; \
  -d '{
    &quot;model_name&quot;: &quot;openai::gpt-4o-mini&quot;,
    &quot;input&quot;: {
      &quot;messages&quot;: [
        {
          &quot;role&quot;: &quot;user&quot;,
          &quot;content&quot;: &quot;Напиши хайку об искусственном интеллекте.&quot;
        }
      ]
    }
  }'
</code></pre>
<p>Смотрите <strong><a href="https://www.tensorzero.com/docs/quickstart">Быстрый старт</a></strong> для получения дополнительной информации.</p>
</details>
<br>
<h3>📈 Оптимизация LLM</h3>
<blockquote>
<p><strong>Отправляйте производственные метрики и обратную связь от пользователей для легкой оптимизации ваших промптов, моделей и стратегий инференса — через UI или программно.</strong></p>
</blockquote>
<h4>Оптимизация модели</h4>
<p>Оптимизируйте закрытые и открытые модели с помощью обучения с учителем (SFT) и обучения с предпочтениями (DPO).</p>
<table>
  <tr></tr> <!-- flip highlight order -->
  <tr>
    <td width="50%" align="center" valign="middle"><b>Обучение с учителем &mdash; UI</b></td>
    <td width="50%" align="center" valign="middle"><b>Обучение с предпочтениями (DPO) &mdash; Jupyter Notebook</b></td>
  </tr>
  <tr>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/cf7acf66-732b-43b3-af2a-5eba1ce40f6f"></td>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/a67a0634-04a7-42b0-b934-9130cb7cdf51"></td>
  </tr>
</table>
<h4>Оптимизация во время инференса</h4>
<p>Увеличьте производительность, динамически обновляя ваши промпты с помощью релевантных примеров, объединяя ответы из нескольких инференсов и многое другое.</p>
<table>
  <tr></tr> <!-- flip highlight order -->
  <tr>
    <td width="50%" align="center" valign="middle"><b><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#best-of-n-sampling">Best-of-N Sampling</a></b></td>
    <td width="50%" align="center" valign="middle"><b><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#mixture-of-n-sampling">Mixture-of-N Sampling</a></b></td>
  </tr>
  <tr>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/c0edfa4c-713c-4996-9964-50c0d26e6970"></td>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/75b5bf05-4c1f-43c4-b158-d69d1b8d05be"></td>
  </tr>
  <tr>
    <td width="50%" align="center" valign="middle"><b><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#dynamic-in-context-learning-dicl">Dynamic In-Context Learning (DICL)</a></b></td>
    <td width="50%" align="center" valign="middle"><b><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#chain-of-thought-cot">Chain-of-Thought (CoT)</a></b></td>
  </tr>
  <tr>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/d8489e92-ce93-46ac-9aab-289ce19bb67d"></td>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/ea13d73c-76a4-4e0c-a35b-0c648f898311" height="320"></td>
  </tr>
</table>
<p><em>Скоро будет больше...</em></p>
<br>
<h4>Оптимизация промптов</h4>
<p>Оптимизируйте ваши промпты программно с помощью исследовательских техник оптимизации.</p>
<table>
  <tr></tr> <!-- flip highlight order -->
  <tr>
    <td width="50%" align="center" valign="middle"><b><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#best-of-n-sampling">MIPROv2</a></b></td>
    <td width="50%" align="center" valign="middle"><b><a href="https://github.com/tensorzero/tensorzero/tree/main/examples/gsm8k-custom-recipe-dspy">Интеграция с DSPy</a></b></td>
  </tr>
  <tr>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/d81a7c37-382f-4c46-840f-e6c2593301db" alt="MIPROv2 diagram"></td>
    <td width="50%" align="center" valign="middle">
      TensorZero поставляется с несколькими рецептами оптимизации, но вы также можете легко создавать свои собственные.
      В этом примере показано, как оптимизировать функцию TensorZero с помощью произвольного инструмента — здесь DSPy, популярной библиотеки для автоматизированной инженерии промптов.
    </td>
  </tr>
</table>
<p><em>Скоро будет больше...</em></p>
<br>
<h3>🔍 Наблюдаемость LLM</h3>
<blockquote>
<p><strong>Приближайтесь для отладки отдельных вызовов API или отслеживайте метрики по моделям и промптам с течением времени — всё это с помощью open-source UI TensorZero.</strong></p>
</blockquote>
<table>
  <tr></tr> <!-- flip highlight order -->
  <tr>
    <td width="50%" align="center" valign="middle"><b>Наблюдаемость » Инференс</b></td>
    <td width="50%" align="center" valign="middle"><b>Наблюдаемость » Функция</b></td>
  </tr>
  <tr>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/2cc3cc9a-f33f-4e94-b8de-07522326f80a"></td>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/00ae6605-8fa0-4efd-8238-ae8ea589860f"></td>
  </tr>
</table>
<br>
<h3>📊 Оценки LLM</h3>
<blockquote>
<p><strong>Сравнивайте промпты, модели и стратегии инференса с помощью TensorZero Evaluations — с поддержкой эвристик и судей на базе LLM.</strong></p>
</blockquote>
<table>
  <tr></tr> <!-- flip highlight order -->
  <tr>
    <td width="50%" align="center" valign="middle"><b>Оценка » UI</b></td>
    <td width="50%" align="center" valign="middle"><b>Оценка » CLI</b></td>
  </tr>
  <tr>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/f4bf54e3-1b63-46c8-be12-2eaabf615699"></td>
    <td width="50%" align="left" valign="middle">
<pre><code class="language-bash">docker compose run --rm evaluations \
  --evaluation-name extract_data \
  --dataset-name hard_test_cases \
  --variant-name gpt_4o \
  --concurrency 5</code></pre>
<pre><code class="language-bash">Run ID: 01961de9-c8a4-7c60-ab8d-15491a9708e4
Number of datapoints: 100
██████████████████████████████████████ 100/100
exact_match: 0.83 ± 0.03
semantic_match: 0.98 ± 0.01
item_count: 7.15 ± 0.39</code></pre>
    </td>
  </tr>
</table>
<h2>Демонстрация</h2>
<blockquote>
<p><strong>Смотрите, как LLM улучшают извлечение данных в реальном времени с TensorZero!</strong></p>
<p><strong><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#dynamic-in-context-learning-dicl">Динамическое обучение в контексте (DICL)</a></strong> — это мощная оптимизация на этапе инференса, доступная из коробки с TensorZero.
Она повышает производительность LLM, автоматически включая релевантные исторические примеры в prompt, без необходимости дообучения модели.</p>
</blockquote>
<p>https://github.com/user-attachments/assets/4df1022e-886e-48c2-8f79-6af3cdad79cb</p>
<h2>Инженерия LLM с TensorZero</h2>
<br>
<p align="center" >
  <a href="https://www.tensorzero.com/docs">
    <picture>
      <source media="(prefers-color-scheme: light)" srcset="https://github.com/user-attachments/assets/34a92c18-242e-4d76-a99c-861283de68a6">
      <source media="(prefers-color-scheme: dark)" srcset="https://github.com/user-attachments/assets/e8bc699b-6378-4c2a-9cc1-6d189025e270">
      <img alt="TensorZero Flywheel" src="https://github.com/user-attachments/assets/34a92c18-242e-4d76-a99c-861283de68a6" width=720>
    </picture>
  </a>
</p>
<br>
<ol>
<li><strong><a href="https://www.tensorzero.com/docs/gateway/">TensorZero Gateway</a></strong> — это высокопроизводительный шлюз моделей, написанный на Rust 🦀, который предоставляет унифицированный API-интерфейс для всех основных LLM-провайдеров, обеспечивая бесшовную интеграцию между платформами и резервирование.</li>
<li>Он поддерживает структурированный инференс на основе схем с задержкой &lt;1мс P99 (см. <strong><a href="https://www.tensorzero.com/docs/gateway/benchmarks">Бенчмарки</a></strong>), а также встроенную наблюдаемость, эксперименты и <strong><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations">оптимизации на этапе инференса</a></strong>.</li>
<li>Также осуществляется сбор downstream-метрик и обратной связи, связанных с этими инференсами, с полноценной поддержкой многошаговых LLM-систем.</li>
<li>Все хранится в хранилище данных ClickHouse, которое вы контролируете, для получения масштабируемой, быстрой и удобной для разработчика аналитики в реальном времени.</li>
<li>Со временем <strong><a href="https://www.tensorzero.com/docs/recipes">TensorZero Recipes</a></strong> используют этот структурированный датасет для оптимизации ваших prompt'ов и моделей: запускайте готовые решения для типовых рабочих процессов, таких как дообучение, или создавайте свои собственные — с полной свободой на любом языке и платформе.</li>
<li>Наконец, функции экспериментов шлюза и GitOps-оркестрация позволяют вам с уверенностью итерационно улучшать и внедрять решения — будь то одна LLM или тысячи LLM.</li>
</ol>
<p>Наша цель — помочь инженерам строить, управлять и оптимизировать новое поколение LLM-приложений: системы, которые учатся на реальном опыте.
Подробнее о нашем <strong><a href="https://www.tensorzero.com/docs/vision-roadmap/">видении и дорожной карте</a></strong>.</p>
<h2>Начало работы</h2>
<p><strong>Начните строить уже сегодня.</strong>
<strong><a href="https://www.tensorzero.com/docs/quickstart">Быстрый старт</a></strong> покажет, как легко развернуть LLM-приложение с TensorZero.
Если хотите погрузиться глубже, <strong><a href="https://www.tensorzero.com/docs/gateway/tutorial">Туториал</a></strong> научит, как собрать простого чат-бота, почтового копилота, систему погодного RAG и pipeline для структурированного извлечения данных.</p>
<p><strong>Есть вопросы?</strong>
Пишите нам в <strong><a href="https://www.tensorzero.com/slack">Slack</a></strong> или <strong><a href="https://www.tensorzero.com/discord">Discord</a></strong>.</p>
<p><strong>Используете TensorZero на работе?</strong>
Пишите на <strong><a href="mailto:hello@tensorzero.com">hello@tensorzero.com</a></strong>, чтобы бесплатно создать Slack или Teams-канал для вашей команды.</p>
<p><strong>Работайте с нами.</strong>
Мы <strong><a href="https://www.tensorzero.com/jobs">ищем сотрудников в Нью-Йорке</a></strong>.
Также будем рады <strong><a href="https://github.com/tensorzero/tensorzero/blob/main/CONTRIBUTING.md">open-source вкладам</a></strong>!</p>
<h2>Примеры</h2>
<p>Мы работаем над серией <strong>полных исполняемых примеров</strong>, иллюстрирующих работу с данными и обучением в TensorZero.</p>
<blockquote>
<p><strong><a href="https://github.com/tensorzero/tensorzero/tree/main/examples/data-extraction-ner">Оптимизация извлечения данных (NER) с TensorZero</a></strong></p>
<p>В этом примере показано, как использовать TensorZero для оптимизации pipeline извлечения данных.
Мы демонстрируем такие техники, как дообучение и динамическое обучение в контексте (DICL).
В итоге оптимизированная модель GPT-4o Mini превосходит GPT-4o в этой задаче — при меньших затратах и задержках — используя небольшой объем обучающих данных.</p>
</blockquote>
<blockquote>
<p><strong><a href="https://github.com/tensorzero/tensorzero/tree/main/examples/rag-retrieval-augmented-generation/simple-agentic-rag/">Agentic RAG — Многошаговые ответы на вопросы с LLM</a></strong></p>
<p>В этом примере показано, как построить многошагового retrieval-агента с помощью TensorZero.
Агент итеративно ищет информацию в Википедии и сам решает, когда у него достаточно контекста для ответа на сложный вопрос.</p>
</blockquote>
<blockquote>
<p><strong><a href="https://github.com/tensorzero/tensorzero/tree/main/examples/haiku-hidden-preferences">Написание хайку для судьи со скрытыми предпочтениями</a></strong></p>
<p>В этом примере GPT-4o Mini дообучается генерировать хайку под определенный вкус.
Вы увидите работу &quot;data flywheel in a box&quot; TensorZero: лучшие варианты приводят к лучшим данным, а лучшие данные — к лучшим вариантам.
Вы увидите прогресс при многократном дообучении LLM.</p>
</blockquote>
<blockquote>
<p><strong><a href="https://github.com/tensorzero/tensorzero/tree/main/examples/chess-puzzles/">Улучшение шахматных навыков LLM с помощью Best-of-N Sampling</a></strong></p>
<p>Этот пример показывает, как best-of-N sampling может значительно повысить шахматные способности LLM, выбирая наиболее перспективные ходы из нескольких сгенерированных вариантов.</p>
</blockquote>
<blockquote>
<p><strong><a href="https://github.com/tensorzero/tensorzero/tree/main/examples/gsm8k-custom-recipe-dspy">Улучшение математических рассуждений с помощью кастомного recipe для автоматизированной инженерии prompt'ов (DSPy)</a></strong></p>
<p>TensorZero предоставляет ряд готовых рецептов оптимизации для стандартных инженерных рабочих процессов LLM.
Но вы также можете легко создавать собственные рецепты и workflow!
В этом примере показано, как оптимизировать функцию TensorZero с помощью любого инструмента — здесь, DSPy.</p>
</blockquote>
<p><em>&amp; многие другие уже на подходе!</em></p>
<hr />
<p>Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx">Open Ai Tx</a> | Last indexed: 2025-06-09</p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Statcounter and other scripts can be added here -->
</body>
</html>