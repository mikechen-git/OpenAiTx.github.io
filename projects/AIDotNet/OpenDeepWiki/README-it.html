<!DOCTYPE html>
<html lang="it">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>OpenDeepWiki - AIDotNet/OpenDeepWiki</title>
    <meta name="title" content="OpenDeepWiki - AIDotNet/OpenDeepWiki">
    <meta name="description" content="AIDotNet/OpenDeepWiki - GitHub repository it documentation and informationOpenDeepWiki 中文 | English Base di Conoscenza del Codice Guidata dall’AI Sponsor 302.AI è una piattaforma AI aziendale all-in-one a pagamento secondo l'uso. Offre una piattaforma aperta e un ecosistema open-source, permettendo all’AI di trovare soluzioni per ogni esigenza. Clicca qui per ottenere $1 di credito gratuito! Funzionalità Conversione Rapida: Tutti i repository di codice di Github, Gitlab, Gitee, Gitea e altri possono essere convertiti in basi di conoscenza in pochi minuti. Supporto Multilingue: Analisi del codice e generazione di documentazione supportate per tutti i linguaggi di programmazione. Struttura del Codice: Generazione automatica di diagrammi Mermaid per comprendere la struttura del codice. Modelli Personalizzati: Supporta modelli e API personalizzati, consentendo espansione secondo necessità. Analisi Intelligente AI: Analisi del codice e comprensione delle relazioni basate sull’AI. SEO Facile: Genera documenti e basi di conoscenza ottimizzate per SEO con Next.js, facilitando l’indicizzazione sui motori di ricerca. Interazione Dialogica: Supporta l’interazione dialogica con...">
    <meta name="keywords" content="AIDotNet, OpenDeepWiki, GitHub, repository, it documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/AIDotNet/OpenDeepWiki/README-it.html">
    <meta property="og:title" content="OpenDeepWiki - AIDotNet/OpenDeepWiki">
    <meta property="og:description" content="AIDotNet/OpenDeepWiki - GitHub repository it documentation and information">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/AIDotNet/OpenDeepWiki" id="githubRepoLink" target="_blank">AIDotNet/OpenDeepWiki</a>
<br>
<h1 style="display: none;">OpenDeepWiki 中文 | English Base di Conoscenza del Codice Guidata dall’AI Sponsor 302.AI è una piattaforma AI aziendale all-in-one a pagamento secondo l'uso. Offre una piattaforma aperta e un ecosistema open-source, permettendo all’AI di trovare soluzioni per ogni esigenza. Clicca qui per ottenere $1 di credito gratuito! Funzionalità Conversione Rapida: Tutti i repository di codice di Github, Gitlab, Gitee, Gitea e altri possono essere convertiti in basi di conoscenza in pochi minuti. Supporto Multilingue: Analisi del codice e generazione di documentazione supportate per tutti i linguaggi di programmazione. Struttura del Codice: Generazione automatica di diagrammi Mermaid per comprendere la struttura del codice. Modelli Personalizzati: Supporta modelli e API personalizzati, consentendo espansione secondo necessità. Analisi Intelligente AI: Analisi del codice e comprensione delle relazioni basate sull’AI. SEO Facile: Genera documenti e basi di conoscenza ottimizzate per SEO con Next.js, facilitando l’indicizzazione sui motori di ricerca. Interazione Dialogica: Supporta l’interazione dialogica con...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <h1>OpenDeepWiki</h1>
<p><a href="https://raw.githubusercontent.com/AIDotNet/OpenDeepWiki/main/README.zh-CN.md">中文</a> | <a href="https://raw.githubusercontent.com/AIDotNet/OpenDeepWiki/main/README.md">English</a></p>
<div align="center">
  <img src="https://raw.githubusercontent.com/AIDotNet/OpenDeepWiki/main/img/favicon.png" alt="OpenDeepWiki Logo" width="200" />
  <h3>Base di Conoscenza del Codice Guidata dall’AI</h3>
</div>
<h1>Sponsor</h1>
<p><a href="https://share.302.ai/jXcaTv"><img src="https://github.com/user-attachments/assets/b1bcb56e-38cb-47bf-adfe-7a21d83774b4" alt="image" /></a></p>
<p><a href="https://share.302.ai/jXcaTv">302.AI</a> è una piattaforma AI aziendale all-in-one a pagamento secondo l'uso. Offre una piattaforma aperta e un ecosistema open-source, permettendo all’AI di trovare soluzioni per ogni esigenza. Clicca <a href="https://share.302.ai/jXcaTv">qui</a> per ottenere $1 di credito gratuito!</p>
<h2>Funzionalità</h2>
<ul>
<li><strong>Conversione Rapida:</strong> Tutti i repository di codice di Github, Gitlab, Gitee, Gitea e altri possono essere convertiti in basi di conoscenza in pochi minuti.</li>
<li><strong>Supporto Multilingue:</strong> Analisi del codice e generazione di documentazione supportate per tutti i linguaggi di programmazione.</li>
<li><strong>Struttura del Codice:</strong> Generazione automatica di diagrammi Mermaid per comprendere la struttura del codice.</li>
<li><strong>Modelli Personalizzati:</strong> Supporta modelli e API personalizzati, consentendo espansione secondo necessità.</li>
<li><strong>Analisi Intelligente AI:</strong> Analisi del codice e comprensione delle relazioni basate sull’AI.</li>
<li><strong>SEO Facile:</strong> Genera documenti e basi di conoscenza ottimizzate per SEO con Next.js, facilitando l’indicizzazione sui motori di ricerca.</li>
<li><strong>Interazione Dialogica:</strong> Supporta l’interazione dialogica con l’AI per ottenere informazioni dettagliate e modalità d’uso del codice, approfondendo la comprensione.</li>
</ul>
<p>Elenco funzionalità:</p>
<ul>
<li>[x] Supporta molteplici repository di codice (Github, Gitlab, Gitee, Gitea, ecc.)</li>
<li>[x] Supporta molti linguaggi di programmazione (Python, Java, C#, JavaScript, ecc.)</li>
<li>[x] Supporta la gestione dei repository, fornendo funzioni per aggiungere, eliminare, modificare e consultare i repository</li>
<li>[x] Supporta diversi provider AI (OpenAI, AzureOpenAI, Anthropic, ecc.)</li>
<li>[x] Supporta diversi database (SQLite, PostgreSQL, SqlServer, ecc.)</li>
<li>[x] Supporta molte lingue (Cinese, Inglese, Francese, ecc.)</li>
<li>[x] Supporta il caricamento di file ZIP e file locali</li>
<li>[x] Fornisce una piattaforma per la generazione di dataset di fine-tuning</li>
<li>[x] Supporta la gestione a livello di directory dei repository, consentendo la generazione di directory personalizzate e la creazione dinamica di documentazione</li>
<li>[x] Supporta la gestione delle directory dei repository, consentendo la modifica delle directory</li>
<li>[x] Supporta la gestione a livello utente, fornendo funzioni per aggiungere, eliminare, modificare e consultare utenti</li>
<li>[ ] Supporta la gestione dei permessi utente, fornendo funzioni per aggiungere, eliminare, modificare e consultare permessi utente</li>
<li>[x] Supporta la generazione di diversi dataset di fine-tuning a livello di repository</li>
</ul>
<h1>Introduzione al Progetto</h1>
<p>OpenDeepWiki è un progetto open-source ispirato a <a href="https://deepwiki.com/">DeepWiki</a>, sviluppato con .NET 9 e Semantic Kernel. Mira ad aiutare gli sviluppatori a comprendere e utilizzare meglio i codebase fornendo funzionalità come analisi del codice, generazione di documentazione e creazione di grafi di conoscenza.</p>
<ul>
<li>Analizza la struttura del codice</li>
<li>Comprende i concetti fondamentali dei repository</li>
<li>Genera la documentazione del codice</li>
<li>Crea automaticamente README.md per il codice
Supporto MCP</li>
</ul>
<p>OpenDeepWiki supporta MCP (Model Context Protocol)</p>
<ul>
<li>Supporta la fornitura di un MCPServer per un singolo repository e l’analisi su un singolo repository.</li>
</ul>
<p>Utilizzo: Di seguito è riportato l’uso di cursor:</p>
<pre><code class="language-json">{
  &quot;mcpServers&quot;: {
    &quot;OpenDeepWiki&quot;:{
      &quot;url&quot;: &quot;http://Il tuo IP servizio OpenDeepWiki:porta/sse?owner=AIDotNet&amp;name=OpenDeepWiki&quot;
    }
  }
}
</code></pre>
<ul>
<li>owner: È il nome dell’organizzazione o del proprietario del repository.</li>
<li>name: È il nome del repository.</li>
</ul>
<p>Dopo aver aggiunto il repository, prova a fare una domanda (nota che prima di ciò il repository deve essere processato): Cos’è OpenDeepWiki? L’effetto è come mostrato in figura: <img src="https://raw.githubusercontent.com/AIDotNet/OpenDeepWiki/main/img/mcp.png" alt="" /></p>
<p>In questo modo puoi usare OpenDeepWiki come MCPServer, rendendolo disponibile per la chiamata da altri modelli AI, facilitando l’analisi e la comprensione di un progetto open-source.</p>
<h2>🚀 Avvio Rapido</h2>
<ol>
<li>Clona il repository</li>
</ol>
<pre><code class="language-bash">git clone https://github.com/AIDotNet/OpenDeepWiki.git
cd OpenDeepWiki
</code></pre>
<ol start="2">
<li>Apri il file <code>docker-compose.yml</code> e modifica le seguenti variabili d’ambiente:</li>
</ol>
<p>Ollama:</p>
<pre><code class="language-yaml">services:
  koalawiki:
    environment:
      - KOALAWIKI_REPOSITORIES=/repositories
      - TASK_MAX_SIZE_PER_USER=5 # Numero massimo di task di generazione documenti in parallelo per utente tramite AI
      - CHAT_MODEL=qwen2.5:32b # Il modello deve supportare le funzioni
      - ANALYSIS_MODEL=qwen2.5:32b # Modello di analisi utilizzato per generare la struttura della directory del repository
      - CHAT_API_KEY=sk-xxxxx # La tua API key
      - LANGUAGE= # Imposta la lingua predefinita di generazione su &quot;Chinese&quot;
      - ENDPOINT=https://IP di Ollama: Porta/v1
      - DB_TYPE=sqlite
      - MODEL_PROVIDER=OpenAI # Provider del modello, predefinito OpenAI, supporta AzureOpenAI e Anthropic
      - DB_CONNECTION_STRING=Data Source=/data/KoalaWiki.db
      - EnableSmartFilter=true # Se abilitare il filtro intelligente può influire su come l’AI ottiene la directory dei file del repository
      - UPDATE_INTERVAL # Intervallo di aggiornamento incrementale del repository, unità: giorni
      - MAX_FILE_LIMIT=100 # Limite massimo per il caricamento dei file, in MB
      - DEEP_RESEARCH_MODEL= # Ricerca approfondita sul modello, usa CHAT_MODEL se vuoto
      - ENABLE_INCREMENTAL_UPDATE=true # Se abilitare gli aggiornamenti incrementali
      - ENABLE_CODED_DEPENDENCY_ANALYSIS=false # Se abilitare l’analisi delle dipendenze del codice, può influire sulla qualità del codice
      - ENABLE_WAREHOUSE_FUNCTION_PROMPT_TASK=false # Se abilitare la generazione di prompt MCP
      - ENABLE_WAREHOUSE_DESCRIPTION_TASK=false # Se abilitare la generazione della descrizione del repository
</code></pre>
<p>OpenAI:</p>
<pre><code class="language-yaml">services:
  koalawiki:
    environment:
      - KOALAWIKI_REPOSITORIES=/repositories
      - TASK_MAX_SIZE_PER_USER=5 # Numero massimo di task di generazione documenti in parallelo per utente tramite AI
      - CHAT_MODEL=DeepSeek-V3 # Il modello deve supportare le funzioni
      - ANALYSIS_MODEL= # Modello di analisi utilizzato per generare la struttura della directory del repository
      - CHAT_API_KEY= # La tua API key
      - LANGUAGE= # Imposta la lingua predefinita di generazione su &quot;Chinese&quot;
      - ENDPOINT=https://api.token-ai.cn/v1
      - DB_TYPE=sqlite
      - MODEL_PROVIDER=OpenAI # Provider del modello, predefinito OpenAI, supporta AzureOpenAI e Anthropic
      - DB_CONNECTION_STRING=Data Source=/data/KoalaWiki.db
      - EnableSmartFilter=true # Se abilitare il filtro intelligente può influire su come l’AI ottiene la directory dei file del repository
      - UPDATE_INTERVAL # Intervallo di aggiornamento incrementale del repository, unità: giorni
      - MAX_FILE_LIMIT=100 # Limite massimo per il caricamento dei file, in MB
      - DEEP_RESEARCH_MODEL= # Ricerca approfondita sul modello, usa CHAT_MODEL se vuoto
      - ENABLE_INCREMENTAL_UPDATE=true # Se abilitare gli aggiornamenti incrementali
      - ENABLE_CODED_DEPENDENCY_ANALYSIS=false # Se abilitare l’analisi delle dipendenze del codice, può influire sulla qualità del codice
      - ENABLE_WAREHOUSE_FUNCTION_PROMPT_TASK=false # Se abilitare la generazione di prompt MCP
      - ENABLE_WAREHOUSE_DESCRIPTION_TASK=false # Se abilitare la generazione della descrizione del repository
</code></pre>
<p>AzureOpenAI:</p>
<pre><code class="language-yaml">services:
  koalawiki:
    environment:
      - KOALAWIKI_REPOSITORIES=/repositories
      - TASK_MAX_SIZE_PER_USER=5 # Numero massimo di task di generazione documenti in parallelo per utente tramite AI
      - CHAT_MODEL=DeepSeek-V3 # Il modello deve supportare le funzioni
      - ANALYSIS_MODEL= # Modello di analisi utilizzato per generare la struttura della directory del repository
      - CHAT_API_KEY= # La tua API key
      - LANGUAGE= # Imposta la lingua predefinita di generazione su &quot;Chinese&quot;
      - ENDPOINT=https://your-azure-address.openai.azure.com/
      - DB_TYPE=sqlite
      - MODEL_PROVIDER=AzureOpenAI # Provider del modello, predefinito OpenAI, supporta AzureOpenAI e Anthropic
      - DB_CONNECTION_STRING=Data Source=/data/KoalaWiki.db
      - EnableSmartFilter=true # Se abilitare il filtro intelligente può influire su come l’AI ottiene la directory dei file del repository
      - UPDATE_INTERVAL # Intervallo di aggiornamento incrementale del repository, unità: giorni
      - MAX_FILE_LIMIT=100 # Limite massimo per il caricamento dei file, in MB
      - DEEP_RESEARCH_MODEL= # Ricerca approfondita sul modello, usa CHAT_MODEL se vuoto
      - ENABLE_INCREMENTAL_UPDATE=true # Se abilitare gli aggiornamenti incrementali
      - ENABLE_CODED_DEPENDENCY_ANALYSIS=false # Se abilitare l’analisi delle dipendenze del codice, può influire sulla qualità del codice
      - ENABLE_WAREHOUSE_FUNCTION_PROMPT_TASK=false # Se abilitare la generazione di prompt MCP
      - ENABLE_WAREHOUSE_DESCRIPTION_TASK=false # Se abilitare la generazione della descrizione del repository
</code></pre>
<p>Anthropic:</p>
<pre><code class="language-yaml">services:
  koalawiki:
    environment:
      - KOALAWIKI_REPOSITORIES=/repositories
      - TASK_MAX_SIZE_PER_USER=5 # Numero massimo di task di generazione documenti in parallelo per utente tramite AI
      - CHAT_MODEL=DeepSeek-V3 # Il modello deve supportare le funzioni
      - ANALYSIS_MODEL= # Modello di analisi utilizzato per generare la struttura della directory del repository
      - CHAT_API_KEY= # La tua API key
      - LANGUAGE= # Imposta la lingua predefinita di generazione su &quot;Chinese&quot;
      - ENDPOINT=https://api.anthropic.com/
      - DB_TYPE=sqlite
      - MODEL_PROVIDER=Anthropic # Provider del modello, predefinito OpenAI, supporta AzureOpenAI e Anthropic
      - DB_CONNECTION_STRING=Data Source=/data/KoalaWiki.db
      - EnableSmartFilter=true # Se abilitare il filtro intelligente può influire su come l’AI ottiene la directory dei file del repository
      - UPDATE_INTERVAL # Intervallo di aggiornamento incrementale del repository, unità: giorni
      - MAX_FILE_LIMIT=100 # Limite massimo per il caricamento dei file, in MB
      - DEEP_RESEARCH_MODEL= # Ricerca approfondita sul modello, usa CHAT_MODEL se vuoto
      - ENABLE_INCREMENTAL_UPDATE=true # Se abilitare gli aggiornamenti incrementali
      - ENABLE_CODED_DEPENDENCY_ANALYSIS=false # Se abilitare l’analisi delle dipendenze del codice, può influire sulla qualità del codice
      - ENABLE_WAREHOUSE_FUNCTION_PROMPT_TASK=false # Se abilitare la generazione di prompt MCP
      - ENABLE_WAREHOUSE_DESCRIPTION_TASK=false # Se abilitare la generazione della descrizione del repository
</code></pre>
<blockquote>
<p>💡 <strong>Come ottenere una API Key:</strong></p>
<ul>
<li>Ottieni la Google API key <a href="https://makersuite.google.com/app/apikey">Google AI Studio</a></li>
<li>Ottieni la OpenAI API key <a href="https://platform.openai.com/api-keys">OpenAI Platform</a></li>
<li>Ottieni CoresHub <a href="https://console.coreshub.cn/xb3/maas/global-keys">CoresHub</a> <a href="https://account.coreshub.cn/signup?invite=ZmpMQlZxYVU=">Clicca qui per 50 milioni di token gratis</a></li>
<li>Ottieni TokenAI <a href="https://api.token-ai.cn/">TokenAI</a></li>
</ul>
</blockquote>
<ol start="3">
<li>Avvia il servizio</li>
</ol>
<p>Puoi utilizzare i comandi Makefile forniti per gestire facilmente l’applicazione:</p>
<pre><code class="language-bash"># Costruisci tutte le immagini Docker
make build

# Avvia tutti i servizi in modalità background
make up

# O avvia in modalità sviluppo (con log visibili)
</code></pre>
<p>make dev</p>
<pre><code>
Quindi visita http://localhost:8090 per accedere alla base di conoscenza.

Per altri comandi:
```bash
make help
</code></pre>
<h3>Per Utenti Windows (senza make)</h3>
<p>Se utilizzi Windows e non hai <code>make</code> disponibile, puoi usare direttamente questi comandi Docker Compose:</p>
<pre><code class="language-bash"># Costruisci tutte le immagini Docker
docker-compose build

# Avvia tutti i servizi in modalità background
docker-compose up -d

# Avvia in modalità sviluppo (con log visibili)
docker-compose up

# Ferma tutti i servizi
docker-compose down

# Visualizza i log
docker-compose logs -f
</code></pre>
<p>Per compilare architetture o servizi specifici, usa:</p>
<pre><code class="language-bash"># Compila solo il backend
docker-compose build koalawiki

# Compila solo il frontend
docker-compose build koalawiki-web

# Compila con parametri di architettura
docker-compose build --build-arg ARCH=arm64
docker-compose build --build-arg ARCH=amd64
</code></pre>
<h3>Deploy su Sealos con Accesso Internet Pubblico</h3>
<p><a href="https://bja.sealos.run/?openapp=system-template%3FtemplateName%3DOpenDeepWiki"><img src="https://raw.githubusercontent.com/labring-actions/templates/main/Deploy-on-Sealos.svg" alt="" /></a>
Per i passaggi dettagliati, fare riferimento a: <a href="https://raw.githubusercontent.com/AIDotNet/OpenDeepWiki/main/scripts/sealos/README.zh-CN.md">Distribuzione con un click di OpenDeepWiki come applicazione Sealos esposta alla rete pubblica utilizzando Template</a></p>
<h2>🔍 Come Funziona</h2>
<p>OpenDeepWiki utilizza l’AI per:</p>
<ul>
<li>Clonare il repository del codice in locale</li>
<li>Analizzare in base al README.md del repository</li>
<li>Analizzare la struttura del codice e leggere i file di codice se necessario, poi generare dati json della directory</li>
<li>Elaborare i task secondo la directory, ogni task è un documento</li>
<li>Leggere i file di codice, analizzare i file di codice, generare la documentazione del codice e creare grafici Mermaid che rappresentano le dipendenze della struttura del codice</li>
<li>Generare il documento finale della base di conoscenza</li>
<li>Analizzare il repository tramite interazione conversazionale e rispondere alle richieste degli utenti</li>
</ul>
<pre><code class="language-mermaid">graph TD
    A[Clona il repository del codice] --&gt; B[Analizza README.md]
    B --&gt; C[Analizza la struttura del codice]
    C --&gt; D[Genera dati json della directory]
    D --&gt; E[Elabora task multipli]
    E --&gt; F[Legge i file di codice]
    F --&gt; G[Analizza i file di codice]
    G --&gt; H[Genera documentazione del codice]
    H --&gt; I[Crea grafici Mermaid]
    I --&gt; J[Genera documento base di conoscenza]
    J --&gt; K[Interazione conversazionale]
</code></pre>
<h2>Configurazione Avanzata</h2>
<h3>Variabili d’Ambiente</h3>
<ul>
<li>KOALAWIKI_REPOSITORIES  Percorso per la memorizzazione dei repository</li>
<li>TASK_MAX_SIZE_PER_USER  Numero massimo di task paralleli per la generazione di documenti AI per utente</li>
<li>CHAT_MODEL  Il modello deve supportare le funzioni</li>
<li>ENDPOINT  Endpoint API</li>
<li>ANALYSIS_MODEL  Modello di analisi per la generazione della struttura della directory del repository</li>
<li>CHAT_API_KEY  La tua API key</li>
<li>LANGUAGE  Cambia la lingua dei documenti generati</li>
<li>DB_TYPE  Tipo di database, il valore predefinito è sqlite</li>
<li>MODEL_PROVIDER  Fornitore del modello, predefinito OpenAI, supporta Azure, OpenAI e Anthropic</li>
<li>DB_CONNECTION_STRING  Stringa di connessione al database</li>
<li>EnableSmartFilter  Se il filtro intelligente è abilitato o meno può influire su come l’AI può ottenere la directory dei file del repository</li>
<li>UPDATE_INTERVAL  Intervallo di aggiornamento incrementale del repository, unità: giorni</li>
<li>MAX_FILE_LIMIT  Limite massimo per il caricamento dei file, in MB</li>
<li>DEEP_RESEARCH_MODEL  Esegui ricerca approfondita sul modello e usa CHAT_MODEL per il vuoto</li>
<li>ENABLE_INCREMENTAL_UPDATE  Se abilitare l’aggiornamento incrementale</li>
<li>ENABLE_CODED_DEPENDENCY_ANALYSIS  Se abilitare l’analisi delle dipendenze del codice, questo potrebbe avere un impatto sulla qualità del codice.</li>
<li>ENABLE_WAREHOUSE_FUNCTION_PROMPT_TASK  # Se abilitare o meno la generazione del prompt MCP.</li>
<li>ENABLE_WAREHOUSE_DESCRIPTION_TASK # Se abilitare la generazione della Descrizione del repository</li>
</ul>
<h3>Compilazione per Diverse Architetture</h3>
<p>Il Makefile fornisce comandi per compilare per diverse architetture CPU:</p>
<pre><code class="language-bash"># Compila per architettura ARM
make build-arm

# Compila per architettura AMD
make build-amd

# Compila solo il backend per ARM
make build-backend-arm

# Compila solo il frontend per AMD
make build-frontend-amd
</code></pre>
<h2>Discord</h2>
<p><a href="https://discord.gg/8sxUNacv">unisciti a noi</a></p>
<h2>WeChat</h2>
<p><img src="https://github.com/user-attachments/assets/2bb0055f-9e45-4db2-b9c9-f1e251996e01" alt="b62354e40046f409b88528dd5631ed45" /></p>
<h2>📄 Licenza</h2>
<p>Questo progetto è rilasciato sotto licenza MIT - vedi il file <a href="https://raw.githubusercontent.com/AIDotNet/OpenDeepWiki/main/LICENSE">LICENSE</a> per i dettagli.</p>
<h2>Star History</h2>
<p><a href="https://www.star-history.com/#AIDotNet/OpenDeepWiki&amp;Date"><img src="https://api.star-history.com/svg?repos=AIDotNet/OpenDeepWiki&amp;type=Date" alt="Star History Chart" /></a></p>
<hr />
<p>Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx">Open Ai Tx</a> | Last indexed: 2025-06-11</p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Statcounter and other scripts can be added here -->
</body>
</html>