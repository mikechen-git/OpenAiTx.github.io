<!DOCTYPE html>
<html lang="fa">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>OpenDeepWiki - AIDotNet/OpenDeepWiki</title>
    <meta name="title" content="OpenDeepWiki - AIDotNet/OpenDeepWiki">
    <meta name="description" content="AIDotNet/OpenDeepWiki - GitHub repository fa documentation and informationOpenDeepWiki 中文 | English پایگاه دانش کد مبتنی بر هوش مصنوعی حمایت‌کننده 302.AI یک پلتفرم هوش مصنوعی در سطح سازمانی، با مدل پرداخت به اندازه مصرف است. این پلتفر...">
    <meta name="keywords" content="AIDotNet, OpenDeepWiki, GitHub, repository, fa documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/AIDotNet/OpenDeepWiki/README-fa.html">
    <meta property="og:title" content="OpenDeepWiki - AIDotNet/OpenDeepWiki">
    <meta property="og:description" content="AIDotNet/OpenDeepWiki - GitHub repository fa documentation and information">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/AIDotNet/OpenDeepWiki" id="githubRepoLink" target="_blank">AIDotNet/OpenDeepWiki</a>
<h1 style="display: none;">OpenDeepWiki 中文 | English پایگاه دانش کد مبتنی بر هوش مصنوعی حمایت‌کننده 302.AI یک پلتفرم هوش مصنوعی در سطح سازمانی، با مدل پرداخت به اندازه مصرف است. این پلتفر...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <h1>OpenDeepWiki</h1>
<p><a href="https://raw.githubusercontent.com/AIDotNet/OpenDeepWiki/main/README.zh-CN.md">中文</a> | <a href="https://raw.githubusercontent.com/AIDotNet/OpenDeepWiki/main/README.md">English</a></p>
<div align="center">
  <img src="https://raw.githubusercontent.com/AIDotNet/OpenDeepWiki/main/img/favicon.png" alt="OpenDeepWiki Logo" width="200" />
  <h3>پایگاه دانش کد مبتنی بر هوش مصنوعی</h3>
</div>
<h1>حمایت‌کننده</h1>
<p><a href="https://share.302.ai/jXcaTv"><img src="https://github.com/user-attachments/assets/b1bcb56e-38cb-47bf-adfe-7a21d83774b4" alt="image" /></a></p>
<p><a href="https://share.302.ai/jXcaTv">302.AI</a> یک پلتفرم هوش مصنوعی در سطح سازمانی، با مدل پرداخت به اندازه مصرف است. این پلتفرم یک اکوسیستم متن‌باز و بستری باز ارائه می‌دهد تا هوش مصنوعی بتواند برای هر نیازی راهکاری بیابد. برای دریافت ۱ دلار اعتبار رایگان، <a href="https://share.302.ai/jXcaTv">اینجا کلیک کنید</a>!</p>
<h2>قابلیت‌ها</h2>
<ul>
<li><strong>تبدیل سریع:</strong> تمامی مخازن کد در Github، Gitlab، Gitee، Gitea و سایر پلتفرم‌ها را می‌توان تنها در چند دقیقه به پایگاه دانش تبدیل کرد.</li>
<li><strong>پشتیبانی چندزبانه:</strong> تحلیل کد و تولید مستندات برای تمام زبان‌های برنامه‌نویسی پشتیبانی می‌شود.</li>
<li><strong>ساختار کد:</strong> به طور خودکار نمودارهای Mermaid برای درک ساختار کد تولید می‌شود.</li>
<li><strong>مدل‌های سفارشی:</strong> مدل‌ها و APIهای سفارشی پشتیبانی می‌شوند و امکان توسعه را فراهم می‌کند.</li>
<li><strong>تحلیل هوشمند مبتنی بر AI:</strong> تحلیل کد و درک روابط کد بر اساس هوش مصنوعی انجام می‌گیرد.</li>
<li><strong>سئوی آسان:</strong> تولید مستندات و پایگاه دانش سئو-پسند با استفاده از Next.js، برای ایندکس بهتر توسط موتورهای جستجو.</li>
<li><strong>تعامل گفتگومحور:</strong> پشتیبانی از تعامل گفتگومحور با هوش مصنوعی برای دریافت اطلاعات جزئی و روش‌های استفاده از کد و درک عمیق آن.</li>
</ul>
<p>لیست امکانات:</p>
<ul>
<li>[x] پشتیبانی از چندین مخزن کد (Github، Gitlab، Gitee، Gitea و ...)</li>
<li>[x] پشتیبانی از چندین زبان برنامه‌نویسی (Python، Java، #C، JavaScript و ...)</li>
<li>[x] پشتیبانی از مدیریت مخزن شامل افزودن، حذف، ویرایش و جستجو</li>
<li>[x] پشتیبانی از چندین ارائه‌دهنده AI (OpenAI، AzureOpenAI، Anthropic و ...)</li>
<li>[x] پشتیبانی از چندین پایگاه داده (SQLite، PostgreSQL، SqlServer و ...)</li>
<li>[x] پشتیبانی از چندین زبان (چینی، انگلیسی، فرانسوی و ...)</li>
<li>[x] پشتیبانی از بارگذاری فایل ZIP و بارگذاری فایل‌های محلی</li>
<li>[x] ارائه پلتفرم ریزتنظیم داده برای تولید دیتاست‌های ریزتنظیم</li>
<li>[x] پشتیبانی از مدیریت سطح دایرکتوری مخزن، امکان تولید دایرکتوری سفارشی و ایجاد مستندات پویا</li>
<li>[x] پشتیبانی از مدیریت دایرکتوری مخزن، امکان ویرایش ساختار دایرکتوری</li>
<li>[x] پشتیبانی از مدیریت سطح کاربر شامل افزودن، حذف، ویرایش و جستجوی کاربران</li>
<li>[ ] پشتیبانی از مدیریت سطح دسترسی کاربر شامل افزودن، حذف، ویرایش و جستجوی مجوزها</li>
<li>[x] پشتیبانی از تولید دیتاست‌های فریمورک ریزتنظیم در سطح مخزن</li>
</ul>
<h1>معرفی پروژه</h1>
<p>OpenDeepWiki یک پروژه متن‌باز است که از <a href="https://deepwiki.com/">DeepWiki</a> الهام گرفته و با استفاده از .NET 9 و Semantic Kernel توسعه یافته است. هدف آن کمک به توسعه‌دهندگان برای درک بهتر و استفاده بهینه از مخازن کد با ارائه قابلیت‌هایی مانند تحلیل کد، تولید مستندات و ایجاد گراف دانش است.</p>
<ul>
<li>تحلیل ساختار کد</li>
<li>درک مفاهیم اصلی مخزن</li>
<li>تولید مستندات کد</li>
<li>تولید خودکار README.md برای کد
پشتیبانی از MCP</li>
</ul>
<p>OpenDeepWiki از MCP (Model Context Protocol) پشتیبانی می‌کند</p>
<ul>
<li>امکان ارائه یک MCPServer برای هر مخزن و انجام تحلیل روی همان مخزن.</li>
</ul>
<p>روش استفاده: شیوه استفاده از cursor در زیر آمده است:</p>
<pre><code class="language-json">{
  &quot;mcpServers&quot;: {
    &quot;OpenDeepWiki&quot;:{
      &quot;url&quot;: &quot;http://آی‌پی سرویس OpenDeepWiki شما:پورت/sse?owner=AIDotNet&amp;name=OpenDeepWiki&quot;
    }
  }
}
</code></pre>
<ul>
<li>owner: نام سازمان یا مالک مخزن است.</li>
<li>name: نام مخزن است.</li>
</ul>
<p>پس از افزودن مخزن، با پرسیدن یک سؤال تست کنید (توجه داشته باشید که قبل از آن باید مخزن پردازش شود): OpenDeepWiki چیست؟ نتیجه به صورت زیر خواهد بود: <img src="https://raw.githubusercontent.com/AIDotNet/OpenDeepWiki/main/img/mcp.png" alt="" /></p>
<p>به این ترتیب می‌توانید از OpenDeepWiki به عنوان MCPServer استفاده کنید و آن را در اختیار مدل‌های هوش مصنوعی دیگر قرار دهید تا تحلیل و درک پروژه‌های متن‌باز را تسهیل کنید.</p>
<h2>🚀 شروع سریع</h2>
<ol>
<li>مخزن را کلون کنید</li>
</ol>
<pre><code class="language-bash">git clone https://github.com/AIDotNet/OpenDeepWiki.git
cd OpenDeepWiki
</code></pre>
<ol start="2">
<li>فایل <code>docker-compose.yml</code> را باز کرده و متغیرهای محیطی زیر را ویرایش کنید:</li>
</ol>
<p>Ollama:</p>
<pre><code class="language-yaml">services:
  koalawiki:
    environment:
      - KOALAWIKI_REPOSITORIES=/repositories
      - TASK_MAX_SIZE_PER_USER=5 # حداکثر تعداد همزمان تولید مستندات برای هر کاربر توسط AI
      - CHAT_MODEL=qwen2.5:32b # مدل باید از توابع پشتیبانی کند
      - ANALYSIS_MODEL=qwen2.5:32b # مدل تحلیل جهت تولید ساختار دایرکتوری مخزن
      - CHAT_API_KEY=sk-xxxxx # کلید API شما
      - LANGUAGE= # زبان پیش‌فرض تولید را &quot;چینی&quot; تنظیم کنید
      - ENDPOINT=https://آی‌پی Ollama شما:پورت/v1
      - DB_TYPE=sqlite
      - MODEL_PROVIDER=OpenAI # ارائه‌دهنده مدل، پیش‌فرض OpenAI است، AzureOpenAI و Anthropic نیز پشتیبانی می‌شود
      - DB_CONNECTION_STRING=Data Source=/data/KoalaWiki.db
      - EnableSmartFilter=true # فعال بودن فیلتر هوشمند، می‌تواند روی نحوه دریافت لیست فایل‌های مخزن تاثیر بگذارد
      - UPDATE_INTERVAL # بازه زمانی بروزرسانی افزایشی مخزن، واحد: روز
      - MAX_FILE_LIMIT=100 # حداکثر حجم مجاز برای بارگذاری فایل‌ها (MB)
      - DEEP_RESEARCH_MODEL= # مدل برای پژوهش عمیق، در صورت خالی بودن از CHAT_MODEL استفاده می‌شود
      - ENABLE_INCREMENTAL_UPDATE=true # فعال‌سازی بروزرسانی افزایشی
      - ENABLE_CODED_DEPENDENCY_ANALYSIS=false # فعال‌سازی تحلیل وابستگی کد، ممکن است روی کیفیت کد تاثیر بگذارد
      - ENABLE_WAREHOUSE_FUNCTION_PROMPT_TASK=false # فعال‌سازی تولید MCP Prompt
      - ENABLE_WAREHOUSE_DESCRIPTION_TASK=false # فعال‌سازی تولید توضیحات مخزن
</code></pre>
<p>OpenAI:</p>
<pre><code class="language-yaml">services:
  koalawiki:
    environment:
      - KOALAWIKI_REPOSITORIES=/repositories
      - TASK_MAX_SIZE_PER_USER=5 # حداکثر تعداد همزمان تولید مستندات برای هر کاربر توسط AI
      - CHAT_MODEL=DeepSeek-V3 # مدل باید از توابع پشتیبانی کند
      - ANALYSIS_MODEL= # مدل تحلیل جهت تولید ساختار دایرکتوری مخزن
      - CHAT_API_KEY= # کلید API شما
      - LANGUAGE= # زبان پیش‌فرض تولید را &quot;چینی&quot; تنظیم کنید
      - ENDPOINT=https://api.token-ai.cn/v1
      - DB_TYPE=sqlite
      - MODEL_PROVIDER=OpenAI # ارائه‌دهنده مدل، پیش‌فرض OpenAI است، AzureOpenAI و Anthropic نیز پشتیبانی می‌شود
      - DB_CONNECTION_STRING=Data Source=/data/KoalaWiki.db
      - EnableSmartFilter=true # فعال بودن فیلتر هوشمند، می‌تواند روی نحوه دریافت لیست فایل‌های مخزن تاثیر بگذارد
      - UPDATE_INTERVAL # بازه زمانی بروزرسانی افزایشی مخزن، واحد: روز
      - MAX_FILE_LIMIT=100 # حداکثر حجم مجاز برای بارگذاری فایل‌ها (MB)
      - DEEP_RESEARCH_MODEL= # مدل برای پژوهش عمیق، در صورت خالی بودن از CHAT_MODEL استفاده می‌شود
      - ENABLE_INCREMENTAL_UPDATE=true # فعال‌سازی بروزرسانی افزایشی
      - ENABLE_CODED_DEPENDENCY_ANALYSIS=false # فعال‌سازی تحلیل وابستگی کد، ممکن است روی کیفیت کد تاثیر بگذارد
      - ENABLE_WAREHOUSE_FUNCTION_PROMPT_TASK=false # فعال‌سازی تولید MCP Prompt
      - ENABLE_WAREHOUSE_DESCRIPTION_TASK=false # فعال‌سازی تولید توضیحات مخزن
</code></pre>
<p>AzureOpenAI:</p>
<pre><code class="language-yaml">services:
  koalawiki:
    environment:
      - KOALAWIKI_REPOSITORIES=/repositories
      - TASK_MAX_SIZE_PER_USER=5 # حداکثر تعداد همزمان تولید مستندات برای هر کاربر توسط AI
      - CHAT_MODEL=DeepSeek-V3 # مدل باید از توابع پشتیبانی کند
      - ANALYSIS_MODEL= # مدل تحلیل جهت تولید ساختار دایرکتوری مخزن
      - CHAT_API_KEY= # کلید API شما
      - LANGUAGE= # زبان پیش‌فرض تولید را &quot;چینی&quot; تنظیم کنید
      - ENDPOINT=https://your-azure-address.openai.azure.com/
      - DB_TYPE=sqlite
      - MODEL_PROVIDER=AzureOpenAI # ارائه‌دهنده مدل، پیش‌فرض OpenAI است، AzureOpenAI و Anthropic نیز پشتیبانی می‌شود
      - DB_CONNECTION_STRING=Data Source=/data/KoalaWiki.db
      - EnableSmartFilter=true # فعال بودن فیلتر هوشمند، می‌تواند روی نحوه دریافت لیست فایل‌های مخزن تاثیر بگذارد
      - UPDATE_INTERVAL # بازه زمانی بروزرسانی افزایشی مخزن، واحد: روز
      - MAX_FILE_LIMIT=100 # حداکثر حجم مجاز برای بارگذاری فایل‌ها (MB)
      - DEEP_RESEARCH_MODEL= # مدل برای پژوهش عمیق، در صورت خالی بودن از CHAT_MODEL استفاده می‌شود
      - ENABLE_INCREMENTAL_UPDATE=true # فعال‌سازی بروزرسانی افزایشی
      - ENABLE_CODED_DEPENDENCY_ANALYSIS=false # فعال‌سازی تحلیل وابستگی کد، ممکن است روی کیفیت کد تاثیر بگذارد
      - ENABLE_WAREHOUSE_FUNCTION_PROMPT_TASK=false # فعال‌سازی تولید MCP Prompt
      - ENABLE_WAREHOUSE_DESCRIPTION_TASK=false # فعال‌سازی تولید توضیحات مخزن
</code></pre>
<p>Anthropic:</p>
<pre><code class="language-yaml">services:
  koalawiki:
    environment:
      - KOALAWIKI_REPOSITORIES=/repositories
      - TASK_MAX_SIZE_PER_USER=5 # حداکثر تعداد همزمان تولید مستندات برای هر کاربر توسط AI
      - CHAT_MODEL=DeepSeek-V3 # مدل باید از توابع پشتیبانی کند
      - ANALYSIS_MODEL= # مدل تحلیل جهت تولید ساختار دایرکتوری مخزن
      - CHAT_API_KEY= # کلید API شما
      - LANGUAGE= # زبان پیش‌فرض تولید را &quot;چینی&quot; تنظیم کنید
      - ENDPOINT=https://api.anthropic.com/
      - DB_TYPE=sqlite
      - MODEL_PROVIDER=Anthropic # ارائه‌دهنده مدل، پیش‌فرض OpenAI است، AzureOpenAI و Anthropic نیز پشتیبانی می‌شود
      - DB_CONNECTION_STRING=Data Source=/data/KoalaWiki.db
      - EnableSmartFilter=true # فعال بودن فیلتر هوشمند، می‌تواند روی نحوه دریافت لیست فایل‌های مخزن تاثیر بگذارد
      - UPDATE_INTERVAL # بازه زمانی بروزرسانی افزایشی مخزن، واحد: روز
      - MAX_FILE_LIMIT=100 # حداکثر حجم مجاز برای بارگذاری فایل‌ها (MB)
      - DEEP_RESEARCH_MODEL= # مدل برای پژوهش عمیق، در صورت خالی بودن از CHAT_MODEL استفاده می‌شود
      - ENABLE_INCREMENTAL_UPDATE=true # فعال‌سازی بروزرسانی افزایشی
      - ENABLE_CODED_DEPENDENCY_ANALYSIS=false # فعال‌سازی تحلیل وابستگی کد، ممکن است روی کیفیت کد تاثیر بگذارد
      - ENABLE_WAREHOUSE_FUNCTION_PROMPT_TASK=false # فعال‌سازی تولید MCP Prompt
      - ENABLE_WAREHOUSE_DESCRIPTION_TASK=false # فعال‌سازی تولید توضیحات مخزن
</code></pre>
<blockquote>
<p>💡 <strong>نحوه دریافت کلید API:</strong></p>
<ul>
<li>دریافت کلید API گوگل <a href="https://makersuite.google.com/app/apikey">Google AI Studio</a></li>
<li>دریافت کلید API OpenAI <a href="https://platform.openai.com/api-keys">OpenAI Platform</a></li>
<li>دریافت CoresHub <a href="https://console.coreshub.cn/xb3/maas/global-keys">CoresHub</a> <a href="https://account.coreshub.cn/signup?invite=ZmpMQlZxYVU=">اینجا برای ۵۰ میلیون توکن رایگان کلیک کنید</a></li>
<li>دریافت TokenAI <a href="https://api.token-ai.cn/">TokenAI</a></li>
</ul>
</blockquote>
<ol start="3">
<li>سرویس را راه‌اندازی کنید</li>
</ol>
<p>می‌توانید با استفاده از دستورات Makefile ارائه‌شده، برنامه را به راحتی مدیریت کنید:</p>
<pre><code class="language-bash"># ساخت همه ایمیج‌های داکر
make build

# راه‌اندازی همه سرویس‌ها در حالت پس‌زمینه
make up

# یا راه‌اندازی در حالت توسعه (با نمایش لاگ‌ها)
</code></pre>
<p>make dev</p>
<pre><code>
سپس به آدرس http://localhost:8090 مراجعه کنید تا به پایگاه دانش دسترسی پیدا کنید.

برای دستورات بیشتر:
```bash
make help
</code></pre>
<h3>برای کاربران ویندوز (بدون make)</h3>
<p>اگر از ویندوز استفاده می‌کنید و <code>make</code> در دسترس ندارید، می‌توانید این دستورات Docker Compose را مستقیماً اجرا کنید:</p>
<pre><code class="language-bash"># ساخت همه ایمیج‌های داکر
docker-compose build

# اجرای همه سرویس‌ها در حالت پس‌زمینه
docker-compose up -d

# اجرای سرویس‌ها در حالت توسعه (با مشاهده لاگ‌ها)
docker-compose up

# توقف همه سرویس‌ها
docker-compose down

# مشاهده لاگ‌ها
docker-compose logs -f
</code></pre>
<p>برای ساخت معماری‌ها یا سرویس‌های خاص، از این دستورات استفاده کنید:</p>
<pre><code class="language-bash"># ساخت فقط backend
docker-compose build koalawiki

# ساخت فقط frontend
docker-compose build koalawiki-web

# ساخت با پارامتر معماری
docker-compose build --build-arg ARCH=arm64
docker-compose build --build-arg ARCH=amd64
</code></pre>
<h3>استقرار روی Sealos با دسترسی اینترنت عمومی</h3>
<p><a href="https://bja.sealos.run/?openapp=system-template%3FtemplateName%3DOpenDeepWiki"><img src="https://raw.githubusercontent.com/labring-actions/templates/main/Deploy-on-Sealos.svg" alt="" /></a>
برای مراحل دقیق‌تر، به این راهنما مراجعه کنید: <a href="https://raw.githubusercontent.com/AIDotNet/OpenDeepWiki/main/scripts/sealos/README.zh-CN.md">استقرار یک‌کلیکی OpenDeepWiki به عنوان یک اپلیکیشن Sealos در شبکه عمومی با استفاده از قالب‌ها</a></p>
<h2>🔍 نحوه عملکرد</h2>
<p>OpenDeepWiki با استفاده از هوش مصنوعی:</p>
<ul>
<li>مخزن کد را به صورت محلی کلون می‌کند</li>
<li>بر اساس README.md مخزن تحلیل انجام می‌دهد</li>
<li>ساختار کد را تحلیل کرده و در صورت نیاز فایل‌های کد را می‌خواند، سپس داده دایرکتوری به صورت json تولید می‌کند</li>
<li>بر اساس دایرکتوری، هر تسک را به عنوان یک سند پردازش می‌کند</li>
<li>فایل‌های کد را می‌خواند، تحلیل می‌کند، مستندات کد تولید می‌کند و نمودارهای Mermaid نمایانگر وابستگی ساختاری کد را ایجاد می‌کند</li>
<li>سند نهایی پایگاه دانش را تولید می‌کند</li>
<li>مخزن را از طریق تعامل مکالمه‌ای تحلیل کرده و به سوالات کاربر پاسخ می‌دهد</li>
</ul>
<pre><code class="language-mermaid">graph TD
    A[کلون کردن مخزن کد] --&gt; B[تحلیل README.md]
    B --&gt; C[تحلیل ساختار کد]
    C --&gt; D[تولید داده دایرکتوری json]
    D --&gt; E[پردازش چندین تسک]
    E --&gt; F[خواندن فایل‌های کد]
    F --&gt; G[تحلیل فایل‌های کد]
    G --&gt; H[تولید مستندات کد]
    H --&gt; I[ایجاد نمودارهای Mermaid]
    I --&gt; J[تولید سند پایگاه دانش]
    J --&gt; K[تعامل مکالمه‌ای]
</code></pre>
<h2>پیکربندی پیشرفته</h2>
<h3>متغیرهای محیطی</h3>
<ul>
<li>KOALAWIKI_REPOSITORIES  مسیر ذخیره‌سازی مخازن</li>
<li>TASK_MAX_SIZE_PER_USER  حداکثر تسک‌های موازی برای تولید اسناد هوش مصنوعی به ازای هر کاربر</li>
<li>CHAT_MODEL  مدل باید از توابع پشتیبانی کند</li>
<li>ENDPOINT  نقطه پایانی API</li>
<li>ANALYSIS_MODEL  مدل تحلیل برای تولید ساختار دایرکتوری مخزن</li>
<li>CHAT_API_KEY  کلید API شما</li>
<li>LANGUAGE  تغییر زبان اسناد تولید شده</li>
<li>DB_TYPE  نوع پایگاه داده، پیش‌فرض sqlite است</li>
<li>MODEL_PROVIDER  ارائه‌دهنده مدل، به طور پیش‌فرض OpenAI، پشتیبانی از Azure، OpenAI و Anthropic</li>
<li>DB_CONNECTION_STRING  رشته اتصال پایگاه داده</li>
<li>EnableSmartFilter فعال یا غیرفعال بودن فیلتر هوشمند که ممکن است بر نحوه دسترسی AI به دایرکتوری فایل مخزن تاثیر بگذارد</li>
<li>UPDATE_INTERVAL بازه به‌روزرسانی افزایشی مخزن، واحد: روز</li>
<li>MAX_FILE_LIMIT حداکثر محدودیت بارگذاری فایل، بر حسب مگابایت</li>
<li>DEEP_RESEARCH_MODEL انجام تحقیق عمیق روی مدل و استفاده از CHAT_MODEL برای حالت خالی</li>
<li>ENABLE_INCREMENTAL_UPDATE فعال‌سازی به‌روزرسانی افزایشی</li>
<li>ENABLE_CODED_DEPENDENCY_ANALYSIS فعال‌سازی تحلیل وابستگی کد، این مورد ممکن است بر کیفیت کد تاثیر بگذارد.</li>
<li>ENABLE_WAREHOUSE_FUNCTION_PROMPT_TASK  # فعال‌سازی یا غیرفعال‌سازی تولید MCP Prompt</li>
<li>ENABLE_WAREHOUSE_DESCRIPTION_TASK # فعال‌سازی یا غیرفعال‌سازی تولید توضیحات مخزن</li>
</ul>
<h3>ساخت برای معماری‌های مختلف</h3>
<p>فایل Makefile دستورات لازم برای ساخت روی معماری‌های مختلف CPU را فراهم می‌کند:</p>
<pre><code class="language-bash"># ساخت برای معماری ARM
make build-arm

# ساخت برای معماری AMD
make build-amd

# ساخت فقط backend برای ARM
make build-backend-arm

# ساخت فقط frontend برای AMD
make build-frontend-amd
</code></pre>
<h2>دیسکورد</h2>
<p><a href="https://discord.gg/8sxUNacv">به ما بپیوندید</a></p>
<h2>وی‌چت</h2>
<p><img src="https://github.com/user-attachments/assets/2bb0055f-9e45-4db2-b9c9-f1e251996e01" alt="b62354e40046f409b88528dd5631ed45" /></p>
<h2>📄 مجوز</h2>
<p>این پروژه تحت مجوز MIT منتشر شده است – برای جزییات به فایل <a href="https://raw.githubusercontent.com/AIDotNet/OpenDeepWiki/main/LICENSE">LICENSE</a> مراجعه نمایید.</p>
<h2>تاریخچه ستاره‌ها</h2>
<p><a href="https://www.star-history.com/#AIDotNet/OpenDeepWiki&amp;Date"><img src="https://api.star-history.com/svg?repos=AIDotNet/OpenDeepWiki&amp;type=Date" alt="نمودار تاریخچه ستاره" /></a></p>
<hr />
<p>Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx">Open Ai Tx</a> | Last indexed: 2025-06-11</p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Statcounter and other scripts can be added here -->
</body>
</html>