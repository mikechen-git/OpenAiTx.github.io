<!DOCTYPE html>
<html lang="id">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>c4-genai-suite - Indonesian Documentation</title>
    <meta name="description" content="Read c4-genai-suite documentation in Indonesian. This project has 123 stars on GitHub.">
    <meta name="keywords" content="c4-genai-suite, Indonesian, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "c4-genai-suite",
  "description": "Documentation for c4-genai-suite in Indonesian",
  "author": {
    "@type": "Person",
    "name": "codecentric"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 123
  },
  "url": "https://OpenAiTx.github.io/projects/codecentric/c4-genai-suite/README-id.html",
  "sameAs": "https://raw.githubusercontent.com/codecentric/c4-genai-suite/main/README.md",
  "datePublished": "2025-07-09",
  "dateModified": "2025-07-09"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            color: #24292e;
            margin-bottom: 8px;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">c4-genai-suite</h1>
            <div class="project-meta">
                <span class="stars">⭐ 123 stars</span>
                <span class="language">Indonesian</span>
                <span>by codecentric</span>
            </div>
        </div>
        
        <div class="content">
            <h1>c4 GenAI Suite</h1></p><p>Aplikasi chatbot AI dengan integrasi Model Context Provider (MCP), didukung oleh Langchain dan kompatibel dengan semua Large Language Models (LLM) utama serta Model Embedding.</p><p>Administrator dapat membuat asisten dengan kemampuan berbeda dengan menambahkan ekstensi, seperti layanan RAG (Retrieval-Augmented Generation) atau server MCP. Aplikasi ini dibangun menggunakan tumpukan teknologi modern, termasuk React, NestJS, dan Python FastAPI untuk layanan REI-S.</p><p>Pengguna dapat berinteraksi dengan asisten melalui antarmuka yang ramah pengguna. Tergantung pada konfigurasi asisten, pengguna dapat mengajukan pertanyaan, mengunggah file mereka sendiri, atau menggunakan fitur lainnya. Para asisten berinteraksi dengan berbagai penyedia LLM untuk memberikan respons berdasarkan ekstensi yang dikonfigurasi. Informasi kontekstual yang disediakan oleh ekstensi yang dikonfigurasi memungkinkan asisten menjawab pertanyaan spesifik domain dan memberikan informasi yang relevan.</p><p>Aplikasi ini dirancang secara modular dan dapat diperluas, memungkinkan pengguna membuat asisten dengan kemampuan berbeda dengan menambahkan ekstensi.</p><p><img src="https://raw.githubusercontent.com/codecentric/c4-genai-suite/main/demo/preview.webp" alt="video demo singkat penggunaan dasar"></p><h2>Fitur</h2></p><h3>Large Language Models (LLM) dan Model Multimodal</h3></p><p>c4 GenAI Suite sudah mendukung banyak model secara langsung. Jika model pilihan Anda belum didukung, seharusnya mudah untuk menulis ekstensi guna mendukungnya.</p><ul><li>Model yang kompatibel dengan OpenAI</li>
<li>Model Azure OpenAI</li>
<li>Model Bedrock</li>
<li>Model Google GenAI</li>
<li>Model yang kompatibel dengan Ollama</li>
</ul><h3>Retrieval Augmented Generation (RAG)</h3></p><p>c4 GenAI Suite mencakup REI-S, sebuah server untuk menyiapkan file agar dapat digunakan oleh LLM.</p><ul><li>REI-S, server RAG terintegrasi khusus</li>
  <li>Penyimpanan vektor</li>
    <li>pgvector</li>
    <li>Azure AI Search</li>
  <li>Model embedding</li>
    <li>Embedding kompatibel OpenAI</li>
    <li>Embedding Azure OpenAI</li>
    <li>Embedding kompatibel Ollama</li>
  <li>Format file:</li>
    <li>pdf, docx, pptx, xlsx, ...</li>
    <li>transkripsi suara file audio (melalui Whisper)</li></p><p></ul><h3>Ekstensi</h3></p><p>c4 GenAI Suite dirancang untuk dapat diperluas. Menulis ekstensi sangat mudah, begitu juga menggunakan server MCP yang sudah ada.</p><ul><li>Server Model Context Protocol (MCP)</li>
<li>Systemprompt kustom</li>
<li>Pencarian Bing</li>
<li>Kalkulator</li>
</ul><h2>Memulai</h2></p><h3>Menggunakan Docker-Compose</h3></p><ul><li>Jalankan <code>docker compose up</code> di root proyek.</li>
<li>Buka <a href="http://localhost:3333" target="_blank" rel="noopener noreferrer">aplikasi</a> di browser. Kredensial login default adalah user <code>admin@example.com</code> dan password <code>secret</code>.</li></p><p></ul><img src="https://raw.githubusercontent.com/codecentric/c4-genai-suite/main/demo/assistants.webp" alt="video menunjukkan konfigurasi asisten"></p><h3>Menggunakan Helm & Kubernetes</h3></p><p>Untuk deployment di lingkungan Kubernetes, silakan merujuk ke <a href="https://raw.githubusercontent.com/codecentric/c4-genai-suite/main/./helm-chart/README.md" target="_blank" rel="noopener noreferrer">README dari Helm Chart kami</a>.</p><h3>Menyiapkan Asisten dan Ekstensi</h3></p><p>c4 GenAI Suite berpusat pada <em>asisten</em>.
Setiap asisten terdiri dari satu set ekstensi, yang menentukan model LLM dan alat apa yang dapat digunakannya.</p><ul><li>Di area admin (klik nama pengguna di kiri bawah), pergi ke <a href="http://localhost:3333/admin/assistants" target="_blank" rel="noopener noreferrer">bagian asisten</a>.</li>
<li>Tambahkan asisten dengan tombol hijau <code>+</code> di sebelah judul bagian. Pilih nama dan deskripsi.</li>
<li>Pilih asisten yang telah dibuat dan klik hijau <code>+ Add Extension</code>.</li>
<li>Pilih model dan isi kredensial.</li>
<li>Gunakan tombol <code>Test</code> untuk memeriksa apakah sudah berfungsi dan <code>save</code>.</li></p><p></ul>Sekarang Anda dapat kembali ke <a href="http://localhost:3333/chat" target="_blank" rel="noopener noreferrer">halaman chat</a> (klik pada <code>c4 GenAI Suite</code> di kiri atas) dan memulai percakapan baru dengan asisten baru Anda.</p><blockquote>[!TIP]</blockquote>
<blockquote><code>docker-compose</code> kami sudah termasuk Ollama lokal, yang berjalan di CPU. Anda dapat menggunakannya untuk pengujian cepat. Namun kecepatannya lambat dan Anda mungkin ingin menggunakan model lain. Jika ingin menggunakannya, cukup buat ekstensi model berikut di Asisten Anda.</blockquote>
<blockquote>* Ekstensi: <code>Dev: Ollama</code></blockquote>
<blockquote>* Endpoint: <code>http://ollama:11434</code></blockquote>
<blockquote>* Model: <code>llama3.2</code></blockquote></p><h3>Model Context Protocol (MCP) [opsional]</h3></p><p>Gunakan server MCP apa pun yang menyediakan antarmuka <code>sse</code> dengan Ekstensi <code>MCP Tools</code> (atau gunakan <code>mcp-tool-as-server</code> kami sebagai proxy di depan server MCP <code>stdio</code>).
Setiap server MCP dapat dikonfigurasi secara detail sebagai ekstensi.</p><h3>Retrieval Augmented Generation (RAG) / Pencarian Berkas [opsional]</h3></p><p>Gunakan server RAG kami <code>REI-S</code> untuk mencari berkas yang disediakan pengguna. Cukup konfigurasikan ekstensi <code>Search Files</code> untuk asisten.
Proses ini dijelaskan secara rinci di <a href="services/reis/#example-configuration-in-c4" target="_blank" rel="noopener noreferrer">subdirektori <code>services/reis</code></a>.</p><h2>Kontribusi & Pengembangan</h2></p><ul><li>Lihat <a href="https://raw.githubusercontent.com/codecentric/c4-genai-suite/main/CONTRIBUTING.md" target="_blank" rel="noopener noreferrer">CONTRIBUTING.md</a> untuk panduan cara berkontribusi.</li>
<li>Untuk onboarding pengembang, periksa <a href="https://raw.githubusercontent.com/codecentric/c4-genai-suite/main/DEVELOPERS.md" target="_blank" rel="noopener noreferrer">DEVELOPERS.md</a>.</li></p><p></ul><h2>Blok Bangunan Utama</h2></p><p>Aplikasi ini terdiri dari <strong>Frontend</strong>, <strong>Backend</strong>, dan layanan <strong>REI-S</strong>.</p><pre><code class="language-">┌──────────┐
│  Pengguna│
└─────┬────┘
      │ akses
      ▼
┌──────────┐
│ Frontend │
└─────┬────┘
      │ akses
      ▼
┌──────────┐     ┌─────────────────┐
│ Backend  │────►│      LLM        │
└─────┬────┘     └─────────────────┘
      │ akses
      ▼
┌──────────┐     ┌─────────────────┐
│  REI-S   │────►│ Embedding Model │
│          │     └─────────────────┘
│          │
│          │     ┌─────────────────┐
│          │────►│  Vector Store   │
└──────────┘     └─────────────────┘</code></pre>
<h3>Frontend</h3></p><p>Frontend dibangun dengan React dan TypeScript, menyediakan antarmuka yang ramah pengguna untuk berinteraksi dengan backend dan layanan REI-S. Frontend ini mencakup fitur untuk mengelola asisten, ekstensi, dan fungsionalitas chat.</p><blockquote>Sumber: <code>/frontend</code></blockquote></p><h3>Backend</h3></p><p>Backend dikembangkan menggunakan NestJS dan TypeScript, berfungsi sebagai lapisan API utama untuk aplikasi. Backend menangani permintaan dari frontend dan berinteraksi dengan penyedia llm untuk memfasilitasi fungsionalitas chat. Backend juga mengelola asisten dan ekstensi mereka, memungkinkan pengguna untuk mengonfigurasi dan menggunakan berbagai model AI untuk chat mereka.</p><p>Selain itu, backend mengelola autentikasi pengguna, dan berkomunikasi dengan layanan REI-S untuk pengindeksan dan pengambilan file.</p><p>Untuk persistensi data, backend menggunakan database <strong>PostgreSQL</strong>.</p><blockquote>Sumber: <code>/backend</code></blockquote></p><h3>REI-S</h3></p><p>REI-S (<strong>R</strong>etrieval <strong>E</strong>xtraction <strong>I</strong>ngestion <strong>S</strong>erver) adalah server berbasis Python yang menyediakan kemampuan dasar RAG (Retrieval-Augmented Generation). Server ini memungkinkan ekstraksi konten file, pengindeksan, dan pencarian, sehingga aplikasi dapat menangani dataset besar secara efisien. Layanan REI-S dirancang agar dapat bekerja secara mulus dengan backend, menyediakan data yang diperlukan untuk fungsionalitas chat dan pencarian file.</p><p>REI-S mendukung Azure AI Search dan pgvector untuk penyimpanan vektor, memungkinkan opsi pengambilan data yang fleksibel dan skalabel. Layanan ini dapat dikonfigurasi menggunakan variabel lingkungan untuk menentukan jenis penyimpanan vektor dan detail koneksi.</p><blockquote>Sumber: <code>/services/reis</code></blockquote>

---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-07-09

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/codecentric/c4-genai-suite/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-07-09 
    </div>
    
</body>
</html>