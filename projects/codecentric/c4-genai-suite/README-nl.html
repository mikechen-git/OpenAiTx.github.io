<!DOCTYPE html>
<html lang="nl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>c4-genai-suite - codecentric/c4-genai-suite nl</title>
    <meta name="title" content="c4-genai-suite - codecentric/c4-genai-suite nl | c4 GenAI Suite Een AI-chatbotapplicatie met Model Context Provider (MCP) integratie, aangedreven door Langchain en compatibiliteit met alle grote Large Language...">
    <meta name="description" content="codecentric/c4-genai-suite - GitHub repository nl documentation and information | c4 GenAI Suite Een AI-chatbotapplicatie met Model Context Provider (MCP) integratie, aangedreven door Langchain en compatibiliteit met alle grote Large Language...">
    <meta name="keywords" content="codecentric, c4-genai-suite, GitHub, repository, nl documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/codecentric/c4-genai-suite/README-nl.html">
    <meta property="og:title" content="c4-genai-suite - codecentric/c4-genai-suite nl | c4 GenAI Suite Een AI-chatbotapplicatie met Model Context Provider (MCP) integratie, aangedreven door Langchain en compatibiliteit met alle grote Large Language...">
    <meta property="og:description" content="codecentric/c4-genai-suite - GitHub repository nl documentation and information | c4 GenAI Suite Een AI-chatbotapplicatie met Model Context Provider (MCP) integratie, aangedreven door Langchain en compatibiliteit met alle grote Large Language...">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div style="position: fixed; top: 2px; left: 2px; z-index: 2000; background: rgba(255,255,255,0.95); border-radius: 6px; box-shadow: 0 2px 8px rgba(0,0,0,0.06); padding: 4px 14px; font-size: 15px; color: #222; font-family: 'Segoe UI', Arial, sans-serif; font-weight: 500; letter-spacing: 0.5px;">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" style="color: #0366d6; text-decoration: none; font-weight: 600;">Open AI Tx</a>
    </div>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/codecentric/c4-genai-suite" id="githubRepoLink" target="_blank">codecentric/c4-genai-suite</a>
<h1 style="display: none;">c4 GenAI Suite Een AI-chatbotapplicatie met Model Context Provider (MCP) integratie, aangedreven door Langchain en compatibiliteit met alle grote Large Language...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <h1>c4 GenAI Suite</h1>
<p>Een AI-chatbotapplicatie met Model Context Provider (MCP) integratie, aangedreven door Langchain en compatibiliteit met alle grote Large Language Models (LLM's) en Embedding Modellen.</p>
<p>Beheerders kunnen assistenten creëren met verschillende mogelijkheden door extensies toe te voegen, zoals RAG (Retrieval-Augmented Generation) services of MCP-servers. De applicatie is gebouwd met behulp van een moderne tech stack, waaronder React, NestJS en Python FastAPI voor de REI-S service.</p>
<p>Gebruikers kunnen met assistenten communiceren via een gebruiksvriendelijke interface. Afhankelijk van de configuratie van de assistent kunnen gebruikers vragen stellen, hun eigen bestanden uploaden of andere functies gebruiken. De assistenten communiceren met verschillende LLM-aanbieders om antwoorden te geven op basis van de geconfigureerde extensies. Contextuele informatie, geleverd door de geconfigureerde extensies, stelt de assistenten in staat om domeinspecifieke vragen te beantwoorden en relevante informatie te geven.</p>
<p>De applicatie is ontworpen om modulair en uitbreidbaar te zijn, zodat gebruikers assistenten kunnen creëren met verschillende mogelijkheden door extensies toe te voegen.</p>
<p><img src="https://raw.githubusercontent.com/codecentric/c4-genai-suite/main/demo/preview.webp" alt="korte demovideo van basisgebruik" /></p>
<h2>Functies</h2>
<h3>Large Language Models (LLM) en Multimodale Modellen</h3>
<p>De c4 GenAI Suite ondersteunt al veel modellen direct. En als uw voorkeursmodel nog niet wordt ondersteund, zou het eenvoudig moeten zijn om een extensie te schrijven om deze te ondersteunen.</p>
<ul>
<li>OpenAI-compatibele modellen</li>
<li>Azure OpenAI-modellen</li>
<li>Bedrock-modellen</li>
<li>Google GenAI-modellen</li>
<li>Ollama-compatibele modellen</li>
</ul>
<h3>Retrieval Augmented Generation (RAG)</h3>
<p>De c4 GenAI Suite bevat REI-S, een server om bestanden voor te bereiden voor gebruik door het LLM.</p>
<ul>
<li>REI-S, een aangepast geïntegreerde RAG-server
<ul>
<li>Vector stores
<ul>
<li>pgvector</li>
<li>Azure AI Search</li>
</ul>
</li>
<li>Embedding modellen
<ul>
<li>OpenAI-compatibele embeddings</li>
<li>Azure OpenAI embeddings</li>
<li>Ollama-compatibele embeddings</li>
</ul>
</li>
<li>Bestandsformaten:
<ul>
<li>pdf, docx, pptx, xlsx, ...</li>
<li>audio-bestand spraaktranscriptie (via Whisper)</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3>Extensies</h3>
<p>De c4 GenAI Suite is ontworpen voor uitbreidbaarheid. Het schrijven van extensies is eenvoudig, evenals het gebruik van een reeds bestaande MCP-server.</p>
<ul>
<li>Model Context Protocol (MCP) servers</li>
<li>Aangepaste systemprompt</li>
<li>Bing Search</li>
<li>Rekenmachine</li>
</ul>
<h2>Aan de slag</h2>
<h3>Gebruik van Docker-Compose</h3>
<ul>
<li>Voer <code>docker compose up</code> uit in de hoofdmap van het project.</li>
<li>Open de <a href="http://localhost:3333">applicatie</a> in een browser. De standaard inloggegevens zijn gebruiker <code>admin@example.com</code> en wachtwoord <code>secret</code>.</li>
</ul>
<p><img src="https://raw.githubusercontent.com/codecentric/c4-genai-suite/main/demo/assistants.webp" alt="video die assistentconfiguratie toont" /></p>
<h3>Gebruik van Helm &amp; Kubernetes</h3>
<p>Voor implementatie in Kubernetes-omgevingen, raadpleeg de <a href="https://raw.githubusercontent.com/codecentric/c4-genai-suite/main/./helm-chart/README.md">README van onze Helm Chart</a>.</p>
<h3>Assistenten en Extensies instellen</h3>
<p>De c4 GenAI Suite draait om <em>assistenten</em>.
Elke assistent bestaat uit een set extensies, die bepalen welk LLM-model en welke tools hij kan gebruiken.</p>
<ul>
<li>Ga in het beheerdersgedeelte (klik op de gebruikersnaam linksonder) naar de <a href="http://localhost:3333/admin/assistants">assistenten sectie</a>.</li>
<li>Voeg een assistent toe met de groene <code>+</code> knop naast de sectietitel. Kies een naam en een beschrijving.</li>
<li>Selecteer de aangemaakte assistent en klik op de groene <code>+ Extensie toevoegen</code>.</li>
<li>Selecteer het model en vul de inloggegevens in.</li>
<li>Gebruik de knop <code>Test</code> om te controleren of alles werkt en <code>opslaan</code>.</li>
</ul>
<p>Nu kun je terugkeren naar de <a href="http://localhost:3333/chat">chatpagina</a> (klik op <code>c4 GenAI Suite</code> linksboven) en een nieuw gesprek starten met je nieuwe assistent.</p>
<blockquote>
<p>[!TIP]
Onze <code>docker-compose</code> bevat een lokale Ollama, die op de CPU draait. Je kunt deze gebruiken voor snel testen. Maar het zal traag zijn en je wilt waarschijnlijk een ander model gebruiken. Als je het wilt gebruiken, maak dan gewoon de volgende modelextensie aan in je Assistent.</p>
<ul>
<li>Extensie: <code>Dev: Ollama</code></li>
<li>Endpoint: <code>http://ollama:11434</code></li>
<li>Model: <code>llama3.2</code></li>
</ul>
</blockquote>
<h3>Model Context Protocol (MCP) [optioneel]</h3>
<p>Gebruik elke MCP-server die een <code>sse</code>-interface aanbiedt met de <code>MCP Tools</code>-extensie (of gebruik onze <code>mcp-tool-as-server</code> als een proxy voor een <code>stdio</code> MCP-server).
Elke MCP-server kan in detail worden geconfigureerd als een extensie.</p>
<h3>Retrieval Augmented Generation (RAG) / Bestanden Zoeken [optioneel]</h3>
<p>Gebruik onze RAG-server <code>REI-S</code> om door door de gebruiker aangeleverde bestanden te zoeken. Configureer hiervoor eenvoudig een <code>Bestanden Zoeken</code>-extensie voor de assistent.
Dit proces wordt in detail beschreven in <a href="services/reis/#example-configuration-in-c4">de submap <code>services/reis</code></a>.</p>
<h2>Bijdragen &amp; Ontwikkeling</h2>
<ul>
<li>Zie <a href="https://raw.githubusercontent.com/codecentric/c4-genai-suite/main/CONTRIBUTING.md">CONTRIBUTING.md</a> voor richtlijnen over hoe je kunt bijdragen.</li>
<li>Voor onboarding van ontwikkelaars, bekijk <a href="https://raw.githubusercontent.com/codecentric/c4-genai-suite/main/DEVELOPERS.md">DEVELOPERS.md</a>.</li>
</ul>
<h2>Belangrijkste Bouwstenen</h2>
<p>De applicatie bestaat uit een <strong>Frontend</strong>, een <strong>Backend</strong> en een <strong>REI-S</strong>-service.</p>
<pre><code>┌──────────┐
│   Gebruiker  │
└─────┬────┘
      │ toegang
      ▼
┌──────────┐
│ Frontend │
└─────┬────┘
      │ toegang
      ▼
┌──────────┐     ┌─────────────────┐
│ Backend  │────►│      LLM        │
└─────┬────┘     └─────────────────┘
      │ toegang
      ▼
┌──────────┐     ┌─────────────────┐
│  REI-S   │────►│ Embedding Model │
│          │     └─────────────────┘
│          │
│          │     ┌─────────────────┐
│          │────►│  Vector Store   │
└──────────┘     └─────────────────┘
</code></pre>
<h3>Frontend</h3>
<p>De frontend is gebouwd met React en TypeScript en biedt een gebruiksvriendelijke interface voor interactie met de backend en de REI-S service. Het bevat functionaliteiten voor het beheren van assistenten, extensies en chatfuncties.</p>
<blockquote>
<p>Bronnen: <code>/frontend</code></p>
</blockquote>
<h3>Backend</h3>
<p>De backend is ontwikkeld met NestJS en TypeScript en dient als de belangrijkste API-laag van de applicatie. Het verwerkt verzoeken van de frontend en communiceert met llm-providers om chatfuncties mogelijk te maken. De backend beheert ook assistenten en hun extensies, waardoor gebruikers verschillende AI-modellen kunnen configureren en gebruiken voor hun chats.</p>
<p>Daarnaast beheert de backend gebruikersauthenticatie en communiceert met de REI-S service voor het indexeren en ophalen van bestanden.</p>
<p>Voor gegevensopslag gebruikt de backend een <strong>PostgreSQL</strong>-database.</p>
<blockquote>
<p>Bronnen: <code>/backend</code></p>
</blockquote>
<h3>REI-S</h3>
<p>De REI-S (<strong>R</strong>etrieval <strong>E</strong>xtraction <strong>I</strong>ngestion <strong>S</strong>erver) is een Python-gebaseerde server die basis RAG (Retrieval-Augmented Generation) mogelijkheden biedt. Het maakt het mogelijk om bestandsinhoud te extraheren, indexeren en op te vragen, waardoor de applicatie grote datasets efficiënt kan verwerken. De REI-S service is ontworpen om naadloos samen te werken met de backend en voorziet in benodigde data voor chatfuncties en bestandszoekopdrachten.</p>
<p>De REI-S ondersteunt Azure AI Search en pgvector voor vectoropslag, waardoor flexibele en schaalbare dataterugvindopties mogelijk zijn. De service kan worden geconfigureerd met omgevingsvariabelen om het type vectorstore en verbindingsgegevens te specificeren.</p>
<blockquote>
<p>Bronnen: <code>/services/reis</code></p>
</blockquote>
<hr />
<p>Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx">Open Ai Tx</a> | Last indexed: 2025-07-09</p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
</body>
</html>