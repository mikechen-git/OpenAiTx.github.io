<!DOCTYPE html>
<html lang="nl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>c4-genai-suite - Dutch Documentation</title>
    <meta name="description" content="Read c4-genai-suite documentation in Dutch. This project has 123 stars on GitHub.">
    <meta name="keywords" content="c4-genai-suite, Dutch, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "c4-genai-suite",
  "description": "Documentation for c4-genai-suite in Dutch",
  "author": {
    "@type": "Person",
    "name": "codecentric"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 123
  },
  "url": "https://OpenAiTx.github.io/projects/codecentric/c4-genai-suite/README-nl.html",
  "sameAs": "https://raw.githubusercontent.com/codecentric/c4-genai-suite/main/README.md",
  "datePublished": "2025-07-09",
  "dateModified": "2025-07-09"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            color: #24292e;
            margin-bottom: 8px;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">c4-genai-suite</h1>
            <div class="project-meta">
                <span class="stars">⭐ 123 stars</span>
                <span class="language">Dutch</span>
                <span>by codecentric</span>
            </div>
        </div>
        
        <div class="content">
            <h1>c4 GenAI Suite</h1></p><p>Een AI-chatbotapplicatie met Model Context Provider (MCP) integratie, aangedreven door Langchain en compatibiliteit met alle grote Large Language Models (LLM's) en Embedding Modellen.</p><p>Beheerders kunnen assistenten creëren met verschillende mogelijkheden door extensies toe te voegen, zoals RAG (Retrieval-Augmented Generation) services of MCP-servers. De applicatie is gebouwd met behulp van een moderne tech stack, waaronder React, NestJS en Python FastAPI voor de REI-S service.</p><p>Gebruikers kunnen met assistenten communiceren via een gebruiksvriendelijke interface. Afhankelijk van de configuratie van de assistent kunnen gebruikers vragen stellen, hun eigen bestanden uploaden of andere functies gebruiken. De assistenten communiceren met verschillende LLM-aanbieders om antwoorden te geven op basis van de geconfigureerde extensies. Contextuele informatie, geleverd door de geconfigureerde extensies, stelt de assistenten in staat om domeinspecifieke vragen te beantwoorden en relevante informatie te geven.</p><p>De applicatie is ontworpen om modulair en uitbreidbaar te zijn, zodat gebruikers assistenten kunnen creëren met verschillende mogelijkheden door extensies toe te voegen.</p><p><img src="https://raw.githubusercontent.com/codecentric/c4-genai-suite/main/demo/preview.webp" alt="korte demovideo van basisgebruik"></p><h2>Functies</h2></p><h3>Large Language Models (LLM) en Multimodale Modellen</h3></p><p>De c4 GenAI Suite ondersteunt al veel modellen direct. En als uw voorkeursmodel nog niet wordt ondersteund, zou het eenvoudig moeten zijn om een extensie te schrijven om deze te ondersteunen.</p><ul><li>OpenAI-compatibele modellen</li>
<li>Azure OpenAI-modellen</li>
<li>Bedrock-modellen</li>
<li>Google GenAI-modellen</li>
<li>Ollama-compatibele modellen</li>
</ul><h3>Retrieval Augmented Generation (RAG)</h3></p><p>De c4 GenAI Suite bevat REI-S, een server om bestanden voor te bereiden voor gebruik door het LLM.</p><ul><li>REI-S, een aangepast geïntegreerde RAG-server</li>
  <li>Vector stores</li>
    <li>pgvector</li>
    <li>Azure AI Search</li>
  <li>Embedding modellen</li>
    <li>OpenAI-compatibele embeddings</li>
    <li>Azure OpenAI embeddings</li>
    <li>Ollama-compatibele embeddings</li>
  <li>Bestandsformaten:</li>
    <li>pdf, docx, pptx, xlsx, ...</li>
    <li>audio-bestand spraaktranscriptie (via Whisper)</li></p><p></ul><h3>Extensies</h3></p><p>De c4 GenAI Suite is ontworpen voor uitbreidbaarheid. Het schrijven van extensies is eenvoudig, evenals het gebruik van een reeds bestaande MCP-server.</p><ul><li>Model Context Protocol (MCP) servers</li>
<li>Aangepaste systemprompt</li>
<li>Bing Search</li>
<li>Rekenmachine</li>
</ul><h2>Aan de slag</h2></p><h3>Gebruik van Docker-Compose</h3></p><ul><li>Voer <code>docker compose up</code> uit in de hoofdmap van het project.</li>
<li>Open de <a href="http://localhost:3333" target="_blank" rel="noopener noreferrer">applicatie</a> in een browser. De standaard inloggegevens zijn gebruiker <code>admin@example.com</code> en wachtwoord <code>secret</code>.</li></p><p></ul><img src="https://raw.githubusercontent.com/codecentric/c4-genai-suite/main/demo/assistants.webp" alt="video die assistentconfiguratie toont"></p><h3>Gebruik van Helm & Kubernetes</h3></p><p>Voor implementatie in Kubernetes-omgevingen, raadpleeg de <a href="https://raw.githubusercontent.com/codecentric/c4-genai-suite/main/./helm-chart/README.md" target="_blank" rel="noopener noreferrer">README van onze Helm Chart</a>.</p><h3>Assistenten en Extensies instellen</h3></p><p>De c4 GenAI Suite draait om <em>assistenten</em>.
Elke assistent bestaat uit een set extensies, die bepalen welk LLM-model en welke tools hij kan gebruiken.</p><ul><li>Ga in het beheerdersgedeelte (klik op de gebruikersnaam linksonder) naar de <a href="http://localhost:3333/admin/assistants" target="_blank" rel="noopener noreferrer">assistenten sectie</a>.</li>
<li>Voeg een assistent toe met de groene <code>+</code> knop naast de sectietitel. Kies een naam en een beschrijving.</li>
<li>Selecteer de aangemaakte assistent en klik op de groene <code>+ Extensie toevoegen</code>.</li>
<li>Selecteer het model en vul de inloggegevens in.</li>
<li>Gebruik de knop <code>Test</code> om te controleren of alles werkt en <code>opslaan</code>.</li></p><p></ul>Nu kun je terugkeren naar de <a href="http://localhost:3333/chat" target="_blank" rel="noopener noreferrer">chatpagina</a> (klik op <code>c4 GenAI Suite</code> linksboven) en een nieuw gesprek starten met je nieuwe assistent.</p><blockquote>[!TIP]</blockquote>
<blockquote>Onze <code>docker-compose</code> bevat een lokale Ollama, die op de CPU draait. Je kunt deze gebruiken voor snel testen. Maar het zal traag zijn en je wilt waarschijnlijk een ander model gebruiken. Als je het wilt gebruiken, maak dan gewoon de volgende modelextensie aan in je Assistent.</blockquote>
<blockquote>* Extensie: <code>Dev: Ollama</code></blockquote>
<blockquote>* Endpoint: <code>http://ollama:11434</code></blockquote>
<blockquote>* Model: <code>llama3.2</code></blockquote>
<h3>Model Context Protocol (MCP) [optioneel]</h3></p><p>Gebruik elke MCP-server die een <code>sse</code>-interface aanbiedt met de <code>MCP Tools</code>-extensie (of gebruik onze <code>mcp-tool-as-server</code> als een proxy voor een <code>stdio</code> MCP-server).
Elke MCP-server kan in detail worden geconfigureerd als een extensie.</p><h3>Retrieval Augmented Generation (RAG) / Bestanden Zoeken [optioneel]</h3></p><p>Gebruik onze RAG-server <code>REI-S</code> om door door de gebruiker aangeleverde bestanden te zoeken. Configureer hiervoor eenvoudig een <code>Bestanden Zoeken</code>-extensie voor de assistent.
Dit proces wordt in detail beschreven in <a href="services/reis/#example-configuration-in-c4" target="_blank" rel="noopener noreferrer">de submap <code>services/reis</code></a>.</p><h2>Bijdragen & Ontwikkeling</h2></p><ul><li>Zie <a href="https://raw.githubusercontent.com/codecentric/c4-genai-suite/main/CONTRIBUTING.md" target="_blank" rel="noopener noreferrer">CONTRIBUTING.md</a> voor richtlijnen over hoe je kunt bijdragen.</li>
<li>Voor onboarding van ontwikkelaars, bekijk <a href="https://raw.githubusercontent.com/codecentric/c4-genai-suite/main/DEVELOPERS.md" target="_blank" rel="noopener noreferrer">DEVELOPERS.md</a>.</li></p><p></ul><h2>Belangrijkste Bouwstenen</h2></p><p>De applicatie bestaat uit een <strong>Frontend</strong>, een <strong>Backend</strong> en een <strong>REI-S</strong>-service.</p><pre><code class="language-">┌──────────┐
│   Gebruiker  │
└─────┬────┘
      │ toegang
      ▼
┌──────────┐
│ Frontend │
└─────┬────┘
      │ toegang
      ▼
┌──────────┐     ┌─────────────────┐
│ Backend  │────►│      LLM        │
└─────┬────┘     └─────────────────┘
      │ toegang
      ▼
┌──────────┐     ┌─────────────────┐
│  REI-S   │────►│ Embedding Model │
│          │     └─────────────────┘
│          │
│          │     ┌─────────────────┐
│          │────►│  Vector Store   │
└──────────┘     └─────────────────┘</code></pre>
<h3>Frontend</h3></p><p>De frontend is gebouwd met React en TypeScript en biedt een gebruiksvriendelijke interface voor interactie met de backend en de REI-S service. Het bevat functionaliteiten voor het beheren van assistenten, extensies en chatfuncties.</p><blockquote>Bronnen: <code>/frontend</code></blockquote></p><h3>Backend</h3></p><p>De backend is ontwikkeld met NestJS en TypeScript en dient als de belangrijkste API-laag van de applicatie. Het verwerkt verzoeken van de frontend en communiceert met llm-providers om chatfuncties mogelijk te maken. De backend beheert ook assistenten en hun extensies, waardoor gebruikers verschillende AI-modellen kunnen configureren en gebruiken voor hun chats.</p><p>Daarnaast beheert de backend gebruikersauthenticatie en communiceert met de REI-S service voor het indexeren en ophalen van bestanden.</p><p>Voor gegevensopslag gebruikt de backend een <strong>PostgreSQL</strong>-database.</p><blockquote>Bronnen: <code>/backend</code></blockquote></p><h3>REI-S</h3></p><p>De REI-S (<strong>R</strong>etrieval <strong>E</strong>xtraction <strong>I</strong>ngestion <strong>S</strong>erver) is een Python-gebaseerde server die basis RAG (Retrieval-Augmented Generation) mogelijkheden biedt. Het maakt het mogelijk om bestandsinhoud te extraheren, indexeren en op te vragen, waardoor de applicatie grote datasets efficiënt kan verwerken. De REI-S service is ontworpen om naadloos samen te werken met de backend en voorziet in benodigde data voor chatfuncties en bestandszoekopdrachten.</p><p>De REI-S ondersteunt Azure AI Search en pgvector voor vectoropslag, waardoor flexibele en schaalbare dataterugvindopties mogelijk zijn. De service kan worden geconfigureerd met omgevingsvariabelen om het type vectorstore en verbindingsgegevens te specificeren.</p><blockquote>Bronnen: <code>/services/reis</code></blockquote></p><p>
---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-07-09

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/codecentric/c4-genai-suite/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-07-09 
    </div>
    
</body>
</html>