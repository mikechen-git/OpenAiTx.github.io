<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>c4-genai-suite - codecentric/c4-genai-suite es</title>
    <meta name="title" content="c4-genai-suite - codecentric/c4-genai-suite es | c4 GenAI Suite Una aplicación de chatbot de IA con integración de Model Context Provider (MCP), impulsada por Langchain y compatible con todos los principales M...">
    <meta name="description" content="codecentric/c4-genai-suite - GitHub repository es documentation and information | c4 GenAI Suite Una aplicación de chatbot de IA con integración de Model Context Provider (MCP), impulsada por Langchain y compatible con todos los principales M...">
    <meta name="keywords" content="codecentric, c4-genai-suite, GitHub, repository, es documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/codecentric/c4-genai-suite/README-es.html">
    <meta property="og:title" content="c4-genai-suite - codecentric/c4-genai-suite es | c4 GenAI Suite Una aplicación de chatbot de IA con integración de Model Context Provider (MCP), impulsada por Langchain y compatible con todos los principales M...">
    <meta property="og:description" content="codecentric/c4-genai-suite - GitHub repository es documentation and information | c4 GenAI Suite Una aplicación de chatbot de IA con integración de Model Context Provider (MCP), impulsada por Langchain y compatible con todos los principales M...">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div style="position: fixed; top: 2px; left: 2px; z-index: 2000; background: rgba(255,255,255,0.95); border-radius: 6px; box-shadow: 0 2px 8px rgba(0,0,0,0.06); padding: 4px 14px; font-size: 15px; color: #222; font-family: 'Segoe UI', Arial, sans-serif; font-weight: 500; letter-spacing: 0.5px;">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" style="color: #0366d6; text-decoration: none; font-weight: 600;">Open AI Tx</a>
    </div>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/codecentric/c4-genai-suite" id="githubRepoLink" target="_blank">codecentric/c4-genai-suite</a>
<h1 style="display: none;">c4 GenAI Suite Una aplicación de chatbot de IA con integración de Model Context Provider (MCP), impulsada por Langchain y compatible con todos los principales M...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <h1>c4 GenAI Suite</h1>
<p>Una aplicación de chatbot de IA con integración de Model Context Provider (MCP), impulsada por Langchain y compatible con todos los principales Modelos de Lenguaje de Gran Escala (LLMs) y Modelos de Embedding.</p>
<p>Los administradores pueden crear asistentes con diferentes capacidades añadiendo extensiones, como servicios RAG (Generación Aumentada por Recuperación) o servidores MCP. La aplicación está construida utilizando una pila tecnológica moderna, incluyendo React, NestJS y Python FastAPI para el servicio REI-S.</p>
<p>Los usuarios pueden interactuar con los asistentes a través de una interfaz fácil de usar. Dependiendo de la configuración del asistente, los usuarios pueden hacer preguntas, subir sus propios archivos o utilizar otras funciones. Los asistentes interactúan con varios proveedores de LLM para proporcionar respuestas basadas en las extensiones configuradas. La información contextual proporcionada por las extensiones configuradas permite a los asistentes responder preguntas específicas de dominio y ofrecer información relevante.</p>
<p>La aplicación está diseñada para ser modular y extensible, permitiendo a los usuarios crear asistentes con diferentes capacidades mediante la adición de extensiones.</p>
<p><img src="https://raw.githubusercontent.com/codecentric/c4-genai-suite/main/demo/preview.webp" alt="vídeo corto de demostración del uso básico" /></p>
<h2>Características</h2>
<h3>Modelos de Lenguaje de Gran Escala (LLM) y Modelos Multimodales</h3>
<p>La c4 GenAI Suite ya es compatible con muchos modelos directamente. Y si tu modelo preferido aún no está soportado, debería ser fácil escribir una extensión para soportarlo.</p>
<ul>
<li>Modelos compatibles con OpenAI</li>
<li>Modelos Azure OpenAI</li>
<li>Modelos Bedrock</li>
<li>Modelos Google GenAI</li>
<li>Modelos compatibles con Ollama</li>
</ul>
<h3>Generación Aumentada por Recuperación (RAG)</h3>
<p>La Suite c4 GenAI incluye REI-S, un servidor para preparar archivos para su consumo por el LLM.</p>
<ul>
<li>REI-S, un servidor RAG integrado personalizado
<ul>
<li>Almacenes vectoriales
<ul>
<li>pgvector</li>
<li>Azure AI Search</li>
</ul>
</li>
<li>Modelos de embedding
<ul>
<li>Embeddings compatibles con OpenAI</li>
<li>Embeddings de Azure OpenAI</li>
<li>Embeddings compatibles con Ollama</li>
</ul>
</li>
<li>Formatos de archivo:
<ul>
<li>pdf, docx, pptx, xlsx, ...</li>
<li>transcripción de voz de archivos de audio (vía Whisper)</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3>Extensiones</h3>
<p>La Suite c4 GenAI está diseñada para ser extensible. Es fácil escribir extensiones, así como utilizar un servidor MCP ya existente.</p>
<ul>
<li>Servidores de Protocolo de Contexto de Modelo (MCP)</li>
<li>Systemprompt personalizado</li>
<li>Búsqueda de Bing</li>
<li>Calculadora</li>
</ul>
<h2>Comenzando</h2>
<h3>Usando Docker-Compose</h3>
<ul>
<li>Ejecuta <code>docker compose up</code> en la raíz del proyecto.</li>
<li>Abre la <a href="http://localhost:3333">aplicación</a> en un navegador. Las credenciales de inicio de sesión por defecto son usuario <code>admin@example.com</code> y contraseña <code>secret</code>.</li>
</ul>
<p><img src="https://raw.githubusercontent.com/codecentric/c4-genai-suite/main/demo/assistants.webp" alt="video mostrando la configuración del asistente" /></p>
<h3>Usando Helm y Kubernetes</h3>
<p>Para el despliegue en entornos Kubernetes, por favor consulta el <a href="https://raw.githubusercontent.com/codecentric/c4-genai-suite/main/./helm-chart/README.md">README de nuestro Helm Chart</a>.</p>
<h3>Configuración de Asistentes y Extensiones</h3>
<p>La c4 GenAI Suite gira en torno a los <em>asistentes</em>.
Cada asistente consiste en un conjunto de extensiones, que determinan el modelo LLM y qué herramientas puede utilizar.</p>
<ul>
<li>En el área de administración (haz clic en el nombre de usuario en la parte inferior izquierda), ve a la <a href="http://localhost:3333/admin/assistants">sección de asistentes</a>.</li>
<li>Agrega un asistente con el botón verde <code>+</code> junto al título de la sección. Elige un nombre y una descripción.</li>
<li>Selecciona el asistente creado y haz clic en el botón verde <code>+ Agregar Extensión</code>.</li>
<li>Selecciona el modelo y completa las credenciales.</li>
<li>Usa el botón <code>Probar</code> para verificar que funciona y <code>guardar</code>.</li>
</ul>
<p>Ahora puedes regresar a la <a href="http://localhost:3333/chat">página de chat</a> (haz clic en <code>c4 GenAI Suite</code> en la parte superior izquierda) y comenzar una nueva conversación con tu nuevo asistente.</p>
<blockquote>
<p>[!TIP]
Nuestro <code>docker-compose</code> incluye un Ollama local, que se ejecuta en la CPU. Puedes utilizarlo para pruebas rápidas. Pero será lento y probablemente querrás usar otro modelo. Si deseas utilizarlo, simplemente crea la siguiente extensión de modelo en tu Asistente.</p>
<ul>
<li>Extensión: <code>Dev: Ollama</code></li>
<li>Endpoint: <code>http://ollama:11434</code></li>
<li>Modelo: <code>llama3.2</code></li>
</ul>
</blockquote>
<h3>Protocolo de Contexto de Modelo (MCP) [opcional]</h3>
<p>Utilice cualquier servidor MCP que ofrezca una interfaz <code>sse</code> con la Extensión <code>MCP Tools</code> (o use nuestro <code>mcp-tool-as-server</code> como proxy frente a un servidor MCP <code>stdio</code>).
Cada servidor MCP puede configurarse en detalle como una extensión.</p>
<h3>Generación Aumentada por Recuperación (RAG) / Búsqueda de Archivos [opcional]</h3>
<p>Utilice nuestro servidor RAG <code>REI-S</code> para buscar en archivos proporcionados por el usuario. Solo necesita configurar una extensión <code>Buscar Archivos</code> para el asistente.
Este proceso se describe en detalle en <a href="services/reis/#example-configuration-in-c4">el subdirectorio <code>services/reis</code></a>.</p>
<h2>Contribuir y Desarrollo</h2>
<ul>
<li>Consulte <a href="https://raw.githubusercontent.com/codecentric/c4-genai-suite/main/CONTRIBUTING.md">CONTRIBUTING.md</a> para obtener pautas sobre cómo contribuir.</li>
<li>Para la incorporación de desarrolladores, revise <a href="https://raw.githubusercontent.com/codecentric/c4-genai-suite/main/DEVELOPERS.md">DEVELOPERS.md</a>.</li>
</ul>
<h2>Bloques Constructivos Principales</h2>
<p>La aplicación consiste en un <strong>Frontend</strong>, un <strong>Backend</strong> y un servicio <strong>REI-S</strong>.</p>
<pre><code>┌──────────┐
│  Usuario │
└─────┬────┘
      │ acceso
      ▼
┌──────────┐
│ Frontend │
└─────┬────┘
      │ acceso
      ▼
┌──────────┐     ┌─────────────────┐
│ Backend  │────►│      LLM        │
└─────┬────┘     └─────────────────┘
      │ acceso
      ▼
┌──────────┐     ┌─────────────────┐
│  REI-S   │────►│ Modelo de Embedding │
│          │     └─────────────────┘
│          │
│          │     ┌─────────────────┐
│          │────►│  Almacén Vectorial │
└──────────┘     └─────────────────┘
</code></pre>
<h3>Frontend</h3>
<p>El frontend está construido con React y TypeScript, proporcionando una interfaz fácil de usar para interactuar con el backend y el servicio REI-S. Incluye funcionalidades para la gestión de asistentes, extensiones y funciones de chat.</p>
<blockquote>
<p>Fuentes: <code>/frontend</code></p>
</blockquote>
<h3>Backend</h3>
<p>El backend está desarrollado con NestJS y TypeScript, sirviendo como la capa principal de API para la aplicación. Gestiona las solicitudes del frontend e interactúa con los proveedores de LLM para facilitar las funcionalidades de chat. El backend también administra los asistentes y sus extensiones, permitiendo a los usuarios configurar y utilizar diversos modelos de IA para sus chats.</p>
<p>Además, el backend gestiona la autenticación de usuarios y se comunica con el servicio REI-S para la indexación y recuperación de archivos.</p>
<p>Para la persistencia de datos, el backend utiliza una base de datos <strong>PostgreSQL</strong>.</p>
<blockquote>
<p>Fuentes: <code>/backend</code></p>
</blockquote>
<h3>REI-S</h3>
<p>El REI-S (<strong>R</strong>etrieval <strong>E</strong>xtraction <strong>I</strong>ngestion <strong>S</strong>erver) es un servidor basado en Python que proporciona capacidades básicas de RAG (Generación Aumentada por Recuperación). Permite la extracción de contenido de archivos, indexación y consultas, lo que habilita a la aplicación para manejar grandes conjuntos de datos de manera eficiente. El servicio REI-S está diseñado para funcionar sin problemas con el backend, proporcionando los datos necesarios para las funcionalidades de chat y búsquedas de archivos.</p>
<p>El REI-S es compatible con Azure AI Search y pgvector para el almacenamiento vectorial, permitiendo opciones de recuperación de datos flexibles y escalables. El servicio puede configurarse mediante variables de entorno para especificar el tipo de almacenamiento vectorial y los detalles de conexión.</p>
<blockquote>
<p>Fuentes: <code>/services/reis</code></p>
</blockquote>
<hr />
<p>Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx">Open Ai Tx</a> | Last indexed: 2025-07-09</p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
</body>
</html>