<!DOCTYPE html>
<html lang="hi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>c4-genai-suite - Hindi Documentation</title>
    <meta name="description" content="Read c4-genai-suite documentation in Hindi. This project has 123 stars on GitHub.">
    <meta name="keywords" content="c4-genai-suite, Hindi, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "c4-genai-suite",
  "description": "Documentation for c4-genai-suite in Hindi",
  "author": {
    "@type": "Person",
    "name": "codecentric"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 123
  },
  "url": "https://OpenAiTx.github.io/projects/codecentric/c4-genai-suite/README-hi.html",
  "sameAs": "https://raw.githubusercontent.com/codecentric/c4-genai-suite/main/README.md",
  "datePublished": "2025-07-09",
  "dateModified": "2025-07-09"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            color: #24292e;
            margin-bottom: 8px;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">c4-genai-suite</h1>
            <div class="project-meta">
                <span class="stars">⭐ 123 stars</span>
                <span class="language">Hindi</span>
                <span>by codecentric</span>
            </div>
        </div>
        
        <div class="content">
            <h1>c4 GenAI Suite</h1></p><p>एक एआई चैटबॉट एप्लिकेशन जिसमें मॉडल कॉन्टेक्स्ट प्रोवाइडर (MCP) एकीकरण है, जो लैंगचेन द्वारा संचालित है और सभी प्रमुख लार्ज लैंग्वेज मॉडल्स (LLMs) और एम्बेडिंग मॉडल्स के लिए संगत है।</p><p>प्रशासक विभिन्न क्षमताओं वाले असिस्टेंट्स बना सकते हैं, जैसे RAG (रिट्रीवल-ऑग्मेंटेड जेनरेशन) सर्विसेज या MCP सर्वर जोड़कर एक्सटेंशन के माध्यम से। यह एप्लिकेशन एक आधुनिक टेक्नोलॉजी स्टैक का उपयोग करके बनाई गई है, जिसमें REI-S सेवा के लिए React, NestJS, और Python FastAPI शामिल हैं।</p><p>उपयोगकर्ता एक यूज़र-फ्रेंडली इंटरफेस के माध्यम से असिस्टेंट्स के साथ संवाद कर सकते हैं। असिस्टेंट के कॉन्फ़िगरेशन के आधार पर, उपयोगकर्ता प्रश्न पूछ सकते हैं, अपनी खुद की फाइलें अपलोड कर सकते हैं, या अन्य सुविधाओं का उपयोग कर सकते हैं। असिस्टेंट्स विभिन्न LLM प्रदाताओं के साथ संवाद करके, कॉन्फ़िगर किए गए एक्सटेंशन के आधार पर उत्तर प्रदान करते हैं। कॉन्फ़िगर किए गए एक्सटेंशनों द्वारा प्रदान की गई संदर्भ जानकारी असिस्टेंट्स को डोमेन-विशिष्ट प्रश्नों के उत्तर देने और प्रासंगिक जानकारी प्रदान करने में सक्षम बनाती है।</p><p>एप्लिकेशन को मॉड्यूलर और एक्स्टेंसिबल रूप से डिज़ाइन किया गया है, जिससे उपयोगकर्ता एक्सटेंशन जोड़कर विभिन्न क्षमताओं वाले असिस्टेंट्स बना सकते हैं।</p><p><img src="https://raw.githubusercontent.com/codecentric/c4-genai-suite/main/demo/preview.webp" alt="मूल उपयोग का संक्षिप्त डेमो वीडियो"></p><h2>फीचर्स</h2></p><h3>लार्ज लैंग्वेज मॉडल्स (LLM) और मल्टीमोडल मॉडल्स</h3></p><p>c4 GenAI Suite पहले से ही कई मॉडल्स का सीधा समर्थन करता है। और यदि आपका पसंदीदा मॉडल पहले से समर्थित नहीं है, तो उसके लिए एक्सटेंशन लिखना भी आसान है।</p><ul><li>OpenAI संगत मॉडल्स</li>
<li>Azure OpenAI मॉडल्स</li>
<li>Bedrock मॉडल्स</li>
<li>Google GenAI मॉडल्स</li>
<li>Ollama संगत मॉडल्स</li>
</ul><h3>पुनः प्राप्ति संवर्धित जनरेशन (RAG)</h3></p><p>c4 GenAI सुइट में REI-S शामिल है, जो LLM द्वारा फ़ाइलों की खपत के लिए उन्हें तैयार करने वाला एक सर्वर है।</p><ul><li>REI-S, एक कस्टम इंटीग्रेटेड RAG सर्वर</li>
  <li>वेक्टर स्टोर्स</li>
    <li>pgvector</li>
    <li>Azure AI Search</li>
  <li>एम्बेडिंग मॉडल्स</li>
    <li>OpenAI संगत एम्बेडिंग्स</li>
    <li>Azure OpenAI एम्बेडिंग्स</li>
    <li>Ollama संगत एम्बेडिंग्स</li>
  <li>फ़ाइल फ़ॉर्मेट्स:</li>
    <li>pdf, docx, pptx, xlsx, ...</li>
    <li>ऑडियो फ़ाइल वॉइस ट्रांसक्रिप्शन (Whisper के माध्यम से)</li></p><p></ul><h3>एक्सटेंशन</h3></p><p>c4 GenAI सुइट को विस्तारशीलता के लिए डिज़ाइन किया गया है। एक्सटेंशन लिखना आसान है, जैसा कि पहले से मौजूद MCP सर्वर का उपयोग करना भी।</p><ul><li>मॉडल कॉन्टेक्स्ट प्रोटोकॉल (MCP) सर्वर</li>
<li>कस्टम सिस्टमप्रॉम्प्ट</li>
<li>बिंग सर्च</li>
<li>कैलकुलेटर</li>
</ul><h2>शुरुआत करें</h2></p><h3>Docker-Compose का उपयोग करना</h3></p><ul><li>प्रोजेक्ट रूट में <code>docker compose up</code> चलाएँ।</li>
<li>ब्राउज़र में <a href="http://localhost:3333" target="_blank" rel="noopener noreferrer">एप्लिकेशन</a> खोलें। डिफ़ॉल्ट लॉगिन क्रेडेंशियल्स हैं यूज़र <code>admin@example.com</code> और पासवर्ड <code>secret</code>।</li></p><p></ul><img src="https://raw.githubusercontent.com/codecentric/c4-genai-suite/main/demo/assistants.webp" alt="video showing assistant configuration"></p><h3>Helm और Kubernetes का उपयोग करना</h3></p><p>Kubernetes वातावरण में डिप्लॉयमेंट के लिए, कृपया हमारे Helm Chart के <a href="https://raw.githubusercontent.com/codecentric/c4-genai-suite/main/./helm-chart/README.md" target="_blank" rel="noopener noreferrer">README</a> को देखें।</p><h3>असिस्टेंट्स और एक्सटेंशन सेटअप करना</h3></p><p>c4 GenAI Suite <em>असिस्टेंट्स</em> के इर्द-गिर्द घूमती है।
प्रत्येक असिस्टेंट में एक्सटेंशन्स का एक सेट होता है, जो LLM मॉडल और उपलब्ध टूल्स को निर्धारित करता है।</p><ul><li>एडमिन एरिया में (नीचे बाईं ओर यूज़रनेम पर क्लिक करें), <a href="http://localhost:3333/admin/assistants" target="_blank" rel="noopener noreferrer">असिस्टेंट्स सेक्शन</a> पर जाएँ।</li>
<li>सेक्शन टाइटल के पास हरे रंग के <code>+</code> बटन से एक नया असिस्टेंट जोड़ें। एक नाम और विवरण चुनें।</li>
<li>बनाए गए असिस्टेंट को चुनें और हरे <code>+ Add Extension</code> पर क्लिक करें।</li>
<li>मॉडल चुनें और क्रेडेंशियल्स भरें।</li>
<li>यह जांचने के लिए कि सब कुछ सही है, <code>Test</code> बटन का उपयोग करें और फिर <code>save</code> करें।</li></p><p></ul>अब आप <a href="http://localhost:3333/chat" target="_blank" rel="noopener noreferrer">चैट पेज</a> (ऊपर बाईं ओर <code>c4 GenAI Suite</code> पर क्लिक करें) पर वापस जा सकते हैं और अपने नए असिस्टेंट के साथ एक नई बातचीत शुरू कर सकते हैं।</p><blockquote>[!TIP]</blockquote>
<blockquote>हमारे <code>docker-compose</code> में एक लोकल Ollama शामिल है, जो CPU पर चलता है। आप इसका उपयोग त्वरित परीक्षण के लिए कर सकते हैं। लेकिन यह धीमा होगा और संभवतः आप कोई दूसरा मॉडल इस्तेमाल करना चाहेंगे। यदि आप इसका उपयोग करना चाहते हैं, तो अपने असिस्टेंट में निम्नलिखित मॉडल एक्सटेंशन बनाएं।</blockquote>
<blockquote>* एक्सटेंशन: <code>Dev: Ollama</code></blockquote>
<blockquote>* एंडपॉइंट: <code>http://ollama:11434</code></blockquote>
<blockquote>* मॉडल: <code>llama3.2</code></blockquote></p><h3>मॉडल कंटेक्स्ट प्रोटोकॉल (MCP) [वैकल्पिक]</h3></p><p>किसी भी MCP सर्वर का उपयोग करें जो <code>sse</code> इंटरफेस के साथ <code>MCP Tools</code> एक्सटेंशन प्रदान करता है (या हमारे <code>mcp-tool-as-server</code> का उपयोग करें जो <code>stdio</code> MCP सर्वर के सामने एक प्रॉक्सी के रूप में कार्य करता है)।
प्रत्येक MCP सर्वर को विस्तार से एक एक्सटेंशन के रूप में कॉन्फ़िगर किया जा सकता है।</p><h3>रिट्रीवल ऑगमेंटेड जनरेशन (RAG) / फ़ाइल खोज [वैकल्पिक]</h3></p><p>उपयोगकर्ता द्वारा प्रदान की गई फ़ाइलों को खोजने के लिए हमारे RAG सर्वर <code>REI-S</code> का उपयोग करें। बस सहायक के लिए एक <code>Search Files</code> एक्सटेंशन कॉन्फ़िगर करें।
इस प्रक्रिया का विस्तृत विवरण <a href="services/reis/#example-configuration-in-c4" target="_blank" rel="noopener noreferrer"> <code>services/reis</code> उपनिर्देशिका </a> में दिया गया है।</p><h2>योगदान और विकास</h2></p><ul><li>योगदान करने के लिए दिशानिर्देशों के लिए देखें <a href="https://raw.githubusercontent.com/codecentric/c4-genai-suite/main/CONTRIBUTING.md" target="_blank" rel="noopener noreferrer">CONTRIBUTING.md</a>।</li>
<li>डेवलपर ऑनबोर्डिंग के लिए देखें <a href="https://raw.githubusercontent.com/codecentric/c4-genai-suite/main/DEVELOPERS.md" target="_blank" rel="noopener noreferrer">DEVELOPERS.md</a>।</li></p><p></ul><h2>मुख्य निर्माण खंड</h2></p><p>एप्लिकेशन में एक <strong>फ्रंटएंड</strong>, एक <strong>बैकएंड</strong> और एक <strong>REI-S</strong> सेवा होती है।</p><pre><code class="language-">┌──────────┐
│   उपयोगकर्ता   │
└─────┬────┘
      │ पहुँच
      ▼
┌──────────┐
│ फ्रंटएंड │
└─────┬────┘
      │ पहुँच
      ▼
┌──────────┐     ┌─────────────────┐
│ बैकएंड   │────►│      LLM        │
└─────┬────┘     └─────────────────┘
      │ पहुँच
      ▼
┌──────────┐     ┌─────────────────┐
│  REI-S   │────►│ एम्बेडिंग मॉडल  │
│          │     └─────────────────┘
│          │
│          │     ┌─────────────────┐
│          │────►│  वेक्टर स्टोर    │
└──────────┘     └─────────────────┘</code></pre>
<h3>फ्रंटएंड</h3></p><p>फ्रंटएंड React और TypeScript के साथ बनाया गया है, जो बैकएंड और REI-S सेवा के साथ इंटरैक्ट करने के लिए एक यूज़र-फ्रेंडली इंटरफेस प्रदान करता है। इसमें असिस्टेंट्स, एक्सटेंशन्स और चैट फंक्शनैलिटी को प्रबंधित करने के लिए फीचर्स शामिल हैं।</p><blockquote>स्रोत: <code>/frontend</code></blockquote></p><h3>बैकएंड</h3></p><p>बैकएंड NestJS और TypeScript का उपयोग करके विकसित किया गया है, जो एप्लिकेशन के लिए मुख्य API लेयर के रूप में कार्य करता है। यह फ्रंटएंड से अनुरोधों को संभालता है और चैट फंक्शनैलिटी को सक्षम करने के लिए llm प्रदाताओं के साथ इंटरैक्ट करता है। बैकएंड असिस्टेंट्स और उनकी एक्सटेंशन्स का भी प्रबंधन करता है, जिससे उपयोगकर्ता अपनी चैट्स के लिए विभिन्न AI मॉडल्स को कॉन्फ़िगर और उपयोग कर सकते हैं।</p><p>इसके अतिरिक्त, बैकएंड यूज़र ऑथेंटिकेशन का प्रबंधन करता है, और फ़ाइल इंडेक्सिंग और रिट्रीवल के लिए REI-S सेवा के साथ संचार करता है।</p><p>डेटा को सुरक्षित रखने के लिए, बैकएंड <strong>PostgreSQL</strong> डेटाबेस का उपयोग करता है।</p><blockquote>स्रोत: <code>/backend</code></blockquote></p><h3>REI-S</h3></p><p>REI-S (<strong>R</strong>etrieval <strong>E</strong>xtraction <strong>I</strong>ngestion <strong>S</strong>erver) एक Python-आधारित सर्वर है जो बेसिक RAG (Retrieval-Augmented Generation) क्षमताएँ प्रदान करता है। यह फ़ाइल सामग्री निष्कर्षण, इंडेक्सिंग और क्वेरी करने की सुविधा देता है, जिससे एप्लिकेशन बड़े डेटा सेट्स को कुशलतापूर्वक संभाल सकता है। REI-S सेवा को बैकएंड के साथ सहज रूप से काम करने के लिए डिज़ाइन किया गया है, जो चैट फंक्शनैलिटी और फ़ाइल खोज के लिए आवश्यक डेटा प्रदान करता है।</p><p>REI-S Azure AI Search और pgvector को वेक्टर स्टोरेज के लिए सपोर्ट करता है, जिससे लचीले और स्केलेबल डेटा रिट्रीवल विकल्प उपलब्ध होते हैं। सेवा को वातावरण वेरिएबल्स का उपयोग करके कॉन्फ़िगर किया जा सकता है, जिसमें वेक्टर स्टोर का प्रकार और कनेक्शन डिटेल्स निर्दिष्ट की जाती हैं।</p><blockquote>स्रोत: <code>/services/reis</code></blockquote></p><p>
---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-07-09

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/codecentric/c4-genai-suite/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-07-09 
    </div>
    
</body>
</html>