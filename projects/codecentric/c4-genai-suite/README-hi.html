<!DOCTYPE html>
<html lang="hi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>c4-genai-suite - codecentric/c4-genai-suite hi</title>
    <meta name="title" content="c4-genai-suite - codecentric/c4-genai-suite hi | c4 GenAI Suite एक एआई चैटबॉट एप्लिकेशन जिसमें मॉडल कॉन्टेक्स्ट प्रोवाइडर (MCP) एकीकरण है, जो लैंगचेन द्वारा संचालित है और सभी प्रमुख लार्ज लैंग्वेज मॉडल्स (LLMs...">
    <meta name="description" content="codecentric/c4-genai-suite - GitHub repository hi documentation and information | c4 GenAI Suite एक एआई चैटबॉट एप्लिकेशन जिसमें मॉडल कॉन्टेक्स्ट प्रोवाइडर (MCP) एकीकरण है, जो लैंगचेन द्वारा संचालित है और सभी प्रमुख लार्ज लैंग्वेज मॉडल्स (LLMs...">
    <meta name="keywords" content="codecentric, c4-genai-suite, GitHub, repository, hi documentation">
    <meta name="author" content="Open AI Tx">
    <meta name="robots" content="index, follow">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://openaitx.github.io/projects/codecentric/c4-genai-suite/README-hi.html">
    <meta property="og:title" content="c4-genai-suite - codecentric/c4-genai-suite hi | c4 GenAI Suite एक एआई चैटबॉट एप्लिकेशन जिसमें मॉडल कॉन्टेक्स्ट प्रोवाइडर (MCP) एकीकरण है, जो लैंगचेन द्वारा संचालित है और सभी प्रमुख लार्ज लैंग्वेज मॉडल्स (LLMs...">
    <meta property="og:description" content="codecentric/c4-genai-suite - GitHub repository hi documentation and information | c4 GenAI Suite एक एआई चैटबॉट एप्लिकेशन जिसमें मॉडल कॉन्टेक्स्ट प्रोवाइडर (MCP) एकीकरण है, जो लैंगचेन द्वारा संचालित है और सभी प्रमुख लार्ज लैंग्वेज मॉडल्स (LLMs...">
    <meta property="og:image" content="https://openaitx.github.io/logo_crop.png">
    <link rel="icon" type="image/jpeg" href="/icon.jpg">
    <link rel="apple-touch-icon" href="/icon.jpg">
    <script src="/js/marked.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/css/github.min.css?v=20250613">
    <script src="/js/highlight.min.js?v=20250613"></script>
    <link rel="stylesheet" href="/view.css?v=20250613">
    <style>
        body { display: flex; flex-direction: column; min-height: 100vh; }
        .main-container { margin: 0 auto; width: 100%; max-width: 980px; padding: 0 20px; }
        @media (max-width: 768px) { .main-container { padding: 0 15px; } }
        .markdown-body img { max-width: 100%; height: auto; }
        .header { text-align: center; margin-bottom: 30px; padding: 20px; background-color: #f6f8fa; border-bottom: 1px solid #e1e4e8; position: relative; }
        .header .links { margin-top: 10px; font-size: 16px; }
        .header .links a { color: #0366d6; text-decoration: none; margin-left: 5px; }
        .header .links a:hover { text-decoration: underline; }
        .language-badges { margin-top: 15px; text-align: center; }
        .language-badges a { display: inline-block; margin: 2px; text-decoration: none; }
        .language-badges img { height: 20px; border-radius: 3px; }
        .language-badges a:hover img { opacity: 0.8; }
    </style>
</head>
<body>
    <div style="position: fixed; top: 2px; left: 2px; z-index: 2000; background: rgba(255,255,255,0.95); border-radius: 6px; box-shadow: 0 2px 8px rgba(0,0,0,0.06); padding: 4px 14px; font-size: 15px; color: #222; font-family: 'Segoe UI', Arial, sans-serif; font-weight: 500; letter-spacing: 0.5px;">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" style="color: #0366d6; text-decoration: none; font-weight: 600;">Open AI Tx</a>
    </div>
    <div class="header">
        <div class="links">
            GitHub Repository: <a href="https://github.com/codecentric/c4-genai-suite" id="githubRepoLink" target="_blank">codecentric/c4-genai-suite</a>
<h1 style="display: none;">c4 GenAI Suite एक एआई चैटबॉट एप्लिकेशन जिसमें मॉडल कॉन्टेक्स्ट प्रोवाइडर (MCP) एकीकरण है, जो लैंगचेन द्वारा संचालित है और सभी प्रमुख लार्ज लैंग्वेज मॉडल्स (LLMs...</h1>
        </div>
        <div class="language-badges" id="languageBadges">
            <!-- You can generate language badges here if needed -->
        </div>
    </div>
    <div class="main-container">
        <div class="markdown-body" id="content">
            <h1>c4 GenAI Suite</h1>
<p>एक एआई चैटबॉट एप्लिकेशन जिसमें मॉडल कॉन्टेक्स्ट प्रोवाइडर (MCP) एकीकरण है, जो लैंगचेन द्वारा संचालित है और सभी प्रमुख लार्ज लैंग्वेज मॉडल्स (LLMs) और एम्बेडिंग मॉडल्स के लिए संगत है।</p>
<p>प्रशासक विभिन्न क्षमताओं वाले असिस्टेंट्स बना सकते हैं, जैसे RAG (रिट्रीवल-ऑग्मेंटेड जेनरेशन) सर्विसेज या MCP सर्वर जोड़कर एक्सटेंशन के माध्यम से। यह एप्लिकेशन एक आधुनिक टेक्नोलॉजी स्टैक का उपयोग करके बनाई गई है, जिसमें REI-S सेवा के लिए React, NestJS, और Python FastAPI शामिल हैं।</p>
<p>उपयोगकर्ता एक यूज़र-फ्रेंडली इंटरफेस के माध्यम से असिस्टेंट्स के साथ संवाद कर सकते हैं। असिस्टेंट के कॉन्फ़िगरेशन के आधार पर, उपयोगकर्ता प्रश्न पूछ सकते हैं, अपनी खुद की फाइलें अपलोड कर सकते हैं, या अन्य सुविधाओं का उपयोग कर सकते हैं। असिस्टेंट्स विभिन्न LLM प्रदाताओं के साथ संवाद करके, कॉन्फ़िगर किए गए एक्सटेंशन के आधार पर उत्तर प्रदान करते हैं। कॉन्फ़िगर किए गए एक्सटेंशनों द्वारा प्रदान की गई संदर्भ जानकारी असिस्टेंट्स को डोमेन-विशिष्ट प्रश्नों के उत्तर देने और प्रासंगिक जानकारी प्रदान करने में सक्षम बनाती है।</p>
<p>एप्लिकेशन को मॉड्यूलर और एक्स्टेंसिबल रूप से डिज़ाइन किया गया है, जिससे उपयोगकर्ता एक्सटेंशन जोड़कर विभिन्न क्षमताओं वाले असिस्टेंट्स बना सकते हैं।</p>
<p><img src="https://raw.githubusercontent.com/codecentric/c4-genai-suite/main/demo/preview.webp" alt="मूल उपयोग का संक्षिप्त डेमो वीडियो" /></p>
<h2>फीचर्स</h2>
<h3>लार्ज लैंग्वेज मॉडल्स (LLM) और मल्टीमोडल मॉडल्स</h3>
<p>c4 GenAI Suite पहले से ही कई मॉडल्स का सीधा समर्थन करता है। और यदि आपका पसंदीदा मॉडल पहले से समर्थित नहीं है, तो उसके लिए एक्सटेंशन लिखना भी आसान है।</p>
<ul>
<li>OpenAI संगत मॉडल्स</li>
<li>Azure OpenAI मॉडल्स</li>
<li>Bedrock मॉडल्स</li>
<li>Google GenAI मॉडल्स</li>
<li>Ollama संगत मॉडल्स</li>
</ul>
<h3>पुनः प्राप्ति संवर्धित जनरेशन (RAG)</h3>
<p>c4 GenAI सुइट में REI-S शामिल है, जो LLM द्वारा फ़ाइलों की खपत के लिए उन्हें तैयार करने वाला एक सर्वर है।</p>
<ul>
<li>REI-S, एक कस्टम इंटीग्रेटेड RAG सर्वर
<ul>
<li>वेक्टर स्टोर्स
<ul>
<li>pgvector</li>
<li>Azure AI Search</li>
</ul>
</li>
<li>एम्बेडिंग मॉडल्स
<ul>
<li>OpenAI संगत एम्बेडिंग्स</li>
<li>Azure OpenAI एम्बेडिंग्स</li>
<li>Ollama संगत एम्बेडिंग्स</li>
</ul>
</li>
<li>फ़ाइल फ़ॉर्मेट्स:
<ul>
<li>pdf, docx, pptx, xlsx, ...</li>
<li>ऑडियो फ़ाइल वॉइस ट्रांसक्रिप्शन (Whisper के माध्यम से)</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3>एक्सटेंशन</h3>
<p>c4 GenAI सुइट को विस्तारशीलता के लिए डिज़ाइन किया गया है। एक्सटेंशन लिखना आसान है, जैसा कि पहले से मौजूद MCP सर्वर का उपयोग करना भी।</p>
<ul>
<li>मॉडल कॉन्टेक्स्ट प्रोटोकॉल (MCP) सर्वर</li>
<li>कस्टम सिस्टमप्रॉम्प्ट</li>
<li>बिंग सर्च</li>
<li>कैलकुलेटर</li>
</ul>
<h2>शुरुआत करें</h2>
<h3>Docker-Compose का उपयोग करना</h3>
<ul>
<li>प्रोजेक्ट रूट में <code>docker compose up</code> चलाएँ।</li>
<li>ब्राउज़र में <a href="http://localhost:3333">एप्लिकेशन</a> खोलें। डिफ़ॉल्ट लॉगिन क्रेडेंशियल्स हैं यूज़र <code>admin@example.com</code> और पासवर्ड <code>secret</code>।</li>
</ul>
<p><img src="https://raw.githubusercontent.com/codecentric/c4-genai-suite/main/demo/assistants.webp" alt="video showing assistant configuration" /></p>
<h3>Helm और Kubernetes का उपयोग करना</h3>
<p>Kubernetes वातावरण में डिप्लॉयमेंट के लिए, कृपया हमारे Helm Chart के <a href="https://raw.githubusercontent.com/codecentric/c4-genai-suite/main/./helm-chart/README.md">README</a> को देखें।</p>
<h3>असिस्टेंट्स और एक्सटेंशन सेटअप करना</h3>
<p>c4 GenAI Suite <em>असिस्टेंट्स</em> के इर्द-गिर्द घूमती है।
प्रत्येक असिस्टेंट में एक्सटेंशन्स का एक सेट होता है, जो LLM मॉडल और उपलब्ध टूल्स को निर्धारित करता है।</p>
<ul>
<li>एडमिन एरिया में (नीचे बाईं ओर यूज़रनेम पर क्लिक करें), <a href="http://localhost:3333/admin/assistants">असिस्टेंट्स सेक्शन</a> पर जाएँ।</li>
<li>सेक्शन टाइटल के पास हरे रंग के <code>+</code> बटन से एक नया असिस्टेंट जोड़ें। एक नाम और विवरण चुनें।</li>
<li>बनाए गए असिस्टेंट को चुनें और हरे <code>+ Add Extension</code> पर क्लिक करें।</li>
<li>मॉडल चुनें और क्रेडेंशियल्स भरें।</li>
<li>यह जांचने के लिए कि सब कुछ सही है, <code>Test</code> बटन का उपयोग करें और फिर <code>save</code> करें।</li>
</ul>
<p>अब आप <a href="http://localhost:3333/chat">चैट पेज</a> (ऊपर बाईं ओर <code>c4 GenAI Suite</code> पर क्लिक करें) पर वापस जा सकते हैं और अपने नए असिस्टेंट के साथ एक नई बातचीत शुरू कर सकते हैं।</p>
<blockquote>
<p>[!TIP]
हमारे <code>docker-compose</code> में एक लोकल Ollama शामिल है, जो CPU पर चलता है। आप इसका उपयोग त्वरित परीक्षण के लिए कर सकते हैं। लेकिन यह धीमा होगा और संभवतः आप कोई दूसरा मॉडल इस्तेमाल करना चाहेंगे। यदि आप इसका उपयोग करना चाहते हैं, तो अपने असिस्टेंट में निम्नलिखित मॉडल एक्सटेंशन बनाएं।</p>
<ul>
<li>एक्सटेंशन: <code>Dev: Ollama</code></li>
<li>एंडपॉइंट: <code>http://ollama:11434</code></li>
<li>मॉडल: <code>llama3.2</code></li>
</ul>
</blockquote>
<h3>मॉडल कंटेक्स्ट प्रोटोकॉल (MCP) [वैकल्पिक]</h3>
<p>किसी भी MCP सर्वर का उपयोग करें जो <code>sse</code> इंटरफेस के साथ <code>MCP Tools</code> एक्सटेंशन प्रदान करता है (या हमारे <code>mcp-tool-as-server</code> का उपयोग करें जो <code>stdio</code> MCP सर्वर के सामने एक प्रॉक्सी के रूप में कार्य करता है)।
प्रत्येक MCP सर्वर को विस्तार से एक एक्सटेंशन के रूप में कॉन्फ़िगर किया जा सकता है।</p>
<h3>रिट्रीवल ऑगमेंटेड जनरेशन (RAG) / फ़ाइल खोज [वैकल्पिक]</h3>
<p>उपयोगकर्ता द्वारा प्रदान की गई फ़ाइलों को खोजने के लिए हमारे RAG सर्वर <code>REI-S</code> का उपयोग करें। बस सहायक के लिए एक <code>Search Files</code> एक्सटेंशन कॉन्फ़िगर करें।
इस प्रक्रिया का विस्तृत विवरण <a href="services/reis/#example-configuration-in-c4"> <code>services/reis</code> उपनिर्देशिका </a> में दिया गया है।</p>
<h2>योगदान और विकास</h2>
<ul>
<li>योगदान करने के लिए दिशानिर्देशों के लिए देखें <a href="https://raw.githubusercontent.com/codecentric/c4-genai-suite/main/CONTRIBUTING.md">CONTRIBUTING.md</a>।</li>
<li>डेवलपर ऑनबोर्डिंग के लिए देखें <a href="https://raw.githubusercontent.com/codecentric/c4-genai-suite/main/DEVELOPERS.md">DEVELOPERS.md</a>।</li>
</ul>
<h2>मुख्य निर्माण खंड</h2>
<p>एप्लिकेशन में एक <strong>फ्रंटएंड</strong>, एक <strong>बैकएंड</strong> और एक <strong>REI-S</strong> सेवा होती है।</p>
<pre><code>┌──────────┐
│   उपयोगकर्ता   │
└─────┬────┘
      │ पहुँच
      ▼
┌──────────┐
│ फ्रंटएंड │
└─────┬────┘
      │ पहुँच
      ▼
┌──────────┐     ┌─────────────────┐
│ बैकएंड   │────►│      LLM        │
└─────┬────┘     └─────────────────┘
      │ पहुँच
      ▼
┌──────────┐     ┌─────────────────┐
│  REI-S   │────►│ एम्बेडिंग मॉडल  │
│          │     └─────────────────┘
│          │
│          │     ┌─────────────────┐
│          │────►│  वेक्टर स्टोर    │
└──────────┘     └─────────────────┘
</code></pre>
<h3>फ्रंटएंड</h3>
<p>फ्रंटएंड React और TypeScript के साथ बनाया गया है, जो बैकएंड और REI-S सेवा के साथ इंटरैक्ट करने के लिए एक यूज़र-फ्रेंडली इंटरफेस प्रदान करता है। इसमें असिस्टेंट्स, एक्सटेंशन्स और चैट फंक्शनैलिटी को प्रबंधित करने के लिए फीचर्स शामिल हैं।</p>
<blockquote>
<p>स्रोत: <code>/frontend</code></p>
</blockquote>
<h3>बैकएंड</h3>
<p>बैकएंड NestJS और TypeScript का उपयोग करके विकसित किया गया है, जो एप्लिकेशन के लिए मुख्य API लेयर के रूप में कार्य करता है। यह फ्रंटएंड से अनुरोधों को संभालता है और चैट फंक्शनैलिटी को सक्षम करने के लिए llm प्रदाताओं के साथ इंटरैक्ट करता है। बैकएंड असिस्टेंट्स और उनकी एक्सटेंशन्स का भी प्रबंधन करता है, जिससे उपयोगकर्ता अपनी चैट्स के लिए विभिन्न AI मॉडल्स को कॉन्फ़िगर और उपयोग कर सकते हैं।</p>
<p>इसके अतिरिक्त, बैकएंड यूज़र ऑथेंटिकेशन का प्रबंधन करता है, और फ़ाइल इंडेक्सिंग और रिट्रीवल के लिए REI-S सेवा के साथ संचार करता है।</p>
<p>डेटा को सुरक्षित रखने के लिए, बैकएंड <strong>PostgreSQL</strong> डेटाबेस का उपयोग करता है।</p>
<blockquote>
<p>स्रोत: <code>/backend</code></p>
</blockquote>
<h3>REI-S</h3>
<p>REI-S (<strong>R</strong>etrieval <strong>E</strong>xtraction <strong>I</strong>ngestion <strong>S</strong>erver) एक Python-आधारित सर्वर है जो बेसिक RAG (Retrieval-Augmented Generation) क्षमताएँ प्रदान करता है। यह फ़ाइल सामग्री निष्कर्षण, इंडेक्सिंग और क्वेरी करने की सुविधा देता है, जिससे एप्लिकेशन बड़े डेटा सेट्स को कुशलतापूर्वक संभाल सकता है। REI-S सेवा को बैकएंड के साथ सहज रूप से काम करने के लिए डिज़ाइन किया गया है, जो चैट फंक्शनैलिटी और फ़ाइल खोज के लिए आवश्यक डेटा प्रदान करता है।</p>
<p>REI-S Azure AI Search और pgvector को वेक्टर स्टोरेज के लिए सपोर्ट करता है, जिससे लचीले और स्केलेबल डेटा रिट्रीवल विकल्प उपलब्ध होते हैं। सेवा को वातावरण वेरिएबल्स का उपयोग करके कॉन्फ़िगर किया जा सकता है, जिसमें वेक्टर स्टोर का प्रकार और कनेक्शन डिटेल्स निर्दिष्ट की जाती हैं।</p>
<blockquote>
<p>स्रोत: <code>/services/reis</code></p>
</blockquote>
<hr />
<p>Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx">Open Ai Tx</a> | Last indexed: 2025-07-09</p>
<hr />

        </div>
    </div>
    <footer class="footer">
        Powered by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank">Open AI Tx</a>
    </footer>
    <!-- Default Statcounter code for openaitx
https://openaitx.github.io/ -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
</body>
</html>