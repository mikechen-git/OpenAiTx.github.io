<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>c4-genai-suite - Russian Documentation</title>
    <meta name="description" content="Read c4-genai-suite documentation in Russian. This project has 123 stars on GitHub.">
    <meta name="keywords" content="c4-genai-suite, Russian, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "c4-genai-suite",
  "description": "Documentation for c4-genai-suite in Russian",
  "author": {
    "@type": "Person",
    "name": "codecentric"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 123
  },
  "url": "https://OpenAiTx.github.io/projects/codecentric/c4-genai-suite/README-ru.html",
  "sameAs": "https://raw.githubusercontent.com/codecentric/c4-genai-suite/main/README.md",
  "datePublished": "2025-07-09",
  "dateModified": "2025-07-09"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            color: #24292e;
            margin-bottom: 8px;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">c4-genai-suite</h1>
            <div class="project-meta">
                <span class="stars">⭐ 123 stars</span>
                <span class="language">Russian</span>
                <span>by codecentric</span>
            </div>
        </div>
        
        <div class="content">
            <h1>c4 GenAI Suite</h1></p><p>Приложение чат-бота с интеграцией Model Context Provider (MCP), построенное на базе Langchain и совместимое со всеми основными Большими Языковыми Моделями (LLM) и моделями эмбеддинга.</p><p>Администраторы могут создавать ассистентов с различными возможностями, добавляя расширения, такие как сервисы RAG (генерация с расширенным поиском) или MCP-серверы. Приложение построено с использованием современного стека технологий, включая React, NestJS и Python FastAPI для сервиса REI-S.</p><p>Пользователи могут взаимодействовать с ассистентами через удобный пользовательский интерфейс. В зависимости от конфигурации ассистента пользователи могут задавать вопросы, загружать собственные файлы или использовать другие функции. Ассистенты взаимодействуют с различными LLM-провайдерами для предоставления ответов на основе настроенных расширений. Контекстная информация, предоставляемая настроенными расширениями, позволяет ассистентам отвечать на вопросы, относящиеся к определённой предметной области, и предоставлять актуальную информацию.</p><p>Приложение разработано модульным и расширяемым, что позволяет пользователям создавать ассистентов с различными возможностями, добавляя расширения.</p><p><img src="https://raw.githubusercontent.com/codecentric/c4-genai-suite/main/demo/preview.webp" alt="короткое демонстрационное видео базового использования"></p><h2>Возможности</h2></p><h3>Большие языковые модели (LLM) и мультимодальные модели</h3></p><p>c4 GenAI Suite уже поддерживает множество моделей напрямую. Если ваша предпочитаемая модель ещё не поддерживается, написать расширение для её поддержки должно быть просто.</p><ul><li>Модели, совместимые с OpenAI</li>
<li>Модели Azure OpenAI</li>
<li>Модели Bedrock</li>
<li>Модели Google GenAI</li>
<li>Модели, совместимые с Ollama</li>
</ul><h3>Генерация с дополнением извлечённой информации (RAG)</h3></p><p>Пакет c4 GenAI включает REI-S — сервер для подготовки файлов к использованию LLM.</p><ul><li>REI-S, специализированный интегрированный RAG-сервер</li>
  <li>Векторные хранилища</li>
    <li>pgvector</li>
    <li>Azure AI Search</li>
  <li>Модели эмбеддингов</li>
    <li>эмбеддинги, совместимые с OpenAI</li>
    <li>эмбеддинги Azure OpenAI</li>
    <li>эмбеддинги, совместимые с Ollama</li>
  <li>Форматы файлов:</li>
    <li>pdf, docx, pptx, xlsx, ...</li>
    <li>транскрипция голосовых аудиофайлов (через Whisper)</li></p><p></ul><h3>Расширения</h3></p><p>Пакет c4 GenAI разработан с учётом расширяемости. Создавать расширения просто, как и использовать уже существующий MCP-сервер.</p><ul><li>Серверы протокола Model Context Protocol (MCP)</li>
<li>Пользовательский systemprompt</li>
<li>Bing Search</li>
<li>Калькулятор</li>
</ul><h2>Начало работы</h2></p><h3>Использование Docker-Compose</h3></p><ul><li>Запустите <code>docker compose up</code> в корневой папке проекта.</li>
<li>Откройте <a href="http://localhost:3333" target="_blank" rel="noopener noreferrer">приложение</a> в браузере. Стандартные учетные данные для входа: пользователь <code>admin@example.com</code> и пароль <code>secret</code>.</li></p><p></ul><img src="https://raw.githubusercontent.com/codecentric/c4-genai-suite/main/demo/assistants.webp" alt="видео, показывающее настройку ассистента"></p><h3>Использование Helm и Kubernetes</h3></p><p>Для развертывания в средах Kubernetes, пожалуйста, обратитесь к <a href="https://raw.githubusercontent.com/codecentric/c4-genai-suite/main/./helm-chart/README.md" target="_blank" rel="noopener noreferrer">README нашего Helm Chart</a>.</p><h3>Настройка ассистентов и расширений</h3></p><p>C4 GenAI Suite строится вокруг <em>ассистентов</em>.
Каждый ассистент состоит из набора расширений, которые определяют LLM-модель и доступные инструменты.</p><ul><li>В административной панели (нажмите на имя пользователя в левом нижнем углу) перейдите в <a href="http://localhost:3333/admin/assistants" target="_blank" rel="noopener noreferrer">раздел ассистентов</a>.</li>
<li>Добавьте ассистента с помощью зеленой кнопки <code>+</code> рядом с заголовком раздела. Выберите имя и описание.</li>
<li>Выберите созданного ассистента и нажмите зеленую кнопку <code>+ Добавить расширение</code>.</li>
<li>Выберите модель и заполните учетные данные.</li>
<li>Используйте кнопку <code>Test</code>, чтобы проверить работоспособность, и затем <code>сохранить</code>.</li></p><p></ul>Теперь вы можете вернуться на <a href="http://localhost:3333/chat" target="_blank" rel="noopener noreferrer">страницу чата</a> (нажмите на <code>c4 GenAI Suite</code> в левом верхнем углу) и начать новый разговор с вашим новым ассистентом.</p><blockquote>[!ПОДСКАЗКА]</blockquote>
<blockquote>Наш <code>docker-compose</code> включает локальный Ollama, который работает на CPU. Вы можете использовать его для быстрого тестирования. Однако он будет работать медленно, и, вероятно, вы захотите использовать другую модель. Если вы хотите воспользоваться им, просто создайте следующее расширение модели в вашем Ассистенте.</blockquote>
<blockquote>* Расширение: <code>Dev: Ollama</code></blockquote>
<blockquote>* Endpoint: <code>http://ollama:11434</code></blockquote>
<blockquote>* Модель: <code>llama3.2</code></blockquote>
<h3>Протокол Контекста Модели (MCP) [необязательно]</h3></p><p>Используйте любой MCP-сервер, предоставляющий интерфейс <code>sse</code> с расширением <code>MCP Tools</code> (или используйте наш <code>mcp-tool-as-server</code> как прокси перед MCP-сервером с интерфейсом <code>stdio</code>).
Каждый MCP-сервер может быть детально настроен как расширение.</p><h3>Генерация с поддержкой поиска (RAG) / Поиск по файлам [необязательно]</h3></p><p>Используйте наш RAG-сервер <code>REI-S</code> для поиска по предоставленным пользователем файлам. Просто настройте расширение <code>Search Files</code> для ассистента.
Этот процесс подробно описан в <a href="services/reis/#example-configuration-in-c4" target="_blank" rel="noopener noreferrer">подкаталоге <code>services/reis</code></a>.</p><h2>Вклад и разработка</h2></p><ul><li>См. <a href="https://raw.githubusercontent.com/codecentric/c4-genai-suite/main/CONTRIBUTING.md" target="_blank" rel="noopener noreferrer">CONTRIBUTING.md</a> для получения рекомендаций по внесению вклада.</li>
<li>Для ознакомления разработчиков смотрите <a href="https://raw.githubusercontent.com/codecentric/c4-genai-suite/main/DEVELOPERS.md" target="_blank" rel="noopener noreferrer">DEVELOPERS.md</a>.</li></p><p></ul><h2>Основные строительные блоки</h2></p><p>Приложение состоит из <strong>Frontend</strong> , <strong>Backend</strong>  и сервиса <strong>REI-S</strong> .</p><pre><code class="language-">┌──────────┐
│  Пользователь  │
└─────┬────┘
      │ доступ
      ▼
┌──────────┐
│  Фронтенд │
└─────┬────┘
      │ доступ
      ▼
┌──────────┐     ┌─────────────────┐
│ Бэкенд   │────►│      LLM        │
└─────┬────┘     └─────────────────┘
      │ доступ
      ▼
┌──────────┐     ┌─────────────────┐
│  REI-S   │────►│ Embedding Model │
│          │     └─────────────────┘
│          │
│          │     ┌─────────────────┐
│          │────►│  Vector Store   │
└──────────┘     └─────────────────┘</code></pre>
<h3>Фронтенд</h3></p><p>Фронтенд построен с использованием React и TypeScript, обеспечивая удобный пользовательский интерфейс для взаимодействия с бекендом и сервисом REI-S. Включает функции управления ассистентами, расширениями и чат-возможностями.</p><blockquote>Источники: <code>/frontend</code></blockquote></p><h3>Бекенд</h3></p><p>Бекенд разработан с использованием NestJS и TypeScript и служит основным API-слоем приложения. Он обрабатывает запросы от фронтенда и взаимодействует с провайдерами LLM для обеспечения чат-функциональности. Бекенд также управляет ассистентами и их расширениями, позволяя пользователям настраивать и использовать различные AI-модели для своих чатов.</p><p>Кроме того, бекенд управляет аутентификацией пользователей и взаимодействует с сервисом REI-S для индексации и получения файлов.</p><p>Для хранения данных бекенд использует базу данных <strong>PostgreSQL</strong>.</p><blockquote>Источники: <code>/backend</code></blockquote></p><h3>REI-S</h3></p><p>REI-S (<strong>R</strong>etrieval <strong>E</strong>xtraction <strong>I</strong>ngestion <strong>S</strong>erver) — сервер на базе Python, обеспечивающий базовые возможности RAG (Retrieval-Augmented Generation). Он позволяет извлекать содержимое файлов, индексировать и выполнять запросы, что позволяет приложению эффективно работать с большими наборами данных. Сервис REI-S спроектирован для бесшовной работы с бекендом, предоставляя необходимые данные для чатов и поиска по файлам.</p><p>REI-S поддерживает Azure AI Search и pgvector для хранения векторов, что обеспечивает гибкие и масштабируемые варианты поиска данных. Сервис можно настроить с помощью переменных окружения для указания типа векторного хранилища и параметров подключения.</p><blockquote>Источники: <code>/services/reis</code></blockquote>

---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-07-09

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/codecentric/c4-genai-suite/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-07-09 
    </div>
    
</body>
</html>