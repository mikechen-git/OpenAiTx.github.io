<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>c4-genai-suite - Korean Documentation</title>
    <meta name="description" content="Read c4-genai-suite documentation in Korean. This project has 123 stars on GitHub.">
    <meta name="keywords" content="c4-genai-suite, Korean, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "c4-genai-suite",
  "description": "Documentation for c4-genai-suite in Korean",
  "author": {
    "@type": "Person",
    "name": "codecentric"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 123
  },
  "url": "https://OpenAiTx.github.io/projects/codecentric/c4-genai-suite/README-ko.html",
  "sameAs": "https://raw.githubusercontent.com/codecentric/c4-genai-suite/main/README.md",
  "datePublished": "2025-07-09",
  "dateModified": "2025-07-09"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            color: #24292e;
            margin-bottom: 8px;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">c4-genai-suite</h1>
            <div class="project-meta">
                <span class="stars">⭐ 123 stars</span>
                <span class="language">Korean</span>
                <span>by codecentric</span>
            </div>
        </div>
        
        <div class="content">
            <h1>c4 GenAI Suite</h1></p><p>Langchain으로 구동되며 모든 주요 대형 언어 모델(LLM) 및 임베딩 모델과 호환되는 Model Context Provider(MCP) 통합 AI 챗봇 애플리케이션입니다.</p><p>관리자는 RAG(검색 증강 생성) 서비스나 MCP 서버와 같은 확장 기능을 추가하여 다양한 기능을 가진 어시스턴트를 생성할 수 있습니다. 이 애플리케이션은 React, NestJS, 그리고 REI-S 서비스를 위한 Python FastAPI 등 최신 기술 스택을 사용하여 구축되었습니다.</p><p>사용자는 사용자 친화적인 인터페이스를 통해 어시스턴트와 상호 작용할 수 있습니다. 어시스턴트의 구성에 따라 사용자는 질문을 하거나, 자신의 파일을 업로드하거나, 기타 기능을 사용할 수 있습니다. 어시스턴트는 구성된 확장 기능을 기반으로 다양한 LLM 공급자와 상호 작용하여 응답을 제공합니다. 구성된 확장 기능이 제공하는 맥락 정보로 인해 어시스턴트는 도메인 특화 질문에 답변하고 관련 정보를 제공할 수 있습니다.</p><p>이 애플리케이션은 모듈식이고 확장 가능하도록 설계되어, 사용자가 확장 기능을 추가하여 다양한 기능을 가진 어시스턴트를 만들 수 있습니다.</p><p><img src="https://raw.githubusercontent.com/codecentric/c4-genai-suite/main/demo/preview.webp" alt="기본 사용법의 짧은 데모 영상"></p><h2>주요 기능</h2></p><h3>대형 언어 모델(LLM) 및 멀티모달 모델</h3></p><p>c4 GenAI Suite는 이미 많은 모델을 직접 지원합니다. 선호하는 모델이 아직 지원되지 않는 경우, 해당 모델을 지원하는 확장 기능을 쉽게 작성할 수 있습니다.</p><ul><li>OpenAI 호환 모델</li>
<li>Azure OpenAI 모델</li>
<li>Bedrock 모델</li>
<li>Google GenAI 모델</li>
<li>Ollama 호환 모델</li>
</ul><h3>검색 증강 생성(RAG)</h3></p><p>c4 GenAI Suite에는 LLM이 파일을 사용할 수 있도록 준비하는 서버인 REI-S가 포함되어 있습니다.</p><ul><li>REI-S, 맞춤형 통합 RAG 서버</li>
  <li>벡터 저장소</li>
    <li>pgvector</li>
    <li>Azure AI Search</li>
  <li>임베딩 모델</li>
    <li>OpenAI 호환 임베딩</li>
    <li>Azure OpenAI 임베딩</li>
    <li>Ollama 호환 임베딩</li>
  <li>파일 형식:</li>
    <li>pdf, docx, pptx, xlsx, ...</li>
    <li>오디오 파일 음성 전사(Whisper 사용)</li></p><p></ul><h3>확장 기능</h3></p><p>c4 GenAI Suite는 확장성을 염두에 두고 설계되었습니다. 확장 프로그램을 작성하는 것도, 이미 존재하는 MCP 서버를 사용하는 것도 쉽습니다.</p><ul><li>모델 컨텍스트 프로토콜(MCP) 서버</li>
<li>맞춤형 systemprompt</li>
<li>Bing 검색</li>
<li>계산기</li>
</ul><h2>시작하기</h2></p><h3>Docker-Compose 사용하기</h3></p><ul><li>프로젝트 루트에서 <code>docker compose up</code>을 실행합니다.</li>
<li>브라우저에서 <a href="http://localhost:3333" target="_blank" rel="noopener noreferrer">애플리케이션</a>을 엽니다. 기본 로그인 자격 증명은 사용자 <code>admin@example.com</code>과 비밀번호 <code>secret</code>입니다.</li></p><p></ul><img src="https://raw.githubusercontent.com/codecentric/c4-genai-suite/main/demo/assistants.webp" alt="assistant 구성 동영상"></p><h3>Helm & Kubernetes 사용하기</h3></p><p>Kubernetes 환경에서 배포하려면 <a href="https://raw.githubusercontent.com/codecentric/c4-genai-suite/main/./helm-chart/README.md" target="_blank" rel="noopener noreferrer">Helm Chart의 README</a>를 참고하세요.</p><h3>어시스턴트 및 확장 기능 설정</h3></p><p>c4 GenAI Suite는 <em>어시스턴트</em>를 중심으로 작동합니다.  
각 어시스턴트는 확장 기능 세트로 구성되며, 이 확장 기능들이 LLM 모델과 사용할 수 있는 도구를 결정합니다.</p><ul><li>관리자 영역(좌측 하단의 사용자명을 클릭)에서 <a href="http://localhost:3333/admin/assistants" target="_blank" rel="noopener noreferrer">어시스턴트 섹션</a>으로 이동합니다.</li>
<li>섹션 제목 옆의 초록색 <code>+</code> 버튼을 눌러 어시스턴트를 추가합니다. 이름과 설명을 입력하세요.</li>
<li>생성한 어시스턴트를 선택하고 초록색 <code>+ 확장 추가</code> 버튼을 클릭합니다.</li>
<li>모델을 선택하고 자격 증명을 입력합니다.</li>
<li><code>테스트</code> 버튼으로 정상 동작 여부를 확인한 후 <code>저장</code>합니다.</li></p><p></ul>이제 <a href="http://localhost:3333/chat" target="_blank" rel="noopener noreferrer">채팅 페이지</a>로 돌아가서(좌측 상단의 <code>c4 GenAI Suite</code> 클릭) 새로운 어시스턴트로 대화를 시작할 수 있습니다.</p><blockquote>[!TIP]</blockquote>
<blockquote>우리의 <code>docker-compose</code>에는 CPU에서 실행되는 로컬 Ollama가 포함되어 있습니다. 빠른 테스트용으로 사용할 수 있습니다. 그러나 속도가 느리기 때문에 다른 모델 사용을 권장합니다. 만약 사용하고 싶다면, 어시스턴트에 다음과 같이 모델 확장 기능을 추가하세요.</blockquote>
<blockquote>* 확장: <code>Dev: Ollama</code></blockquote>
<blockquote>* 엔드포인트: <code>http://ollama:11434</code></blockquote>
<blockquote>* 모델: <code>llama3.2</code></blockquote>
<h3>모델 컨텍스트 프로토콜 (MCP) [선택 사항]</h3></p><p><code>MCP Tools</code> 확장 기능이 포함된 <code>sse</code> 인터페이스를 제공하는 모든 MCP 서버를 사용하세요 (또는 <code>mcp-tool-as-server</code>를 프록시로 하여 <code>stdio</code> MCP 서버 앞에 둘 수도 있습니다).
각 MCP 서버는 확장 기능으로 세부적으로 구성할 수 있습니다.</p><h3>검색 증강 생성(RAG) / 파일 검색 [선택 사항]</h3></p><p>사용자가 제공한 파일을 검색하기 위해 우리의 RAG 서버인 <code>REI-S</code>를 사용하세요. 어시스턴트에 대해 <code>Search Files</code> 확장 기능만 구성하면 됩니다.
이 프로세스는 <a href="services/reis/#example-configuration-in-c4" target="_blank" rel="noopener noreferrer"> <code>services/reis</code> 하위 디렉터리</a>에서 자세히 설명되어 있습니다.</p><h2>기여 및 개발</h2></p><ul><li>기여 방법에 대한 지침은 <a href="https://raw.githubusercontent.com/codecentric/c4-genai-suite/main/CONTRIBUTING.md" target="_blank" rel="noopener noreferrer">CONTRIBUTING.md</a>를 참조하세요.</li>
<li>개발자 온보딩을 위해서는 <a href="https://raw.githubusercontent.com/codecentric/c4-genai-suite/main/DEVELOPERS.md" target="_blank" rel="noopener noreferrer">DEVELOPERS.md</a>를 확인하세요.</li></p><p></ul><h2>주요 구성 요소</h2></p><p>이 애플리케이션은 <strong>프론트엔드</strong>, <strong>백엔드</strong>, 그리고 <strong>REI-S</strong> 서비스로 구성되어 있습니다.</p><pre><code class="language-">┌──────────┐
│   사용자   │
└─────┬────┘
      │ 접근
      ▼
┌──────────┐
│ 프론트엔드 │
└─────┬────┘
      │ 접근
      ▼
┌──────────┐     ┌─────────────────┐
│ 백엔드   │────►│      LLM        │
└─────┬────┘     └─────────────────┘
      │ 접근
      ▼
┌──────────┐     ┌─────────────────┐
│  REI-S   │────►│ 임베딩 모델     │
│          │     └─────────────────┘
│          │
│          │     ┌─────────────────┐
│          │────►│ 벡터 스토어     │
└──────────┘     └─────────────────┘</code></pre>
<h3>프론트엔드</h3></p><p>프론트엔드는 React와 TypeScript로 구축되어, 백엔드 및 REI-S 서비스와 상호작용할 수 있는 사용자 친화적인 인터페이스를 제공합니다. 이 인터페이스는 어시스턴트, 확장 기능, 채팅 기능 관리를 위한 다양한 기능을 포함하고 있습니다.</p><blockquote>소스: <code>/frontend</code></blockquote></p><h3>백엔드</h3></p><p>백엔드는 NestJS와 TypeScript를 사용하여 개발되었으며, 애플리케이션의 주요 API 계층 역할을 합니다. 프론트엔드에서 오는 요청을 처리하고, llm 공급자와 상호작용하여 채팅 기능을 지원합니다. 또한 백엔드는 어시스턴트 및 그 확장 기능을 관리하며, 사용자가 다양한 AI 모델을 구성하고 채팅에 사용할 수 있도록 지원합니다.</p><p>추가로, 백엔드는 사용자 인증을 관리하고, 파일 인덱싱 및 검색을 위해 REI-S 서비스와 통신합니다.</p><p>데이터 영속성을 위해 백엔드는 <strong>PostgreSQL</strong> 데이터베이스를 사용합니다.</p><blockquote>소스: <code>/backend</code></blockquote></p><h3>REI-S</h3></p><p>REI-S(<strong>R</strong>etrieval <strong>E</strong>xtraction <strong>I</strong>ngestion <strong>S</strong>erver)는 Python 기반의 서버로, 기본적인 RAG(Retrieval-Augmented Generation) 기능을 제공합니다. 이 서버는 파일 콘텐츠 추출, 인덱싱, 쿼리 기능을 제공하여 애플리케이션이 대용량 데이터셋을 효율적으로 처리할 수 있도록 지원합니다. REI-S 서비스는 백엔드와 원활하게 연동되도록 설계되어, 채팅 기능 및 파일 검색에 필요한 데이터를 제공합니다.</p><p>REI-S는 벡터 저장소로 Azure AI Search와 pgvector를 지원하여, 유연하고 확장 가능한 데이터 검색 옵션을 제공합니다. 서비스는 환경 변수를 통해 벡터 저장소 유형 및 연결 정보를 지정하여 구성할 수 있습니다.</p><blockquote>소스: <code>/services/reis</code></blockquote>

---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-07-09

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/codecentric/c4-genai-suite/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-07-09 
    </div>
    
</body>
</html>